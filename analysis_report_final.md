# Dynamic Analysis of Scientific Literature (Using Pre-defined Optimal Parameters)

# Analysis for Window: 2012-2014
**Stats:** Papers: 71, Edges: 207
**Final DBCV Score:** 0.7712
**Parameters Used:** `n_neighbors`: 25, `min_cluster_size`: 15, `min_samples`: 5, `epsilon`: 0.0

### Dominant Topics

- **Topic (ID: 1, Size: 36, Confidence: 0.8331):** word, representations, language, neural, networks, translation, modeling, distributed, linguistic, embeddings, space, based, models, machine, 2012
- **Topic (ID: 0, Size: 18, Confidence: 0.9944):** neural, networks, recurrent, translation, sequence, models, machine, continuous, recognition, learning, deep, speech, statistical, space, modeling

### Top 20 Papers by Citation Count

- (Citation Count: 149584.0000) Adam: A Method for Stochastic Optimization
- (Citation Count: 119504.0000) ImageNet classification with deep convolutional neural networks
- (Citation Count: 39709.0000) Dropout: a simple way to prevent neural networks from overfitting
- (Citation Count: 33467.0000) Distributed Representations of Words and Phrases and their Compositionality
- (Citation Count: 32016.0000) GloVe: Global Vectors for Word Representation
- (Citation Count: 31416.0000) Efficient Estimation of Word Representations in Vector Space
- (Citation Count: 27210.0000) Neural Machine Translation by Jointly Learning to Align and Translate
- (Citation Count: 23254.0000) Learning Phrase Representations using RNN Encoder–Decoder for Statistical M...
- (Citation Count: 20484.0000) Sequence to Sequence Learning with Neural Networks
- (Citation Count: 12647.0000) Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modelin...
- (Citation Count: 9231.0000) Distributed Representations of Sentences and Documents
- (Citation Count: 8448.0000) Recursive Deep Models for Semantic Compositionality Over a Sentiment Treeba...
- (Citation Count: 8313.0000) How transferable are features in deep neural networks?
- (Citation Count: 7335.0000) The Stanford CoreNLP Natural Language Processing Toolkit
- (Citation Count: 6760.0000) On the Properties of Neural Machine Translation: Encoder–Decoder Approaches
- (Citation Count: 6620.0000) ADADELTA: An Adaptive Learning Rate Method
- (Citation Count: 6177.0000) DeepFace: Closing the Gap to Human-Level Performance in Face Verification
- (Citation Count: 6012.0000) Show and tell: A neural image caption generator
- (Citation Count: 5322.0000) On the difficulty of training recurrent neural networks
- (Citation Count: 4026.0000) Generating Sequences With Recurrent Neural Networks

### Top 20 Papers by PageRank

- (PageRank: 0.0556) Statistical Language Models Based on Neural Networks
- (PageRank: 0.0464) ImageNet classification with deep convolutional neural networks
- (PageRank: 0.0445) Efficient Estimation of Word Representations in Vector Space
- (PageRank: 0.0410) Improving Word Representations via Global Context and Multiple Word Prototy...
- (PageRank: 0.0327) Linguistic Regularities in Continuous Space Word Representations
- (PageRank: 0.0248) Large Scale Distributed Deep Networks
- (PageRank: 0.0215) Bilingual Word Embeddings for Phrase-Based Machine Translation
- (PageRank: 0.0210) Continuous Space Translation Models for Phrase-Based Statistical Machine Tr...
- (PageRank: 0.0209) Continuous Space Translation Models with Neural Networks
- (PageRank: 0.0206) A fast and simple algorithm for training neural probabilistic language mode...
- (PageRank: 0.0197) Distributed Representations of Words and Phrases and their Compositionality
- (PageRank: 0.0192) Recursive Deep Models for Semantic Compositionality Over a Sentiment Treeba...
- (PageRank: 0.0179) Generating Sequences With Recurrent Neural Networks
- (PageRank: 0.0179) Theano: new features and speed improvements
- (PageRank: 0.0176) Learning Phrase Representations using RNN Encoder–Decoder for Statistical M...
- (PageRank: 0.0175) On the difficulty of training recurrent neural networks
- (PageRank: 0.0170) Maxout Networks
- (PageRank: 0.0165) Sequence to Sequence Learning with Neural Networks
- (PageRank: 0.0159) Recurrent Continuous Translation Models
- (PageRank: 0.0151) CoNLL-2012 Shared Task: Modeling Multilingual Unrestricted Coreference in O...

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.1311) Efficient Estimation of Word Representations in Vector Space
- (HITS Authority: 0.0882) Linguistic Regularities in Continuous Space Word Representations
- (HITS Authority: 0.0814) Distributed Representations of Words and Phrases and their Compositionality
- (HITS Authority: 0.0498) Learning Phrase Representations using RNN Encoder–Decoder for Statistical M...
- (HITS Authority: 0.0479) Sequence to Sequence Learning with Neural Networks
- (HITS Authority: 0.0450) Recurrent Continuous Translation Models
- (HITS Authority: 0.0446) Generating Sequences With Recurrent Neural Networks
- (HITS Authority: 0.0364) Bilingual Word Embeddings for Phrase-Based Machine Translation
- (HITS Authority: 0.0342) On the difficulty of training recurrent neural networks
- (HITS Authority: 0.0300) Statistical Language Models Based on Neural Networks
- (HITS Authority: 0.0248) On the Properties of Neural Machine Translation: Encoder–Decoder Approaches
- (HITS Authority: 0.0246) Improving Word Representations via Global Context and Multiple Word Prototy...
- (HITS Authority: 0.0245) Neural Machine Translation by Jointly Learning to Align and Translate
- (HITS Authority: 0.0209) Deep Neural Networks for Acoustic Modeling in Speech Recognition
- (HITS Authority: 0.0193) Audio Chord Recognition with Recurrent Neural Networks
- (HITS Authority: 0.0190) Maxout Networks
- (HITS Authority: 0.0181) Multilingual Distributed Representations without Word Alignment
- (HITS Authority: 0.0154) Sequence Transduction with Recurrent Neural Networks
- (HITS Authority: 0.0150) Combining Heterogeneous Models for Measuring Relational Similarity
- (HITS Authority: 0.0146) Continuous Space Translation Models for Phrase-Based Statistical Machine Tr...


# Analysis for Window: 2013-2015
**Stats:** Papers: 71, Edges: 240
**Final DBCV Score:** 0.0000
**Parameters Used:** `n_neighbors`: 10, `min_cluster_size`: 15, `min_samples`: 5, `epsilon`: 0.5

### Dominant Topics


### Top 20 Papers by Citation Count

- (Citation Count: 192834.0000) Deep Residual Learning for Image Recognition
- (Citation Count: 149584.0000) Adam: A Method for Stochastic Optimization
- (Citation Count: 39709.0000) Dropout: a simple way to prevent neural networks from overfitting
- (Citation Count: 33467.0000) Distributed Representations of Words and Phrases and their Compositionality
- (Citation Count: 32016.0000) GloVe: Global Vectors for Word Representation
- (Citation Count: 31416.0000) Efficient Estimation of Word Representations in Vector Space
- (Citation Count: 27242.0000) Rethinking the Inception Architecture for Computer Vision
- (Citation Count: 27210.0000) Neural Machine Translation by Jointly Learning to Align and Translate
- (Citation Count: 23254.0000) Learning Phrase Representations using RNN Encoder–Decoder for Statistical M...
- (Citation Count: 20484.0000) Sequence to Sequence Learning with Neural Networks
- (Citation Count: 19498.0000) Distilling the Knowledge in a Neural Network
- (Citation Count: 12647.0000) Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modelin...
- (Citation Count: 9231.0000) Distributed Representations of Sentences and Documents
- (Citation Count: 8448.0000) Recursive Deep Models for Semantic Compositionality Over a Sentiment Treeba...
- (Citation Count: 8313.0000) How transferable are features in deep neural networks?
- (Citation Count: 7948.0000) Effective Approaches to Attention-based Neural Machine Translation
- (Citation Count: 7701.0000) Neural Machine Translation of Rare Words with Subword Units
- (Citation Count: 7335.0000) The Stanford CoreNLP Natural Language Processing Toolkit
- (Citation Count: 6760.0000) On the Properties of Neural Machine Translation: Encoder–Decoder Approaches
- (Citation Count: 6177.0000) DeepFace: Closing the Gap to Human-Level Performance in Face Verification

### Top 20 Papers by PageRank

- (PageRank: 0.0881) Efficient Estimation of Word Representations in Vector Space
- (PageRank: 0.0824) Linguistic Regularities in Continuous Space Word Representations
- (PageRank: 0.0364) Learning Phrase Representations using RNN Encoder–Decoder for Statistical M...
- (PageRank: 0.0361) Generating Sequences With Recurrent Neural Networks
- (PageRank: 0.0353) Distributed Representations of Words and Phrases and their Compositionality
- (PageRank: 0.0352) Maxout Networks
- (PageRank: 0.0309) Sequence to Sequence Learning with Neural Networks
- (PageRank: 0.0287) Recurrent Continuous Translation Models
- (PageRank: 0.0276) Combining Heterogeneous Models for Measuring Relational Similarity
- (PageRank: 0.0264) Neural Machine Translation by Jointly Learning to Align and Translate
- (PageRank: 0.0252) Bilingual Word Embeddings for Phrase-Based Machine Translation
- (PageRank: 0.0237) Recursive Deep Models for Semantic Compositionality Over a Sentiment Treeba...
- (PageRank: 0.0187) Learning Semantic Representations for the Phrase Translation Model
- (PageRank: 0.0162) Joint Language and Translation Modeling with Recurrent Neural Networks
- (PageRank: 0.0146) Dropout: a simple way to prevent neural networks from overfitting
- (PageRank: 0.0145) On the Properties of Neural Machine Translation: Encoder–Decoder Approaches
- (PageRank: 0.0127) Exact solutions to the nonlinear dynamics of learning in deep linear neural...
- (PageRank: 0.0120) Skip-Thought Vectors
- (PageRank: 0.0119) Multilingual Distributed Representations without Word Alignment
- (PageRank: 0.0117) Show and tell: A neural image caption generator

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.1238) Learning Phrase Representations using RNN Encoder–Decoder for Statistical M...
- (HITS Authority: 0.1139) Sequence to Sequence Learning with Neural Networks
- (HITS Authority: 0.0821) Recurrent Continuous Translation Models
- (HITS Authority: 0.0770) Neural Machine Translation by Jointly Learning to Align and Translate
- (HITS Authority: 0.0720) Efficient Estimation of Word Representations in Vector Space
- (HITS Authority: 0.0481) Generating Sequences With Recurrent Neural Networks
- (HITS Authority: 0.0442) On the Properties of Neural Machine Translation: Encoder–Decoder Approaches
- (HITS Authority: 0.0327) Distributed Representations of Words and Phrases and their Compositionality
- (HITS Authority: 0.0324) Linguistic Regularities in Continuous Space Word Representations
- (HITS Authority: 0.0261) Audio Chord Recognition with Recurrent Neural Networks
- (HITS Authority: 0.0256) Recursive Deep Models for Semantic Compositionality Over a Sentiment Treeba...
- (HITS Authority: 0.0243) Skip-Thought Vectors
- (HITS Authority: 0.0230) Show and tell: A neural image caption generator
- (HITS Authority: 0.0215) Multilingual Distributed Representations without Word Alignment
- (HITS Authority: 0.0195) Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modelin...
- (HITS Authority: 0.0182) GloVe: Global Vectors for Word Representation
- (HITS Authority: 0.0159) A Neural Network for Factoid Question Answering over Paragraphs
- (HITS Authority: 0.0157) Grammar as a Foreign Language
- (HITS Authority: 0.0154) Adam: A Method for Stochastic Optimization
- (HITS Authority: 0.0141) Fast and Accurate Shift-Reduce Constituent Parsing


# Analysis for Window: 2014-2016
**Stats:** Papers: 80, Edges: 303
**Final DBCV Score:** 0.6264
**Parameters Used:** `n_neighbors`: 25, `min_cluster_size`: 15, `min_samples`: 5, `epsilon`: 0.0

### Dominant Topics

- **Topic (ID: 1, Size: 49, Confidence: 0.9950):** learning, neural, language, word, machine, end, translation, networks, models, lstm, representations, vectors, network, sentences, sequence
- **Topic (ID: 0, Size: 20, Confidence: 1.0000):** neural, networks, sequence, deep, learning, machine, translation, recurrent, time, empirical, network, dropout, training, encoder, decoder

### Top 20 Papers by Citation Count

- (Citation Count: 192834.0000) Deep Residual Learning for Image Recognition
- (Citation Count: 149584.0000) Adam: A Method for Stochastic Optimization
- (Citation Count: 39709.0000) Dropout: a simple way to prevent neural networks from overfitting
- (Citation Count: 32016.0000) GloVe: Global Vectors for Word Representation
- (Citation Count: 27242.0000) Rethinking the Inception Architecture for Computer Vision
- (Citation Count: 27210.0000) Neural Machine Translation by Jointly Learning to Align and Translate
- (Citation Count: 23254.0000) Learning Phrase Representations using RNN Encoder–Decoder for Statistical M...
- (Citation Count: 20484.0000) Sequence to Sequence Learning with Neural Networks
- (Citation Count: 19498.0000) Distilling the Knowledge in a Neural Network
- (Citation Count: 14474.0000) Xception: Deep Learning with Depthwise Separable Convolutions
- (Citation Count: 12647.0000) Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modelin...
- (Citation Count: 10421.0000) Layer Normalization
- (Citation Count: 9944.0000) Enriching Word Vectors with Subword Information
- (Citation Count: 9231.0000) Distributed Representations of Sentences and Documents
- (Citation Count: 8313.0000) How transferable are features in deep neural networks?
- (Citation Count: 8081.0000) SQuAD: 100,000+ Questions for Machine Comprehension of Text
- (Citation Count: 7948.0000) Effective Approaches to Attention-based Neural Machine Translation
- (Citation Count: 7701.0000) Neural Machine Translation of Rare Words with Subword Units
- (Citation Count: 7335.0000) The Stanford CoreNLP Natural Language Processing Toolkit
- (Citation Count: 7295.0000) Matching Networks for One Shot Learning

### Top 20 Papers by PageRank

- (PageRank: 0.0992) Learning Phrase Representations using RNN Encoder–Decoder for Statistical M...
- (PageRank: 0.0742) Sequence to Sequence Learning with Neural Networks
- (PageRank: 0.0683) An Autoencoder Approach to Learning Bilingual Word Representations
- (PageRank: 0.0549) Neural Machine Translation by Jointly Learning to Align and Translate
- (PageRank: 0.0389) Fast and Robust Neural Network Joint Models for Statistical Machine Transla...
- (PageRank: 0.0309) On the Properties of Neural Machine Translation: Encoder–Decoder Approaches
- (PageRank: 0.0295) Don’t count, predict! A systematic comparison of context-counting vs. conte...
- (PageRank: 0.0241) Dropout: a simple way to prevent neural networks from overfitting
- (PageRank: 0.0230) Distributed Representations of Sentences and Documents
- (PageRank: 0.0224) Adam: A Method for Stochastic Optimization
- (PageRank: 0.0218) GloVe: Global Vectors for Word Representation
- (PageRank: 0.0186) Overcoming the Curse of Sentence Length for Neural Machine Translation usin...
- (PageRank: 0.0170) Skip-Thought Vectors
- (PageRank: 0.0162) Training Very Deep Networks
- (PageRank: 0.0157) Finding Function in Form: Compositional Character Models for Open Vocabular...
- (PageRank: 0.0143) Linguistic Regularities in Sparse and Explicit Word Representations
- (PageRank: 0.0142) Grammar as a Foreign Language
- (PageRank: 0.0126) Show and tell: A neural image caption generator
- (PageRank: 0.0120) Character-Aware Neural Language Models
- (PageRank: 0.0112) Multi-task Sequence to Sequence Learning

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.1672) Sequence to Sequence Learning with Neural Networks
- (HITS Authority: 0.1540) Neural Machine Translation by Jointly Learning to Align and Translate
- (HITS Authority: 0.1421) Learning Phrase Representations using RNN Encoder–Decoder for Statistical M...
- (HITS Authority: 0.0518) Adam: A Method for Stochastic Optimization
- (HITS Authority: 0.0375) On the Properties of Neural Machine Translation: Encoder–Decoder Approaches
- (HITS Authority: 0.0373) Skip-Thought Vectors
- (HITS Authority: 0.0341) Grammar as a Foreign Language
- (HITS Authority: 0.0298) Effective Approaches to Attention-based Neural Machine Translation
- (HITS Authority: 0.0285) Deep Residual Learning for Image Recognition
- (HITS Authority: 0.0241) Show and tell: A neural image caption generator
- (HITS Authority: 0.0232) GloVe: Global Vectors for Word Representation
- (HITS Authority: 0.0196) Edinburgh’s Phrase-based Machine Translation Systems for WMT-14
- (HITS Authority: 0.0191) Google's Neural Machine Translation System: Bridging the Gap between Human ...
- (HITS Authority: 0.0169) Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modelin...
- (HITS Authority: 0.0167) Neural GPUs Learn Algorithms
- (HITS Authority: 0.0151) Deep Recurrent Models with Fast-Forward Connections for Neural Machine Tran...
- (HITS Authority: 0.0132) Dropout: a simple way to prevent neural networks from overfitting
- (HITS Authority: 0.0120) A Neural Network for Factoid Question Answering over Paragraphs
- (HITS Authority: 0.0117) Distributed Representations of Sentences and Documents
- (HITS Authority: 0.0114) A large annotated corpus for learning natural language inference


# Analysis for Window: 2015-2017
**Stats:** Papers: 94, Edges: 319
**Final DBCV Score:** 0.7537
**Parameters Used:** `n_neighbors`: 10, `min_cluster_size`: 15, `min_samples`: 5, `epsilon`: 0.0

### Dominant Topics

- **Topic (ID: 1, Size: 36, Confidence: 0.7669):** learning, neural, networks, end, machine, deep, attention, translation, language, model, sequence, memory, natural, shot, structured
- **Topic (ID: 2, Size: 22, Confidence: 0.8845):** neural, models, word, learning, language, disambiguation, sense, evaluation, character, coreference, embedding, bidirectional, vectors, sequence, end
- **Topic (ID: 0, Size: 16, Confidence: 0.9980):** comprehension, reading, machine, language, natural, inference, question, large, networks, learning, attention, answering, scale, dataset, visual

### Top 20 Papers by Citation Count

- (Citation Count: 192834.0000) Deep Residual Learning for Image Recognition
- (Citation Count: 130102.0000) Attention is All you Need
- (Citation Count: 27242.0000) Rethinking the Inception Architecture for Computer Vision
- (Citation Count: 22656.0000) Decoupled Weight Decay Regularization
- (Citation Count: 19498.0000) Distilling the Knowledge in a Neural Network
- (Citation Count: 14474.0000) Xception: Deep Learning with Depthwise Separable Convolutions
- (Citation Count: 11810.0000) Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks
- (Citation Count: 10421.0000) Layer Normalization
- (Citation Count: 9944.0000) Enriching Word Vectors with Subword Information
- (Citation Count: 8081.0000) SQuAD: 100,000+ Questions for Machine Comprehension of Text
- (Citation Count: 7948.0000) Effective Approaches to Attention-based Neural Machine Translation
- (Citation Count: 7701.0000) Neural Machine Translation of Rare Words with Subword Units
- (Citation Count: 7295.0000) Matching Networks for One Shot Learning
- (Citation Count: 6772.0000) Google's Neural Machine Translation System: Bridging the Gap between Human ...
- (Citation Count: 5436.0000) VQA: Visual Question Answering
- (Citation Count: 4452.0000) A Broad-Coverage Challenge Corpus for Sentence Understanding through Infere...
- (Citation Count: 4264.0000) A large annotated corpus for learning natural language inference
- (Citation Count: 4005.0000) Neural Architectures for Named Entity Recognition
- (Citation Count: 3394.0000) Optimization as a Model for Few-Shot Learning
- (Citation Count: 3279.0000) Convolutional Sequence to Sequence Learning

### Top 20 Papers by PageRank

- (PageRank: 0.1563) Skip-Thought Vectors
- (PageRank: 0.1392) Aligning Books and Movies: Towards Story-Like Visual Explanations by Watchi...
- (PageRank: 0.0340) Training Very Deep Networks
- (PageRank: 0.0264) Finding Function in Form: Compositional Character Models for Open Vocabular...
- (PageRank: 0.0216) Effective Approaches to Attention-based Neural Machine Translation
- (PageRank: 0.0214) A large annotated corpus for learning natural language inference
- (PageRank: 0.0187) SQuAD: 100,000+ Questions for Machine Comprehension of Text
- (PageRank: 0.0185) Character-Aware Neural Language Models
- (PageRank: 0.0175) Deep Residual Learning for Image Recognition
- (PageRank: 0.0158) End-To-End Memory Networks
- (PageRank: 0.0152) Neural GPUs Learn Algorithms
- (PageRank: 0.0151) Long Short-Term Memory-Networks for Machine Reading
- (PageRank: 0.0144) Neural Machine Translation of Rare Words with Subword Units
- (PageRank: 0.0131) End-to-end learning of semantic role labeling using recurrent neural networ...
- (PageRank: 0.0123) Multi-task Sequence to Sequence Learning
- (PageRank: 0.0120) A Theoretically Grounded Application of Dropout in Recurrent Neural Network...
- (PageRank: 0.0120) Rethinking the Inception Architecture for Computer Vision
- (PageRank: 0.0113) Google's Neural Machine Translation System: Bridging the Gap between Human ...
- (PageRank: 0.0105) Bidirectional Attention Flow for Machine Comprehension
- (PageRank: 0.0105) A Decomposable Attention Model for Natural Language Inference

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.0977) Google's Neural Machine Translation System: Bridging the Gap between Human ...
- (HITS Authority: 0.0781) Effective Approaches to Attention-based Neural Machine Translation
- (HITS Authority: 0.0769) Deep Residual Learning for Image Recognition
- (HITS Authority: 0.0624) Deep Recurrent Models with Fast-Forward Connections for Neural Machine Tran...
- (HITS Authority: 0.0531) A large annotated corpus for learning natural language inference
- (HITS Authority: 0.0523) Skip-Thought Vectors
- (HITS Authority: 0.0450) Neural Machine Translation of Rare Words with Subword Units
- (HITS Authority: 0.0336) Exploring the Limits of Language Modeling
- (HITS Authority: 0.0306) End-To-End Memory Networks
- (HITS Authority: 0.0264) SQuAD: 100,000+ Questions for Machine Comprehension of Text
- (HITS Authority: 0.0260) Neural Machine Translation in Linear Time
- (HITS Authority: 0.0246) Character-Aware Neural Language Models
- (HITS Authority: 0.0244) A Decomposable Attention Model for Natural Language Inference
- (HITS Authority: 0.0241) Bidirectional Attention Flow for Machine Comprehension
- (HITS Authority: 0.0210) End-to-end learning of semantic role labeling using recurrent neural networ...
- (HITS Authority: 0.0198) Attention is All you Need
- (HITS Authority: 0.0197) Learning Distributed Representations of Sentences from Unlabelled Data
- (HITS Authority: 0.0173) Layer Normalization
- (HITS Authority: 0.0155) Long Short-Term Memory-Networks for Machine Reading
- (HITS Authority: 0.0150) Convolutional Sequence to Sequence Learning


# Analysis for Window: 2016-2018
**Stats:** Papers: 1812, Edges: 1221
**Final DBCV Score:** 0.6370
**Parameters Used:** `n_neighbors`: 35, `min_cluster_size`: 25, `min_samples`: 15, `epsilon`: 0.0

### Dominant Topics

- **Topic (ID: 1, Size: 695, Confidence: 0.9743):** language, learning, natural, neural, processing, deep, text, using, based, networks, machine, word, data, analysis, network
- **Topic (ID: 0, Size: 25, Confidence: 1.0000):** comprehension, question, reading, answering, machine, inference, language, natural, attention, challenge, networks, learning, dataset, multi, scale

### Top 20 Papers by Citation Count

- (Citation Count: 130102.0000) Attention is All you Need
- (Citation Count: 22656.0000) Decoupled Weight Decay Regularization
- (Citation Count: 14474.0000) Xception: Deep Learning with Depthwise Separable Convolutions
- (Citation Count: 11860.0000) Improving Language Understanding by Generative Pre-Training
- (Citation Count: 11810.0000) Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks
- (Citation Count: 11526.0000) Deep Contextualized Word Representations
- (Citation Count: 10421.0000) Layer Normalization
- (Citation Count: 9944.0000) Enriching Word Vectors with Subword Information
- (Citation Count: 8081.0000) SQuAD: 100,000+ Questions for Machine Comprehension of Text
- (Citation Count: 7295.0000) Matching Networks for One Shot Learning
- (Citation Count: 7103.0000) GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Und...
- (Citation Count: 6772.0000) Google's Neural Machine Translation System: Bridging the Gap between Human ...
- (Citation Count: 4452.0000) A Broad-Coverage Challenge Corpus for Sentence Understanding through Infere...
- (Citation Count: 4005.0000) Neural Architectures for Named Entity Recognition
- (Citation Count: 3628.0000) Universal Language Model Fine-tuning for Text Classification
- (Citation Count: 3499.0000) SentencePiece: A simple and language independent subword tokenizer and deto...
- (Citation Count: 3394.0000) Optimization as a Model for Few-Shot Learning
- (Citation Count: 3279.0000) Convolutional Sequence to Sequence Learning
- (Citation Count: 2958.0000) A Call for Clarity in Reporting BLEU Scores
- (Citation Count: 2954.0000) Domain randomization for transferring deep neural networks from simulation ...

### Top 20 Papers by PageRank

- (PageRank: 0.0150) Enriching Word Vectors with Subword Information
- (PageRank: 0.0146) Charagram: Embedding Words and Sentences via Character n-grams
- (PageRank: 0.0142) Neural Architectures for Named Entity Recognition
- (PageRank: 0.0126) Learning Distributed Representations of Sentences from Unlabelled Data
- (PageRank: 0.0122) Deep Recurrent Models with Fast-Forward Connections for Neural Machine Tran...
- (PageRank: 0.0113) Exploring the Limits of Language Modeling
- (PageRank: 0.0105) SQuAD: 100,000+ Questions for Machine Comprehension of Text
- (PageRank: 0.0104) Google's Neural Machine Translation System: Bridging the Gap between Human ...
- (PageRank: 0.0091) Attention is All you Need
- (PageRank: 0.0088) Long Short-Term Memory-Networks for Machine Reading
- (PageRank: 0.0061) Supervised Learning of Universal Sentence Representations from Natural Lang...
- (PageRank: 0.0060) Bidirectional Attention Flow for Machine Comprehension
- (PageRank: 0.0057) End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF
- (PageRank: 0.0056) A Decomposable Attention Model for Natural Language Inference
- (PageRank: 0.0054) Deep Contextualized Word Representations
- (PageRank: 0.0036) Convolutional Sequence to Sequence Learning
- (PageRank: 0.0034) A Broad-Coverage Challenge Corpus for Sentence Understanding through Infere...
- (PageRank: 0.0033) Learning Global Features for Coreference Resolution
- (PageRank: 0.0031) Neural Machine Translation in Linear Time
- (PageRank: 0.0031) Layer Normalization

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.0774) Deep Contextualized Word Representations
- (HITS Authority: 0.0683) Attention is All you Need
- (HITS Authority: 0.0613) Bidirectional Attention Flow for Machine Comprehension
- (HITS Authority: 0.0545) SQuAD: 100,000+ Questions for Machine Comprehension of Text
- (HITS Authority: 0.0440) Learned in Translation: Contextualized Word Vectors
- (HITS Authority: 0.0438) Supervised Learning of Universal Sentence Representations from Natural Lang...
- (HITS Authority: 0.0312) A Broad-Coverage Challenge Corpus for Sentence Understanding through Infere...
- (HITS Authority: 0.0271) Enhanced LSTM for Natural Language Inference
- (HITS Authority: 0.0263) TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading ...
- (HITS Authority: 0.0228) A Decomposable Attention Model for Natural Language Inference
- (HITS Authority: 0.0219) Neural Architectures for Named Entity Recognition
- (HITS Authority: 0.0196) Google's Neural Machine Translation System: Bridging the Gap between Human ...
- (HITS Authority: 0.0187) Convolutional Sequence to Sequence Learning
- (HITS Authority: 0.0181) Semi-supervised sequence tagging with bidirectional language models
- (HITS Authority: 0.0173) A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks
- (HITS Authority: 0.0170) Gated Self-Matching Networks for Reading Comprehension and Question Answeri...
- (HITS Authority: 0.0152) Enriching Word Vectors with Subword Information
- (HITS Authority: 0.0151) Deep Semantic Role Labeling: What Works and What’s Next
- (HITS Authority: 0.0151) Stochastic Answer Networks for Machine Reading Comprehension
- (HITS Authority: 0.0145) Learning Distributed Representations of Sentences from Unlabelled Data


# Analysis for Window: 2017-2019
**Stats:** Papers: 3646, Edges: 3818
**Final DBCV Score:** 0.2717
**Parameters Used:** `n_neighbors`: 10, `min_cluster_size`: 35, `min_samples`: 15, `epsilon`: 0.0

### Dominant Topics

- **Topic (ID: 2, Size: 1541, Confidence: 0.9971):** language, learning, natural, processing, deep, neural, using, text, based, analysis, word, machine, networks, sentiment, model
- **Topic (ID: 0, Size: 281, Confidence: 0.9993):** language, processing, natural, learning, clinical, using, deep, based, health, machine, data, medical, biomedical, text, electronic
- **Topic (ID: 1, Size: 49, Confidence: 0.9514):** adversarial, language, neural, natural, networks, deep, text, examples, training, attacks, classification, survey, machine, network, generative

### Top 20 Papers by Citation Count

- (Citation Count: 130102.0000) Attention is All you Need
- (Citation Count: 94099.0000) BERT: Pre-training of Deep Bidirectional Transformers for Language Understa...
- (Citation Count: 24213.0000) RoBERTa: A Robustly Optimized BERT Pretraining Approach
- (Citation Count: 22682.0000) Language Models are Unsupervised Multitask Learners
- (Citation Count: 22656.0000) Decoupled Weight Decay Regularization
- (Citation Count: 19888.0000) Exploring the Limits of Transfer Learning with a Unified Text-to-Text Trans...
- (Citation Count: 11860.0000) Improving Language Understanding by Generative Pre-Training
- (Citation Count: 11810.0000) Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks
- (Citation Count: 11526.0000) Deep Contextualized Word Representations
- (Citation Count: 10743.0000) BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Gene...
- (Citation Count: 8395.0000) XLNet: Generalized Autoregressive Pretraining for Language Understanding
- (Citation Count: 7422.0000) DistilBERT, a distilled version of BERT: smaller, faster, cheaper and light...
- (Citation Count: 7103.0000) GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Und...
- (Citation Count: 6424.0000) ALBERT: A Lite BERT for Self-supervised Learning of Language Representation...
- (Citation Count: 5602.0000) BioBERT: a pre-trained biomedical language representation model for biomedi...
- (Citation Count: 4452.0000) A Broad-Coverage Challenge Corpus for Sentence Understanding through Infere...
- (Citation Count: 3715.0000) Transformer-XL: Attentive Language Models beyond a Fixed-Length Context
- (Citation Count: 3664.0000) ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Visi...
- (Citation Count: 3628.0000) Universal Language Model Fine-tuning for Text Classification
- (Citation Count: 3499.0000) SentencePiece: A simple and language independent subword tokenizer and deto...

### Top 20 Papers by PageRank

- (PageRank: 0.0233) Attention is All you Need
- (PageRank: 0.0181) Supervised Learning of Universal Sentence Representations from Natural Lang...
- (PageRank: 0.0164) TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading ...
- (PageRank: 0.0152) BERT: Pre-training of Deep Bidirectional Transformers for Language Understa...
- (PageRank: 0.0148) Deep Contextualized Word Representations
- (PageRank: 0.0146) RACE: Large-scale ReAding Comprehension Dataset From Examinations
- (PageRank: 0.0136) A Structured Self-attentive Sentence Embedding
- (PageRank: 0.0095) A Broad-Coverage Challenge Corpus for Sentence Understanding through Infere...
- (PageRank: 0.0081) Neural Sequence Learning Models for Word Sense Disambiguation
- (PageRank: 0.0079) Word Sense Disambiguation: A Unified Evaluation Framework and Empirical Com...
- (PageRank: 0.0057) Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts L...
- (PageRank: 0.0052) Learned in Translation: Contextualized Word Vectors
- (PageRank: 0.0051) Convolutional Sequence to Sequence Learning
- (PageRank: 0.0046) Semi-supervised sequence tagging with bidirectional language models
- (PageRank: 0.0042) Gated Self-Matching Networks for Reading Comprehension and Question Answeri...
- (PageRank: 0.0042) Deep Semantic Role Labeling: What Works and What’s Next
- (PageRank: 0.0041) Recent Trends in Deep Learning Based Natural Language Processing
- (PageRank: 0.0036) On the State of the Art of Evaluation in Neural Language Models
- (PageRank: 0.0035) Improving Language Understanding by Generative Pre-Training
- (PageRank: 0.0032) End-to-end Neural Coreference Resolution

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.1405) BERT: Pre-training of Deep Bidirectional Transformers for Language Understa...
- (HITS Authority: 0.0985) Attention is All you Need
- (HITS Authority: 0.0863) Deep Contextualized Word Representations
- (HITS Authority: 0.0557) Improving Language Understanding by Generative Pre-Training
- (HITS Authority: 0.0319) GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Und...
- (HITS Authority: 0.0312) Language Models are Unsupervised Multitask Learners
- (HITS Authority: 0.0302) XLNet: Generalized Autoregressive Pretraining for Language Understanding
- (HITS Authority: 0.0266) Universal Language Model Fine-tuning for Text Classification
- (HITS Authority: 0.0245) RoBERTa: A Robustly Optimized BERT Pretraining Approach
- (HITS Authority: 0.0213) A Broad-Coverage Challenge Corpus for Sentence Understanding through Infere...
- (HITS Authority: 0.0184) Cross-lingual Language Model Pretraining
- (HITS Authority: 0.0169) Learned in Translation: Contextualized Word Vectors
- (HITS Authority: 0.0151) Multi-Task Deep Neural Networks for Natural Language Understanding
- (HITS Authority: 0.0140) Transformer-XL: Attentive Language Models beyond a Fixed-Length Context
- (HITS Authority: 0.0138) Know What You Don’t Know: Unanswerable Questions for SQuAD
- (HITS Authority: 0.0119) Supervised Learning of Universal Sentence Representations from Natural Lang...
- (HITS Authority: 0.0083) RACE: Large-scale ReAding Comprehension Dataset From Examinations
- (HITS Authority: 0.0082) ALBERT: A Lite BERT for Self-supervised Learning of Language Representation...
- (HITS Authority: 0.0081) Convolutional Sequence to Sequence Learning
- (HITS Authority: 0.0078) Semi-supervised sequence tagging with bidirectional language models


# Analysis for Window: 2018-2020
**Stats:** Papers: 5511, Edges: 8505
**Final DBCV Score:** 0.5204
**Parameters Used:** `n_neighbors`: 50, `min_cluster_size`: 15, `min_samples`: 5, `epsilon`: 0.5

### Dominant Topics

- **Topic (ID: 3, Size: 3161, Confidence: 0.9974):** language, natural, learning, processing, using, deep, based, text, neural, analysis, survey, machine, data, models, sentiment
- **Topic (ID: 1, Size: 501, Confidence: 0.9974):** language, processing, natural, clinical, learning, using, medical, based, health, data, machine, text, electronic, deep, biomedical
- **Topic (ID: 0, Size: 86, Confidence: 0.6439):** learning, deep, language, using, chemical, natural, processing, protein, prediction, machine, based, modeling, molecular, sequence, drug
- **Topic (ID: 2, Size: 35, Confidence: 0.6006):** language, survey, learning, neural, processing, model, natural, data, word, models, embeddings, deep, bias, gender, methods

### Top 20 Papers by Citation Count

- (Citation Count: 94099.0000) BERT: Pre-training of Deep Bidirectional Transformers for Language Understa...
- (Citation Count: 41302.0000) Language Models are Few-Shot Learners
- (Citation Count: 24213.0000) RoBERTa: A Robustly Optimized BERT Pretraining Approach
- (Citation Count: 22682.0000) Language Models are Unsupervised Multitask Learners
- (Citation Count: 19888.0000) Exploring the Limits of Transfer Learning with a Unified Text-to-Text Trans...
- (Citation Count: 11860.0000) Improving Language Understanding by Generative Pre-Training
- (Citation Count: 11526.0000) Deep Contextualized Word Representations
- (Citation Count: 10743.0000) BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Gene...
- (Citation Count: 8395.0000) XLNet: Generalized Autoregressive Pretraining for Language Understanding
- (Citation Count: 7422.0000) DistilBERT, a distilled version of BERT: smaller, faster, cheaper and light...
- (Citation Count: 7103.0000) GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Und...
- (Citation Count: 6690.0000) Training data-efficient image transformers & distillation through attention
- (Citation Count: 6424.0000) ALBERT: A Lite BERT for Self-supervised Learning of Language Representation...
- (Citation Count: 6136.0000) Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks
- (Citation Count: 5602.0000) BioBERT: a pre-trained biomedical language representation model for biomedi...
- (Citation Count: 4707.0000) Scaling Laws for Neural Language Models
- (Citation Count: 4304.0000) Measuring Massive Multitask Language Understanding
- (Citation Count: 3715.0000) Transformer-XL: Attentive Language Models beyond a Fixed-Length Context
- (Citation Count: 3664.0000) ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Visi...
- (Citation Count: 3628.0000) Universal Language Model Fine-tuning for Text Classification

### Top 20 Papers by PageRank

- (PageRank: 0.0453) Deep Contextualized Word Representations
- (PageRank: 0.0371) BERT: Pre-training of Deep Bidirectional Transformers for Language Understa...
- (PageRank: 0.0121) Annotation Artifacts in Natural Language Inference Data
- (PageRank: 0.0095) Visual Referring Expression Recognition: What Do Systems Actually Learn?
- (PageRank: 0.0086) Universal Language Model Fine-tuning for Text Classification
- (PageRank: 0.0068) Improving Language Understanding by Generative Pre-Training
- (PageRank: 0.0066) GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Und...
- (PageRank: 0.0059) Dissecting Contextual Word Embeddings: Architecture and Representation
- (PageRank: 0.0055) Language Models are Unsupervised Multitask Learners
- (PageRank: 0.0052) RoBERTa: A Robustly Optimized BERT Pretraining Approach
- (PageRank: 0.0050) Semi-Supervised Sequence Modeling with Cross-View Training
- (PageRank: 0.0047) XLNet: Generalized Autoregressive Pretraining for Language Understanding
- (PageRank: 0.0043) QANet: Combining Local Convolution with Global Self-Attention for Reading C...
- (PageRank: 0.0041) Character-Level Language Modeling with Deeper Self-Attention
- (PageRank: 0.0036) AllenNLP: A Deep Semantic Natural Language Processing Platform
- (PageRank: 0.0031) Neural Network Acceptability Judgments
- (PageRank: 0.0029) Learning Word Vectors for 157 Languages
- (PageRank: 0.0027) Learning General Purpose Distributed Sentence Representations via Large Sca...
- (PageRank: 0.0026) Know What You Don’t Know: Unanswerable Questions for SQuAD
- (PageRank: 0.0026) Contextual String Embeddings for Sequence Labeling

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.1722) BERT: Pre-training of Deep Bidirectional Transformers for Language Understa...
- (HITS Authority: 0.0637) Deep Contextualized Word Representations
- (HITS Authority: 0.0612) RoBERTa: A Robustly Optimized BERT Pretraining Approach
- (HITS Authority: 0.0417) XLNet: Generalized Autoregressive Pretraining for Language Understanding
- (HITS Authority: 0.0399) Improving Language Understanding by Generative Pre-Training
- (HITS Authority: 0.0390) GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Und...
- (HITS Authority: 0.0360) Language Models are Unsupervised Multitask Learners
- (HITS Authority: 0.0276) ALBERT: A Lite BERT for Self-supervised Learning of Language Representation...
- (HITS Authority: 0.0220) Universal Language Model Fine-tuning for Text Classification
- (HITS Authority: 0.0180) Exploring the Limits of Transfer Learning with a Unified Text-to-Text Trans...
- (HITS Authority: 0.0159) Cross-lingual Language Model Pretraining
- (HITS Authority: 0.0142) DistilBERT, a distilled version of BERT: smaller, faster, cheaper and light...
- (HITS Authority: 0.0140) Multi-Task Deep Neural Networks for Natural Language Understanding
- (HITS Authority: 0.0122) Transformer-XL: Attentive Language Models beyond a Fixed-Length Context
- (HITS Authority: 0.0112) Know What You Don’t Know: Unanswerable Questions for SQuAD
- (HITS Authority: 0.0101) BioBERT: a pre-trained biomedical language representation model for biomedi...
- (HITS Authority: 0.0084) SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding ...
- (HITS Authority: 0.0074) Unified Language Model Pre-training for Natural Language Understanding and ...
- (HITS Authority: 0.0072) Contextual String Embeddings for Sequence Labeling
- (HITS Authority: 0.0072) Patient Knowledge Distillation for BERT Model Compression


# Analysis for Window: 2019-2021
**Stats:** Papers: 5582, Edges: 11216
**Final DBCV Score:** 0.4279
**Parameters Used:** `n_neighbors`: 15, `min_cluster_size`: 50, `min_samples`: 25, `epsilon`: 0.0

### Dominant Topics

- **Topic (ID: 2, Size: 4569, Confidence: 0.9923):** language, natural, processing, learning, using, based, deep, text, analysis, models, neural, machine, survey, data, model
- **Topic (ID: 0, Size: 229, Confidence: 0.9721):** adversarial, language, learning, natural, detection, processing, using, deep, based, attacks, privacy, models, machine, text, attack
- **Topic (ID: 1, Size: 101, Confidence: 0.9372):** learning, deep, language, using, protein, sequence, chemical, molecular, natural, prediction, models, based, data, processing, model

### Top 20 Papers by Citation Count

- (Citation Count: 94099.0000) BERT: Pre-training of Deep Bidirectional Transformers for Language Understa...
- (Citation Count: 41302.0000) Language Models are Few-Shot Learners
- (Citation Count: 28903.0000) Learning Transferable Visual Models From Natural Language Supervision
- (Citation Count: 24213.0000) RoBERTa: A Robustly Optimized BERT Pretraining Approach
- (Citation Count: 22682.0000) Language Models are Unsupervised Multitask Learners
- (Citation Count: 19888.0000) Exploring the Limits of Transfer Learning with a Unified Text-to-Text Trans...
- (Citation Count: 10743.0000) BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Gene...
- (Citation Count: 10099.0000) LoRA: Low-Rank Adaptation of Large Language Models
- (Citation Count: 8395.0000) XLNet: Generalized Autoregressive Pretraining for Language Understanding
- (Citation Count: 7422.0000) DistilBERT, a distilled version of BERT: smaller, faster, cheaper and light...
- (Citation Count: 6690.0000) Training data-efficient image transformers & distillation through attention
- (Citation Count: 6424.0000) ALBERT: A Lite BERT for Self-supervised Learning of Language Representation...
- (Citation Count: 6136.0000) Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks
- (Citation Count: 5602.0000) BioBERT: a pre-trained biomedical language representation model for biomedi...
- (Citation Count: 5385.0000) Evaluating Large Language Models Trained on Code
- (Citation Count: 4707.0000) Scaling Laws for Neural Language Models
- (Citation Count: 4617.0000) Review of deep learning: concepts, CNN architectures, challenges, applicati...
- (Citation Count: 4304.0000) Measuring Massive Multitask Language Understanding
- (Citation Count: 3934.0000) Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in...
- (Citation Count: 3715.0000) Transformer-XL: Attentive Language Models beyond a Fixed-Length Context

### Top 20 Papers by PageRank

- (PageRank: 0.1130) BERT: Pre-training of Deep Bidirectional Transformers for Language Understa...
- (PageRank: 0.0168) Language Models are Unsupervised Multitask Learners
- (PageRank: 0.0155) RoBERTa: A Robustly Optimized BERT Pretraining Approach
- (PageRank: 0.0121) XLNet: Generalized Autoregressive Pretraining for Language Understanding
- (PageRank: 0.0101) Multi-Task Deep Neural Networks for Natural Language Understanding
- (PageRank: 0.0072) Transformer-XL: Attentive Language Models beyond a Fixed-Length Context
- (PageRank: 0.0064) Cross-lingual Language Model Pretraining
- (PageRank: 0.0059) ALBERT: A Lite BERT for Self-supervised Learning of Language Representation...
- (PageRank: 0.0049) Improving Multi-Task Deep Neural Networks via Knowledge Distillation for Na...
- (PageRank: 0.0046) BioBERT: a pre-trained biomedical language representation model for biomedi...
- (PageRank: 0.0045) Exploring the Limits of Transfer Learning with a Unified Text-to-Text Trans...
- (PageRank: 0.0044) Unified Language Model Pre-training for Natural Language Understanding and ...
- (PageRank: 0.0042) Language Models are Few-Shot Learners
- (PageRank: 0.0031) DistilBERT, a distilled version of BERT: smaller, faster, cheaper and light...
- (PageRank: 0.0029) SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding ...
- (PageRank: 0.0027) MASS: Masked Sequence to Sequence Pre-training for Language Generation
- (PageRank: 0.0025) Publicly Available Clinical BERT Embeddings
- (PageRank: 0.0023) Lipstick on a Pig: Debiasing Methods Cover up Systematic Gender Biases in W...
- (PageRank: 0.0021) BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Gene...
- (PageRank: 0.0019) Generating Long Sequences with Sparse Transformers

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.2137) BERT: Pre-training of Deep Bidirectional Transformers for Language Understa...
- (HITS Authority: 0.0778) RoBERTa: A Robustly Optimized BERT Pretraining Approach
- (HITS Authority: 0.0446) Language Models are Unsupervised Multitask Learners
- (HITS Authority: 0.0414) XLNet: Generalized Autoregressive Pretraining for Language Understanding
- (HITS Authority: 0.0359) ALBERT: A Lite BERT for Self-supervised Learning of Language Representation...
- (HITS Authority: 0.0260) Exploring the Limits of Transfer Learning with a Unified Text-to-Text Trans...
- (HITS Authority: 0.0232) Language Models are Few-Shot Learners
- (HITS Authority: 0.0203) DistilBERT, a distilled version of BERT: smaller, faster, cheaper and light...
- (HITS Authority: 0.0167) Cross-lingual Language Model Pretraining
- (HITS Authority: 0.0146) BioBERT: a pre-trained biomedical language representation model for biomedi...
- (HITS Authority: 0.0131) Transformer-XL: Attentive Language Models beyond a Fixed-Length Context
- (HITS Authority: 0.0130) BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Gene...
- (HITS Authority: 0.0117) Multi-Task Deep Neural Networks for Natural Language Understanding
- (HITS Authority: 0.0105) TinyBERT: Distilling BERT for Natural Language Understanding
- (HITS Authority: 0.0104) SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding ...
- (HITS Authority: 0.0098) SciBERT: A Pretrained Language Model for Scientific Text
- (HITS Authority: 0.0084) Patient Knowledge Distillation for BERT Model Compression
- (HITS Authority: 0.0069) Unified Language Model Pre-training for Natural Language Understanding and ...
- (HITS Authority: 0.0069) MASS: Masked Sequence to Sequence Pre-training for Language Generation
- (HITS Authority: 0.0068) Publicly Available Clinical BERT Embeddings


# Analysis for Window: 2020-2022
**Stats:** Papers: 5579, Edges: 7223
**Final DBCV Score:** 0.5879
**Parameters Used:** `n_neighbors`: 25, `min_cluster_size`: 35, `min_samples`: 25, `epsilon`: 0.5

### Dominant Topics

- **Topic (ID: 3, Size: 4344, Confidence: 0.9991):** language, natural, learning, processing, using, based, text, models, deep, analysis, survey, neural, model, machine, sentiment
- **Topic (ID: 2, Size: 805, Confidence: 0.9804):** language, natural, processing, using, learning, clinical, health, based, machine, medical, review, electronic, data, text, records
- **Topic (ID: 1, Size: 235, Confidence: 0.9992):** language, learning, adversarial, natural, processing, detection, models, using, privacy, based, attacks, attack, nlp, deep, text
- **Topic (ID: 0, Size: 127, Confidence: 0.5983):** language, learning, deep, using, natural, models, protein, model, processing, chemical, data, sequence, prediction, based, molecular

### Top 20 Papers by Citation Count

- (Citation Count: 41302.0000) Language Models are Few-Shot Learners
- (Citation Count: 28903.0000) Learning Transferable Visual Models From Natural Language Supervision
- (Citation Count: 12686.0000) Training language models to follow instructions with human feedback
- (Citation Count: 10099.0000) LoRA: Low-Rank Adaptation of Large Language Models
- (Citation Count: 9151.0000) Chain of Thought Prompting Elicits Reasoning in Large Language Models
- (Citation Count: 6690.0000) Training data-efficient image transformers & distillation through attention
- (Citation Count: 6159.0000) PaLM: Scaling Language Modeling with Pathways
- (Citation Count: 6136.0000) Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks
- (Citation Count: 5385.0000) Evaluating Large Language Models Trained on Code
- (Citation Count: 4707.0000) Scaling Laws for Neural Language Models
- (Citation Count: 4617.0000) Review of deep learning: concepts, CNN architectures, challenges, applicati...
- (Citation Count: 4332.0000) Large Language Models are Zero-Shot Reasoners
- (Citation Count: 4304.0000) Measuring Massive Multitask Language Understanding
- (Citation Count: 3934.0000) Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in...
- (Citation Count: 3533.0000) Self-Consistency Improves Chain of Thought Reasoning in Language Models
- (Citation Count: 3350.0000) SimCSE: Simple Contrastive Learning of Sentence Embeddings
- (Citation Count: 2790.0000) BEiT: BERT Pre-Training of Image Transformers
- (Citation Count: 2698.0000) DeBERTa: Decoding-enhanced BERT with Disentangled Attention
- (Citation Count: 2675.0000) A Survey of Convolutional Neural Networks: Analysis, Applications, and Pros...
- (Citation Count: 2478.0000) Transformers in Vision: A Survey

### Top 20 Papers by PageRank

- (PageRank: 0.0439) How Much Knowledge Can You Pack into the Parameters of a Language Model?
- (PageRank: 0.0418) REALM: Retrieval-Augmented Language Model Pre-Training
- (PageRank: 0.0318) Language Models are Few-Shot Learners
- (PageRank: 0.0068) Scaling Laws for Neural Language Models
- (PageRank: 0.0054) Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks
- (PageRank: 0.0048) Language (Technology) is Power: A Critical Survey of “Bias” in NLP
- (PageRank: 0.0046) Learning Transferable Visual Models From Natural Language Supervision
- (PageRank: 0.0044) Adversarial Training for Large Neural Language Models
- (PageRank: 0.0040) Training data-efficient image transformers & distillation through attention
- (PageRank: 0.0036) Pretrained Transformers Improve Out-of-Distribution Robustness
- (PageRank: 0.0034) Train Large, Then Compress: Rethinking Model Size for Efficient Training an...
- (PageRank: 0.0034) Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Lan...
- (PageRank: 0.0032) StereoSet: Measuring stereotypical bias in pretrained language models
- (PageRank: 0.0030) Multilingual Denoising Pre-training for Neural Machine Translation
- (PageRank: 0.0029) How Can We Accelerate Progress Towards Human-like Linguistic Generalization...
- (PageRank: 0.0029) Stanza: A Python Natural Language Processing Toolkit for Many Human Languag...
- (PageRank: 0.0028) AraBERT: Transformer-based Model for Arabic Language Understanding
- (PageRank: 0.0028) UnifiedQA: Crossing Format Boundaries With a Single QA System
- (PageRank: 0.0024) Compressing Large-Scale Transformer-Based Models: A Case Study on BERT
- (PageRank: 0.0023) Pre-trained models for natural language processing: A survey

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.2121) Language Models are Few-Shot Learners
- (HITS Authority: 0.0324) Learning Transferable Visual Models From Natural Language Supervision
- (HITS Authority: 0.0218) Chain of Thought Prompting Elicits Reasoning in Large Language Models
- (HITS Authority: 0.0205) Evaluating Large Language Models Trained on Code
- (HITS Authority: 0.0174) PaLM: Scaling Language Modeling with Pathways
- (HITS Authority: 0.0166) Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in...
- (HITS Authority: 0.0161) Scaling Laws for Neural Language Models
- (HITS Authority: 0.0158) REALM: Retrieval-Augmented Language Model Pre-Training
- (HITS Authority: 0.0147) Training data-efficient image transformers & distillation through attention
- (HITS Authority: 0.0146) Training language models to follow instructions with human feedback
- (HITS Authority: 0.0115) DeBERTa: Decoding-enhanced BERT with Disentangled Attention
- (HITS Authority: 0.0110) GLaM: Efficient Scaling of Language Models with Mixture-of-Experts
- (HITS Authority: 0.0109) How Much Knowledge Can You Pack into the Parameters of a Language Model?
- (HITS Authority: 0.0104) Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Lan...
- (HITS Authority: 0.0097) Self-Consistency Improves Chain of Thought Reasoning in Language Models
- (HITS Authority: 0.0095) Linformer: Self-Attention with Linear Complexity
- (HITS Authority: 0.0086) Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks
- (HITS Authority: 0.0086) Large Language Models are Zero-Shot Reasoners
- (HITS Authority: 0.0081) Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Sca...
- (HITS Authority: 0.0080) Domain-Specific Language Model Pretraining for Biomedical Natural Language ...


# Analysis for Window: 2021-2023
**Stats:** Papers: 5684, Edges: 8779
**Final DBCV Score:** 0.3912
**Parameters Used:** `n_neighbors`: 30, `min_cluster_size`: 75, `min_samples`: 40, `epsilon`: 0.25

### Dominant Topics

- **Topic (ID: 2, Size: 5244, Confidence: 0.9921):** language, natural, processing, models, learning, using, based, large, text, deep, survey, model, analysis, review, machine
- **Topic (ID: 0, Size: 256, Confidence: 0.9620):** language, learning, models, natural, adversarial, detection, processing, based, privacy, using, attacks, nlp, federated, model, security
- **Topic (ID: 1, Size: 132, Confidence: 0.8985):** language, models, learning, protein, using, model, deep, molecular, based, prediction, chemical, sequence, design, data, natural

### Top 20 Papers by Citation Count

- (Citation Count: 28903.0000) Learning Transferable Visual Models From Natural Language Supervision
- (Citation Count: 12954.0000) LLaMA: Open and Efficient Foundation Language Models
- (Citation Count: 12686.0000) Training language models to follow instructions with human feedback
- (Citation Count: 10099.0000) LoRA: Low-Rank Adaptation of Large Language Models
- (Citation Count: 9151.0000) Chain of Thought Prompting Elicits Reasoning in Large Language Models
- (Citation Count: 6159.0000) PaLM: Scaling Language Modeling with Pathways
- (Citation Count: 5385.0000) Evaluating Large Language Models Trained on Code
- (Citation Count: 4617.0000) Review of deep learning: concepts, CNN architectures, challenges, applicati...
- (Citation Count: 4332.0000) Large Language Models are Zero-Shot Reasoners
- (Citation Count: 3934.0000) Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in...
- (Citation Count: 3800.0000) Direct Preference Optimization: Your Language Model is Secretly a Reward Mo...
- (Citation Count: 3533.0000) Self-Consistency Improves Chain of Thought Reasoning in Language Models
- (Citation Count: 3350.0000) SimCSE: Simple Contrastive Learning of Sentence Embeddings
- (Citation Count: 3256.0000) DINOv2: Learning Robust Visual Features without Supervision
- (Citation Count: 2790.0000) BEiT: BERT Pre-Training of Image Transformers
- (Citation Count: 2659.0000) A Survey of Large Language Models
- (Citation Count: 2478.0000) Transformers in Vision: A Survey
- (Citation Count: 2364.0000) BLOOM: A 176B-Parameter Open-Access Multilingual Language Model
- (Citation Count: 2355.0000) Learning to Prompt for Vision-Language Models
- (Citation Count: 2098.0000) Efficient Memory Management for Large Language Model Serving with PagedAtte...

### Top 20 Papers by PageRank

- (PageRank: 0.0292) Learning Transferable Visual Models From Natural Language Supervision
- (PageRank: 0.0159) Evaluating Large Language Models Trained on Code
- (PageRank: 0.0118) Training language models to follow instructions with human feedback
- (PageRank: 0.0106) PaLM: Scaling Language Modeling with Pathways
- (PageRank: 0.0096) Chain of Thought Prompting Elicits Reasoning in Large Language Models
- (PageRank: 0.0089) Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in...
- (PageRank: 0.0072) BEiT: BERT Pre-Training of Image Transformers
- (PageRank: 0.0068) ExT5: Towards Extreme Multi-Task Scaling for Transfer Learning
- (PageRank: 0.0060) What’s in Your Head? Emergent Behaviour in Multi-Task Transformer Models
- (PageRank: 0.0058) LLaMA: Open and Efficient Foundation Language Models
- (PageRank: 0.0052) Self-Consistency Improves Chain of Thought Reasoning in Language Models
- (PageRank: 0.0051) PanGu-α: Large-scale Autoregressive Pretrained Chinese Language Models with...
- (PageRank: 0.0042) Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Sca...
- (PageRank: 0.0039) SimCSE: Simple Contrastive Learning of Sentence Embeddings
- (PageRank: 0.0037) BLOOM: A 176B-Parameter Open-Access Multilingual Language Model
- (PageRank: 0.0035) QNLP in Practice: Running Compositional Models of Meaning on a Quantum Comp...
- (PageRank: 0.0034) LoRA: Low-Rank Adaptation of Large Language Models
- (PageRank: 0.0033) Large Language Models are Zero-Shot Reasoners
- (PageRank: 0.0029) lambeq: An Efficient High-Level Python Library for Quantum NLP
- (PageRank: 0.0028) GLaM: Efficient Scaling of Language Models with Mixture-of-Experts

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.0802) Training language models to follow instructions with human feedback
- (HITS Authority: 0.0700) Chain of Thought Prompting Elicits Reasoning in Large Language Models
- (HITS Authority: 0.0540) LLaMA: Open and Efficient Foundation Language Models
- (HITS Authority: 0.0511) Learning Transferable Visual Models From Natural Language Supervision
- (HITS Authority: 0.0505) PaLM: Scaling Language Modeling with Pathways
- (HITS Authority: 0.0391) Evaluating Large Language Models Trained on Code
- (HITS Authority: 0.0335) Self-Consistency Improves Chain of Thought Reasoning in Language Models
- (HITS Authority: 0.0319) Large Language Models are Zero-Shot Reasoners
- (HITS Authority: 0.0267) LoRA: Low-Rank Adaptation of Large Language Models
- (HITS Authority: 0.0214) BLOOM: A 176B-Parameter Open-Access Multilingual Language Model
- (HITS Authority: 0.0144) A Survey of Large Language Models
- (HITS Authority: 0.0139) Solving Quantitative Reasoning Problems with Language Models
- (HITS Authority: 0.0137) Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in...
- (HITS Authority: 0.0136) Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Sca...
- (HITS Authority: 0.0114) GLaM: Efficient Scaling of Language Models with Mixture-of-Experts
- (HITS Authority: 0.0079) CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Cod...
- (HITS Authority: 0.0067) Is ChatGPT a General-Purpose Natural Language Processing Task Solver?
- (HITS Authority: 0.0065) Inner Monologue: Embodied Reasoning through Planning with Language Models
- (HITS Authority: 0.0062) PanGu-α: Large-scale Autoregressive Pretrained Chinese Language Models with...
- (HITS Authority: 0.0061) Code as Policies: Language Model Programs for Embodied Control


# Analysis for Window: 2022-2024
**Stats:** Papers: 5921, Edges: 10079
**Final DBCV Score:** 0.5291
**Parameters Used:** `n_neighbors`: 10, `min_cluster_size`: 75, `min_samples`: 5, `epsilon`: 0.0

### Dominant Topics

- **Topic (ID: 1, Size: 4548, Confidence: 0.9858):** language, models, large, natural, learning, processing, based, using, model, survey, text, analysis, deep, generation, review
- **Topic (ID: 3, Size: 824, Confidence: 0.8957):** language, natural, processing, clinical, using, medical, models, review, large, health, learning, model, based, artificial, intelligence
- **Topic (ID: 0, Size: 252, Confidence: 0.9376):** language, models, large, learning, privacy, natural, attacks, detection, processing, based, adversarial, survey, model, using, federated
- **Topic (ID: 2, Size: 179, Confidence: 0.8885):** language, models, protein, learning, large, model, based, using, deep, prediction, molecular, natural, design, drug, processing

### Top 20 Papers by Citation Count

- (Citation Count: 12954.0000) LLaMA: Open and Efficient Foundation Language Models
- (Citation Count: 12686.0000) Training language models to follow instructions with human feedback
- (Citation Count: 9151.0000) Chain of Thought Prompting Elicits Reasoning in Large Language Models
- (Citation Count: 6159.0000) PaLM: Scaling Language Modeling with Pathways
- (Citation Count: 4332.0000) Large Language Models are Zero-Shot Reasoners
- (Citation Count: 3800.0000) Direct Preference Optimization: Your Language Model is Secretly a Reward Mo...
- (Citation Count: 3533.0000) Self-Consistency Improves Chain of Thought Reasoning in Language Models
- (Citation Count: 3256.0000) DINOv2: Learning Robust Visual Features without Supervision
- (Citation Count: 2659.0000) A Survey of Large Language Models
- (Citation Count: 2364.0000) BLOOM: A 176B-Parameter Open-Access Multilingual Language Model
- (Citation Count: 2098.0000) Efficient Memory Management for Large Language Model Serving with PagedAtte...
- (Citation Count: 1756.0000) Qwen Technical Report
- (Citation Count: 1619.0000) A Survey on Evaluation of Large Language Models
- (Citation Count: 1360.0000) Diffusion Models: A Comprehensive Survey of Methods and Applications
- (Citation Count: 1225.0000) A Survey on Large Language Model based Autonomous Agents
- (Citation Count: 1224.0000) How Does ChatGPT Perform on the United States Medical Licensing Examination...
- (Citation Count: 1178.0000) PaLM 2 Technical Report
- (Citation Count: 1155.0000) G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment
- (Citation Count: 1098.0000) Swin UNETR: Swin Transformers for Semantic Segmentation of Brain Tumors in ...
- (Citation Count: 1084.0000) RT-1: Robotics Transformer for Real-World Control at Scale

### Top 20 Papers by PageRank

- (PageRank: 0.0445) PaLM: Scaling Language Modeling with Pathways
- (PageRank: 0.0413) Training language models to follow instructions with human feedback
- (PageRank: 0.0377) Chain of Thought Prompting Elicits Reasoning in Large Language Models
- (PageRank: 0.0234) Self-Consistency Improves Chain of Thought Reasoning in Language Models
- (PageRank: 0.0203) Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Sca...
- (PageRank: 0.0180) LLaMA: Open and Efficient Foundation Language Models
- (PageRank: 0.0110) BLOOM: A 176B-Parameter Open-Access Multilingual Language Model
- (PageRank: 0.0107) Large Language Models are Zero-Shot Reasoners
- (PageRank: 0.0085) Designing Effective Sparse Expert Models
- (PageRank: 0.0070) Solving Quantitative Reasoning Problems with Language Models
- (PageRank: 0.0057) Repairing the Cracked Foundation: A Survey of Obstacles in Evaluation Pract...
- (PageRank: 0.0029) A Survey of Large Language Models
- (PageRank: 0.0027) Natural Language to Code Translation with Execution
- (PageRank: 0.0026) Is ChatGPT a General-Purpose Natural Language Processing Task Solver?
- (PageRank: 0.0020) EleutherAI: Going Beyond "Open Science" to "Science in the Open"
- (PageRank: 0.0019) BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation a...
- (PageRank: 0.0019) Autoformalization with Large Language Models
- (PageRank: 0.0018) Direct Preference Optimization: Your Language Model is Secretly a Reward Mo...
- (PageRank: 0.0018) A Contrastive Framework for Neural Text Generation
- (PageRank: 0.0016) Contrastive Search Is What You Need For Neural Text Generation

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.1048) Training language models to follow instructions with human feedback
- (HITS Authority: 0.0943) LLaMA: Open and Efficient Foundation Language Models
- (HITS Authority: 0.0777) Chain of Thought Prompting Elicits Reasoning in Large Language Models
- (HITS Authority: 0.0592) PaLM: Scaling Language Modeling with Pathways
- (HITS Authority: 0.0385) Self-Consistency Improves Chain of Thought Reasoning in Language Models
- (HITS Authority: 0.0346) Large Language Models are Zero-Shot Reasoners
- (HITS Authority: 0.0290) BLOOM: A 176B-Parameter Open-Access Multilingual Language Model
- (HITS Authority: 0.0202) A Survey of Large Language Models
- (HITS Authority: 0.0139) Solving Quantitative Reasoning Problems with Language Models
- (HITS Authority: 0.0119) Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Sca...
- (HITS Authority: 0.0107) Direct Preference Optimization: Your Language Model is Secretly a Reward Mo...
- (HITS Authority: 0.0082) PaLM 2 Technical Report
- (HITS Authority: 0.0075) Is ChatGPT a General-Purpose Natural Language Processing Task Solver?
- (HITS Authority: 0.0065) Selection-Inference: Exploiting Large Language Models for Interpretable Log...
- (HITS Authority: 0.0062) Inner Monologue: Embodied Reasoning through Planning with Language Models
- (HITS Authority: 0.0057) Qwen Technical Report
- (HITS Authority: 0.0056) Towards Reasoning in Large Language Models: A Survey
- (HITS Authority: 0.0055) CodeT5+: Open Code Large Language Models for Code Understanding and Generat...
- (HITS Authority: 0.0054) Red Teaming Language Models with Language Models
- (HITS Authority: 0.0053) BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation a...


# Analysis for Window: 2023-2025
**Stats:** Papers: 4766, Edges: 6128
**Final DBCV Score:** 0.4112
**Parameters Used:** `n_neighbors`: 30, `min_cluster_size`: 50, `min_samples`: 30, `epsilon`: 0.25

### Dominant Topics

- **Topic (ID: 2, Size: 617, Confidence: 0.8501):** language, natural, processing, models, large, medical, clinical, review, using, health, learning, healthcare, chatgpt, applications, model
- **Topic (ID: 6, Size: 275, Confidence: 0.9183):** language, chatgpt, ai, education, natural, learning, processing, intelligence, artificial, models, large, review, using, chatbot, generative
- **Topic (ID: 12, Size: 266, Confidence: 0.8088):** language, models, large, knowledge, graph, retrieval, natural, generation, text, augmented, survey, processing, sql, graphs, question
- **Topic (ID: 13, Size: 227, Confidence: 0.7906):** language, image, models, multimodal, visual, vision, generation, text, learning, large, video, understanding, natural, multi, 3d
- **Topic (ID: 14, Size: 199, Confidence: 0.8298):** language, models, large, translation, languages, multilingual, processing, machine, natural, low, resource, arabic, model, survey, evaluation
- **Topic (ID: 10, Size: 170, Confidence: 0.7568):** language, code, models, large, generation, software, natural, using, llm, requirements, engineering, llms, based, study, processing
- **Topic (ID: 0, Size: 169, Confidence: 0.8278):** language, models, large, attacks, privacy, survey, llm, adversarial, security, model, detection, backdoor, learning, based, natural
- **Topic (ID: 1, Size: 154, Confidence: 0.8410):** language, models, protein, learning, large, model, based, drug, using, natural, prediction, design, molecular, processing, transformer
- **Topic (ID: 20, Size: 147, Confidence: 0.9128):** language, large, models, efficient, tuning, fine, model, llm, inference, parameter, llms, decoding, low, efficiency, training
- **Topic (ID: 9, Size: 135, Confidence: 0.7881):** analysis, sentiment, language, learning, natural, processing, based, deep, using, classification, model, models, text, techniques, social
- **Topic (ID: 19, Size: 131, Confidence: 0.9430):** learning, deep, time, series, models, neural, networks, survey, transformers, forecasting, transformer, based, model, language, review
- **Topic (ID: 7, Size: 100, Confidence: 0.8729):** intelligence, ai, artificial, driven, management, role, processing, review, language, natural, challenges, enhancing, sustainable, learning, machine
- **Topic (ID: 17, Size: 85, Confidence: 0.9079):** language, large, models, robot, autonomous, model, survey, robotic, vision, manipulation, learning, driving, using, action, navigation
- **Topic (ID: 15, Size: 81, Confidence: 0.9664):** language, reasoning, models, large, natural, survey, explanations, logical, causal, symbolic, model, llms, ai, inference, learning
- **Topic (ID: 3, Size: 80, Confidence: 0.8598):** speech, language, audio, models, large, generation, natural, text, model, survey, using, recognition, processing, synthesis, evaluation
- **Topic (ID: 16, Size: 80, Confidence: 0.9903):** language, large, models, evaluation, survey, generation, model, llm, data, nlp, text, llms, natural, evaluating, challenges
- **Topic (ID: 4, Size: 76, Confidence: 0.9967):** language, processing, natural, models, large, human, brain, learning, neural, survey, deep, word, comprehension, based, using
- **Topic (ID: 8, Size: 59, Confidence: 0.9915):** detection, language, processing, using, natural, news, fake, learning, based, model, social, media, deep, spam, machine
- **Topic (ID: 18, Size: 53, Confidence: 0.9994):** language, agents, large, agent, llm, models, based, multi, planning, framework, model, reasoning, llms, tasks, autonomous
- **Topic (ID: 5, Size: 52, Confidence: 0.9991):** language, models, bias, large, fairness, gender, social, natural, mitigating, biases, llms, model, processing, survey, evaluating
- **Topic (ID: 11, Size: 50, Confidence: 1.0000):** recommendation, language, large, recommender, models, survey, systems, based, model, personalized, generation, generative, llm, chatgpt, user

### Top 20 Papers by Citation Count

- (Citation Count: 12954.0000) LLaMA: Open and Efficient Foundation Language Models
- (Citation Count: 3800.0000) Direct Preference Optimization: Your Language Model is Secretly a Reward Mo...
- (Citation Count: 3256.0000) DINOv2: Learning Robust Visual Features without Supervision
- (Citation Count: 2659.0000) A Survey of Large Language Models
- (Citation Count: 2098.0000) Efficient Memory Management for Large Language Model Serving with PagedAtte...
- (Citation Count: 1756.0000) Qwen Technical Report
- (Citation Count: 1619.0000) A Survey on Evaluation of Large Language Models
- (Citation Count: 1225.0000) A Survey on Large Language Model based Autonomous Agents
- (Citation Count: 1224.0000) How Does ChatGPT Perform on the United States Medical Licensing Examination...
- (Citation Count: 1178.0000) PaLM 2 Technical Report
- (Citation Count: 1155.0000) G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment
- (Citation Count: 943.0000) Intelligent Clinical Documentation: Harnessing Generative AI for Patient-Ce...
- (Citation Count: 830.0000) Sentiment Analysis
- (Citation Count: 816.0000) A Survey on Hallucination in Large Language Models: Principles, Taxonomy, C...
- (Citation Count: 774.0000) A Brief Overview of ChatGPT: The History, Status Quo and Potential Future D...
- (Citation Count: 760.0000) Unifying Large Language Models and Knowledge Graphs: A Roadmap
- (Citation Count: 755.0000) Evaluating Object Hallucination in Large Vision-Language Models
- (Citation Count: 747.0000) StarCoder: may the source be with you!
- (Citation Count: 702.0000) Abstractive Text Summarization Using GAN
- (Citation Count: 692.0000) Is ChatGPT a General-Purpose Natural Language Processing Task Solver?

### Top 20 Papers by PageRank

- (PageRank: 0.0658) LLaMA: Open and Efficient Foundation Language Models
- (PageRank: 0.0114) A Survey of Large Language Models
- (PageRank: 0.0111) Is ChatGPT a General-Purpose Natural Language Processing Task Solver?
- (PageRank: 0.0059) Direct Preference Optimization: Your Language Model is Secretly a Reward Mo...
- (PageRank: 0.0050) PaLM 2 Technical Report
- (PageRank: 0.0047) Pretraining Language Models with Human Preferences
- (PageRank: 0.0037) A Comprehensive Survey on Pretrained Foundation Models: A History from BERT...
- (PageRank: 0.0035) Efficient Memory Management for Large Language Model Serving with PagedAtte...
- (PageRank: 0.0035) G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment
- (PageRank: 0.0034) Qwen Technical Report
- (PageRank: 0.0034) A Survey on Evaluation of Large Language Models
- (PageRank: 0.0031) How Does ChatGPT Perform on the United States Medical Licensing Examination...
- (PageRank: 0.0030) Large Language Models
- (PageRank: 0.0026) Scaling Transformer to 1M tokens and beyond with RMT
- (PageRank: 0.0026) RWKV: Reinventing RNNs for the Transformer Era
- (PageRank: 0.0024) Augmented Language Models: a Survey
- (PageRank: 0.0024) StarCoder: may the source be with you!
- (PageRank: 0.0022) Natural Language Processing in the Legal Domain
- (PageRank: 0.0022) A Survey on Large Language Model based Autonomous Agents
- (PageRank: 0.0020) Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.3034) LLaMA: Open and Efficient Foundation Language Models
- (HITS Authority: 0.0411) A Survey of Large Language Models
- (HITS Authority: 0.0169) Direct Preference Optimization: Your Language Model is Secretly a Reward Mo...
- (HITS Authority: 0.0156) Qwen Technical Report
- (HITS Authority: 0.0149) PaLM 2 Technical Report
- (HITS Authority: 0.0104) Efficient Memory Management for Large Language Model Serving with PagedAtte...
- (HITS Authority: 0.0096) One Fits All: Power General Time Series Analysis by Pretrained LM
- (HITS Authority: 0.0089) StarCoder: may the source be with you!
- (HITS Authority: 0.0087) Is ChatGPT a General-Purpose Natural Language Processing Task Solver?
- (HITS Authority: 0.0086) Time-LLM: Time Series Forecasting by Reprogramming Large Language Models
- (HITS Authority: 0.0084) HuaTuo: Tuning LLaMA Model with Chinese Medical Knowledge
- (HITS Authority: 0.0079) CodeT5+: Open Code Large Language Models for Code Understanding and Generat...
- (HITS Authority: 0.0077) A Survey on Evaluation of Large Language Models
- (HITS Authority: 0.0068) Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond
- (HITS Authority: 0.0067) G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment
- (HITS Authority: 0.0059) A Survey on Large Language Model based Autonomous Agents
- (HITS Authority: 0.0058) Augmented Language Models: a Survey
- (HITS Authority: 0.0057) ChatCAD: Interactive Computer-Aided Diagnosis on Medical Image using Large ...
- (HITS Authority: 0.0056) PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark fo...
- (HITS Authority: 0.0055) Language is All a Graph Needs


# Analysis for Window: 2024-2026
**Stats:** Papers: 2760, Edges: 898
**Final DBCV Score:** 0.5208
**Parameters Used:** `n_neighbors`: 35, `min_cluster_size`: 50, `min_samples`: 25, `epsilon`: 0.5

### Dominant Topics

- **Topic (ID: 1, Size: 2300, Confidence: 0.9974):** language, models, large, natural, learning, processing, model, survey, based, llm, generation, llms, using, ai, analysis
- **Topic (ID: 0, Size: 420, Confidence: 0.9946):** language, natural, models, processing, large, review, learning, medical, using, clinical, model, healthcare, protein, applications, systematic

### Top 20 Papers by Citation Count

- (Citation Count: 943.0000) Intelligent Clinical Documentation: Harnessing Generative AI for Patient-Ce...
- (Citation Count: 830.0000) Sentiment Analysis
- (Citation Count: 702.0000) Abstractive Text Summarization Using GAN
- (Citation Count: 400.0000) GPT-4 passes the bar exam
- (Citation Count: 394.0000) Large Language Models: A Survey
- (Citation Count: 388.0000) OLMo: Accelerating the Science of Language Models
- (Citation Count: 216.0000) AI-Driven Proactive Cloud Application Data Access Security
- (Citation Count: 215.0000) Statistical mechanics of deep learning
- (Citation Count: 210.0000) SegMamba: Long-range Sequential Modeling Mamba For 3D Medical Image Segment...
- (Citation Count: 205.0000) TrustLLM: Trustworthiness in Large Language Models
- (Citation Count: 181.0000) PMC-LLaMA: toward building open-source language models for medicine
- (Citation Count: 177.0000) A Survey on Large Language Models for Code Generation
- (Citation Count: 169.0000) SliceGPT: Compress Large Language Models by Deleting Rows and Columns
- (Citation Count: 168.0000) Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Clos...
- (Citation Count: 149.0000) Autoencoders and their applications in machine learning: a survey
- (Citation Count: 149.0000) Evaluating Text-to-Visual Generation with Image-to-Text Generation
- (Citation Count: 144.0000) Transformative Potential of AI in Healthcare: Definitions, Applications, an...
- (Citation Count: 136.0000) Qwen2-Audio Technical Report
- (Citation Count: 135.0000) Chatbots and Large Language Models in Radiology: A Practical Primer for Cli...
- (Citation Count: 125.0000) Security and Privacy Challenges of Large Language Models: A Survey

### Top 20 Papers by PageRank

- (PageRank: 0.0052) TrustLLM: Trustworthiness in Large Language Models
- (PageRank: 0.0036) OLMo: Accelerating the Science of Language Models
- (PageRank: 0.0032) Implicit Optimization Bias of Next-token Prediction in Linear Models
- (PageRank: 0.0032) Large Language Models: A Survey
- (PageRank: 0.0032) Evaluating Text-to-Visual Generation with Image-to-Text Generation
- (PageRank: 0.0030) GenAI-Bench: Evaluating and Improving Compositional Text-to-Visual Generati...
- (PageRank: 0.0027) SpeechVerse: A Large-scale Generalizable Audio Language Model
- (PageRank: 0.0019) SliceGPT: Compress Large Language Models by Deleting Rows and Columns
- (PageRank: 0.0019) Efficiency Optimization of Large-Scale Language Models Based on Deep Learni...
- (PageRank: 0.0018) Mechanics of Next Token Prediction with Self-Attention
- (PageRank: 0.0017) Qwen2-Audio Technical Report
- (PageRank: 0.0017) Implicit Geometry of Next-token Prediction: From Language Sparsity Patterns...
- (PageRank: 0.0016) PMC-LLaMA: toward building open-source language models for medicine
- (PageRank: 0.0016) ShieldGPT: An LLM-based Framework for DDoS Mitigation
- (PageRank: 0.0015) CAMEx: Curvature-aware Merging of Experts
- (PageRank: 0.0015) Self-Exploring Language Models: Active Preference Elicitation for Online Al...
- (PageRank: 0.0015) Exploratory Preference Optimization: Harnessing Implicit Q*-Approximation f...
- (PageRank: 0.0015) MoLEx: Mixture of Layer Experts for Finetuning with Sparse Upcycling
- (PageRank: 0.0015) Word-specific tonal realizations in Mandarin
- (PageRank: 0.0015) Time and thyme again: Connecting English spoken word duration to models of ...

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.4782) BitDistiller: Unleashing the Potential of Sub-4-Bit LLMs via Self-Distillat...
- (HITS Authority: 0.4424) DB-LLM: Accurate Dual-Binarization for Efficient LLMs
- (HITS Authority: 0.0543) SliceGPT: Compress Large Language Models by Deleting Rows and Columns
- (HITS Authority: 0.0098) ARB-LLM: Alternating Refined Binarizations for Large Language Models
- (HITS Authority: 0.0028) SLEB: Streamlining LLMs through Redundancy Verification and Elimination of ...
- (HITS Authority: 0.0015) Security and Privacy Challenges of Large Language Models: A Survey
- (HITS Authority: 0.0011) EdgeLLM: Fast On-Device LLM Inference With Speculative Decoding
- (HITS Authority: 0.0008) EdgeShard: Efficient LLM Inference via Collaborative Edge Computing
- (HITS Authority: 0.0007) A Survey on Mixture of Experts in Large Language Models
- (HITS Authority: 0.0007) Evaluation of Retrieval-Augmented Generation: A Survey
- (HITS Authority: 0.0006) PMC-LLaMA: toward building open-source language models for medicine
- (HITS Authority: 0.0006) Mobile-LLaMA: Instruction Fine-Tuning Open-Source LLM for Network Analysis ...
- (HITS Authority: 0.0006) Harnessing LLMs for API Interactions: A Framework for Classification and Sy...
- (HITS Authority: 0.0006) Generative AI Meets Semantic Communication: Evolution and Revolution of Com...
- (HITS Authority: 0.0006) A Survey on Large Language Models for Communication, Network, and Service M...
- (HITS Authority: 0.0006) Personalized Wireless Federated Learning for Large Language Models
- (HITS Authority: 0.0006) Distributed Foundation Models for Multi-Modal Learning in 6G Wireless Netwo...
- (HITS Authority: 0.0006) Multilingual Brain Surgeon: Large Language Models Can Be Compressed Leaving...
- (HITS Authority: 0.0004) SpeechVerse: A Large-scale Generalizable Audio Language Model
- (HITS Authority: 0.0003) WavLLM: Towards Robust and Adaptive Speech Large Language Model

