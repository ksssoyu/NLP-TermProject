paper_id,title,year,eigenvector,cluster_id
W2962784628,Neural Machine Translation of Rare Words with Subword Units,2016,0.29755929568088074,1
W2964308564,Neural Machine Translation by Jointly Learning to Align and Translate,2015,0.28538345341525395,1
W2963403868,Attention is All you Need,2017,0.22167021625177344,1
W2963216553,Improving Neural Machine Translation Models with Monolingual Data,2016,0.1496593676095961,1
W1902237438,Effective Approaches to Attention-based Neural Machine Translation,2015,0.1431474997482316,1
W2525778437,Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation,2016,0.12459117943608994,1
W2550821151,Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation,2017,0.12200798643133184,1
W2963532001,A Call for Clarity in Reporting BLEU Scores,2018,0.10686541515764854,1
W2963506925,Six Challenges for Neural Machine Translation,2017,0.09578358039168851,1
W3153411045,Domain Adaptation and Multi-Domain Adaptation for Neural Machine Translation: A Survey,2022,0.09109359767470783,1
W2963247703,"Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism",2016,0.0889698476559764,1
W2889326796,Understanding Back-Translation at Scale,2018,0.08621334011362966,1
W3198189804,Survey of Low-Resource Machine Translation,2022,0.08357384745721591,1
W3089472875,Neural Machine Translation: A Review,2020,0.08319052563847787,1
W3173162544,Neural Machine Translation for Low-resource Languages: A Survey,2022,0.08297437673231693,1
W2933138175,"fairseq: A Fast, Extensible Toolkit for Sequence Modeling",2019,0.08276525358150788,1
W2757291580,Neural Machine Translation,2020,0.08146050583658457,1
W3089276103,"Neural machine translation: Challenges, progress and future",2020,0.07007612741186611,1
W2958953787,Massively Multilingual Neural Machine Translation in the Wild: Findings and Challenges,2019,0.06751086988033281,1
W2963088995,Transfer Learning for Low-Resource Neural Machine Translation,2016,0.0668914637758886,1
W2919290281,Massively Multilingual Neural Machine Translation,2019,0.06651837968169057,1
W2100664567,On Using Very Large Target Vocabulary for Neural Machine Translation,2015,0.06429159116974452,1
W2251743902,Multi-Task Learning for Multiple Language Translation,2015,0.06331793452065956,1
W2903193068,Findings of the 2018 Conference on Machine Translation (WMT18),2018,0.06255374642238377,1
W2964007535,Zero-Resource Translation with Multi-Lingual Neural Machine Translation,2016,0.06212049119096408,1
W2962801832,Edinburgh Neural Machine Translation Systems for WMT 16,2016,0.06177795051983534,1
W2963212250,OpenNMT: Open-Source Toolkit for Neural Machine Translation,2017,0.059896036700598516,1
W2555745756,Toward Multilingual Neural Machine Translation with Universal Encoder and Decoder,2016,0.059421147822381136,1
W2561274697,Exploiting Source-side Monolingual Data in Neural Machine Translation,2016,0.05932786659244755,1
W2118434577,Addressing the Rare Word Problem in Neural Machine Translation,2015,0.05667593442814004,1
W2963206679,Phrase-Based &amp; Neural Unsupervised Machine Translation,2018,0.05565504327254362,1
W2996844526,A Comprehensive Survey of Multilingual Neural Machine Translation,2020,0.05519745945194476,1
W3204406378,Stanford neural machine translation systems for spoken language domains.,2015,0.05516671644725106,1
W1915251500,On Using Monolingual Corpora in Neural Machine Translation,2015,0.05497173077556446,1
W3017454464,Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation,2020,0.05485032492461753,1
W2963993537,Universal Neural Machine Translation for Extremely Low Resource Languages,2018,0.05403472880663464,1
W2963807318,Scaling Neural Machine Translation,2018,0.0530101876181347,1
W2963463964,Minimum Risk Training for Neural Machine Translation,2016,0.052327589923811334,1
W4235805184,Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Papers),2019,0.05226346203211616,1
W2888456631,Contextual Parameter Generation for Universal Neural Machine Translation,2018,0.050122077361918045,1
W3133652505,"Neural machine translation: A review of methods, resources, and tools",2020,0.04939839473655118,1
W2887920589,Rapid Adaptation of Neural Machine Translation to New Languages,2018,0.049289657564636054,1
W2902214435,Proceedings of the 2nd Workshop on Neural Machine Translation and Generation,2018,0.04909861570012412,1
W2970279348,Findings of the 2019 Conference on Machine Translation (WMT19),2019,0.04857969764476491,1
W2756566411,Copied Monolingual Data Improves Low-Resource Neural Machine Translation,2017,0.048247827778508424,1
W4231667498,"Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",2019,0.04818788509332389,1
W2949973181,Revisiting Low-Resource Neural Machine Translation: A Case Study,2019,0.04792783627457966,1
W2953190730,A Compact and Language-Sensitive Multilingual Translation Method,2019,0.04779486949905904,1
W2760656271,Findings of the 2017 Conference on Machine Translation (WMT17),2017,0.046847786810554765,1
W2531207078,Fully Character-Level Neural Machine Translation without Explicit Segmentation,2017,0.04662949819446911,1
W2970925270,"Simple, Scalable Adaptation for Neural Machine Translation",2019,0.046432630969185644,1
W2546938941,Dual Learning for Machine Translation,2016,0.04592769176911432,1
W2952614664,Effective Cross-lingual Transfer of Neural Machine Translation Models without Shared Vocabularies,2019,0.0457284719731352,1
W3093871477,Beyond English-Centric Multilingual Machine Translation,2020,0.04562202458535605,1
W2964073484,Consistency by Agreement in Zero-Shot Neural Machine Translation,2019,0.04537574691564929,1
W3104652516,Trivial Transfer Learning for Low-Resource Neural Machine Translation,2018,0.04509014261427839,1
W2963897095,A Survey of Domain Adaptation for Neural Machine Translation,2018,0.04502851058037886,1
W2799051177,Context-Aware Neural Machine Translation Learns Anaphora Resolution,2018,0.0441096961967905,1
W3035464238,Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation,2020,0.043734492331229204,1
W2964093087,Exploiting Cross-Sentence Context for Neural Machine Translation,2017,0.043619702043376764,1
W2952468927,MASS: Masked Sequence to Sequence Pre-training for Language Generation,2019,0.04296578943234756,1
W2963331137,A Teacher-Student Framework for Zero-Resource Neural Machine Translation,2017,0.04282032582663749,1
W2962778428,A neural interlingua for multilingual machine translation,2018,0.042664917978902483,1
W2767206889,Non-Autoregressive Neural Machine Translation,2017,0.041944875029735124,1
W2888541716,Meta-Learning for Low-Resource Neural Machine Translation,2018,0.04191756051109776,1
W2964045208,The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation,2018,0.04180842531285668,1
W2963736842,Sequence-Level Knowledge Distillation,2016,0.041745906791177595,1
W2963983698,Parameter Sharing Methods for Multilingual Self-Attentional Translation Models,2018,0.04170856657652826,1
W2970015022,Tagged Back-Translation,2019,0.04111835319034466,1
W2963542740,Learning Deep Transformer Models for Machine Translation,2019,0.041020891376028774,1
W2891924676,Three Strategies to Improve One-to-Many Multilingual Translation,2018,0.04089102230437861,1
W3090350559,A Survey of Multilingual Neural Machine Translation,2020,0.04064136783093298,1
W3193077216,A Survey on Low-Resource Neural Machine Translation,2021,0.040277097993670574,1
W2962712961,Improving the Transformer Translation Model with Document-Level Context,2018,0.0401747118378925,1
W3006381853,Incorporating BERT into Neural Machine Translation,2020,0.040096027812777046,1
W2886095922,Iterative Back-Translation for Neural Machine Translation,2018,0.04002821413249055,1
W2964034111,Multi-Source Neural Translation,2016,0.03993514894266817,1
W2963260202,Modeling Coverage for Neural Machine Translation,2016,0.03983366337297763,1
W2921280978,The Missing Ingredient in Zero-Shot Neural Machine Translation,2019,0.03948872368187365,1
W2962802109,Neural Machine Translation with Extended Context,2017,0.03928781333757092,1
W2963876447,Linguistic Input Features Improve Neural Machine Translation,2016,0.039194030565552276,1
W2951451051,Massively Multilingual Neural Machine Translation,2019,0.03887051619526412,1
W2970925677,Multilingual Neural Machine Translation with Language Clustering,2019,0.038616533674729454,1
W2962708992,Incorporating Discrete Translation Lexicons into Neural Machine Translation,2016,0.03845953481956594,1
W2798931235,Phrase-Based & Neural Unsupervised Machine Translation.,2018,0.038197574295168166,1
W2971120622,The FLORES Evaluation Datasets for Low-Resource Machine Translation: Nepali–English and Sinhala–English,2019,0.03805556417060827,1
W2552839021,A Convolutional Encoder Model for Neural Machine Translation,2017,0.03779555058942497,1
W2952650870,Multilingual Neural Machine Translation with Knowledge Distillation,2019,0.037663173001174714,1
W2744813330,An Empirical Comparison of Domain Adaptation Methods for Neural Machine Translation,2017,0.03754970735066515,1
W4390768253,Improving neural machine translation of languages with little data and rich morphology,2024,0.037539022571259406,1
W4225593490,"Neural Natural Language Generation: A Survey on Multilinguality, Multimodality, Controllability and Learning",2022,0.037510750815256545,1
W3166514234,Harnessing Multilinguality in Unsupervised Machine Translation for Rare Languages,2021,0.037422053824849644,1
W3153805297,Recipes for Adapting Pre-trained Monolingual and Multilingual Models to Machine Translation,2021,0.037344143667147986,1
W3098341425,Data Augmentation for Low-Resource Neural Machine Translation,2017,0.037337287838281615,1
W2963347649,Using the Output Embedding to Improve Language Models,2017,0.037215153215889564,1
W2964013027,Unsupervised Neural Machine Translation with Weight Sharing,2018,0.03707186539566543,1
W2963434219,Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement,2018,0.0369843712565052,1
W2594229957,Nematus: a Toolkit for Neural Machine Translation,2017,0.03682896539837857,1
W2537667581,SYSTRAN's Pure Neural Machine Translation Systems,2016,0.03670411748224014,1
W2995722251,A Survey on Document-level Neural Machine Translation: Methods and Evaluation,2019,0.03669326430329047,1
W2962943802,Selective Attention for Context-aware Neural Machine Translation,2019,0.03664738623839468,1
W3106106701,Revisiting Modularized Multilingual NMT to Meet Industrial Demands,2020,0.0363551433256512,1
W2963324947,Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models,2016,0.03562017588229046,1
W4211185538,Neural Machine Translation,2020,0.03556244217076033,1
W4378974641,Transformer: A General Framework from Machine Translation to Others,2023,0.03548323709693206,1
W2555428947,Unsupervised Pretraining for Sequence to Sequence Learning,2017,0.03534406351007282,1
W2963842551,Learning to Remember Translation History with a Continuous Cache,2018,0.03519920917625686,1
W2964190861,Classical Structured Prediction Losses for Sequence to Sequence Learning,2018,0.035162236897568436,1
W3082017874,When and Why is Unsupervised Neural Machine Translation Useless?,2020,0.03513272962746891,1
W3180521376,Progress in Machine Translation,2021,0.03502614993258252,1
W2963569817,Bi-Directional Neural Machine Translation with Synthetic Parallel Data,2018,0.03499395439681147,1
W2964120396,A Large-Scale Test Set for the Evaluation of Context-Aware Pronoun Translation in Neural Machine Translation,2018,0.03481122988135512,1
W2952809536,Pay Less Attention with Lightweight and Dynamic Convolutions,2019,0.03461875339123469,1
W2963633299,"Transfer Learning across Low-Resource, Related Languages for Neural Machine Translation",2017,0.034554217358261516,1
W3105038888,Multi-task Learning for Multilingual Neural Machine Translation,2020,0.034399456194509445,1
W2970295111,Facebook FAIR’s WMT19 News Translation Task Submission,2019,0.034248537606042406,1
W2994928925,Incorporating BERT into Neural Machine Translation,2020,0.0340705030152774,1
W2970311224,Exploiting Monolingual Data at Scale for Neural Machine Translation,2019,0.033887453617018407,1
W2950940239,Domain Adaptation of Neural Machine Translation by Lexicon Induction,2019,0.03380546790059577,1
W2985204668,Zero-Resource Neural Machine Translation with Monolingual Pivot Data,2019,0.033704612875356726,1
W2964085268,When and Why Are Pre-Trained Word Embeddings Useful for Neural Machine Translation?,2018,0.03370447806875736,1
W2888159079,Has Machine Translation Achieved Human Parity? A Case for Document-level Evaluation,2018,0.03362900919238201,1
W2964289193,Document Context Neural Machine Translation with Memory Networks,2018,0.03354521497776951,1
W2903810591,Tied Transformers: Neural Machine Translation with Shared Encoder and Decoder,2019,0.03354521356315201,1
W2963366389,Dynamic Data Selection for Neural Machine Translation,2017,0.03354345955840947,1
W3202201199,On the Complementarity between Pre-Training and Back-Translation for Neural Machine Translation,2021,0.03342259958207622,1
W3104273515,Language Model Prior for Low-Resource Neural Machine Translation,2020,0.033415435224045796,1
W2888539709,Why Self-Attention? A Targeted Evaluation of Neural Machine Translation Architectures,2018,0.03340515328094757,1
W2963919854,On the Impact of Various Types of Noise on Neural Machine Translation,2018,0.0334031580945267,1
W2594990650,Massive Exploration of Neural Machine Translation Architectures,2017,0.033218053591068955,1
W2899015110,Multilingual NMT with a Language-Independent Attention Bridge,2019,0.03321356381935319,1
W3101672304,A Multilingual View of Unsupervised Machine Translation,2020,0.03308761020774198,1
W2964048171,Towards Robust Neural Machine Translation,2018,0.03305922136357316,1
W2971302374,Improving Back-Translation with Uncertainty-based Confidence Estimation,2019,0.0328162309168125,1
W2945534329,Effective Cross-lingual Transfer of Neural Machine Translation Models without Shared Vocabularies,2019,0.03271179890710088,1
W2970109976,Pivot-based Transfer Learning for Neural Machine Translation between Non-English Languages,2019,0.03268926232068888,1
W2902614977,Using Monolingual Data in Neural Machine Translation: a Systematic Study,2018,0.032664353614356705,1
W3175260681,Language Tags Matter for Zero-Shot Neural Machine Translation,2021,0.032649305894685836,1
W3126910220,Extremely low-resource neural machine translation for Asian languages,2020,0.032550856181656984,1
W3174724858,Multilingual Translation from Denoising Pre-Training,2021,0.03252975676651475,1
W3214581470,Improving Neural Machine Translation by Bidirectional Training,2021,0.032437128006806225,1
W2610245951,A Teacher-Student Framework for Zero-Resource Neural Machine Translation,2017,0.03242324261409624,1
W2891534142,Document-Level Neural Machine Translation with Hierarchical Attention Networks,2018,0.03237913867130291,1
W3047397334,A Survey of Orthographic Information in Machine Translation,2021,0.032201857604107556,1
W3093816530,Enriching the transfer learning with pre-trained lexicon embedding for low-resource neural machine translation,2021,0.032189467596059826,1
W3115362515,Dynamic Curriculum Learning for Low-Resource Neural Machine Translation,2020,0.03205547605918226,1
W3106144205,Vocabulary Adaptation for Domain Adaptation in Neural Machine Translation,2020,0.03204253137082472,1
W2963499433,A Comparison of Transformer and Recurrent Neural Networks on Multilingual Neural Machine Translation,2018,0.0319221505634945,1
W2887516053,Enhancement of Encoder and Attention Using Target Monolingual Corpora in Neural Machine Translation,2018,0.031883244535373174,1
W3101683892,Dynamic Context Selection for Document-level Neural Machine Translation via Reinforcement Learning,2020,0.03183985488566235,1
W3173190788,Contrastive Learning for Many-to-many Multilingual Neural Machine Translation,2021,0.03179349486071713,1
W3156404059,<i>Samanantar</i>: The Largest Publicly Available Parallel Corpora Collection for 11 Indic Languages,2022,0.03174953534554036,1
W2970290486,Improving Deep Transformer with Depth-Scaled Initialization and Merged Attention,2019,0.031740943421682814,1
W2952446148,"When a Good Translation is Wrong in Context: Context-Aware Machine Translation Improves on Deixis, Ellipsis, and Lexical Cohesion",2019,0.03167176942114816,1
W2593341061,Doubly-Attentive Decoder for Multi-modal Neural Machine Translation,2017,0.031664789347143736,1
W3103915675,ChrEn: Cherokee-English Machine Translation for Endangered Language Revitalization,2020,0.031612907899756536,1
W3200578235,Multilingual Translation via Grafting Pre-trained Language Models,2021,0.03159313377619018,1
W2963251942,A Character-level Decoder without Explicit Segmentation for Neural Machine Translation,2016,0.03158128927089128,1
W2970544750,Combining Local and Document-Level Context: The LMU Munich Neural Machine Translation System at WMT19,2019,0.03150343870700454,1
W2886342729,Regularized Training Objective for Continued Training for Domain Adaptation in Neural Machine Translation,2018,0.031148504369888634,1
W3091540052,Data Diversification: A Simple Strategy For Neural Machine Translation,2019,0.031094654708355842,1
W4388953014,Low-Resource Neural Machine Translation: A Systematic Literature Review,2023,0.030904128550395628,1
W3035254119,"In Neural Machine Translation, What Does Transfer Learning Transfer?",2020,0.030901985296433145,1
W2988975212,Mask-Predict: Parallel Decoding of Conditional Masked Language Models,2019,0.030893567332965832,1
W2970845336,CUED@WMT19:EWC&amp;LMs,2019,0.030847623452457673,1
W2985165968,"Domain, Translationese and Noise in Synthetic Data for Neural Machine Translation",2019,0.030794577585942437,1
W2963141266,Trainable Greedy Decoding for Neural Machine Translation,2017,0.03075819129472746,1
W2963086938,Improving Lexical Choice in Neural Machine Translation,2018,0.03073760413403168,1
W2983108239,When and Why is Document-level Context Useful in Neural Machine Translation?,2019,0.030723460783116538,1
W3174636484,Importance-based Neuron Allocation for Multilingual Neural Machine Translation,2021,0.030623791356890057,1
W2952153923,Improved Zero-shot Neural Machine Translation via Ignoring Spurious Correlations,2019,0.03057451000977479,1
W2964343359,Marian: Fast Neural Machine Translation in C++,2018,0.030382745332026152,1
W3034716087,On The Evaluation of Machine Translation Systems Trained With Back-Translation,2020,0.030377340080874463,1
W2758310181,Using Target-side Monolingual Data for Neural Machine Translation through Multi-task Learning,2017,0.030354895601738804,1
W2913659301,The FLoRes Evaluation Datasets for Low-Resource Machine Translation: Nepali-English and Sinhala-English.,2019,0.03030143793771883,1
W2962732637,Character-based Neural Machine Translation,2016,0.030294601805960393,1
W2962700074,Neural System Combination for Machine Translation,2017,0.030278621788160594,1
W3042199843,Better Document-Level Machine Translation with Bayes’ Rule,2020,0.03023993963964997,1
W3041269366,Massive Exploration of Pseudo Data for Grammatical Error Correction,2020,0.03021150198087009,1
W2970521905,An Empirical Study of Incorporating Pseudo Data into Grammatical Error Correction,2019,0.03011673023257057,1
W2767019613,Evaluating Discourse Phenomena in Neural Machine Translation,2018,0.030019225077113836,1
W2970611505,Synchronously Generating Two Languages with Interactive Decoding,2019,0.02997740247762293,1
W3169001897,Counterfactual Data Augmentation for Neural Machine Translation,2021,0.029936492089955365,1
W2890007195,Unsupervised Statistical Machine Translation,2018,0.029749198195357207,1
W2971152344,Improving Zero-shot Translation with Language-Independent Constraints,2019,0.02966855244160104,1
W2890964657,Layer-Wise Coordination between Encoder and Decoder for Neural Machine Translation,2018,0.029575852142837027,1
W2803728065,From Feature To Paradigm: Deep Learning In Machine Translation,2018,0.02956616497567296,1
W2890244613,Addressing Troublesome Words in Neural Machine Translation,2018,0.02956504668772145,1
W3106321930,Pre-training Multilingual Neural Machine Translation by Leveraging Alignment Information,2020,0.02950789994777898,1
W2252272516,Montreal Neural Machine Translation Systems for WMT’15,2015,0.02950078876704653,1
W3022839720,A Diverse Data Augmentation Strategy for Low-Resource Neural Machine Translation,2020,0.029456284391630838,1
W2963174344,Simple Fusion: Return of the Language Model,2018,0.02938385565372365,1
W2962807144,Multilingual Neural Machine Translation with Task-Specific Attention,2018,0.029346184116963766,1
W3034938700,Norm-Based Curriculum Learning for Neural Machine Translation,2020,0.02932185916908187,1
W3035531963,Bilingual Dictionary Based Neural Machine Translation without Using Parallel Sentences,2020,0.02926667529322159,1
W2963109507,Joint Training for Neural Machine Translation Models with Monolingual Data,2018,0.029214771373483384,1
W2962714778,Neural Machine Translation Decoding with Terminology Constraints,2018,0.02918906688627902,1
W2945059185,Syntax-Enhanced Neural Machine Translation with Syntax-Aware Word Representations,2019,0.0291727677958731,1
W4241461373,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop,2021,0.029126465253821513,1
W2963823140,Robust Neural Machine Translation with Doubly Adversarial Inputs,2019,0.02910414700517035,1
W3093404841,Capturing Longer Context for Document-level Neural Machine Translation: A Multi-resolutional Approach.,2020,0.0289192051341543,1
W3106504817,Fixed Encoder Self-Attention Patterns in Transformer-Based Machine Translation,2020,0.028901402995203076,1
W2964302946,Modeling Localness for Self-Attention Networks,2018,0.028896929290828724,1
W2962931466,Exploiting Deep Representations for Neural Machine Translation,2018,0.028822621709798876,1
W2567571499,Fast Domain Adaptation for Neural Machine Translation,2016,0.028753266798418078,1
W2971347700,Context-Aware Monolingual Repair for Neural Machine Translation,2019,0.028686981714187713,1
W3005724337,A Survey of Deep Learning Techniques for Neural Machine Translation,2020,0.028638185908320287,1
W4397012280,A survey of context in neural machine translation and its evaluation,2024,0.028583274757034465,1
W2997518171,Cross-Lingual Pre-Training Based Transfer for Zero-Shot Neural Machine Translation,2020,0.02856961080212174,1
W2994772196,Multimodal machine translation through visuals and speech,2020,0.028568528793258934,1
W2923622379,Competence-based Curriculum Learning for Neural Machine Translation,2019,0.028557800043359907,1
W2785093437,Dual Transfer Learning for Neural Machine Translation with Marginal Distribution Regularization,2018,0.02851558751370747,1
W3035313462,Unsupervised Multimodal Neural Machine Translation with Pseudo Visual Pivoting,2020,0.028485321294666972,1
W3014432386,Low Resource Neural Machine Translation: A Benchmark for Five African Languages,2020,0.028338935189017537,1
W3105912780,CSP:Code-Switching Pre-training for Neural Machine Translation,2020,0.028303306283857375,1
W2964082031,Approaching Neural Grammatical Error Correction as a Low-Resource Machine Translation Task,2018,0.028267514502883437,1
W3034351728,A Simple and Effective Unified Encoder for Document-Level Machine Translation,2020,0.028241692728702854,1
W3026592756,Towards More Diverse Input Representation for Neural Machine Translation,2020,0.028154012038594037,1
W2963713328,Variational Neural Machine Translation,2016,0.028088859523584506,1
W2988249555,Domain Robustness in Neural Machine Translation,2019,0.0279309733999789,1
W3039805635,Non-Autoregressive Machine Translation with Disentangled Context Transformer,2020,0.027916338655146908,1
W2888808532,Back-Translation Sampling by Targeting Difficult Words in Neural Machine Translation,2018,0.027848876110931852,1
W2958127121,Facebook FAIR's WMT19 News Translation Task Submission,2019,0.027848141303165586,1
W2798389157,Filtering and Mining Parallel Data in a Joint Multilingual Space,2018,0.02782467647799631,1
W2970045405,Jointly Learning to Align and Translate with Transformer Models,2019,0.02775430521874403,1
W2963773505,A Stable and Effective Learning Strategy for Trainable Greedy Decoding,2018,0.02769077861882502,1
W3089025530,Energy-Based Reranking: Improving Neural Machine Translation Using Energy-Based Models,2021,0.02762442433128191,1
W2946379889,Curriculum Learning for Domain Adaptation in Neural Machine Translation,2019,0.027623612265223457,1
W2597891111,On integrating a language model into neural machine translation,2017,0.027620705277270816,1
W2948798935,Learning Deep Transformer Models for Machine Translation,2019,0.027594502216294742,1
W3199890931,Improving Multilingual Translation by Representation and Gradient Regularization,2021,0.02757315498033449,1
W2970076840,A Neural Grammatical Error Correction System Built On Better Pre-training and Sequential Transfer Learning,2019,0.0275699711072142,1
W2581101319,Incorporating Global Visual Features into Attention-based Neural Machine Translation.,2017,0.027544330863101714,1
W2985301125,Exploiting Multilingualism through Multistage Fine-Tuning for Low-Resource Neural Machine Translation,2019,0.02749522800435093,1
W3118485656,Diving Deep into Context-Aware Neural Machine Translation,2020,0.027464787777426135,1
W2888442053,A Study of Reinforcement Learning for Neural Machine Translation,2018,0.027455463838995012,1
W2963062480,Sparse and Constrained Attention for Neural Machine Translation,2018,0.027447678908445544,1
W2542860122,Bridging Neural Machine Translation and Bilingual Dictionaries,2016,0.027438898531364254,1
W2963641561,Neural versus Phrase-Based Machine Translation Quality: a Case Study,2016,0.02713532145611097,1
W3175374354,Learning Language Specific Sub-network for Multilingual Machine Translation,2021,0.02710178109003753,1
W2592864539,Neural Machine Translation and Sequence-to-sequence Models: A Tutorial,2017,0.027101567773568848,1
W2970810442,Encoders Help You Disambiguate Word Senses in Neural Machine Translation,2019,0.027052142474077594,1
W2890501761,Semi-Autoregressive Neural Machine Translation,2018,0.02694342721149862,1
W2963653811,Graph Convolutional Encoders for Syntax-aware Neural Machine Translation,2017,0.026921148309248345,1
W2970009562,Neural Machine Translation of Low-Resource and Similar Languages with Backtranslation,2019,0.026878434903183993,1
W2970694516,Simple and Effective Noisy Channel Modeling for Neural Machine Translation,2019,0.026869760545593487,1
W3102507836,Enhancing Context Modeling with a Query-Guided Capsule Network for Document-level Translation,2019,0.02685257627606469,1
W2964110616,Transformer-XL: Attentive Language Models beyond a Fixed-Length Context,2019,0.0268290765145008,1
W2798761464,How Much Attention Do You Need? A Granular Analysis of Neural Machine Translation Architectures,2018,0.02682532276867059,1
W3019166713,A Survey of the Usages of Deep Learning for Natural Language Processing,2020,0.0267992003787235,1
W3176466730,Continual Mixed-Language Pre-Training for Extremely Low-Resource Neural Machine Translation,2021,0.026749706182338424,1
W3174481817,Self-Training Sampling with Monolingual Data Uncertainty for Neural Machine Translation,2021,0.026707090554410444,1
W3176366152,Improving Zero-Shot Translation by Disentangling Positional Information,2021,0.026692380399832183,1
W3036422752,Neural machine translation of low-resource languages using SMT phrase pair injection,2020,0.026669641665369684,1
W2963913268,Modeling Source Syntax for Neural Machine Translation,2017,0.02665073997985838,1
W2963011474,Stronger Baselines for Trustable Results in Neural Machine Translation,2017,0.02663036624459109,1
W3035214886,"On Exposure Bias, Hallucination and Domain Shift in Neural Machine Translation",2020,0.026625835211753414,1
W2884083742,Dependency-to-Dependency Neural Machine Translation,2018,0.02661934323004481,1
W3135335819,"Deep Encoder, Shallow Decoder: Reevaluating Non-autoregressive Machine Translation",2020,0.02659178506443878,1
W2936597270,Corpora Generation for Grammatical Error Correction,2019,0.02654946278501671,1
W3214532454,Learning to Rewrite for Non-Autoregressive Neural Machine Translation,2021,0.026492068442198237,1
W2948197522,Syntactically Supervised Transformers for Faster Neural Machine Translation,2019,0.026440218723370094,1
W4377079846,A Survey on Non-Autoregressive Generation for Neural Machine Translation and Beyond,2023,0.026396363380022173,1
W2739978843,Joint Training for Pivot-Based Neural Machine Translation,2019,0.026382550261545307,1
W2885637246,Linguistic Knowledge-Aware Neural Machine Translation,2018,0.0263561072768524,1
W2935811960,Synchronous Bidirectional Neural Machine Translation,2019,0.02635511839330466,1
W3174659183,Do Context-Aware Translation Models Pay the Right Attention?,2021,0.026341693860835538,1
W2963648186,Towards String-To-Tree Neural Machine Translation,2017,0.02627410561252142,1
W4385573489,ConsistTL: Modeling Consistency in Transfer Learning for Low-Resource Neural Machine Translation,2022,0.02624383344161442,1
W3115711567,Revisiting Low Resource Status of Indian Languages in Machine Translation,2020,0.026193005290968824,1
W2949920209,Freezing Subnetworks to Analyze Domain Adaptation in Neural Machine Translation,2018,0.02617939385468157,1
W2883900035,Incorporating Statistical Machine Translation Word Knowledge Into Neural Machine Translation,2018,0.026176502025610674,1
W2892244498,Multi-Domain Neural Machine Translation with Word-Level Domain Context Discrimination,2018,0.026164746880554233,1
W2946068894,Soft Contextual Data Augmentation for Neural Machine Translation,2019,0.02615930385347132,1
W3134357720,A Survey on Document-level Neural Machine Translation,2021,0.02615437818490319,1
W3006801027,Fixed Encoder Self-Attention Patterns in Transformer-Based Machine Translation,2020,0.02613712181214879,1
W2798465082,Adaptive Knowledge Sharing in Multi-Task Learning: Improving Low-Resource Neural Machine Translation,2018,0.026134184197619526,1
W3166829167,Multi-Hop Transformer for Document-Level Machine Translation,2021,0.026108799123056983,1
W3200396895,Counter-Interference Adapter for Multilingual Machine Translation,2021,0.026108515784540494,1
W2962945603,Translating Phrases in Neural Machine Translation,2017,0.026085361044579407,1
W3035317912,Distilling Knowledge Learned in BERT for Text Generation,2020,0.026075798447064622,1
W2946375144,Levenshtein Transformer,2019,0.02606676199884259,1
W2760452458,Effective Domain Mixing for Neural Machine Translation,2017,0.02605685976779307,1
W3103544486,Reference Language based Unsupervised Neural Machine Translation,2020,0.026037856112212474,1
W2759173152,Improving Word Sense Disambiguation in Neural Machine Translation with Sense Embeddings,2017,0.026022924186489573,1
W2983590910,Context-Aware Neural Machine Translation Decoding,2019,0.025990329568248753,1
W3166567197,Towards Continual Learning for Multilingual Machine Translation via Vocabulary Substitution,2021,0.025925497594974495,1
W4385570335,Improving Long Context Document-Level Machine Translation,2023,0.025906807612887592,1
W2962822108,Multi-Head Attention with Disagreement Regularization,2018,0.02590000512186363,1
W4285105102,CipherDAug: Ciphertext based Data Augmentation for Neural Machine Translation,2022,0.02585365315066401,1
W2888519496,SwitchOut: an Efficient Data Augmentation Algorithm for Neural Machine Translation,2018,0.025809558476897476,1
W2963277143,Context-dependent word representation for neural machine translation,2017,0.025782721003966284,1
W2963122608,Domain Control for Neural Machine Translation,2017,0.025773479019147224,1
W2757592053,Multi-Domain Neural Machine Translation through Unsupervised Adaptation,2017,0.02575758963978782,1
W2765961751,Unsupervised Machine Translation Using Monolingual Corpora Only,2017,0.025750100489210472,1
W2944815030,MASS: Masked Sequence to Sequence Pre-training for Language Generation,2019,0.025611528067618617,1
W2467834614,Controlling Politeness in Neural Machine Translation via Side Constraints,2016,0.025569002328761553,1
W2984500026,Data augmentation using back-translation for context-aware neural machine translation,2019,0.02555343652113362,1
W2986562961,On the use of BERT for Neural Machine Translation,2019,0.02554886365374018,1
W2963661253,Tree-to-Sequence Attentional Neural Machine Translation,2016,0.025501301432402215,1
W2970777192,Adaptively Sparse Transformers,2019,0.025501046183901643,1
W3174089676,On the Copying Behaviors of Pre-Training for Neural Machine Translation,2021,0.025447105747552552,1
W2970038984,APE at Scale and Its Implications on MT Evaluation Biases,2019,0.025432453243790627,1
W2767899794,Synthetic and Natural Noise Both Break Neural Machine Translation,2017,0.02541739207322489,1
W3170463198,Pruning-then-Expanding Model for Domain Adaptation of Neural Machine Translation,2021,0.0253926005821566,1
W2963443683,An Effective Approach to Unsupervised Machine Translation,2019,0.02537742442778523,1
W3034640977,Unsupervised Domain Clusters in Pretrained Language Models,2020,0.025342635509833473,1
W2952356761,Retrieving Sequential Information for Non-Autoregressive Neural Machine Translation,2019,0.025276539435886963,1
W3170427498,Fast Nearest Neighbor Machine Translation,2022,0.0252685849114578,1
W3113488190,Optimizing Transformer for Low-Resource Neural Machine Translation,2020,0.025266647932055193,1
W2797913374,Investigating Backtranslation in Neural Machine Translation,2018,0.025266347080360994,1
W2888520903,Training Deeper Neural Machine Translation Models with Transparent Attention,2018,0.025195428169494275,1
W2951476960,Generalized Data Augmentation for Low-Resource Translation,2019,0.025163431023922316,1
W2964093309,Depth Growing for Neural Machine Translation,2019,0.025041640047930528,1
W2963536265,Non-Autoregressive Machine Translation with Auxiliary Regularization,2019,0.025033914509721325,1
W2897507397,An Analysis of Attention Mechanisms: The Case of Word Sense Disambiguation in Neural Machine Translation,2018,0.025011218300853483,1
W3174255604,Rejuvenating Low-Frequency Words: Making the Most of Parallel Data in Non-Autoregressive Translation,2021,0.024947202254298972,1
W3035577668,AdvAug: Robust Adversarial Augmentation for Neural Machine Translation,2020,0.02491026828255391,1
W4205243694,Arabic Machine Translation: A Survey with Challenges and Future Directions,2021,0.024894936419005826,1
W2897983179,Neural Machine Translation with Deep Attention,2018,0.02487248979298955,1
W2970247882,Incorporating Source Syntax into Transformer-Based Neural Machine Translation,2019,0.02481521502521886,1
W3127719526,Share or Not? Learning to Schedule Language-Specific Capacity for Multilingual Translation,2021,0.024763156788375634,1
W3207091856,Why don’t people use character-level machine translation?,2022,0.024734592627210304,1
W3101286153,Reusing a Pretrained Language Model on Languages with Limited Corpora for Unsupervised NMT,2020,0.024678811492864477,1
W3173691187,G-Transformer for Document-Level Machine Translation,2021,0.02463262413357212,1
W4408384615,Improving Neural Machine Translation Through Code‐Mixed Data Augmentation,2025,0.0246076083223882,1
W2899490399,Improving Zero-Shot Translation of Low-Resource Languages,2018,0.024571649256078694,1
W2222235228,Mutual Information and Diverse Decoding Improve Neural Machine Translation,2016,0.024557733771506517,1
W2963672008,Learning Joint Multilingual Sentence Representations with Neural Machine Translation,2017,0.024542907433950056,1
W4285121328,Rethinking Document-level Neural Machine Translation,2022,0.024538457650844087,1
W4280557709,An empirical study of low-resource neural machine translation of manipuri in multilingual settings,2022,0.024516430788218278,1
W3123615524,Random Feature Attention,2021,0.02447106855081903,1
W2963413917,Unsupervised Neural Machine Translation with SMT as Posterior Regularization,2019,0.024451519434012813,1
W2950886580,Latent Variable Model for Multi-modal Translation,2019,0.02444166067327804,1
W2527845440,Is Neural Machine Translation Ready for Deployment? A Case Study on 30 Translation Directions,2016,0.02443318699193153,1
W2964108048,From Bilingual to Multilingual Neural Machine Translation by Incremental Training,2019,0.024429080246290872,1
W2759461255,Adapting Neural Machine Translation with Parallel Synthetic Data,2017,0.024429010002221318,1
W2970858854,Findings of the WMT 2019 Shared Task on Parallel Corpus Filtering for Low-Resource Conditions,2019,0.024417714493241694,1
W3177172118,Fully Non-autoregressive Neural Machine Translation: Tricks of the Trade,2021,0.02438016896144836,1
W2788330850,Search Engine Guided Neural Machine Translation,2018,0.02434115269649904,1
W2949745489,Neural Machine Translation with Reordering Embeddings,2019,0.024287652336635924,1
W3030384960,Benchmarking Neural and Statistical Machine Translation on Low-Resource African Languages,2020,0.024282967484837457,1
W2982026991,Controlling the Output Length of Neural Machine Translation,2019,0.02421738051709948,1
W2962863357,Regularization techniques for fine-tuning in neural machine translation,2017,0.02421001272374558,1
W3023986361,Leveraging Monolingual Data with Self-Supervision for Multilingual Neural Machine Translation,2020,0.02417491542279872,1
W3082674894,Sockeye: A Toolkit for Neural Machine Translation,2017,0.024167762068583558,1
W2997197207,"MetaMT, a Meta Learning Method Leveraging Multiple Domain Data for Low Resource Machine Translation",2020,0.02413104586139654,1
W2963333747,Incorporating Structural Alignment Biases into an Attentional Neural Translation Model,2016,0.024077618566448182,1
W2970316683,Investigating Multilingual NMT Representations at Scale,2019,0.02404514231306934,1
W2892213699,End-to-End Non-Autoregressive Neural Machine Translation with Connectionist Temporal Classification,2018,0.02404326554024851,1
W3200230461,Non-Parametric Unsupervised Domain Adaptation for Neural Machine Translation,2021,0.023972840326594903,1
W3046531489,Document-level Neural MT: A Systematic Comparison,2020,0.023968116627798523,1
W3034719878,Language-aware Interlingua for Multilingual Neural Machine Translation,2020,0.023931072609878652,1
W3102475290,Dynamic Context-guided Capsule Network for Multimodal Machine Translation,2020,0.02389850886412633,1
W2997003477,Neural Machine Translation With GRU-Gated Attention Model,2020,0.023852253163957664,1
W2970692082,On NMT Search Errors and Model Errors: Cat Got Your Tongue?,2019,0.023830023441913144,1
W2963665552,Breaking the Beam Search Curse: A Study of (Re-)Scoring Methods and Stopping Criteria for Neural Machine Translation,2018,0.023825406500596877,1
W3104688854,"Not Low-Resource Anymore: Aligner Ensembling, Batch Filtering, and New Datasets for Bengali-English Machine Translation",2020,0.023818846162779066,1
W3179639371,Character-based Neural Semantic Parsing,2021,0.023740631930709678,1
W2970871182,Findings of the WMT 2019 Shared Task on Automatic Post-Editing,2019,0.023725034052984494,1
W3182737888,BERT-JAM: Maximizing the utilization of BERT for neural machine translation,2021,0.02371699298918962,1
W2963149635,Non-Parametric Adaptation for Neural Machine Translation,2019,0.02370286580686331,1
W2766182427,Unsupervised Neural Machine Translation,2017,0.02365175375489137,1
W2566623769,Neural Machine Translation by Minimising the Bayes-risk with Respect to Syntactic Translation Lattices,2017,0.02364647219311521,1
W2899423466,Convolutional Self-Attention Networks,2019,0.023639984203345493,1
W4221017237,Low-resource Neural Machine Translation: Methods and Trends,2022,0.02359594007035673,1
W2889411721,Multi-Source Syntactic Neural Machine Translation,2018,0.023592756745718833,1
W3156064004,Zero-Shot Cross-Lingual Transfer of Neural Machine Translation with Multilingual Pretrained Encoders,2021,0.02356753293368948,1
W2609278920,An Empirical Analysis of NMT-Derived Interlingual Embeddings and Their Use in Parallel Sentence Identification,2017,0.023557350367198564,1
W2885950361,The Sockeye 2 Neural Machine Translation Toolkit at AMTA 2020,2020,0.023527811170047895,1
W2963382396,Correcting Length Bias in Neural Machine Translation,2018,0.023468967633504083,1
W2962717763,Exploiting Linguistic Resources for Neural Machine Translation Using Multi-task Learning,2017,0.023468676647235325,1
W2952509486,"fairseq: A Fast, Extensible Toolkit for Sequence Modeling.",2019,0.023427533932552078,1
W3035629723,Does Multi-Encoder Help? A Case Study on Context-Aware Neural Machine Translation,2020,0.02333129726229136,1
W2951338945,Shared-Private Bilingual Word Embeddings for Neural Machine Translation,2019,0.023287153782123347,1
W2945383715,Overcoming Catastrophic Forgetting During Domain Adaptation of Neural Machine Translation,2019,0.02325710283488248,1
W2989276524,Recycling a Pre-trained BERT Encoder for Neural Machine Translation,2019,0.02317305644464693,1
W2963792777,Memory-augmented Neural Machine Translation,2017,0.023167022594000646,1
W2964334713,Neural Machine Translation Leveraging Phrase-based Models in a Hybrid Search,2017,0.023115402235992327,1
W3119872155,Findings of the WMT 2020 Shared Task on Parallel Corpus Filtering and Alignment,2020,0.02310890488699266,1
W2552124255,"Multi-way, multilingual neural machine translation",2016,0.023106843550092453,1
W2970529093,Microsoft Translator at WMT 2019: Towards Large-Scale Document-Level Neural Machine Translation,2019,0.023052698619780914,1
W3099417250,Token-level Adaptive Training for Neural Machine Translation,2020,0.023040713270569762,1
W3034425996,ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine Translation,2020,0.023024579479999117,1
W3034427563,Using Context in Neural Machine Translation Training Objectives,2020,0.02297377682437453,1
W2808508619,Modeling Coherence for Neural Machine Translation with Dynamic and Topic Caches,2017,0.022950292210675623,1
W2963641307,Modeling Recurrence for Transformer,2019,0.022925759078086305,1
W3034955736,Hard-Coded Gaussian Attention for Neural Machine Translation,2020,0.022925338221484175,1
W3164747806,TranSmart: A Practical Interactive Machine Translation System,2021,0.022848476729554482,1
W2884159461,A Survey of the Usages of Deep Learning in Natural Language Processing,2018,0.022835270139124366,1
W3212651325,Multilingual Unsupervised Neural Machine Translation with Denoising Adapters,2021,0.022812952313399866,1
W2539201987,Neural Machine Translation Advised by Statistical Machine Translation,2017,0.022798631847977088,1
W2979636403,Transformers without Tears: Improving the Normalization of Self-Attention,2019,0.022794866787565222,1
W3173680274,Modeling Bilingual Conversational Characteristics for Neural Chat Translation,2021,0.022792950796214774,1
W2741049976,Paraphrasing Revisited with Neural Machine Translation,2017,0.02277743875726393,1
W2963407669,Attention Strategies for Multi-Source Sequence-to-Sequence Learning,2017,0.022769511881508334,1
W2921311659,Neutron: An Implementation of the Transformer Translation Model and its Variants,2019,0.022728800495298157,1
W2950858167,Sparse Sequence-to-Sequence Models,2019,0.0227272783697078,1
W3034474651,Tagged Back-translation Revisited: Why Does It Really Work?,2020,0.022718529349588894,1
W2786058094,A Bag of Useful Tricks for Practical Neural Machine Translation: Embedding Layer Initialization and Large Batch Size,2017,0.02270947471601487,1
W3011824510,Unsupervised Neural Machine Translation With Cross-Lingual Language Representation Agreement,2020,0.02269760090399628,1
W3174160883,Fast and Accurate Neural Machine Translation with Translation Memory,2021,0.022696929459926185,1
W2950485982,Self-Supervised Neural Machine Translation,2019,0.022680729652235804,1
W3105306115,Improving the Efficiency of Grammatical Error Correction with Erroneous Span Detection and Correction,2020,0.022672263390373995,1
W2964029788,Lexically Constrained Decoding for Sequence Generation Using Grid Beam Search,2017,0.022665017343110837,1
W3201295503,"BERT, mBERT, or BiBERT? A Study on Contextualized Embeddings for Neural Machine Translation",2021,0.022582780636306254,1
W2963829526,Guiding Neural Machine Translation with Retrieved Translation Pieces,2018,0.02257421243581865,1
W2964345285,Bridging the Gap between Training and Inference for Neural Machine Translation,2019,0.02256171421747184,1
W3103169714,Dynamic Data Selection and Weighting for Iterative Back-Translation,2020,0.022547180005282268,1
W2963841178,One Sentence One Model for Neural Machine Translation,2018,0.022540239660588553,1
W3023856002,Syntax-Aware Data Augmentation for Neural Machine Translation,2023,0.022529401218132773,1
W2985694911,Insertion-based Decoding with Automatically Inferred Generation Order,2019,0.022526844098020287,1
W2970731908,The NiuTrans Machine Translation Systems for WMT19,2019,0.022519331797227368,1
W2963406157,Information Aggregation for Multi-Head Attention with Routing-by-Agreement,2019,0.022517336400653093,1
W3035289598,Jointly Masked Sequence-to-Sequence Model for Non-Autoregressive Neural Machine Translation,2020,0.022517273253310887,1
W3166943438,Can You Traducir This? Machine Translation for Code-Switched Input,2021,0.022502143951408874,1
W3103182178,Finding the Optimal Vocabulary Size for Neural Machine Translation,2020,0.022494664744727447,1
W3099107321,The OpenNMT Neural Machine Translation Toolkit: 2020 Edition,2020,0.0224623137260432,1
W2809456172,A Comparison of Transformer and Recurrent Neural Networks on Multilingual Neural Machine Translation,2018,0.02239392451859066,1
W3015078597,Meta-Learning for Few-Shot NMT Adaptation,2020,0.022370745294647797,1
W3167739156,Rethinking Perturbations in Encoder-Decoders for Fast Training,2021,0.022362998416117073,1
W3202484768,Deep Transformer modeling via grouping skip connection for neural machine translation,2021,0.02236215312705691,1
W3113819942,A review of the state-of-the-art in automatic post-editing,2020,0.022360171290758485,1
W3176626464,Measuring and Increasing Context Usage in Context-Aware Machine Translation,2021,0.02235613689102,1
W2950428495,Unsupervised Bilingual Word Embedding Agreement for Unsupervised Neural Machine Translation,2019,0.02235324950585443,1
W2963331233,Findings of the Second Shared Task on Multimodal Machine Translation and Multilingual Image Description,2017,0.022348052950035547,1
W3003693721,A Hierarchical Clustering Approach to Fuzzy Semantic Representation of Rare Words in Neural Machine Translation,2020,0.022326779134126513,1
W2964240726,Microsoft’s Submission to the WMT2018 News Translation Task: How I Learned to Stop Worrying and Love the Data,2018,0.022297679527208798,1
W2767982226,Neural machine translation for low-resource languages without parallel corpora,2017,0.02228811718805814,1
W4220674272,Challenges of Neural Machine Translation for Short Texts,2022,0.022252492871536064,1
W3023166997,Distilling Knowledge Learned in BERT for Text Generation,2019,0.02223010820297925,1
W3015504467,When Does Unsupervised Machine Translation Work?,2020,0.02220968983956081,1
W2759932073,Guiding Neural Machine Translation Decoding with External Knowledge,2017,0.022206187895762494,1
W4281770000,One Reference Is Not Enough: Diverse Distillation with Reference Selection for Non-Autoregressive Translation,2022,0.022191336263767358,1
W2970646865,Auto-Encoding Variational Neural Machine Translation,2019,0.02216575952059412,1
W3035019713,Balancing Training for Multilingual Neural Machine Translation,2020,0.022116220103004694,1
W2963887123,Revisiting Character-Based Neural Machine Translation with Capacity and Compression,2018,0.022087471621842162,1
W3035636774,Improving Neural Machine Translation with Soft Template Prediction,2020,0.022054880917172795,1
W3171088343,Probing Word Translations in the Transformer and Trading Decoder for Encoder Layers,2021,0.022048013799066953,1
W3102657423,"If beam search is the answer, what was the question?",2020,0.022045335613910266,1
W2952444318,Understanding Back-Translation at Scale,2018,0.022006020858950034,1
W2755989362,A Context-Aware Recurrent Encoder for Neural Machine Translation,2017,0.021998381735831393,1
W2997763445,Acquiring Knowledge from Pre-Trained Model to Neural Machine Translation,2020,0.02199002929562792,1
W2909737760,Hallucinations in Neural Machine Translation,2018,0.021964400519253816,1
W2903728819,Context-Aware Self-Attention Networks,2019,0.021931336137985046,1
W3196896228,Towards Making the Most of Dialogue Characteristics for Neural Chat Translation,2021,0.02186218646400588,1
W4281728254,Universal Conditional Masked Language Pre-training for Neural Machine Translation,2022,0.021854087015420846,1
W2995460523,Data-dependent Gaussian Prior Objective for Language Generation,2020,0.02183111307209745,1
W2979303251,Future-Aware Knowledge Distillation for Neural Machine Translation,2019,0.021830822854562056,1
W3035393249,Lexical-Constraint-Aware Neural Machine Translation via Data Augmentation,2020,0.021789121384418953,1
W4229853184,Capturing document context inside sentence-level neural machine translation models with self-training,2021,0.021786458843048126,1
W3034906024,Knowledge Distillation for Multilingual Unsupervised Neural Machine Translation,2020,0.021726205542676152,1
W2903012348,Sogou Neural Machine Translation Systems for WMT17,2017,0.021711124539441663,1
W3176913643,Neural Machine Translation with Monolingual Translation Memory,2021,0.021706446537399893,1
W2964098600,OpenNMT: Neural Machine Translation Toolkit,2018,0.021705444947448718,1
W2573119710,A Multifaceted Evaluation of Neural versus Phrase-Based Machine Translation for 9 Language Directions,2017,0.02166738617382827,1
W2997753998,Explicit Sparse Transformer: Concentrated Attention Through Explicit Selection,2019,0.021662659747566537,1
W2561792472,Interactive neural machine translation,2016,0.02164025211554932,1
W2594047108,Learning to Parse and Translate Improves Neural Machine Translation,2017,0.021550889439743173,1
W2963583256,Code-Switching for Enhancing,2019,0.02154864063215001,1
W2885588803,How Grammatical is Character-level Neural Machine Translation? Assessing MT Quality with Contrastive Translation Pairs,2017,0.02154429330950434,1
W2400065810,The AMU-UEDIN Submission to the WMT16 News Translation Task: Attention-based NMT Models as Feature Functions in Phrase-based SMT,2016,0.021523005196194635,1
W2946567085,Adaptive Attention Span in Transformers,2019,0.021509250960990958,1
W2963684875,Sequence to Sequence Mixture Model for Diverse Machine Translation,2018,0.021509239287446885,1
W2971134989,Naver Labs Europe’s Systems for the WMT19 Machine Translation Robustness Task,2019,0.02149624032275287,1
W3034201598,Uncertainty-Aware Curriculum Learning for Neural Machine Translation,2020,0.021450782776662188,1
W3176079416,Bridging Subword Gaps in Pretrain-Finetune Paradigm for Natural Language Generation,2021,0.02143743570394683,1
W2601324753,Improving Neural Machine Translation with Conditional Sequence Generative Adversarial Nets,2018,0.021428159185755635,1
W2923779212,Selective Attention for Context-aware Neural Machine Translation,2019,0.0214247952616566,1
W2962982474,Scheduled Multi-Task Learning: From Syntax to Translation,2018,0.021424651169676134,1
W3155609600,Word Alignment by Fine-tuning Embeddings on Parallel Corpora,2021,0.02138240571417606,1
W3100113229,Adversarial Grammatical Error Correction,2020,0.02136714352950416,1
W3155457266,Multilingual Neural Machine Translation with Deep Encoder and Multiple Shallow Decoders,2021,0.021354503610729988,1
W1938755728,Character-Aware Neural Language Models,2015,0.021310011940573515,1
W2785047343,A Multilayer Convolutional Encoder-Decoder Neural Network for Grammatical Error Correction,2018,0.021291588167810294,1
W2969696767,Neural Machine Translation With Sentence-Level Topic Context,2019,0.021282922672284293,1
W2574872930,OpenNMT: Open-source Toolkit for Neural Machine Translation,2017,0.021266650318937052,1
W2964213727,Accelerating Neural Transformer via an Average Attention Network,2018,0.021237404421631675,1
W2974078243,Improving tree-based neural machine translation with dynamic lexicalized dependency encoding,2019,0.021231989246075385,1
W2963551569,Neural Machine Translation with Reconstruction,2017,0.021224162765088973,1
W2922709902,Pre-trained language model representations for language generation,2019,0.021200959336453207,1
W2750588180,Neural Machine Translation Training in a Multi-Domain Scenario,2017,0.021188865405590736,1
W2971031524,Explicit Cross-lingual Pre-training for Unsupervised Machine Translation,2019,0.021176038269913426,1
W3035207248,BPE-Dropout: Simple and Effective Subword Regularization,2020,0.021151273012023287,1
W3175863856,Adaptive Nearest Neighbor Machine Translation,2021,0.021124132886963874,1
W2950359962,Dual Learning for Machine Translation,2016,0.02109775664045894,1
W2971254483,NICT’s Unsupervised Neural and Statistical Machine Translation Systems for the WMT19 News Translation Task,2019,0.02109039708053012,1
W2741838462,Curriculum Learning and Minibatch Bucketing in Neural Machine Translation,2017,0.02106471330757325,1
W2982644924,Fill in the Blanks: Imputing Missing Sentences for Larger-Context Neural Machine Translation,2019,0.02105108634283027,1
W2896667998,On internal language representations in deep learning : an analysis of machine translation and speech recognition,2018,0.020999350766260225,1
W2995999067,Understanding Knowledge Distillation in Non-autoregressive Machine Translation,2019,0.020958510629837744,1
W3034216012,Learning to Recover from Multi-Modality Errors for Non-Autoregressive Neural Machine Translation,2020,0.020949306372411748,1
W3046368065,Multilingual Translation with Extensible Multilingual Pretraining and Finetuning,2020,0.020936277866160546,1
W4285258432,Redistributing Low-Frequency Words: Making the Most of Monolingual Data in Non-Autoregressive Translation,2022,0.020901141020275363,1
W3139537596,Finetuning Pretrained Transformers into RNNs,2021,0.020893814290788564,1
W4244167344,Joint Training for Pivot-based Neural Machine Translation,2017,0.020888981616688354,1
W3034939458,How Does Selective Mechanism Improve Self-Attention Networks?,2020,0.020863126683106963,1
W2971278086,Hierarchical Modeling of Global Context for Document-Level Neural Machine Translation,2019,0.020841271212328906,1
W2963599677,Deep Neural Machine Translation with Linear Associative Unit,2017,0.020812441487009996,1
W2911658506,Deep Learning and Its Applications to Natural Language Processing,2019,0.0207921107924993,1
W3034789084,Dynamic Programming Encoding for Subword Segmentation in Neural Machine Translation,2020,0.020740982802434246,1
W2962969034,Non-Autoregressive Neural Machine Translation with Enhanced Decoder Input,2019,0.02070716133038293,1
W3173785189,Machine Translation into Low-resource Language Varieties,2021,0.02070113275189382,1
W2767989436,Weighted Transformer Network for Machine Translation,2017,0.02067655486517307,1
W2971073020,NICT’s Supervised Neural Machine Translation Systems for the WMT19 News Translation Task,2019,0.02063722081966279,1
W2796108585,Training Tips for the Transformer Model,2018,0.020618320983121285,1
W2995538013,Multi-Source Neural Machine Translation With Missing Data,2019,0.02058937091014907,1
W3035812575,"Deep Encoder, Shallow Decoder: Reevaluating the Speed-Quality Tradeoff in Machine Translation",2020,0.020582510044959913,1
W4220997127,Enhancing low-resource neural machine translation with syntax-graph guided self-attention,2022,0.020552638386404407,1
W2962830144,Zero-Resource Neural Machine Translation with Multi-Agent Communication Game,2018,0.020549610122098654,1
W3174556939,Attention Calibration for Transformer in Neural Machine Translation,2021,0.020525866051919105,1
W2229833550,"Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism",2016,0.02051379998076123,1
W2737638662,Predicting Target Language CCG Supertags Improves Neural Machine Translation,2017,0.020512640172397983,1
W3092327118,Pre-training Multilingual Neural Machine Translation by Leveraging Alignment Information,2020,0.020501963622097996,1
W2951559648,Character-Aware Neural Language Models,2016,0.020457911809628908,1
W4205902821,Document Graph for Neural Machine Translation,2021,0.0203825786200931,1
W3119866316,Complete Multilingual Neural Machine Translation,2020,0.020336547778234404,1
W4224083781,Learning to Generalize to More: Continuous Semantic Augmentation for Neural Machine Translation,2022,0.020318197104144193,1
W2902031175,CUNI System for the WMT18 Multimodal Translation Task,2018,0.020274115052523987,1
W2980462515,Using Whole Document Context in Neural Machine Translation,2019,0.0202699732961946,1
W4408525846,An empirical investigation of the neural base approaches based on the sentence length using low-resource language: English-to-Nyishi,2025,0.02026114603324262,1
W2886776719,Regularizing Neural Machine Translation by Target-Bidirectional Agreement,2019,0.020223563110366258,1
W2803739890,Sentence Selection and Weighting for Neural Machine Translation Domain Adaptation,2018,0.020183240592812218,1
W2979047515,Putting Machine Translation in Context with the Noisy Channel Model,2019,0.02017358506462986,1
W2740553716,Neural vs. Phrase-Based Machine Translation in a Multi-Domain Scenario,2017,0.020132917816443264,1
W3122836184,Word Alignment by Fine-tuning Embeddings on Parallel Corpora,2021,0.020111725877872483,1
W2798416860,Fluency Boost Learning and Inference for Neural Grammatical Error Correction,2018,0.02010262169501553,1
W2951456627,STACL: Simultaneous Translation with Implicit Anticipation and Controllable Latency using Prefix-to-Prefix Framework,2019,0.020095397430157418,1
W3035747971,Lipschitz Constrained Parameter Initialization for Deep Transformers,2020,0.02006403970727338,1
W2962882341,Contextual Neural Model for Translating Bilingual Multi-Speaker Conversations,2018,0.019987656802324456,1
W2798362442,A Call for Clarity in Reporting BLEU Scores.,2018,0.019938016190789755,1
W3097996341,Detecting Word Sense Disambiguation Biases in Machine Translation for Model-Agnostic Adversarial Attacks,2020,0.019898654563903256,1
W2963816901,Log-linear Combinations of Monolingual and Bilingual Neural Machine Translation Models for Automatic Post-Editing,2016,0.019834709435811077,1
W2756978580,Instance Weighting for Neural Machine Translation Domain Adaptation,2017,0.01983085849951115,1
W3168577192,Multi-Task Learning with Shared Encoder for Non-Autoregressive Machine Translation,2021,0.019813520011088076,1
W4287597359,Monolingual Adapters for Zero-Shot Neural Machine Translation,2020,0.019813384856674384,1
W2963352809,Fast Lexically Constrained Decoding with Dynamic Beam Allocation for Neural Machine Translation,2018,0.019811790703661895,1
W3120749277,Tencent AI Lab Machine Translation Systems for WMT20 Chat Translation Task,2020,0.01980753833947784,1
W2912070261,Adding Interpretable Attention to Neural Translation Models Improves Word Alignment,2019,0.01978709974822602,1
W2339995566,Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models,2016,0.01974250273003068,1
W2964130895,A Challenge Set Approach to Evaluating Machine Translation,2017,0.019700696300038918,1
W2972529197,Sequence-to-sequence Pre-training with Data Augmentation for Sentence Rewriting,2019,0.019675457118938203,1
W2963357083,Semi-Supervised Learning for Neural Machine Translation,2016,0.01965789602555133,1
W3035144493,Leveraging Monolingual Data with Self-Supervision for Multilingual Neural Machine Translation,2020,0.01965300592288372,1
W3087057727,Document-level Neural Machine Translation with Document Embeddings,2025,0.019610073966869833,1
W2995746049,Revisiting Self-Training for Neural Sequence Generation,2020,0.019519000323286885,1
W2885185669,SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing,2018,0.019484582818741113,1
W3034772996,On Layer Normalization in the Transformer Architecture,2020,0.019482067614295648,1
W2586559132,Neural Machine Translation with Source-Side Latent Graph Parsing,2017,0.019479470692479926,1
W2741040846,Visualizing and Understanding Neural Machine Translation,2017,0.01947864783593896,1
W4385571586,Accelerating Transformer Inference for Translation via Parallel Decoding,2023,0.019446653258741797,1
W2970558573,Findings of the First Shared Task on Machine Translation Robustness,2019,0.019420066958021513,1
W2889606145,Beyond Error Propagation in Neural Machine Translation: Characteristics of Language Also Matter,2018,0.019397395003555876,1
W3019527251,Lite Transformer with Long-Short Range Attention,2020,0.019383750497462975,1
W2964053711,Linguistically Motivated Vocabulary Reduction for Neural Machine Translation from Turkish to English,2017,0.019323612531772096,1
W2952682849,On the Word Alignment from Neural Machine Translation,2019,0.019321234805630205,1
W4385572192,Text Style Transfer Back-Translation,2023,0.019304070089054354,1
W3162226363,Adaptive Adapters: An Efficient Way to Incorporate BERT Into Neural Machine Translation,2021,0.019283265271859158,1
W2997244573,On the Linguistic Representational Power of Neural Machine Translation Models,2020,0.019282479311190426,1
W2773795499,A user-study on online adaptation of neural machine translation to human post-edits,2018,0.019233552582305937,1
W2964247056,MTNT: A Testbed for Machine Translation of Noisy Text,2018,0.019206723701837236,1
W2922158773,Attaining the Unattainable? Reassessing Claims of Human Parity in Neural Machine Translation,2018,0.019193182497870415,1
W2950037171,Lattice-Based Transformer Encoder for Neural Machine Translation,2019,0.019153713524603884,1
W3169012807,Luna: Linear Unified Nested Attention,2021,0.019132675728957767,1
W2607987856,Adversarial Neural Machine Translation,2017,0.019125468437727958,1
W2970947975,Baidu Neural Machine Translation Systems for WMT19,2019,0.01912229433851053,1
W2964174820,What does Attention in Neural Machine Translation Pay Attention to,2017,0.019116681035881516,1
W3035072529,On the Inference Calibration of Neural Machine Translation,2020,0.019067747479943973,1
W2952524847,Exploiting Sentential Context for Neural Machine Translation,2019,0.018947268458942457,1
W2593543827,Enabling Multi-Source Neural Machine Translation By Concatenating Source Sentences In Multiple Languages.,2017,0.018892515541108747,1
W2964116568,Neural AMR: Sequence-to-Sequence Models for Parsing and Generation,2017,0.018886912071743332,1
W2963246629,Bag-of-Words as Target for Neural Machine Translation,2018,0.018816641579144994,1
W3035520602,Towards Making the Most of Context in Neural Machine Translation,2020,0.018770199638162118,1
W2911265970,Deep Learning for Natural Language Processing,2019,0.018762524978918366,1
W3176395632,Good for Misconceived Reasons: An Empirical Revisiting on the Need for Visual Context in Multimodal Machine Translation,2021,0.018756155540970525,1
W4386566338,Language-Family Adapters for Low-Resource Multilingual Neural Machine Translation,2023,0.01875237313202748,1
W3116179216,Finding Sparse Structures for Domain Specific Neural Machine Translation,2021,0.01874444540993016,1
W3173506780,Analyzing the Source and Target Contributions to Predictions in Neural Machine Translation,2021,0.018732677652831486,1
W3169369929,The <scp>Flores-101</scp> Evaluation Benchmark for Low-Resource and Multilingual Machine Translation,2022,0.01872849606020412,1
W2948335087,Neural Grammatical Error Correction Systems with Unsupervised Pre-training on Synthetic Data,2019,0.01872097635612473,1
W2803237843,Noising and Denoising Natural Language: Diverse Backtranslation for Grammar Correction,2018,0.018717519481691636,1
W3015162217,Aligned Cross Entropy for Non-Autoregressive Machine Translation,2020,0.018716827604071503,1
W2963714898,Variational Recurrent Neural Machine Translation,2018,0.01867087124773284,1
W3104669693,Improving Grammatical Error Correction Models with Purpose-Built Adversarial Examples,2020,0.018656376988593668,1
W2885616807,Document-Level Adaptation for Neural Machine Translation,2018,0.01864248899873215,1
W4281679347,Bilingual attention based neural machine translation,2022,0.018613425427327922,1
W2212703438,A Theoretically Grounded Application of Dropout in Recurrent Neural Networks,2015,0.01861108696188768,1
W3211978535,Encouraging Lexical Translation Consistency for Document-Level Neural Machine Translation,2021,0.018596834548491818,1
W4285242045,Towards Making the Most of Cross-Lingual Transfer for Zero-Shot Neural Machine Translation,2022,0.018591177557096748,1
W2903343986,Findings of the Third Shared Task on Multimodal Machine Translation,2018,0.018588210989090467,1
W2962901607,A Nested Attention Neural Hybrid Model for Grammatical Error Correction,2017,0.018584148042625613,1
W2899181341,Learning to Actively Learn Neural Machine Translation,2018,0.01857432687253928,1
W2789910672,Neural Interactive Translation Prediction,2016,0.01853917099254331,1
W2962915948,Imitation Learning for Non-Autoregressive Neural Machine Translation,2019,0.018533571545303967,1
W3175204760,Adapting High-resource NMT Models to Translate Low-resource Related Languages without Parallel Data,2021,0.018493298988059143,1
W4321617771,Machine translation and its evaluation: a study,2023,0.018489809947045157,1
W3175810841,Mask-Align: Self-Supervised Neural Word Alignment,2021,0.01848057728591475,1
W2963643655,Compression of Neural Machine Translation Models via Pruning,2016,0.018472429166493998,1
W3207645655,Beyond Distillation: Task-level Mixture-of-Experts for Efficient Inference,2021,0.018468062724615902,1
W4385570486,kNN-TL: k-Nearest-Neighbor Transfer Learning for Low-Resource Neural Machine Translation,2023,0.01845687036939,1
W2890560993,FRAGE: Frequency-Agnostic Word Representation,2018,0.018441263484361516,1
W3173367141,Progressive Multi-Granularity Training for Non-Autoregressive Translation,2021,0.018435931201894896,1
W3095962368,Detecting Hallucinated Content in Conditional Neural Sequence Generation,2020,0.018427797374624067,1
W2964091381,Addressing word-order Divergence in Multilingual Neural Machine Translation for extremely Low Resource Languages,2019,0.018368743902564915,1
W3116864188,Improving Grammatical Error Correction with Data Augmentation by Editing Latent Representation,2020,0.018359056643249234,1
W2962889503,Multi-Source Neural Machine Translation with Missing Data,2018,0.01834998257576241,1
W3199258042,Cross-Attention is All You Need: Adapting Pretrained Transformers for Machine Translation,2021,0.018343678797746607,1
W2963652649,Context-Aware Self-Attention Networks,2019,0.018338470393826058,1
W2741917668,Maximum Expected Likelihood Estimation for Zero-resource Neural Machine Translation,2017,0.01830755567959814,1
W4410544883,Addressing Syntactic Divergence in Low-Resource Neural Machine Translation via Language Independent Word Reordering,2025,0.018292743128074874,1
W3031696893,Attention in Natural Language Processing,2020,0.018280007018850335,1
W3131922516,Efficient Content-Based Sparse Attention with Routing Transformers,2021,0.01827623495180282,1
W2970832665,FlowSeq: Non-Autoregressive Conditional Sequence Generation with Generative Flow,2019,0.01825542635915294,1
W4386857706,P-Transformer: Towards Better Document-to-Document Neural Machine Translation,2023,0.01821455469335312,1
W3035540807,Lexically Constrained Neural Machine Translation with Levenshtein Transformer,2020,0.018153108127391324,1
W2962878352,Fine-grained attention mechanism for neural machine translation,2018,0.018143486148964764,1
W2741900445,Detecting Cross-Lingual Semantic Divergence for Neural Machine Translation,2017,0.018131301023917287,1
W3119378114,Unsupervised Bitext Mining and Translation via Self-Trained Contextual Embeddings,2020,0.018120291543494937,1
W2995558462,Neural Machine Translation with Universal Visual Representation,2020,0.018110227646064007,1
W3127887696,Multilingual Neural Machine Translation for Low-Resource Languages,2018,0.01810490683059774,1
W2901987885,Translators’ perceptions of literary post-editing using statistical and neural machine translation,2018,0.018104784258990748,1
W2962735107,Margin-based Parallel Corpus Mining with Multilingual Sentence Embeddings,2019,0.018087203800761783,1
W2963631431,Deep architectures for Neural Machine Translation,2017,0.01808465632293731,1
W3200388885,AligNART: Non-autoregressive Neural Machine Translation by Jointly Learning to Estimate Alignment and Translate,2021,0.01807133786648906,1
W3177223224,Putting words into the system’s mouth: A targeted attack on neural machine translation using monolingual data poisoning,2021,0.018054946467709717,1
W4407684421,Character-Level Encoding based Neural Machine Translation for Hindi language,2025,0.018040728591257816,1
W2961117861,OmniNet: A unified architecture for multi-modal multi-task learning,2019,0.018035166998477365,1
W4384200848,Investigating Unsupervised Neural Machine Translation for Low-resource Language Pair English-Mizo via Lexically Enhanced Pre-trained Language Models,2023,0.01803322028747173,1
W2952564229,Massive Exploration of Neural Machine Translation Architectures,2017,0.018012784732532608,1
W3154414470,On the diversity of multi-head attention,2021,0.018011625368139723,1
W4229744135,Proceedings of the First Workshop on Subword and Character Level Models in NLP,2017,0.017975031499552117,1
W2963777589,Robust Neural Machine Translation with Joint Textual and Phonetic Embedding,2019,0.017973881706109595,1
W2976965654,Hint-Based Training for Non-Autoregressive Machine Translation,2019,0.017937053385321547,1
W3203385474,The Low-Resource Double Bind: An Empirical Study of Pruning for Low-Resource Machine Translation,2021,0.01791121595347631,1
W3099405210,Semantic Neural Machine Translation Using AMR,2019,0.017906821136707416,1
W2971524460,Adaptively Sparse Transformers,2019,0.01788749505567759,1
W2922349260,compare-mt: A Tool for Holistic Comparison of Language Generation Systems,2019,0.017880529646708127,1
W2945735543,Improved Lexically Constrained Decoding for Translation and Monolingual Rewriting,2019,0.017849329434261128,1
W3176846012,On Compositional Generalization of Neural Machine Translation,2021,0.017834598007337298,1
W3034214887,Learning a Multi-Domain Curriculum for Neural Machine Translation,2020,0.017829732267402424,1
W2739894144,Sequence-to-Dependency Neural Machine Translation,2017,0.017819274625720246,1
W4389518727,Viewing Knowledge Transfer in Multilingual Machine Translation Through a Representational Lens,2023,0.01781655812994884,1
W2952339051,Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer,2017,0.01781284872047481,1
W3036939249,Multi-branch Attentive Transformer,2020,0.017795140053812934,1
W2410082850,Linguistic Input Features Improve Neural Machine Translation,2016,0.017764431727894,1
W2783419700,Translating Pro-Drop Languages With Reconstruction Models,2018,0.01774875443326917,1
W2798749466,Graph-to-Sequence Learning using Gated Graph Neural Networks,2018,0.017710609425717404,1
W2951977278,Assessing the Ability of Self-Attention Networks to Learn Word Order,2019,0.0176975844060697,1
W3130523865,Revisiting Multi-Domain Machine Translation,2021,0.017671686233619657,1
W3175665465,Glancing Transformer for Non-Autoregressive Neural Machine Translation,2021,0.01765853673257218,1
W2952518244,Meta-Learning for Low-Resource Neural Machine Translation,2018,0.01764227884738188,1
W3172096628,UniDrop: A Simple yet Effective Technique to Improve Transformer without Extra Cost,2021,0.017640059805936168,1
W4377291249,A Scenario-Generic Neural Machine Translation Data Augmentation Method,2023,0.0176097962829154,1
W2950207430,Distilling Translations with Visual Awareness,2019,0.01758655167155959,1
W2963499882,On The Alignment Problem In Multi-Head Attention-Based Neural Machine Translation,2018,0.01756821111241721,1
W2962739703,Towards Bidirectional Hierarchical Representations for Attention-based Neural Machine Translation,2017,0.01756808272199693,1
W3103699753,Character-level Representations Improve DRS-based Semantic Parsing Even in the Age of BERT,2020,0.017497124331707078,1
W2963699608,Coverage Embedding Models for Neural Machine Translation,2016,0.017484958926085568,1
W3017643757,On Sparsifying Encoder Outputs in Sequence-to-Sequence Models,2020,0.017476803990599393,1
W2963500732,Neural Machine Translation into Language Varieties,2018,0.017472129793917695,1
W2963598809,Supervised Attentions for Neural Machine Translation,2016,0.01746929696060285,1
W2740718109,Cost Weighting for Neural Machine Translation Domain Adaptation,2017,0.017466559009407533,1
W2757222607,When to Finish? Optimal Beam Search for Neural Text Generation (modulo beam size),2017,0.017458461616813276,1
W2963281280,Dual Conditional Cross-Entropy Filtering of Noisy Parallel Corpora,2018,0.01745096778993596,1
W2963091079,Asynchronous Bidirectional Decoding for Neural Machine Translation,2018,0.017447971432010687,1
W2807535859,Multilingual Neural Machine Translation with Task-Specific Attention,2018,0.01742680635581063,1
W3035589854,Enhancing Machine Translation with Dependency-Aware Self-Attention,2020,0.017388678611071427,1
W3118026775,Is MAP Decoding All You Need? The Inadequacy of the Mode in Neural Machine Translation,2020,0.017388169866051028,1
W2962834107,Neural Machine Translation with Supervised Attention,2016,0.017327733527082397,1
W2953173959,Soft Contextual Data Augmentation for Neural Machine Translation,2019,0.017316224799910435,1
W2951563833,Leveraging Local and Global Patterns for Self-Attention Networks,2019,0.017289452218513177,1
W3104681546,Seq2Edits: Sequence Transduction Using Span-level Edit Operations,2020,0.017277391917058006,1
W2975711469,Monotonic Multihead Attention,2019,0.01726076806631064,1
W2996843693,Latent-Variable Non-Autoregressive Neural Machine Translation with Deterministic Inference Using a Delta Posterior,2020,0.017235138954598234,1
W2963174729,Simple Recurrent Units for Highly Parallelizable Recurrence,2018,0.01720457702073732,1
W2963261349,Ensembling Factored Neural Machine Translation Models for Automatic Post-Editing and Quality Estimation,2017,0.017192838783626666,1
W3102516861,Beam Search Strategies for Neural Machine Translation,2017,0.017162365353457793,1
W3103878009,Long-Short Term Masking Transformer: A Simple but Effective Baseline for Document-level Neural Machine Translation,2020,0.017146344332162784,1
W2936627440,Code-Switching for Enhancing NMT with Pre-Specified Translation,2019,0.017121832806101384,1
W2963988211,Imagination improves Multimodal Translation,2017,0.017119056835402834,1
W4243882989,Proceedings of The Third Workshop on Representation Learning for NLP,2018,0.017109366071122,1
W2971296520,Saliency-driven Word Alignment Interpretation for Neural Machine Translation,2019,0.017107482980189295,1
W2995428172,Monotonic Multihead Attention,2020,0.01709004037567491,1
W2920359981,Assembling translations from multi-engine machine translation outputs,2019,0.017083961915538355,1
W4400678841,Context-Aware Machine Translation with Source Coreference Explanation,2024,0.01707147118716053,1
W3031586918,A Multilingual Parallel Corpora Collection Effort for Indian Languages,2020,0.016972672647711892,1
W3104234009,Simultaneous Machine Translation with Visual Context,2020,0.016971971130253484,1
W2898774411,Exploring Neural Methods for Parsing Discourse Representation Structures,2018,0.016963895947044186,1
W3034786666,Contextual Neural Machine Translation Improves Translation of Cataphoric Pronouns,2020,0.016932949223509925,1
W2951309718,Densely Connected Graph Convolutional Networks for Graph-to-Sequence Learning,2019,0.016917066705538875,1
W2963913356,Extreme Adaptation for Personalized Neural Machine Translation,2018,0.016905362720168297,1
W3101221466,XL-AMR: Enabling Cross-Lingual AMR Parsing with Transfer Learning Techniques,2020,0.016896761275768883,1
W2982434686,A Latent Morphology Model for Open-Vocabulary Neural Machine Translation,2019,0.016874433253174424,1
W2886440583,Neural Machine Translation Techniques for Named Entity Transliteration,2018,0.016857078855816388,1
W3011573365,Syntax-aware Transformer Encoder for Neural Machine Translation,2019,0.016841634935404675,1
W2612881151,Graph Convolutional Encoders for Syntax-aware Neural Machine Translation,2017,0.016832647218979743,1
W2983577274,Improving Pre-Trained Multilingual Model with Vocabulary Expansion,2019,0.016788057851402485,1
W3035463087,End-to-End Neural Word Alignment Outperforms GIZA++,2020,0.01677018966384075,1
W2741239863,Improved Neural Machine Translation with Source Syntax,2017,0.016767238103444174,1
W3037162118,"GECToR – Grammatical Error Correction: Tag, Not Rewrite",2020,0.01676197780728893,1
W2902537726,Coreference and Coherence in Neural Machine Translation: A Study Using Oracle Experiments,2018,0.01675812904883956,1
W3093345276,Incorporating BERT into Parallel Sequence Decoding with Adapters,2020,0.016711934718671658,1
W4402332667,Distilling BERT knowledge into Seq2Seq with regularized Mixup for low-resource neural machine translation,2024,0.01667801694633049,1
W3099230264,Machine Translation using Semantic Web Technologies: A Survey,2018,0.016670509087949627,1
W3036839309,Cross-lingual Retrieval for Iterative Self-Supervised Training,2020,0.016668623728626725,1
W3172669006,The Curious Case of Hallucinations in Neural Machine Translation,2021,0.016657251808326497,1
W2971154170,Towards Understanding Neural Machine Translation with Word Importance,2019,0.016654231197120832,1
W3104652292,On the Sub-layer Functionalities of Transformer Decoder,2020,0.01663334740626345,1
W2951065878,Target Conditioned Sampling: Optimizing Data Selection for Multilingual Neural Machine Translation,2019,0.01661807895844317,1
W3171649327,A Survey of Transformers.,2021,0.016617705119933456,1
W2951560313,Pre-trained Language Model Representations for Language Generation,2019,0.01660060540787603,1
W3021293129,Synthesizer: Rethinking Self-Attention in Transformer Models,2020,0.016563213038049036,1
W3104890489,Improving AMR Parsing with Sequence-to-Sequence Pre-training,2020,0.0165615972310483,1
W2916835973,Improving Robustness of Machine Translation with Synthetic Noise,2019,0.016528871337282307,1
W2532807140,Pre-Translation for Neural Machine Translation,2016,0.016527505295689696,1
W2757041753,Target-side Word Segmentation Strategies for Neural Machine Translation,2017,0.016517368788764183,1
W3040573126,GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding,2020,0.016484518001505622,1
W3174864715,R-Drop: Regularized Dropout for Neural Networks,2021,0.016449818413410613,1
W2889404673,A Tree-based Decoder for Neural Machine Translation,2018,0.016411413558970828,1
W2669742347,THUMT: An Open Source Toolkit for Neural Machine Translation,2017,0.016400437988574757,1
W3126425262,Nearest Neighbor Machine Translation,2021,0.016398673498300338,1
W3144451117,Towards achieving a delicate blending between rule-based translator and neural machine translator,2021,0.016378266296536444,1
W3119175506,XLM-T: Scaling up Multilingual Machine Translation with Pretrained Cross-lingual Transformer Encoders,2020,0.016337494678676106,1
W2902604592,Discourse-Related Language Contrasts in English-Croatian Human and Machine Translation,2018,0.01630676566439152,1
W2443536229,Zero-Resource Translation with Multi-Lingual Neural Machine Translation,2016,0.01630463574221154,1
W2606134370,Neural Monkey: An Open-source Tool for Sequence Learning,2017,0.016302380131787027,1
W2980216782,Unsupervised Multi-Modal Neural Machine Translation,2019,0.01625405357162109,1
W2962780935,Pre-Translation for Neural Machine Translation.,2016,0.016242786187395063,1
W2509282593,A Shared Task on Multimodal Machine Translation and Crosslingual Image Description,2016,0.01624196554132648,1
W3066373881,Very Deep Transformers for Neural Machine Translation,2020,0.016204718569139027,1
W3098041136,Multilingual AMR-to-Text Generation,2020,0.016174097863637816,1
W2971141904,The MuCoW Test Suite at WMT 2019: Automatically Harvested Multilingual Contrastive Word Sense Disambiguation Test Sets for Machine Translation,2019,0.01616510176205762,1
W2979190299,Improving Anaphora Resolution in Neural Machine Translation Using Curriculum Learning.,2019,0.0161516253511908,1
W3088304121,The Challenges of Using Neural Machine Translation for Literature,2019,0.016147746975140372,1
W3100753857,Non-Autoregressive Machine Translation with Latent Alignments,2020,0.01605424898301081,1
W2905288168,Learning to Generate Corrective Patches using Neural Machine Translation,2018,0.01605050028467569,1
W2889545026,The MeMAD Submission to the WMT18 Multimodal Translation Task,2018,0.016047540310239725,1
W2625092622,Six Challenges for Neural Machine Translation,2017,0.01602299172581158,1
W2890230387,Neural Quality Estimation of Grammatical Error Correction,2018,0.01602021262487773,1
W3082760180,Transforming machine translation: a deep learning system reaches news translation quality comparable to human professionals,2020,0.016016646986963215,1
W2866343820,Universal Transformers,2018,0.015938286692047932,1
W2963909453,Multi30K: Multilingual English-German Image Descriptions,2016,0.01593612354819307,1
W3176997878,BERTTune: Fine-Tuning Neural Machine Translation with BERTScore,2021,0.015934324521305995,1
W2801219566,Human versus automatic quality evaluation of NMT and PBSMT,2018,0.01592366845852042,1
W3174851730,Instantaneous Grammatical Error Correction with Shallow Aggressive Decoding,2021,0.015913694528466187,1
W2964078338,Incremental Decoding and Training Methods for Simultaneous Translation in Neural Machine Translation,2018,0.015907767118867974,1
W3167056186,Continual Learning for Neural Machine Translation,2021,0.015904139112021473,1
W3176120057,Selective Knowledge Distillation for Neural Machine Translation,2021,0.01590291450853039,1
W3034871396,A Novel Graph-based Multi-modal Fusion Encoder for Neural Machine Translation,2020,0.015892998951808377,1
W2949335953,Effective Approaches to Attention-based Neural Machine Translation,2015,0.01587842246318388,1
W3212044575,Multi-Class Grammatical Error Detection for Correction: A Tale of Two Systems,2021,0.01586258263166723,1
W2970084653,Speculative Beam Search for Simultaneous Translation,2019,0.015829136629742238,1
W2566564022,Improved Neural Machine Translation with SMT Features,2016,0.015811854060558343,1
W2963069010,Grammar as a foreign language,2015,0.015805243215234115,1
W2513263213,Attention-based Multimodal Neural Machine Translation,2016,0.015801710184199125,1
W3176297128,Don’t Take It Literally: An Edit-Invariant Sequence Loss for Text Generation,2022,0.01579612771502412,1
W2982588609,Document-level Neural Machine Translation with Inter-Sentence Attention.,2019,0.0157842887709771,1
W2417549359,Does Multimodality Help Human and Machine for Translation and Image Captioning?,2016,0.01574672115439138,1
W2940744433,Generating Long Sequences with Sparse Transformers.,2019,0.015746560975284367,1
W3155915431,Multilingual Machine Translation: Closing the Gap between Shared and Language-specific Encoder-Decoders,2021,0.01567243153817401,1
W3087346608,Alleviating the Inequality of Attention Heads for Neural Machine Translation,2020,0.01564768855088916,1
W2904829696,DTMT: A Novel Deep Transition Architecture for Neural Machine Translation,2019,0.015639199995576402,1
W2962929176,Input Combination Strategies for Multi-Source Transformer Decoder,2018,0.015629195034769457,1
W3035219095,Evaluating Robustness to Input Perturbations for Neural Machine Translation,2020,0.015602509720388909,1
W3089072946,Deep Transformers with Latent Depth,2020,0.015597044483094931,1
W3109387650,Multi-modal neural machine translation with deep semantic interactions,2020,0.015590758906685924,1
W3106146701,A Set of Recommendations for Assessing Human–Machine Parity in Language Translation,2020,0.015562726092860716,1
W2988451549,CCMatrix: Mining Billions of High-Quality Parallel Sentences on the WEB,2019,0.015509510293418509,1
W3175216677,XLPT-AMR: Cross-Lingual Pre-Training via Multi-Task Learning for Zero-Shot AMR Parsing and Text Generation,2021,0.015507781871150251,1
W3102446692,Losing Heads in the Lottery: Pruning Transformer Attention in Neural Machine Translation,2020,0.01550641990984021,1
W3037793211,Re-translation versus Streaming for Simultaneous Translation,2020,0.015496433629858667,1
W2950651087,Effective Adversarial Regularization for Neural Machine Translation,2019,0.015488076740754851,1
W4200585851,A Comprehensive Survey of Grammatical Error Correction,2021,0.015479648168653153,1
W3113715281,Understanding and Improving Lexical Choice in Non-Autoregressive Translation,2020,0.015466115544645003,1
W2963266340,A theoretically grounded application of dropout in recurrent neural networks,2016,0.015458849904996694,1
W3102138045,On Long-Tailed Phenomena in Neural Machine Translation,2020,0.015454503653246545,1
W4289521458,An Efficient Method for Generating Synthetic Data for Low-Resource Machine Translation,2022,0.015447827455089283,1
W2970868759,The BEA-2019 Shared Task on Grammatical Error Correction,2019,0.015427237314930453,1
W3119303959,Subformer: Exploring Weight Sharing for Parameter Efficiency in Generative Transformers,2021,0.015410724941710129,1
W4397024830,"Implications of using AI in Translation Studies: Trends, Challenges, and Future Direction",2024,0.015408135003431104,1
W2963881719,Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data,2019,0.015384997850649415,1
W3090145300,Nearest Neighbor Machine Translation,2020,0.015327955267809421,1
W2738371943,Towards Decoding as Continuous Optimisation in Neural Machine Translation,2017,0.015296286518638048,1
W3116815090,A Theoretical Analysis of the Repetition Problem in Text Generation,2021,0.015290561737263458,1
W3205067433,MSP: Multi-Stage Prompting for Making Pre-trained Language Models Better Translators,2022,0.01528627247120896,1
W4385572748,Multilingual Machine Translation with Hyper-Adapters,2022,0.015253035424078217,1
W2984051011,Training on Synthetic Noise Improves Robustness to Natural Noise in Machine Translation,2019,0.015242354857509547,1
W2962826395,MS-UEdin Submission to the WMT2018 APE Shared Task: Dual-Source Transformer for Automatic Post-Editing,2018,0.015225344287698332,1
W3105178602,Dependency-based syntax-aware word representations,2020,0.015210130058912197,1
W2963975242,Near Human-Level Performance in Grammatical Error Correction with Hybrid Machine Translation,2018,0.015208925916373637,1
W2964125283,Neural Machine Translation with Recurrent Attention Modeling,2017,0.015188999380987996,1
W2902767466,CUNI Transformer Neural MT System for WMT18,2018,0.015152080155955842,1
W2768123736,Neural versus phrase-based MT quality: An in-depth analysis on English–German and English–French,2017,0.015134215410169759,1
W2970328625,Controlling Text Complexity in Neural Machine Translation,2019,0.015124006883163541,1
W2768763386,Syntax-Directed Attention for Neural Machine Translation,2018,0.015100491583177139,1
W3033638351,Unsupervised Translation of Programming Languages,2020,0.015094970526373397,1
W2946028745,Improving Neural Machine Translation with Neural Syntactic Distance,2019,0.015094366339899776,1
W4206688402,Finetuning Pretrained Transformers into RNNs,2021,0.015083809673712256,1
W3035691519,Improving Transformer Models by Reordering their Sublayers,2020,0.015083546961729333,1
W2911109671,Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context,2019,0.015062282850395133,1
W2952355681,The Evolved Transformer,2019,0.015058546347006232,1
W4367599042,Grammatical Error Correction: A Survey of the State of the Art,2023,0.015022801170403442,1
W2998135987,Alignment-Enhanced Transformer for Constraining NMT with Pre-Specified Translations,2020,0.014977972921679168,1
W3000840023,Semi-Autoregressive Training Improves Mask-Predict Decoding,2020,0.014971525886971685,1
W2771291973,Making sense of neural machine translation,2017,0.014963220739266368,1
W2950737607,Cross-Sentence Grammatical Error Correction,2019,0.014956971169701001,1
W2972858361,Multilingual multimodal machine translation for Dravidian languages utilizing phonetic transcription,2019,0.014907225411488043,1
W2948975009,Real or Fake? Learning to Discriminate Machine from Human Generated Text.,2019,0.014879661458909059,1
W3118069529,Continual Lifelong Learning in Natural Language Processing: A Survey,2020,0.014874615570050358,1
W2996987694,Fine-Tuning by Curriculum Learning for Non-Autoregressive Neural Machine Translation,2020,0.014853962048323968,1
W4385570274,Lessons on Parameter Sharing across Layers in Transformers,2023,0.014845816370848301,1
W2981040094,Root Mean Square Layer Normalization,2019,0.014815025076552597,1
W3093260394,Memformer: The Memory-Augmented Transformer,2021,0.01480301055191895,1
W4230252363,Learning Kernel-Smoothed Machine Translation with Retrieved Examples,2021,0.014767732875071026,1
W2998547639,Generating Diverse Translation by Manipulating Multi-Head Attention,2020,0.01473306405423503,1
W3167880383,Non-Autoregressive Translation by Learning Target Categorical Codes,2021,0.014689363582285299,1
W3168169499,Context-aware Self-Attention Networks for Natural Language Processing,2021,0.014667202039912558,1
W3106051020,Membership Inference Attacks on Sequence-to-Sequence Models: Is My Data In Your Machine Translation System?,2020,0.014665648901786512,1
W2952649152,Scheduled Sampling for Transformers,2019,0.014633757058387546,1
W2963964898,Exploiting Semantics in Neural Machine Translation with Graph Convolutional Networks,2018,0.014626011846004296,1
W3164316202,Synthetic Data Generation for Grammatical Error Correction with Tagged Corruption Models,2021,0.01461058252607025,1
W3087105636,Arabic Machine Translation: A survey of the latest trends and challenges,2020,0.01459598847092668,1
W4221155857,Neural Machine Translation with Phrase-Level Universal Visual Representations,2022,0.014564487894689695,1
W3127901106,Understanding and Improving Lexical Choice in Non-Autoregressive Translation,2021,0.014539602292925537,1
W2410539690,Modeling Coverage for Neural Machine Translation,2016,0.014532021949344368,1
W3092173171,Why Skip If You Can Combine: A Simple Knowledge Distillation Technique for Intermediate Layers,2020,0.01450671829621083,1
W2924677654,Neural Models of Text Normalization for Speech Applications,2019,0.014468077439398487,1
W4250928698,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations,2019,0.014448756567338626,1
W3176957840,Discriminative Reranking for Neural Machine Translation,2021,0.014444711110821464,1
W3034363136,A Study of Non-autoregressive Model for Sequence Generation,2020,0.014436965472586022,1
W2947898088,A Generalized Framework of Sequence Generation with Application to Undirected Sequence Models,2019,0.014417619233708762,1
W3175301726,CCMatrix: Mining Billions of High-Quality Parallel Sentences on the Web,2021,0.014376252838134443,1
W2741823585,Analyzing Neural MT Search and Model Performance,2017,0.01434690507246651,1
W2950513705,Mixture Models for Diverse Machine Translation: Tricks of the Trade,2019,0.014342182899871568,1
W2963898017,CUNI System for the WMT17 Multimodal Translation Task,2017,0.014328966130384447,1
W2970469088,Translate and Label! An Encoder-Decoder Approach for Cross-lingual Semantic Role Labeling,2019,0.014315391037334972,1
W2995575179,Compressive Transformers for Long-Range Sequence Modelling,2020,0.014274310829598525,1
W2962890089,Denoising Neural Machine Translation Training with Trusted Data and Online Data Selection,2018,0.014268246913005992,1
W2952180055,Convolutional Self-Attention Networks,2019,0.014241600157263896,1
W4389518883,MixEdit: Revisiting Data Augmentation and Beyond for Grammatical Error Correction,2023,0.014232456045449099,1
W3035512170,Generalized Entropy Regularization or: There’s Nothing Special about Label Smoothing,2020,0.014232418822968912,1
W2758137671,Neural Machine Translation with Source Dependency Representation,2017,0.014205645885852642,1
W2587694128,Ensemble Distillation for Neural Machine Translation,2017,0.014205283676045533,1
W2997613748,Unsupervised dialectal neural machine translation,2020,0.014185503699689597,1
W3163644064,Testing Machine Translation via Referential Transparency,2021,0.014153986872554031,1
W2994673210,Reformer: The Efficient Transformer,2020,0.01413057049119629,1
W2987188351,Findings of the Fourth Workshop on Neural Generation and Translation,2020,0.014112827394273355,1
W2970682957,Multi-Granularity Self-Attention for Neural Machine Translation,2019,0.014112465827356849,1
W2944852028,Is Word Segmentation Necessary for Deep Learning of Chinese Representations?,2019,0.01408163392158493,1
W2971248291,Evaluating Pronominal Anaphora in Machine Translation: An Evaluation Measure and a Test Suite,2019,0.014080362434786999,1
W3098507616,NMTPY: A Flexible Toolkit for Advanced Neural Machine Translation Systems,2017,0.014068673005381262,1
W2945767825,Are Sixteen Heads Really Better than One,2019,0.014050327455445493,1
W3144827309,ODE Transformer: An Ordinary Differential Equation-Inspired Model for Neural Machine Translation,2021,0.014045672121801547,1
W3166016508,Graph Neural Networks for Natural Language Processing: A Survey,2021,0.014025920659868688,1
W2970963828,Pushing the Limits of Low-Resource Morphological Inflection,2019,0.013988385099335027,1
W4386566643,Looking for a Needle in a Haystack: A Comprehensive Study of Hallucinations in Neural Machine Translation,2023,0.013981571138265744,1
W2740743644,Sentence Embedding for Neural Machine Translation Domain Adaptation,2017,0.013953602156163274,1
W4281636848,Bi-SimCut: A Simple Strategy for Boosting Neural Machine Translation,2022,0.013907046268725246,1
W3156394741,Cross-lingual Visual Pre-training for Multimodal Machine Translation,2021,0.013879247189451844,1
W2422843715,Semi-supervised Learning for Neural Machine Translation,2019,0.013855832105553445,1
W2890909908,Surprisingly Easy Hard-Attention for Sequence to Sequence Learning,2018,0.013820984377401195,1
W2937808806,Mask-Predict: Parallel Decoding of Conditional Masked Language Models.,2019,0.013819490904592509,1
W2963030892,LCANet: End-to-End Lipreading with Cascaded Attention-CTC,2018,0.013754504376390165,1
W3204470331,Predicting Attention Sparsity in Transformers,2022,0.013749810361893124,1
W3028827502,Comparison of the Evaluation Metrics for Neural Grammatical Error Correction With Overcorrection,2020,0.013730521091186687,1
W3034296505,A Mixture of h - 1 Heads is Better than h Heads,2020,0.013688024149313806,1
W4320016113,A Voyage on Neural Machine Translation for Indic Languages,2023,0.013662687925607039,1
W3103942011,A Supervised Word Alignment Method based on Cross-Language Span Prediction using Multilingual BERT,2020,0.013649814060729386,1
W4205862160,A study of BERT for context-aware neural machine translation,2022,0.013640146929568827,1
W2805493160,Marian: Cost-effective High-Quality Neural Machine Translation in C++,2018,0.013579610947997612,1
W2997732209,Improving Context-Aware Neural Machine Translation Using Self-Attentive Sentence Embedding,2020,0.013514343455619271,1
W2978824654,Controlling the Reading Level of Machine Translation Output,2019,0.013477924227717871,1
W4409890951,Disfluency processing for cascaded speech translation involving English and Indian languages,2025,0.013473990506901309,1
W2948981900,Understanding and Improving Transformer From a Multi-Particle Dynamic System Point of View,2019,0.01346219518966578,1
W4324291650,Pipeline Signed Japanese Translation Using PBSMT and Transformer in a Low-Resource Setting,2023,0.013460556281069219,1
W2798742628,Improving Beam Search by Removing Monotonic Constraint for Neural Machine Translation,2018,0.01344615836076151,1
W2890026292,Context and Copying in Neural Machine Translation,2018,0.013417887519047284,1
W2963360627,Probing the Need for Visual Context in Multimodal Machine Translation,2019,0.013415999758713815,1
W2903035303,Prompsit’s submission to WMT 2018 Parallel Corpus Filtering shared task,2018,0.013413092731519138,1
W2955227499,Augmenting Self-attention with Persistent Memory,2019,0.013410589273613053,1
W3130868440,When Attention Meets Fast Recurrence: Training Language Models with Reduced Compute,2021,0.013400862099888241,1
W2805490244,Meaningless yet meaningful: Morphology grounded subword-level NMT,2018,0.01339992451458636,1
W4393235323,Neural Machine Translation with CARU-Embedding Layer and CARU-Gated Attention Layer,2024,0.01332541380751935,1
W3204920203,Causal Direction of Data Collection Matters: Implications of Causal and Anticausal Learning for NLP,2021,0.01330791587697526,1
W2953333557,Depthwise Separable Convolutions for Neural Machine Translation,2017,0.013286220381061958,1
W3175212568,Vocabulary Learning via Optimal Transport for Neural Machine Translation,2021,0.013252748130127641,1
W3173417753,Learning Light-Weight Translation Models from Deep Transformer,2021,0.013243666912442251,1
W3035490389,Task-Level Curriculum Learning for Non-Autoregressive Neural Machine Translation,2020,0.013237867901247272,1
W2951635603,Lattice Transformer for Speech Translation,2019,0.013219492371395051,1
W2885213066,Youdao’s Winning Solution to the NLPCC-2018 Task 2 Challenge: A Neural Machine Translation Approach to Chinese Grammatical Error Correction,2018,0.013217083840926935,1
W3105962700,Simulated multiple reference training improves low-resource machine translation,2020,0.013202616498281621,1
W2970917831,Core Semantic First: A Top-down Approach for AMR Parsing,2019,0.013190168167770881,1
W2938824541,Adapting Sequence to Sequence Models for Text Normalization in Social Media,2019,0.013183542649018888,1
W2920812691,Cloze-driven Pretraining of Self-attention Networks,2019,0.013170178256397071,1
W3037915423,Is 42 the Answer to Everything in Subtitling-oriented Speech Translation?,2020,0.01312657725630446,1
W4382317864,AMOM: Adaptive Masking over Masking for Conditional Masked Language Model,2023,0.013110192713249208,1
W2971087717,Modeling Graph Structure in Transformer for Better AMR-to-Text Generation,2019,0.013091337671663903,1
W3213934211,How Suitable Are Subword Segmentation Strategies for Translating Non-Concatenative Morphology?,2021,0.013077569615055806,1
W3122154272,DeLighT: Deep and Light-weight Transformer,2021,0.013067328081621022,1
W3165048362,An Improved English-to-Mizo Neural Machine Translation,2021,0.013016624729840475,1
W2970429618,Parallel Iterative Edit Models for Local Sequence Transduction,2019,0.012983392668202594,1
W2988008229,Utilizing Knowledge Graphs for Neural Machine Translation Augmentation,2019,0.012973757297475701,1
W2962697716,Handling Homographs in Neural Machine Translation,2018,0.012972845930815213,1
W4282937133,Video Pivoting Unsupervised Multi-Modal Machine Translation,2022,0.012894664252531536,1
W2963888305,Improved Neural Machine Translation with a Syntax-Aware Encoder and Decoder,2017,0.012886185690571782,1
W3132607382,Position Information in Transformers: An Overview,2022,0.012875574268067213,1
W2781918655,A Hierarchy-to-Sequence Attentional Neural Machine Translation Model,2018,0.01286978556550282,1
W2798308429,Exploiting Semantics in Neural Machine Translation with Graph Convolutional Networks,2018,0.01285892468623502,1
W2900013662,Translation Quality and Productivity: A Study on Rich Morphology Languages.,2017,0.012846096197704018,1
W2902918014,Findings of the WMT 2018 Shared Task on Parallel Corpus Filtering,2018,0.012811664593424147,1
W3175164646,Guiding Non-Autoregressive Neural Machine Translation Decoding with Reordering Information,2021,0.012796144676063572,1
W2740592942,Multilingual Semantic Parsing And Code-Switching,2017,0.012786197655401463,1
W2810035278,Reaching Human-level Performance in Automatic Grammatical Error Correction: An Empirical Study,2018,0.012745727901134905,1
W3120658156,An Efficient Transformer Decoder with Compressed Sub-layers,2021,0.01273849151657606,1
W2987998469,Pretrained Language Models for Document-Level Neural Machine Translation,2019,0.01273820557255893,1
W3085139254,Efficient Transformers: A Survey,2022,0.012736830517790511,1
W2789541106,Self-Attention with Relative Position Representations,2018,0.012734070940252307,1
W2964253663,Addressing the Data Sparsity Issue in Neural AMR Parsing,2017,0.012707641897988597,1
W2996854111,Towards Making the Most of BERT in Neural Machine Translation,2020,0.012689673557851543,1
W3035702572,Heterogeneous Graph Transformer for Graph-to-Sequence Learning,2020,0.01267121504983766,1
W3034822304,Structural Information Preserving for Graph-to-Text Generation,2020,0.012666694419109822,1
W3120964679,The University of Maryland’s Submissions to the WMT20 Chat Translation Task: Searching for More Data to Adapt Discourse-Aware Neural Machine Translation,2020,0.012657939559704557,1
W2995082892,Recurrent Neural Networks (RNNs): A gentle Introduction and Overview,2019,0.012657620061961963,1
W4221152019,Integrating Vectorized Lexical Constraints for Neural Machine Translation,2022,0.012654284032518134,1
W4385571897,Towards Accurate Translation via Semantically Appropriate Application of Lexical Constraints,2023,0.012607953406685074,1
W3162090017,FNet: Mixing Tokens with Fourier Transforms,2022,0.01257011744622921,1
W3177132412,Investigating the Reordering Capability in CTC-based Non-Autoregressive End-to-End Speech Translation,2021,0.012559630087355745,1
W2963497309,Sentence-State LSTM for Text Representation,2018,0.012543752419156179,1
W3035010485,Encoder-Decoder Models Can Benefit from Pre-trained Masked Language Models in Grammatical Error Correction,2020,0.012512565889328144,1
W2962705709,One-Shot Neural Cross-Lingual Transfer for Paradigm Completion,2017,0.012468323522816214,1
W3128651145,Neural machine translation with a polysynthetic low resource language,2020,0.012445694406649454,1
W4390938901,Encoder-Decoder Calibration for Multimodal Machine Translation,2024,0.012442819002572176,1
W2995154514,Generalization through Memorization: Nearest Neighbor Language Models,2020,0.012442450124804967,1
W3137065374,"Low-Resource Machine Translation for Low-Resource Languages: Leveraging Comparable Data, Code-Switching and Compute Resources.",2021,0.012418224268313831,1
W3170034074,Macro-Average: Rare Types Are Important Too,2021,0.01240504971547805,1
W4399365598,Scaling neural machine translation to 200 languages,2024,0.01240414497428284,1
W3046835050,DeLighT: Very Deep and Light-weight Transformer,2020,0.012403902409632144,1
W3000965575,PMIndia -- A Collection of Parallel Corpora of Languages of India,2020,0.012389703353397133,1
W3133264589,Do Transformer Modifications Transfer Across Implementations and Applications?,2021,0.012344645761185045,1
W3090988182,Structure-invariant testing for machine translation,2020,0.01228202399239546,1
W4225470987,Conditional Bilingual Mutual Information Based Adaptive Training for Neural Machine Translation,2022,0.012269961818070054,1
W3116929749,Part-of-speech tagging of building codes empowered by deep learning and transformational rules,2020,0.012253036913102054,1
W3088331602,Decoding Strategies for Improving Low-Resource Machine Translation,2020,0.012238273838336578,1
W2960374072,WikiMatrix: Mining 135M Parallel Sentences in 1620 Language Pairs from Wikipedia,2019,0.01222969348759255,1
W3033962033,Modeling Discourse Structure for Document-level Neural Machine Translation,2020,0.012195978742265592,1
W3102885980,Generating Diverse Translation from Model Distribution with Dropout,2020,0.012184629495252402,1
W4285128732,latent-GLAT: Glancing at Latent Variables for Parallel Text Generation,2022,0.012171289821920235,1
W2998335012,Explicit Sentence Compression for Neural Machine Translation,2020,0.012170954186774162,1
W3035291402,Learning Architectures from an Extended Search Space for Language Modeling,2020,0.01216566376583197,1
W3034881347,Simple and Effective Retrieve-Edit-Rerank Text Generation,2020,0.012164657082456804,1
W4380152257,A benchmark dataset and evaluation methodology for Chinese zero pronoun translation,2023,0.012158021999505237,1
W4205476602,End-to-end entity-aware neural machine translation,2022,0.012138422753143377,1
W3035169973,AMR Parsing with Latent Structural Information,2020,0.012127875410945598,1
W2952479981,Interactive Attention for Neural Machine Translation,2016,0.012120994554530713,1
W3180936947,"Neural machine translation: past, present, and future",2021,0.012108205931313825,1
W3174339925,An Efficient Transformer Decoder with Compressed Sub-layers,2021,0.012079788013922397,1
W3200520312,SHAPE: Shifted Absolute Position Embedding for Transformers,2021,0.012048659866748588,1
W2983981554,From Research to Production and Back: Ludicrously Fast Neural Machine Translation,2019,0.012033003967397517,1
W3175663471,Crafting Adversarial Examples for Neural Machine Translation,2021,0.012027481090971483,1
W4376612203,Nearest Neighbor Non-autoregressive Text Generation,2023,0.012027233411690201,1
W4223967157,ODE Transformer: An Ordinary Differential Equation-Inspired Model for Sequence Generation,2022,0.012007447348968027,1
W4385574203,GuoFeng: A Benchmark for Zero Pronoun Recovery and Translation,2022,0.012006256589373404,1
W3101734317,Online Back-Parsing for AMR-to-Text Generation,2020,0.011997881127019206,1
W2997015083,Context based machine translation with recurrent neural network for English–Amharic translation,2021,0.011989668015227977,1
W3099872554,POINTER: Constrained Progressive Text Generation via Insertion-based Generative Pre-training,2020,0.011950618226264361,1
W2998353611,Neural Machine Translation with Byte-Level Subwords,2020,0.011949074523085938,1
W3155618984,Machine Translationese: Effects of Algorithmic Bias on Linguistic Complexity in Machine Translation,2021,0.011944418647013514,1
W4409799499,Prompt enhanced neural machine translation with POS tags,2025,0.01193273898105976,1
W3101299315,"Lightweight, Dynamic Graph Convolutional Networks for AMR-to-Text Generation",2020,0.011923569356979623,1
W2552838200,Neural Machine Translation with Reconstruction,2016,0.01189124307142012,1
W4287258879,BlonDe: An Automatic Evaluation Metric for Document-level Machine Translation,2022,0.011848903075873557,1
W4251616496,Proceedings of the Third Workshop on Discourse in Machine Translation,2017,0.011844272233176948,1
W3160789530,Neural Inverse Text Normalization,2021,0.011825671848172684,1
W2971046749,INMT: Interactive Neural Machine Translation Prediction,2019,0.011804802681427641,1
W3122317902,GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding,2021,0.011801422969315864,1
W3101155369,Self-Paced Learning for Neural Machine Translation,2020,0.011758023484697568,1
W4407290098,Research on morphological knowledge-guided low-resource agglutinative languages-Chinese translation,2025,0.01173529821739997,1
W2971319154,Erroneous data generation for Grammatical Error Correction,2019,0.011732729360761696,1
W3103334733,Understanding the Difficulty of Training Transformers,2020,0.01171793795583437,1
W3112317145,SongMASS: Automatic Song Writing with Pre-training and Alignment Constraint,2021,0.011715614240068296,1
W4285255685,IndicBART: A Pre-trained Model for Indic Natural Language Generation,2022,0.011713379767985223,1
W2964189376,DiSAN: Directional Self-Attention Network for RNN/CNN-Free Language Understanding,2018,0.01169896571667837,1
W3037973456,PowerNorm: Rethinking Batch Normalization in Transformers,2020,0.011698875117738362,1
W4385572987,Chunk-based Nearest Neighbor Machine Translation,2022,0.011685699301380784,1
W2964053550,Tensorized Self-Attention: Efficiently Modeling Pairwise and Global Dependencies Together,2019,0.01163927034303784,1
W4365802915,HanoiT: Enhancing Context-aware Translation via Selective Context,2023,0.011630664475098022,1
W2963593215,Prior Knowledge Integration for Neural Machine Translation using Posterior Regularization,2017,0.011620018357466951,1
W3199990076,The Trade-offs of Domain Adaptation for Neural Language Models,2022,0.011602371181955212,1
W2995971510,Encoding word order in complex embeddings,2019,0.011595380603458605,1
W4285182954,BiTIIMT: A Bilingual Text-infilling Method for Interactive Machine Translation,2022,0.011582866411538772,1
W2936497627,Language Models with Transformers,2019,0.011539793555251369,1
W3105136071,Large-Scale Learnable Graph Convolutional Networks,2018,0.011485115227929573,1
W2951184134,Google's Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation,2016,0.011480288781258159,1
W4287889965,Quality-Aware Decoding for Neural Machine Translation,2022,0.011458800375527841,1
W2757920198,Controlling the Voice of a Sentence in Japanese-to-English Neural Machine Translation.,2016,0.011436337622985595,1
W2951391755,AMR Parsing as Sequence-to-Graph Transduction,2019,0.011434971067714714,1
W2949830548,Negative Lexically Constrained Decoding for Paraphrase Generation,2019,0.011422298477452223,1
W2553397501,Quasi-Recurrent Neural Networks,2018,0.0114152839998664,1
W4389519128,"Machine Translation with Large Language Models: Prompting, Few-shot Learning, and Fine-tuning with QLoRA",2023,0.01139885308980683,1
W3084095723,Unsupervised Quality Estimation for Neural Machine Translation,2020,0.01137158753321078,1
W2986922898,Compressive Transformers for Long-Range Sequence Modelling,2019,0.011367120381359296,1
W2986815055,DSTP-RNN: A dual-stage two-phase attention-based recurrent neural network for long-term and multivariate time series prediction,2019,0.011366246715212755,1
W4285209801,Adjusting the Precision-Recall Trade-Off with Align-and-Predict Decoding for Grammatical Error Correction,2022,0.01133561706400051,1
W2985010700,Context-aware Neural Machine Translation with Coreference Information,2019,0.011308605483328418,1
W3205972749,Taming Sparsely Activated Transformer with Stochastic Experts,2021,0.011302661047642389,1
W2949405462,Unsupervised Parallel Sentence Extraction with Parallel Segment Detection Helps Machine Translation,2019,0.01129603144948947,1
W4401626610,"Recurrent Neural Networks: A Comprehensive Review of Architectures, Variants, and Applications",2024,0.011278509004073454,1
W2971332944,Learning to combine Grammatical Error Corrections,2019,0.011269354025349699,1
W2997517014,Efficient Content-Based Sparse Attention with Routing Transformers,2020,0.011243980160008644,1
W3198957252,LM-Critic: Language Models for Unsupervised Grammatical Error Correction,2021,0.011221394639611044,1
W3046263488,The importance of short lag-time in the runoff forecasting model based on long short-term memory,2020,0.011220356543598016,1
W4316468172,Low-Resource Neural Machine Translation Improvement Using Source-Side Monolingual Data,2023,0.011217261628003988,1
W2952436057,Quasi-Recurrent Neural Networks,2016,0.01121564671480103,1
W2525332836,Pointer Sentinel Mixture Models,2016,0.01121146403701613,1
W4225388806,Nearest Neighbor Knowledge Distillation for Neural Machine Translation,2022,0.011208761623844486,1
W3008282111,Tree-structured Attention with Hierarchical Accumulation,2020,0.011196319915170491,1
W2919188216,Reinforcement Learning based Curriculum Optimization for Neural Machine Translation,2019,0.011194414125872229,1
W2963928591,Recurrent Stacking of Layers for Compact Neural Machine Translation Models,2019,0.011188728173773869,1
W3175591469,Semantic Representation for Dialogue Modeling,2021,0.011179292227990974,1
W3119000810,The Tatoeba Translation Challenge – Realistic Data Sets for Low Resource and Multilingual MT,2020,0.011169609931089824,1
W4281483006,Sequence-to-Action: Grammatical Error Correction with Action Guided Sequence Generation,2022,0.01116591597068998,1
W3034700448,Efficient Context-Aware Neural Machine Translation with Layer-Wise Weighting and Input-Aware Gating,2020,0.011161578195224621,1
W3153854882,Better Neural Machine Translation by Extracting Linguistic Information from BERT,2021,0.011128054570680836,1
W4386600757,Towards better Chinese-centric neural machine translation for low-resource languages,2023,0.011092072746899943,1
W2963970792,Language modeling with gated convolutional networks,2017,0.01107723461553717,1
W3154987757,Robust Open-Vocabulary Translation from Visual Text Representations,2021,0.011076079367804135,1
W2902582221,A Pronoun Test Suite Evaluation of the English–German MT Systems at WMT 2018,2018,0.011055846327799034,1
W4389520065,Document-Level Machine Translation with Large Language Models,2023,0.011041528783866071,1
W2905224888,Graph Neural Networks: A Review of Methods and Applications,2018,0.011023603280525453,1
W3006127095,"Deep Learning for Source Code Modeling and Generation: Models, Applications and Challenges.",2020,0.011013969215929802,1
W4392623252,Unsupervised Multimodal Machine Translation for Low-resource Distant Language Pairs,2024,0.011011831291911734,1
W2949938546,Generating Diverse Translations with Sentence Codes,2019,0.010992802503320647,1
W4385574256,Breaking the Representation Bottleneck of Chinese Characters: Neural Machine Translation with Stroke Sequence Modeling,2022,0.010978925896958076,1
W3034773362,Multimodal Transformer for Multimodal Machine Translation,2020,0.010967212091796161,1
W3211994460,Beyond Grammatical Error Correction: Improving L1-influenced research writing in English using pre-trained encoder-decoder models,2021,0.010965025540106395,1
W3010232603,LIUM-CVC Submissions for WMT18 Multimodal Translation Task,2018,0.010951177953879102,1
W4206119104,Region-attentive multimodal neural machine translation,2022,0.01094393883841649,1
W2890908793,Top-down Tree Structured Decoding with Syntactic Connections for Neural Machine Translation and Parsing,2018,0.010928929532895048,1
W3200409031,Do Long-Range Language Models Actually Use Long-Range Context?,2021,0.01089728167372069,1
W3172643943,Choose a Transformer: Fourier or Galerkin,2021,0.010893152025873655,1
W3202970975,Language Translation as a Socio-Technical System:Case-Studies of Mixed-Initiative Interactions,2021,0.010881051588539619,1
W3154504973,Non-Autoregressive Text Generation with Pre-trained Language Models,2021,0.010860838561360981,1
W2908503141,MuVAN: A Multi-view Attention Network for Multivariate Temporal Data,2018,0.010851659447509317,1
W2945927415,AMR Parsing as Sequence-to-Graph Transduction,2019,0.010845742344244671,1
W2984864519,BP-Transformer: Modelling Long-Range Context via Binary Partitioning,2019,0.01084106633119171,1
W3156246620,EDITOR: An Edit-Based Transformer with Repositioning for Neural Machine Translation with Soft Lexical Constraints,2021,0.010833568246824176,1
W2952474700,Dynamically Composing Domain-Data Selection with Clean-Data Selection by “Co-Curricular Learning” for Neural Machine Translation,2019,0.010811632894447495,1
W2740087922,Chunk-based Decoder for Neural Machine Translation,2017,0.010809231873082165,1
W3121071870,Findings of the WMT 2023 Shared Task on Automatic Post-Editing,2023,0.01080185064595082,1
W4389777735,Hallucinations in Large Multilingual Translation Models,2023,0.010741135948208363,1
W2965575120,Dynamic Layer Aggregation for Neural Machine Translation with Routing-by-Agreement,2019,0.010725703161801138,1
W2955666607,The Impact of Preprocessing on Arabic-English Statistical and Neural Machine Translation,2019,0.01068773498152289,1
W3136101012,Wind Power Forecasting Using Attention-Based Recurrent Neural Networks: A Comparative Study,2021,0.010683264469564408,1
W3105238007,ETC: Encoding Long and Structured Inputs in Transformers,2020,0.010639969570527333,1
W4385574244,Towards Opening the Black Box of Neural Machine Translation: Source and Target Interpretations of the Transformer,2022,0.01063416194534138,1
W4285275708,Confidence Based Bidirectional Global Context Aware Training Framework for Neural Machine Translation,2022,0.010597399575502467,1
W3120929527,Findings of the 2020 Conference on Machine Translation (WMT20),2020,0.010589537619024621,1
W2997636815,MaskGEC: Improving Neural Grammatical Error Correction via Dynamic Masking,2020,0.010588765467521813,1
W2970686691,Low-Resource Corpus Filtering Using Multilingual Sentence Embeddings,2019,0.010538885712035725,1
W2769134508,Zero-Shot Style Transfer in Text Using Recurrent Neural Networks.,2017,0.01051933756434316,1
W4224925597,Adversarial Mask Transformer for Sequential Learning,2022,0.010486128885290798,1
W4285296929,Pre-Trained Multilingual Sequence-to-Sequence Models: A Hope for Low-Resource Language Translation?,2022,0.010445478152668438,1
W2567070169,Language Modeling with Gated Convolutional Networks,2016,0.010409855753848464,1
W2966045039,DuTongChuan: Context-aware Translation Model for Simultaneous Interpreting,2019,0.010400651656624776,1
W2787026069,Controlling Target Features in Neural Machine Translation via Prefix Constraints,2017,0.010400416262963705,1
W3105626768,Learning Adaptive Segmentation Policy for Simultaneous Translation,2020,0.010389157041252041,1
W3102662787,Weakly Supervised Medication Regimen Extraction from Medical Conversations,2020,0.010364835841196225,1
W4407778892,Technical Report of OPPO’s Machine Translation Systems for CCMT 2024,2025,0.010305405308593913,1
W4394871646,Are Character-level Translations Worth the Wait? Comparing ByT5 and mT5 for Machine Translation,2024,0.010264648692967315,1
W2951672049,Improving Neural Language Models with a Continuous Cache,2016,0.010251603714753792,1
W4385570671,Knowledge Transfer in Incremental Learning for Multilingual Neural Machine Translation,2023,0.010248493278178871,1
W2970780025,Customizing Neural Machine Translation for Subtitling,2019,0.010243057474432419,1
W3169496116,Mask Attention Networks: Rethinking and Strengthen Transformer,2021,0.01022577986502662,1
W2527133236,Lattice-Based Recurrent Neural Network Encoders for Neural Machine Translation,2017,0.010225388005346179,1
W3214250531,Controlling Machine Translation for Multiple Attributes with Additive Interventions,2021,0.010164123152490628,1
W3174805484,Meta-Curriculum Learning for Domain Adaptation in Neural Machine Translation,2021,0.010141311637882799,1
W3035618017,Improving Transformer Optimization Through Better Initialization,2020,0.010138432111800547,1
W2887005286,Low-Latency Neural Speech Translation,2018,0.010138199503670115,1
W4318815354,Graph Neural Networks for Natural Language Processing: A Survey,2023,0.010102102870326621,1
W3203011138,A Transformer-Based Neural Machine Translation Model for Arabic Dialects That Utilizes Subword Units,2021,0.010071823530239011,1
W2945888757,Highly Effective,2019,0.010068710882060334,1
W2549416390,Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling,2016,0.010065953469076495,1
W4324157275,Improving Multilingual Neural Machine Translation System for Indic Languages,2023,0.010010721234589291,1
W3045733172,Big Bird: Transformers for Longer Sequences,2020,0.009998475773092751,1
W3007216417,On Feature Normalization and Data Augmentation,2020,0.009977551737475197,1
W3170740203,Sentence Concatenation Approach to Data Augmentation for Neural Machine Translation,2021,0.00996486333200456,1
W2810953419,English–Mizo Machine Translation using neural and statistical approaches,2018,0.009937034118241879,1
W3111507638,Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting,2020,0.009930415013412913,1
W2463507112,Sequence-Level Knowledge Distillation,2016,0.009910120377643045,1
W3020775333,Augmenting Transformers with KNN-Based Composite Memory for Dialogue,2020,0.00988630570350577,1
W2949305207,Coherent Comments Generation for Chinese Articles with a Graph-to-Sequence Model,2019,0.009882854857246078,1
W2789543585,Fast Decoding in Sequence Models using Discrete Latent Variables,2018,0.009860473837654444,1
W2963824830,“Bilingual Expert” Can Find Translation Errors,2019,0.009830731278262868,1
W2594978815,Data Noising as Smoothing in Neural Network Language Models,2017,0.009820998626050065,1
W2989571009,MUSE: Parallel Multi-Scale Attention for Sequence to Sequence Learning,2019,0.009802006750200355,1
W2924961378,Structural Neural Encoders for,2019,0.009738254541095944,1
W3175441946,A Simple Recipe for Multilingual Grammatical Error Correction,2021,0.00973562078270313,1
W3120951354,Two-Phase Cross-Lingual Language Model Fine-Tuning for Machine Translation Quality Estimation.,2020,0.009722290657737569,1
W2962678612,ESCAPE: a Large-scale Synthetic Corpus for Automatic Post-Editing,2018,0.009717835741846056,1
W2797371199,Approaching Neural Grammatical Error Correction as a Low-Resource Machine Translation Task,2018,0.009690468983935193,1
W4382202554,Prompting Neural Machine Translation with Translation Memories,2023,0.009682717734137062,1
W2981515358,WordNet Gloss Translation for Under-resourced Languages using Multilingual Neural Machine Translation.,2019,0.00968221544551714,1
W3132134318,What has changed with neural machine translation? A critical review of human factors,2021,0.009667026657581571,1
W3037798801,Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention,2020,0.009657152471791912,1
W3104132024,Fine-Grained Human Evaluation of Neural Versus Phrase-Based Machine Translation,2017,0.009616188915687959,1
W4399851779,Enhancing Document-Level Translation of Large Language Model Via Translation Mixed-Instructions,2024,0.00960675884304882,1
W2971287409,One Model to Learn Both: Zero Pronoun Prediction and Translation,2019,0.009595969507072276,1
W2769618705,Neural Text Generation: A Practical Guide,2017,0.009588246559446987,1
W2963109131,Grammatical Error Correction with Neural Reinforcement Learning,2017,0.009587796247276615,1
W2964204137,Multilingual Hierarchical Attention Networks for Document Classification,2017,0.009554803229816396,1
W2950300355,Regularizing Neural Networks by Penalizing Confident Output Distributions,2017,0.009553221110637236,1
W3098985395,Scheduled DropHead: A Regularization Method for Transformer Models,2020,0.009551874750852925,1
W4292595872,Improving Readability for Automatic Speech Recognition Transcription,2022,0.00953333146202415,1
W3212440929,Geo-BERT Pre-training Model for Query Rewriting in POI Search,2021,0.009532678857730898,1
W3135593154,Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth,2021,0.009530786153187185,1
W2759511005,Neural Machine Translation for Cross-Lingual Pronoun Prediction,2017,0.009524393996951142,1
W2983902802,Transformer Dissection: An Unified Understanding for Transformer’s Attention via the Lens of Kernel,2019,0.009517204764941766,1
W2955750298,Character-level Supervision for Low-resource POS Tagging,2018,0.009493416689102611,1
W3174554374,Towards Fully Automated Manga Translation,2021,0.00948386084763316,1
W4225302758,ISOMETRIC MT: Neural Machine Translation for Automatic Dubbing,2022,0.009483550352156858,1
W2889841884,Cross-lingual Decompositional Semantic Parsing,2018,0.00947144220798575,1
W2796167946,Graph2Seq: Graph to Sequence Learning with Attention-based Neural Networks,2018,0.009465577223612645,1
W3113952093,Neural Grammatical Error Correction for Romanian,2020,0.009443827088627765,1
W2970550739,Self-Attention with Structural Position Representations,2019,0.009416922874665315,1
W4285170631,Efficient Machine Translation Domain Adaptation,2022,0.00939019818432559,1
W4384161799,Supervised Copy Mechanism for Grammatical Error Correction,2023,0.009382720466478152,1
W3035376668,Unsupervised Morphological Paradigm Completion,2020,0.009372623432723963,1
W4225849768,Incorporating rich syntax information in Grammatical Error Correction,2022,0.009349935414450143,1
W2964941017,Supervised and Unsupervised Neural Approaches to Text Readability,2021,0.009337070535851626,1
W4386566814,Summarize and Generate to Back-translate: Unsupervised Translation of Programming Languages,2023,0.009313095184173538,1
W3172044616,Neural Quality Estimation with Multiple Hypotheses for Grammatical Error Correction,2021,0.009285249855120704,1
W4323338301,A Data Augmentation Method for English-Vietnamese Neural Machine Translation,2023,0.00928041855631509,1
W2962947230,AMR Parsing as Graph Prediction with Latent Alignment,2018,0.009263118666834692,1
W2911379778,GILE: A Generalized Input-Label Embedding for Text Classification,2019,0.009247298677750393,1
W2564861257,Source sentence simplification for statistical machine translation,2016,0.009225032903552156,1
W3153368012,When FastText Pays Attention: Efficient Estimation of Word Representations using Constrained Positional Weighting,2022,0.009218703011979607,1
W3166029516,Non-Autoregressive Semantic Parsing for Compositional Task-Oriented Dialog,2021,0.009195698590622619,1
W2988390689,Minimally-Augmented Grammatical Error Correction,2019,0.009186744428942661,1
W3045571807,Robust Prediction of Punctuation and Truecasing for Medical ASR,2020,0.009185709759479976,1
W2995253144,Hierarchical Data Augmentation and the Application in Text Classification,2019,0.009145637804694799,1
W3106124812,Graph-to-Tree Neural Networks for Learning Structured Input-Output Translation with Applications to Semantic Parsing and Math Word Problem,2020,0.00912494425670113,1
W2605202026,Neural Lattice-to-Sequence Models for Uncertain Inputs,2017,0.009103719073676061,1
W3163874900,DirectQE: Direct Pretraining for Machine Translation Quality Estimation,2021,0.009101183592873993,1
W2963680955,What Level of Quality Can Neural Machine Translation Attain on Literary Text?,2018,0.009071098110456557,1
W4378619223,Reduction of Neural Machine Translation Failures by Incorporating Statistical Machine Translation,2023,0.009030000930116827,1
W2902463012,Findings of the WMT 2018 Shared Task on Quality Estimation,2018,0.009012821916799123,1
W2986388218,Grammatical Error Correction in Low-Resource Scenarios,2019,0.0090033153947167,1
W2939208918,Self-Attention Graph Pooling,2019,0.00897111326308978,1
W2766184602,Emergent Translation in Multi-Agent Communication,2017,0.008968992671459166,1
W2894741346,Seq2Slate: Re-ranking and Slate Optimization with RNNs,2018,0.0089093665823647,1
W3175710487,H-Transformer-1D: Fast One-Dimensional Hierarchical Attention for Sequences,2021,0.00890366044089927,1
W3171460770,Dynamic Language Models for Continuously Evolving Content,2021,0.008892796778255701,1
W4385570052,Synthetic Pre-Training Tasks for Neural Machine Translation,2023,0.008887462864034527,1
W2619122421,A Regularized Framework for Sparse and Structured Neural Attention,2017,0.008877147305701352,1
W3207024370,GNN-LM: Language Modeling based on Global Contexts via GNN,2021,0.008872216577038055,1
W4394698525,"DeepNet: Scaling Transformers to 1,000 Layers",2024,0.008866742573626,1
W2414484917,Sequence-to-Sequence Learning as Beam-Search Optimization,2016,0.008864373336243398,1
W3171665133,SCINet: Time Series Modeling and Forecasting with Sample Convolution and Interaction,2021,0.008864034324974243,1
W4385569940,Scene Graph as Pivoting: Inference-time Image-free Unsupervised Multimodal Machine Translation with Visual Scene Hallucination,2023,0.008835279203240275,1
W2963374482,A Graph-to-Sequence Model for AMR-to-Text Generation,2018,0.008821629204596131,1
W3024508854,A Comprehensive Survey of Grammar Error Correction,2020,0.008812450461842572,1
W3124842510,Automated Source Code Generation and Auto-Completion Using Deep Learning: Comparing and Discussing Current Language Model-Related Approaches,2021,0.008808934885551921,1
W4385571393,SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control,2023,0.008796511276239285,1
W3173407600,Dual-Aspect Self-Attention Based on Transformer for Remaining Useful Life Prediction,2022,0.008786728851356012,1
W2963836274,Open Information Extraction from Question-Answer Pairs,2019,0.008748157879061092,1
W2963912736,Joint Embedding of Words and Labels for Text Classification,2018,0.008740158368136536,1
W3133618741,A review of irregular time series data handling with gated recurrent neural networks,2021,0.008734511035055462,1
W3158927431,Machine Translation Verbosity Control for Automatic Dubbing,2021,0.008734362396411125,1
W2998681865,Neuron Interaction Based Representation Composition for Neural Machine Translation,2020,0.008719617975047849,1
W2792764867,An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling,2018,0.008702389250716102,1
W4385572835,LVP-M3: Language-aware Visual Prompt for Multilingual Multimodal Machine Translation,2022,0.00868325576819443,1
W2998702685,Graph Transformer for Graph-to-Sequence Learning,2020,0.008680256003002108,1
W2952443824,Paraphrases as Foreign Languages in Multilingual Neural Machine Translation,2019,0.008667127679056065,1
W3176948526,RealFormer: Transformer Likes Residual Attention,2021,0.008643559678988045,1
W4285127897,Ensembling and Knowledge Distilling of Large Sequence Taggers for Grammatical Error Correction,2022,0.008636171176919429,1
W3160523328,FastCorrect: Fast Error Correction with Edit Alignment for Automatic Speech Recognition,2021,0.008608529513180871,1
W2999089077,"Progress in Neural NLP: Modeling, Learning, and Reasoning",2020,0.008576433228940816,1
W3168492867,Learnable Fourier Features for Multi-Dimensional Spatial Positional Encoding,2021,0.00856997872465533,1
W3007332492,Benchmarking Graph Neural Networks,2020,0.008557075727284901,1
W4391311153,Low Resource Arabic Dialects Transformer Neural Machine Translation Improvement through Incremental Transfer of Shared Linguistic Features,2024,0.008555245344609188,1
W2901299405,GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism,2018,0.008553543912871265,1
W3172198372,LightSeq: A High Performance Inference Library for Transformers,2021,0.008541917196850157,1
W3192500523,The Paradox of the Compositionality of Natural Language: A Neural Machine Translation Case Study,2022,0.008536821712885556,1
W3123673616,Addressing Some Limitations of Transformers with Feedback Memory,2020,0.008527265787559569,1
W4319598896,The neural machine translation models for the low-resource Kazakh–English language pair,2023,0.008500137421180505,1
W3007385124,Using a thousand optimization tasks to learn hyperparameter search strategies,2020,0.008494914502374273,1
W3115860342,RealFormer: Transformer Likes Residual Attention,2020,0.008445645619133262,1
W4385567238,SynGEC: Syntax-Enhanced Grammatical Error Correction with a Tailored GEC-Oriented Parser,2022,0.00844562716172442,1
W3016635207,Understanding the Difficulty of Training Transformers,2020,0.00844325646677934,1
W4410253015,Deep Learning Techniques for Machine Translation: A Survey,2025,0.008425326305412437,1
W2811992740,Review of State-of-the-Art in Deep Learning Artificial Intelligence,2018,0.008416424153805493,1
W3156993586,Document-level grammatical error correction,2021,0.008411882006985621,1
W2988226917,DSANet,2019,0.008385067876458178,1
W2949558560,Bridging the Gap: Attending to Discontinuity in Identification of Multiword Expressions,2019,0.008377846208095506,1
W3207377511,The Dawn of Quantum Natural Language Processing,2022,0.00836703811227523,1
W4407591251,Incorporating bilingual translation templates into neural machine translation,2025,0.0083303033919197,1
W3109714359,Step-Wise Deep Learning Models for Solving Routing Problems,2020,0.008314568339793918,1
W2890212927,Better Transition-Based AMR Parsing with a Refined Search Space,2018,0.008302507347859575,1
W4381461529,Optimizing the impact of data augmentation for low-resource grammatical error correction,2023,0.008289445762305201,1
W3092632253,MLQE-PE: A Multilingual Quality Estimation and Post-Editing Dataset.,2020,0.008283153357004061,1
W3017887871,Incorporating Sememes into Chinese Definition Modeling,2020,0.00828269741377495,1
W2799493995,Post-editing Effort of a Novel With Statistical and Neural Machine Translation,2018,0.008282311651218859,1
W3015712039,A Spatial–Temporal Attention Approach for Traffic Prediction,2020,0.008271035581647677,1
W4229040548,A Compression-Based Multiple Subword Segmentation for Neural Machine Translation,2022,0.008261370607280312,1
W2891713103,Encoding Gated Translation Memory into Neural Machine Translation,2018,0.008257997117292602,1
W2893384461,Research on the LSTM Mongolian and Chinese machine translation based on morpheme encoding,2018,0.008249605242613285,1
W3164487383,Spatial-Temporal Conv-Sequence Learning With Accident Encoding for Traffic Flow Prediction,2022,0.00823518183510039,1
W3121416198,Graph-Based Bilingual Word Embedding for Statistical Machine Translation,2018,0.008215941878943174,1
W3174974057,Attention-based model for predicting question relatedness on Stack Overflow,2021,0.008205070361737414,1
W2728069591,Multilingual Hierarchical Attention Networks for Document Classification,2017,0.00818646905432464,1
W2970418174,Automatically Learning Data Augmentation Policies for Dialogue Tasks,2019,0.008132973981689448,1
W3101177651,Learning Private Neural Language Modeling with Attentive Aggregation,2019,0.008087690600171197,1
W3091991378,Efficient Wait-k Models for Simultaneous Machine Translation,2020,0.00806596093265399,1
W3199518308,Scalable and Efficient MoE Training for Multitask Multilingual Models,2021,0.008026809168802645,1
W3102823002,Gradient-guided Unsupervised Lexically Constrained Text Generation,2020,0.008024111275419141,1
W4285227169,Interpretability for Language Learners Using Example-Based Grammatical Error Correction,2022,0.008016470736412928,1
W2573834658,Zero-resource machine translation by multimodal encoder–decoder network with multimedia pivot,2017,0.008002881361222753,1
W3177804148,Can Transformers Jump Around Right in Natural Language? Assessing Performance Transfer from SCAN,2021,0.0079984014273314,1
W3045622142,Simultaneous Translation and Paraphrase for Language Education,2020,0.007998278471902126,1
W3120329789,BERT Enhanced Neural Machine Translation and Sequence Tagging Model for Chinese Grammatical Error Diagnosis,2020,0.00799359457205511,1
W2890096158,Temporal pattern attention for multivariate time series forecasting,2019,0.007991456055001856,1
W4401889742,"Recurrent Neural Networks: A Comprehensive Review of Architectures, Variants, and Applications",2024,0.007967326837556129,1
W3121592593,Long Range Arena : A Benchmark for Efficient Transformers,2021,0.007935346681515682,1
W3153224075,Applying the Transformer to Character-level Transduction,2021,0.00792893854594922,1
W3091156754,Rethinking Attention with Performers,2020,0.007889712466562225,1
W3099136959,Dipole,2017,0.00787884603615725,1
W3152893301,Graph neural networks: A review of methods and applications,2020,0.00787649014514706,1
W2995273672,Are Transformers universal approximators of sequence-to-sequence functions?,2020,0.007838856568158458,1
W2804604520,RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Networks on Electronic Medical Records,2018,0.007801005830177846,1
W3026538704,Applying the Transformer to Character-level Transduction,2020,0.007790096382536422,1
W4324142619,Contrastive Adversarial Training for Multi-Modal Machine Translation,2023,0.007785854502475672,1
W3100715140,Consistency of a Recurrent Language Model With Respect to Incomplete Decoding,2020,0.007779396124850362,1
W2971724044,Recurrent Neural Networks for Time Series Forecasting: Current status and future directions,2020,0.007769558142587323,1
W2885928764,A Sequence to Sequence Learning for Chinese Grammatical Error Correction,2018,0.007734855618945888,1
W3114268635,Reservoir Transformers,2021,0.0077340784793227734,1
W3116890009,Synthetic data with neural machine translation for automatic correction in arabic grammar,2020,0.007723949998441692,1
W2838081464,deepQuest: A Framework for Neural-based Quality Estimation,2018,0.007692522532777082,1
W3113709932,Rethinking the Value of Transformer Components,2020,0.007688183139760903,1
W2962906084,RIGA at SemEval-2016 Task 8: Impact of Smatch Extensions and Character-Level Neural Translation on AMR Parsing Accuracy,2016,0.007688129694964043,1
W3142584950,A large English–Thai parallel corpus from the web and machine-generated text,2021,0.007662991593641024,1
W4319029136,Learning from flowsheets: A generative transformer model for autocompletion of flowsheets,2023,0.007651165549201598,1
W4237056802,Exploring Methods for Generating Feedback Comments for Writing Learning,2021,0.007650328364768604,1
W3188334090,(Un)solving Morphological Inflection: Lemma Overlap Artificially Inflates Models’ Performance,2022,0.007639706785070822,1
W2963368804,Deep Learning Under Privileged Information Using Heteroscedastic Dropout,2018,0.00763158625963242,1
W1816079941,When Are Tree Structures Necessary for Deep Learning of Representations?,2015,0.007587840935427736,1
W4287888115,Maximum Bayes Smatch Ensemble Distillation for AMR Parsing,2022,0.007564719304067736,1
W4393160356,Hierarchical Text Classification and Its Foundations: A Review of Current Research,2024,0.007555454976930511,1
W3035586188,AMR Parsing via Graph-Sequence Iterative Inference,2020,0.007553128753656037,1
W4385571264,In-context Examples Selection for Machine Translation,2023,0.00754004044989316,1
W4385571208,Exploring Effectiveness of GPT-3 in Grammatical Error Correction: A Study on Performance and Controllability in Prompt-Based Methods,2023,0.007537802153031278,1
W3119746927,Efficient Object-Level Visual Context Modeling for Multimodal Machine Translation: Masking Irrelevant Objects Helps Grounding,2021,0.007515217928814245,1
W4281741710,A Comprehensive Survey on Various Fully Automatic Machine Translation Evaluation Metrics,2022,0.0075139987478385715,1
W2952136670,Frustratingly Short Attention Spans in Neural Language Modeling,2017,0.007511099364356675,1
W2585253991,Neural Multi-Source Morphological Reinflection,2017,0.007486362380227462,1
W3173677700,One SPRING to Rule Them Both: Symmetric AMR Semantic Parsing and Generation without a Complex Pipeline,2021,0.007480484099594112,1
W2964022663,Identifying Semantic Divergences in Parallel Text without Annotations,2018,0.007473019178373363,1
W4392715732,Multilingual Neural Machine Translation for Indic to Indic Languages,2024,0.007460590989627863,1
W3037838322,From Speech-to-Speech Translation to Automatic Dubbing,2020,0.007427612432762053,1
W2804145368,Theory and Experiments on Vector Quantized Autoencoders,2018,0.007421469003703813,1
W1847088711,Gated Feedback Recurrent Neural Networks,2015,0.007418213485592142,1
W3105425516,CCAligned: A Massive Collection of Cross-Lingual Web-Document Pairs,2020,0.007408499857958286,1
W4399586229,Revolutionising Translation with AI: Unravelling Neural Machine Translation and Generative Pre-trained Large Language Models,2024,0.00734528631623457,1
W2951352467,A Retrieve-and-Edit Framework for Predicting Structured Outputs,2018,0.007342339116646324,1
W4385572877,Neural Machine Translation with Contrastive Translation Memories,2022,0.00731576209048734,1
W2785806165,A Multi-Task Framework for Monitoring Health Conditions via Attention-based Recurrent Neural Networks.,2017,0.007310546775787744,1
W3033943443,Masked Language Modeling for Proteins via Linearly Scalable Long-Context Transformers,2020,0.007297105799094759,1
W1800356822,A Simple Way to Initialize Recurrent Networks of Rectified Linear Units,2015,0.007292564143540475,1
W3106274667,OCR Post Correction for Endangered Language Texts,2020,0.007277951255841163,1
W2224454470,Language to Logical Form with Neural Attention,2016,0.007237354068546132,1
W2964101465,Data2Vis: Automatic Generation of Data Visualizations Using Sequence-to-Sequence Recurrent Neural Networks,2019,0.007180234000641545,1
W3084827186,Quality Expectations of Machine Translation,2018,0.007170245381427544,1
W2963194310,Learning to Jointly Translate and Predict Dropped Pronouns with a Shared Reconstruction Mechanism,2018,0.0071699729073586935,1
W2972677740,Token-Level Ensemble Distillation for Grapheme-to-Phoneme Conversion,2019,0.007162133540194987,1
W3138833245,Continual learning for recurrent neural networks: An empirical evaluation,2021,0.007132330899178919,1
W4407574881,Improving Low-Resource Kazakh-English and Turkish-English Neural Machine Translation Using Transfer Learning and Part of Speech Tags,2025,0.007118064144799284,1
W2901578516,Topical Co-Attention Networks for hashtag recommendation on microblogs,2018,0.007098573042660631,1
W2888799392,Direct Output Connection for a High-Rank Language Model,2018,0.007072987981803441,1
W3181262653,Long-Short Transformer: Efficient Transformers for Language and Vision,2021,0.007037970070401086,1
W2970392338,Hierarchical Document Encoder for Parallel Corpus Mining,2019,0.007030942597161076,1
W2805041018,Unsupervised Text Style Transfer using Language Models as Discriminators,2018,0.006995141280057238,1
W3187058997,BTS: Back TranScription for Speech-to-Text Post-Processor using Text-to-Speech-to-Text,2021,0.006990028822519363,1
W4387787572,Analysis of Language Model Role in Improving Machine Translation Accuracy for Extremely Low Resource Languages,2023,0.006957065242809711,1
W2888726123,Semantic-Unit-Based Dilated Convolution for Multi-Label Text Classification,2018,0.00694614234381673,1
W3103682594,Long Range Arena: A Benchmark for Efficient Transformers,2020,0.006931449632783323,1
W4285241608,On Vision Features in Multimodal Machine Translation,2022,0.006922378979438653,1
W2902545332,The Word Sense Disambiguation Test Suite at WMT18,2018,0.006915122476647969,1
W3170796112,Hash Layers For Large Sparse Models,2021,0.006909282702603268,1
W3132366366,Fusion Models for Improved Image Captioning,2021,0.006897094177478324,1
W3031420959,ADAHESSIAN: An Adaptive Second Order Optimizer for Machine Learning,2021,0.0068961836212891574,1
W4385567303,A Survey on Zero Pronoun Translation,2023,0.006893856232479389,1
W4285270642,Understanding and Improving Sequence-to-Sequence Pretraining for Neural Machine Translation,2022,0.006891168035842636,1
W4306955484,A survey of transformers,2022,0.00689015613082278,1
W3213720774,Grammatical Error Correction with Contrastive Learning in Low Error Density Domains,2021,0.0068697839460099795,1
W4286906805,WeTS: A Benchmark for Translation Suggestion,2022,0.006860224384850769,1
W3202576380,FastCorrect 2: Fast Error Correction on Multiple Candidates for Automatic Speech Recognition,2021,0.006854431519613205,1
W2964028737,Adversarial Generation of Natural Language,2017,0.006844197687468025,1
W4385571866,Improving Grammatical Error Correction with Multimodal Feature Integration,2023,0.0068406005732327075,1
W4391892535,The Impact of Artificial Intelligence on Language Translation: A Review,2024,0.0068245070469754475,1
W4409831893,Spanish to Mexican Sign Language glosses corpus for natural language processing tasks,2025,0.006820494816804863,1
W4311294852,Towards Energy-Preserving Natural Language Understanding With Spiking Neural Networks,2022,0.006807693728395848,1
W2600702321,Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling,2017,0.006767391876121138,1
W4385571296,Bidirectional Transformer Reranker for Grammatical Error Correction,2023,0.006760987688350487,1
W2913917571,Using Wikipedia Edits in Low Resource Grammatical Error Correction,2018,0.006738048006948795,1
W4377211416,Tackling Ambiguity with Images: Improved Multimodal Machine Translation and Contrastive Evaluation,2023,0.00673254590749097,1
W2971043182,The Effect of Translationese in Machine Translation Test Sets,2019,0.006726043856206015,1
W3096648221,Data Weighted Training Strategies for Grammatical Error Correction,2020,0.006721970423720976,1
W3016697633,ETC: Encoding Long and Structured Inputs in Transformers,2020,0.0067085198745420755,1
W2751185861,Training RNNs as Fast as CNNs,2017,0.006703227616792537,1
W4285193872,Mukayese: Turkish NLP Strikes Back,2022,0.006702988835151037,1
W3181186005,Combiner: Full Attention Transformer with Sparse Computation Cost,2021,0.0066593242882655584,1
W4385571532,TemplateGEC: Improving Grammatical Error Correction with Detection Template,2023,0.0066588124760320125,1
W2705373224,Sequence-to-sequence models for punctuated transcription combining lexical and acoustic features,2017,0.00665739684124844,1
W3155116954,Transformer-based Machine Translation for Low-resourced Languages embedded with Language Identification,2021,0.006635811490300999,1
W3104976898,Statistical Power and Translationese in Machine Translation Evaluation,2020,0.00662827574391225,1
W2950129230,Compositional generalization through meta sequence-to-sequence learning,2019,0.006616312563339098,1
W3034561418,Do Transformers Need Deep Long-Range Memory?,2020,0.0066012555188768385,1
W2963716836,Order Matters: Sequence to sequence for sets,2015,0.0065939382127157015,1
W3125056032,Rethinking Attention with Performers,2021,0.006592388179719728,1
W4318588669,Data augmentation using Heuristic Masked Language Modeling,2023,0.00658503284847485,1
W3123221884,An Attention Free Transformer,2021,0.006538997787360707,1
W4212930502,Knowledge Distillation: A Method for Making Neural Machine Translation More Efficient,2022,0.0064715849629555944,1
W2884806734,What to expect from Neural Machine Translation: a practical in-class translation evaluation exercise,2018,0.006469763861346777,1
W3003446182,AMR-To-Text Generation with Graph Transformer,2020,0.00643663514368422,1
W3085422212,Cluster-Former: Clustering-based Sparse Transformer for Long-Range Dependency Encoding,2020,0.006433116964176645,1
W3217545443,Unsupervised time series outlier detection with diversity-driven convolutional ensembles,2021,0.006412700082117485,1
W3006983028,Sparse Sinkhorn Attention,2020,0.006391646937441416,1
W2792376130,An Analysis of Neural Language Modeling at Multiple Scales,2018,0.006382827612485186,1
W2962729168,Reinforced Self-Attention Network: a Hybrid of Hard and Soft Attention for Sequence Modeling,2018,0.00638034111832152,1
W3156646638,Korean Grammatical Error Correction Based on Transformer with Copying Mechanisms and Grammatical Noise Implantation Methods,2021,0.006331872822998517,1
W2951227497,CNNs found to jump around more skillfully than RNNs: Compositional Generalization in Seq2seq Convolutional Networks,2019,0.006322281352391983,1
W2885249278,Automatic Reference-Based Evaluation of Pronoun Translation Misses the Point,2018,0.006314885817531065,1
W3208413651,Structure-aware Fine-tuning of Sequence-to-sequence Transformers for Transition-based AMR Parsing,2021,0.006288453110199589,1
W3091407209,Automatic testing and improvement of machine translation,2020,0.006276171644562082,1
W4396496351,An Evaluation of ChatGPT's Translation Accuracy Using BLEU Score,2024,0.0062519409336798,1
W4386566380,A Low-Resource Approach to the Grammatical Error Correction of Ukrainian,2023,0.006235669709042555,1
W3125658501,A dual‐stage attention‐based Conv‐LSTM network for spatio‐temporal correlation and multivariate time series prediction,2021,0.006202769605564872,1
W2952975409,Neural Architecture Optimization,2018,0.006182481792063633,1
W4389519421,"Large Language Models Effectively Leverage Document-level Context for Literary Translation, but Critical Errors Persist",2023,0.006169298320378127,1
W2898410387,Evaluating prose style transfer with the Bible,2018,0.0061646025537116685,1
W2963472176,Unlabeled Data for Morphological Generation With Character-Based Sequence-to-Sequence Models,2017,0.006151511622475297,1
W3159560594,Designing a Uniform Meaning Representation for Natural Language Processing,2021,0.006151373958189825,1
W4385571312,Subword Segmental Machine Translation: Unifying Segmentation and Target Sentence Generation,2023,0.006149701722337521,1
W2964325863,Learning Character-level Compositionality with Visual Features,2017,0.006138425091209384,1
W2798485145,Multi-Input Attention for Unsupervised OCR Correction,2018,0.006127714558872669,1
W3034651160,Multi-Label and Multilingual News Framing Analysis,2020,0.006125253152165314,1
W2946575095,Interpretable deep learning to map diagnostic texts to ICD-10 codes,2019,0.006101210240874758,1
W2910795780,Graph Convolutional Network with Sequential Attention for Goal-Oriented Dialogue Systems,2019,0.006092161610081595,1
W4385574170,EdgeFormer: A Parameter-Efficient Transformer for On-Device Seq2seq Generation,2022,0.006086116440500039,1
W3126170988,A Transformer Self-attention Model for Time Series Forecasting,2021,0.006061422548392302,1
W3125498921,Cluster-Former: Clustering-based Sparse Transformer for Question Answering,2021,0.006041632644200205,1
W3216107495,Transformers for modeling physical systems,2021,0.006041003368646559,1
W2964010366,Recurrent Neural Networks for Multivariate Time Series with Missing Values,2018,0.0060198176210293705,1
W2991324852,Single Headed Attention RNN: Stop Thinking With Your Head,2019,0.006018404032237762,1
W3101036738,Sparse Communication for Distributed Gradient Descent,2017,0.006017302257651734,1
W3203619751,Long-Range Transformers for Dynamic Spatiotemporal Forecasting,2021,0.00601503212391338,1
W4224299101,StableMoE: Stable Routing Strategy for Mixture of Experts,2022,0.0060146354773717246,1
W2963304263,Recurrent Batch Normalization,2016,0.00599323761850085,1
W3019932981,Beyond 512 Tokens: Siamese Multi-depth Transformer-based Hierarchical Encoder for Long-Form Document Matching,2020,0.005982917909887187,1
W3010212250,Automated text classification of near-misses from safety reports: An improved deep learning approach,2020,0.005966384554703393,1
W2988435740,Low-Rank and Locality Constrained Self-Attention for Sequence Modeling,2019,0.005965673011032224,1
W2885301267,Automatic Spelling Correction for Resource-Scarce Languages using Deep Learning,2018,0.005959682388295507,1
W3118324981,"Machine Translation for English–Inuktitut with Segmentation, Data Acquisition and Pre-Training",2020,0.005947940759386815,1
W4307646385,Multimodality information fusion for automated machine translation,2022,0.005941612219712257,1
W4395680645,Eliciting the Translation Ability of Large Language Models via Multilingual Finetuning with Translation Instructions,2024,0.005930366697099287,1
W3153395274,Machine translation systems and quality assessment: a systematic review,2021,0.005912200298104895,1
W4385573925,Multilingual Sentence Transformer as A Multilingual Word Aligner,2022,0.005897325352722573,1
W4285180072,An Imitation Learning Curriculum for Text Editing with Non-Autoregressive Models,2022,0.005896065829906132,1
W3064840847,HiPPO: Recurrent Memory with Optimal Polynomial Projections,2020,0.005892598579111652,1
W4399687297,Unlocking the language barrier: A Journey through Arabic machine translation,2024,0.005876057027939296,1
W4409990846,Rethinking Transformers for Efficiency and Scalability,2025,0.005860464953029661,1
W3038287124,Multi-Head Attention: Collaborate Instead of Concatenate,2021,0.005854117477771159,1
W2798546337,Discourse Representation Structure Parsing,2018,0.005844159275223689,1
W4362614755,Machine Translation Systems Based on Classical-Statistical-Deep-Learning Approaches,2023,0.005837429805442526,1
W3175990774,Self-Attention Networks Can Process Bounded Hierarchical Languages,2021,0.005831252669271493,1
W4362589932,LenM: Improving Low-Resource Neural Machine Translation Using Target Length Modeling,2023,0.005795080723961891,1
W2973065121,How to evaluate machine translation: A review of automated and human metrics,2019,0.00577889870789917,1
W4385571101,Open-ended Long Text Generation via Masked Language Modeling,2023,0.005706219233575483,1
W2952103439,Translationese in Machine Translation Evaluation,2019,0.005692416786923923,1
W3163721282,Relative Positional Encoding for Transformers with Linear Complexity,2021,0.005690728021541151,1
W4224247818,Multilingual fine-tuning for Grammatical Error Correction,2022,0.0056760228367862585,1
W2971162405,The Unreasonable Effectiveness of Transformer Language Models in Grammatical Error Correction,2019,0.005668052063194845,1
W3212259963,Smelting Gold and Silver for Improved Multilingual AMR-to-Text Generation,2021,0.005662447976422744,1
W3198794504,TCCT: Tightly-coupled convolutional transformer on time series forecasting,2022,0.005659642730755157,1
W2807925339,Topic-to-Essay Generation with Neural Networks,2018,0.005600221275105397,1
W3155806510,RoFormer: Enhanced Transformer with Rotary Position Embedding,2021,0.005577046331282648,1
W2988533489,A survey of word embeddings based on deep learning,2019,0.005564836091083561,1
W2896538705,KAME,2018,0.005555020358940603,1
W4285600138,A Unified Strategy for Multilingual Grammatical Error Correction with Pre-trained Cross-Lingual Language Model,2022,0.005527541518772847,1
W2740753882,Machine Translation and Automated Analysis of the Sumerian Language,2017,0.005502013202162273,1
W4409603142,Beqi: Revitalize the Senegalese Wolof Language with a Robust Spelling Corrector,2025,0.005457644849642253,1
W3157764526,Investigating the Performance of Fine-tuned Text Classification Models Based-on Bert,2020,0.005414485517059125,1
W4392271377,Natural Language Processing Methods for Symbolic Music Generation and Information Retrieval: A Survey,2025,0.005412655283132865,1
W3111445527,Time Series Forecasting and Classification Models Based on Recurrent with Attention Mechanism and Generative Adversarial Networks,2020,0.0054060997787195855,1
W3173069567,Deep learning approach for Translating Arabic Holy Quran into Italian language,2021,0.0054040901380128055,1
W3170261818,DA-Transformer: Distance-aware Transformer,2021,0.00539951545867317,1
W2244807774,Gated Graph Sequence Neural Networks,2016,0.005361792419467729,1
W4317897818,Locally Typical Sampling,2023,0.005361786013820867,1
W4386124663,Exploring Natural Language Processing Methods for Interactive Behaviour Modelling,2023,0.005343788674399042,1
W2963112338,Mixed Precision Training,2017,0.005319681326015242,1
W4311165734,Boosting Neural Networks to Decompile Optimized Binaries,2022,0.005301738371302896,1
W4386576838,Multilingual Representation Distillation with Contrastive Learning,2023,0.0052923161954890425,1
W2998081612,Reinforced Curriculum Learning on Pre-Trained Neural Machine Translation Models,2020,0.005281474972254236,1
W4385570660,BigVideo: A Large-scale Video Subtitle Translation Dataset for Multimodal Machine Translation,2023,0.00525732461993375,1
W2975933472,Neighbors helping the poor: improving low-resource machine translation using related languages,2019,0.005238308459814437,1
W3092850823,PopMAG,2020,0.0052183748949912335,1
W3110908468,Fact-Enhanced Synthetic News Generation,2021,0.005194859281614901,1
W3191119619,Transformer-Encoder-GRU (T-E-GRU) for Chinese Sentiment Analysis on Chinese Comment Text,2022,0.005188266756174202,1
W2956480774,R-Transformer: Recurrent Neural Network Enhanced Transformer,2019,0.005178433731582613,1
W3016151632,On Optimal Transformer Depth for Low-Resource Language Translation,2020,0.005175272532043615,1
W3204663006,CRAN: An Hybrid CNN-RNN Attention-Based Model for Arabic Machine Translation,2021,0.00517167067262028,1
W4385573924,EdiT5: Semi-Autoregressive Text Editing with T5 Warm-Start,2022,0.00511447164572003,1
W2319453305,Minimal gated unit for recurrent neural networks,2016,0.005112605456925466,1
W2624054409,Comparing Language Related Issues for NMT and PBMT between German and English,2017,0.005109549942569371,1
W3148242325,Correlational graph attention-based Long Short-Term Memory network for multivariate time series prediction,2021,0.005106257750165191,1
W2970744242,"Encode, Tag, Realize: High-Precision Text Editing",2019,0.005100129607184285,1
W2621975677,Pushing the Limits of Translation Quality Estimation,2017,0.005097107011687172,1
W3205328383,NormFormer: Improved Transformer Pretraining with Extra Normalization,2021,0.005093950779638434,1
W2754753494,Predictor-Estimator,2017,0.005084231219844402,1
W4387332734,Toward automatic generation of control structures for process flow diagrams with large language models,2023,0.005078532188636711,1
W2201092681,Feed-Forward Networks with Attention Can Solve Some Long-Term Memory Problems,2015,0.005077293503312067,1
W4365597197,Angler: Helping Machine Translation Practitioners Prioritize Model Improvements,2023,0.005074532378825926,1
W2578396138,Hashtag recommendation with topical attention-based LSTM,2016,0.005071917980120746,1
W2577986441,Hashtag recommendation using attention-based convolutional neural network,2016,0.0050719179801207446,1
W2963088785,Character-Level Language Modeling with Deeper Self-Attention,2019,0.005064099781937908,1
W2570431255,Aspect-augmented Adversarial Networks for Domain Adaptation,2017,0.005042408927775737,1
W4385570703,"Detecting and Mitigating Hallucinations in Machine Translation: Model Internal Workings Alone Do Well, Sentence Similarity Even Better",2023,0.005041627327027639,1
W4206249782,Sometimes We Want Ungrammatical Translations,2021,0.005034678427972309,1
W2798060623,A novel channel-aware attention framework for multi-channel EEG seizure detection via multi-view deep learning,2018,0.005032745289126975,1
W4407832567,Post-ocr text correction for Bulgarian historical documents,2025,0.0050319907767985,1
W4312471667,VALHALLA: Visual Hallucination for Machine Translation,2022,0.005028493287199371,1
W3006585575,Machine Remaining Useful Life Prediction via an Attention-Based Deep Learning Approach,2020,0.004978627400798334,1
W4401541163,LLMs-based machine translation for E-commerce,2024,0.004961677466850044,1
W3101997094,Learning a Deep Listwise Context Model for Ranking Refinement,2018,0.004947492023056828,1
W3111375540,ReTransformer,2020,0.0049440276393504165,1
W2789954303,On extended long short-term memory and dependent bidirectional recurrent neural network,2019,0.004934315942508538,1
W3042959233,Short-term energy use prediction of solar-assisted water heating system: Application case of combined attention-based LSTM and time-series decomposition,2020,0.004932075924735579,1
W3000514857,Reformer: The Efficient Transformer,2020,0.0049237997677636265,1
W581956982,An Empirical Exploration of Recurrent Network Architectures,2015,0.004923648856072994,1
W4380995299,Understanding and Detecting Hallucinations in Neural Machine Translation via Model Introspection,2023,0.00492011811862514,1
W4392903654,Enhancing End-to-End Conversational Speech Translation Through Target Language Context Utilization,2024,0.004910204235240478,1
W3186290349,Multi-label text classification via joint learning from label embedding and label correlation,2021,0.004889222786020317,1
W2954731415,Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting,2019,0.00488407404409788,1
W4409680692,Cross-Dataset Analysis of Language Models for Generalised Multi-label Review Note Distribution in Animated Productions,2025,0.004863577547385235,1
W4385572691,ELMER: A Non-Autoregressive Pre-trained Language Model for Efficient and Effective Text Generation,2022,0.004828871418830816,1
W2952926545,Device Placement Optimization with Reinforcement Learning,2017,0.004825139658478646,1
W2968370607,Robust Attentional Aggregation of Deep Feature Sets for Multi-view 3D Reconstruction,2019,0.004813445581099501,1
W2267186426,Long Short-Term Memory-Networks for Machine Reading,2016,0.004797165638531697,1
W3106208347,It’s not a Non-Issue: Negation as a Source of Error in Machine Translation,2020,0.0047871157027280925,1
W2983864285,Graph Convolutional Networks with Motif-based Attention,2019,0.004785657515338114,1
W4303856974,A Reverse Positional Encoding Multi-Head Attention-Based Neural Machine Translation Model for Arabic Dialects,2022,0.00478101278673998,1
W2951305674,Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences,2016,0.004777073723859216,1
W3174794493,Hi-Transformer: Hierarchical Interactive Transformer for Efficient and Effective Long Document Modeling,2021,0.004771768348508627,1
W3204896549,ATISS: Autoregressive Transformers for Indoor Scene Synthesis,2021,0.004765768737533499,1
W4389518624,Leveraging GPT-4 for Automatic Translation Post-Editing,2023,0.00476160513349789,1
W4406911809,Overcoming language barriers via machine translation with sparse Mixture-of-Experts fusion of large language models,2025,0.004760717228183474,1
W4389520222,Towards Making the Most of ChatGPT for Machine Translation,2023,0.004759390480623752,1
W4399068029,A neural network transformer model for composite microstructure homogenization,2024,0.004754477245055329,1
W3175963743,SemFace: Pre-training Encoder and Decoder with a Semantic Interface for Neural Machine Translation,2021,0.004751393034964411,1
W3026999846,Radar Emitter Classification With Attention-Based Multi-RNNs,2020,0.0047455288175389165,1
W2889903020,Adversarial Evaluation of Multimodal Machine Translation,2018,0.004742239820213838,1
W4381195314,Artificial Intelligence based Arabic-to-English machine versus human translation of poetry: An analytical study of outcomes,2023,0.004695563197155673,1
W3035338169,A Hybrid Deep Learning Model With Attention-Based Conv-LSTM Networks for Short-Term Traffic Flow Prediction,2020,0.004677833044607607,1
W2601322194,One-Shot Imitation Learning,2017,0.004655349461656809,1
W2963983719,Recurrent Highway Networks,2017,0.00465509836023153,1
W3124426233,A data aggregation based approach to exploit dynamic spatio-temporal correlations for citywide crowd flows prediction in fog computing,2021,0.004630675597984711,1
W2547418827,Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences,2016,0.004627098005603476,1
W2804243520,Thermal load forecasting in district heating networks using deep learning and advanced feature selection methods,2018,0.004619260087470795,1
W4385573825,Improved grammatical error correction by ranking elementary edits,2022,0.004599403515772362,1
W3186833834,Text Guide: Improving the Quality of Long Text Classification by a Text Selection Method Based on Feature Importance,2021,0.004578646985319076,1
W3100268441,Sequence-Level Mixed Sample Data Augmentation,2020,0.004575731158375417,1
W3174401451,Shortformer: Better Language Modeling using Shorter Inputs,2021,0.0045741701545160855,1
W3154410208,Data Augmentation for Hypernymy Detection,2021,0.004554305767854745,1
W3194203264,Fastformer: Additive Attention Can Be All You Need,2021,0.0044807846856242724,1
W2997908677,Visual Agreement Regularized Training for Multi-Modal Machine Translation,2020,0.004459493383434652,1
W2963490187,Learning Representation Mapping for Relation Detection in Knowledge Base Question Answering,2019,0.004457311673183178,1
W4385574121,Exploring Document-Level Literary Machine Translation with Parallel Paragraphs from World Literature,2022,0.00443691309669891,1
W3106298483,Blockwise Self-Attention for Long Document Understanding,2020,0.004394602540193764,1
W4385572225,Prompting PaLM for Translation: Assessing Strategies and Performance,2023,0.0043889875192685964,1
W2807475932,Neural Machine Translation of Indian Languages,2017,0.004378713751074022,1
W2983381967,Improving Robustness of Task Oriented Dialog Systems,2019,0.004362290392131777,1
W3217345529,A transformer-based model for default prediction in mid-cap corporate markets,2022,0.00435139966893985,1
W3026718724,Malware-Detection Method with a Convolutional Recurrent Neural Network Using Opcode Sequences,2020,0.00434272635021761,1
W3211986039,The Eval4NLP Shared Task on Explainable Quality Estimation: Overview and Results,2021,0.004315165862503513,1
W2998259434,Enhancing Pointer Network for Sentence Ordering with Pairwise Ordering Predictions,2020,0.004312927632277611,1
W3164401570,Geometric deep learning and equivariant neural networks,2023,0.0042635739018957045,1
W3212319100,IST-Unbabel 2021 Submission for the Explainable Quality Estimation Shared Task,2021,0.004254564203254535,1
W2964046661,Recurrent neural network-based semantic variational autoencoder for Sequence-to-sequence learning,2019,0.004245176172797783,1
W2962955856,Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback,2017,0.004245061158139651,1
W3035664258,Improving Graph Neural Network Expressivity via Subgraph Isomorphism Counting,2022,0.004239348903802806,1
W4389519005,Improving Seq2Seq Grammatical Error Correction via Decoding Interventions,2023,0.004229756863079815,1
W4206232983,A Plug-and-Play Method for Controlled Text Generation,2021,0.004205770448024565,1
W3197111027,Tool wear estimation using a CNN-transformer model with semi-supervised learning,2021,0.004190347650989269,1
W3113146152,Encoder-Decoder Models Can Benefit from Pre-trained Masked Language Models in Grammatical Error Correction,2020,0.004160051373956802,1
W2970398671,Heterogeneous Graph Attention Networks for Semi-supervised Short Text Classification,2019,0.004152815968004595,1
W3099845049,TeMP: Temporal Message Passing for Temporal Knowledge Graph Completion,2020,0.004140468804101677,1
W2525907473,Semantic Tagging with Deep Residual Networks,2016,0.004136388128589423,1
W2902608666,Alibaba Submission for WMT18 Quality Estimation Task,2018,0.004124824413854515,1
W3196027777,Text Classification Using Neural Network Language Model (NNLM) and BERT: An Empirical Comparison,2021,0.004110746144960786,1
W3193301525,Automated identification of cell populations in flow cytometry data with transformers,2022,0.0040996356645861005,1
W2964301648,Baseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms,2018,0.004096061670442529,1
W4409831355,Syntax-enhanced Chinese–Vietnamese neural machine translation with linguistic feature template integration,2025,0.0040956793651129655,1
W3014146531,Remaining Useful Life Prediction Using a Novel Feature-Attention-Based End-to-End Approach,2020,0.004092748491000545,1
W4289779195,Muformer: A long sequence time-series forecasting model based on modified multi-head attention,2022,0.004088398396790429,1
W3040538742,Conditional Set Generation with Transformers,2020,0.0040861131193288625,1
W2928406799,Grammar Error Correction in Morphologically Rich Languages: The Case of Russian,2019,0.004061985299917018,1
W3003504112,Domain Knowledge Guided Deep Learning with Electronic Health Records,2019,0.004051238765051759,1
W2899310090,Weakly Supervised Grammatical Error Correction using Iterative Decoding,2018,0.004023600941523841,1
W3024560045,Foundations and Modeling of Dynamic Networks Using Dynamic Graph Neural Networks: A Survey,2021,0.003985983890672392,1
W3096631793,Towards the Natural Language Processing as Spelling Correction for Offline Handwritten Text Recognition Systems,2020,0.003983157761250616,1
W4410288220,Triplet-modality group-guided incremental distillation with regularized group semantic consistency for multi-modal neural machine translation,2025,0.0039720438726110864,1
W2945542139,Rethinking Complex Neural Network Architectures for Document Classification,2019,0.00393909782545677,1
W3207290297,Video Background Music Generation with Controllable Music Transformer,2021,0.003928994975989442,1
W2970796523,Broad-Coverage Semantic Parsing as Transduction,2019,0.003917650678682062,1
W3035263353,Verbal Multiword Expressions for Identification of Metaphor,2020,0.003909741050639689,1
W3080098168,HiTANet: Hierarchical Time-Aware Attention Networks for Risk Prediction on Electronic Health Records,2020,0.0039011742608791554,1
W3203898572,Deep learning approach towards accurate state of charge estimation for lithium-ion batteries using self-supervised transformer model,2021,0.0038898829261757146,1
W3097294131,Adversarial Sparse Transformer for Time Series Forecasting,2020,0.0038705546613285297,1
W3204263062,Anomaly Transformer: Time Series Anomaly Detection with Association Discrepancy,2021,0.0038626012741688072,1
W3183572711,Spatio-Temporal Graph Neural Networks for Multi-Site PV Power Forecasting,2021,0.00385866761104539,1
W2981025102,A Novel Machine Learning Method Based Approach for Li-Ion Battery Prognostic and Health Management,2019,0.003856058051176075,1
W4409364692,Text augmentation method with adjustable manipulation intensity based on in-context learning,2025,0.003849413206629877,1
W2791366550,Independently Recurrent Neural Network (IndRNN): Building A Longer and Deeper RNN,2018,0.0038366847230824493,1
W3119881489,Findings of the WMT 2023 Shared Task on Quality Estimation,2023,0.003818529763208826,1
W3212722208,Self-Supervised Curriculum Learning for Spelling Error Correction,2021,0.003796044083155973,1
W4389524378,ChatGPT MT: Competitive for High- (but Not Low-) Resource Languages,2023,0.00379277437617841,1
W4390037644,Unsupervised multilingual machine translation with pretrained cross-lingual encoders,2023,0.003761395163746481,1
W3088321919,"Tasks, stability, architecture, and compute: Training more effective learned optimizers, and using them to train themselves.",2020,0.0037244994083100347,1
W3023672669,VGCN-BERT: Augmenting BERT with Graph Embedding for Text Classification,2020,0.003704222912725141,1
W4383340789,Self-attention Mechanism at the Token Level: Gradient Analysis and Algorithm Optimization,2023,0.0036968790675681908,1
W3005007700,A novel transformer-based neural network model for tool wear estimation,2020,0.003665737150724264,1
W3131623996,Relational Graph Learning for Crowd Navigation,2020,0.0036479774261156004,1
W3205400264,Decentralized Structural-RNN for Robot Crowd Navigation with Deep Reinforcement Learning,2021,0.0036479774261156,1
W3128634608,Multivariate Time-Series Anomaly Detection via Graph Attention Network,2020,0.003638218661519825,1
W3153961130,Attention-Based LSTM for Non-Contact Sleep Stage Classification Using IR-UWB Radar,2021,0.003633980460722074,1
W1026270304,Training Very Deep Networks,2015,0.0036144931502659593,1
W3119688269,Short-term origin-destination demand prediction in urban rail transit systems: A channel-wise attentive split-convolutional neural network method,2021,0.0036108595228320686,1
W3102427165,Translating math formula images to LaTeX sequences using deep neural networks with sequence-level training,2020,0.0036074305083726474,1
W3197022418,Heterogeneity-Aware Twitter Bot Detection with Relational Graph Transformers,2022,0.00360188917609377,1
W3016321512,Neural machine translation with Gumbel Tree-LSTM based encoder,2020,0.0035697375289863264,1
W4407410754,Applying cultural-historical activity theory to understand Korean tourists’ experiences with language translation applications,2025,0.0035118217999261484,1
W2743945814,Regularizing and Optimizing LSTM Language Models,2017,0.0035036616409041166,1
W2622101571,"A Linguistic Evaluation of Rule-Based, Phrase-Based, and Neural MT Engines",2017,0.0035022111102764046,1
W4392772180,Evaluation of Instagram's Neural Machine Translation for Literary Texts: An MQM-Based Analysis,2024,0.003448795071683633,1
W2525246036,Multiplicative LSTM for sequence modelling,2016,0.0034456432890219084,1
W2623559126,Using Word Embeddings to Enforce Document-Level Lexical Consistency in Machine Translation,2017,0.003434239781061012,1
W4392698767,Sparsity in transformers: A systematic literature review,2024,0.0034325837475887647,1
W4287855135,Frustratingly Easy System Combination for Grammatical Error Correction,2022,0.003426024756156902,1
W4306402945,"Water Quality Prediction Based on LSTM and Attention Mechanism: A Case Study of the Burnett River, Australia",2022,0.003421740533109599,1
W4224921333,MuCGEC: a Multi-Reference Multi-Source Evaluation Dataset for Chinese Grammatical Error Correction,2022,0.003398257287481327,1
W2971270287,Novel positional encodings to enable tree-based transformers,2019,0.0033234899528713177,1
W2969262604,An Introductory Survey on Attention Mechanisms in NLP Problems,2019,0.0033227345672462434,1
W4406171371,Transformer-Based Re-Ranking Model for Enhancing Contextual and Syntactic Translation in Low-Resource Neural Machine Translation,2025,0.003305704375667351,1
W2997205428,Nonlinear Mixup: Out-Of-Manifold Data Augmentation for Text Classification,2020,0.0032958345790017026,1
W4385565080,Searching for Needles in a Haystack: On the Role of Incidental Bilingualism in PaLM’s Translation Capability,2023,0.003295517148922082,1
W4296540711,Natural Language Processing Challenges and Issues: A Literature Review,2022,0.00328462899880999,1
W4403826725,Recent Advances in Interactive Machine Translation with Large Language Models,2024,0.003282474643311164,1
W2963532813,Attend and Diagnose: Clinical Time Series Analysis Using Attention Models,2018,0.003254805615213888,1
W2751262944,Tree-structured decoding with doubly-recurrent neural networks,2017,0.003254530166176988,1
W4226383734,Czech Grammar Error Correction with a Large and Diverse Corpus,2022,0.003241907832587727,1
W4396917044,Novel deep-learning method based on LSA-Transformer for fault detection and its implementation in penicillin fermentation process,2024,0.0032371791456450283,1
W2998104826,Multi-level convolutional autoencoder networks for parametric prediction of spatio-temporal dynamics,2020,0.0032358388593700734,1
W4291910369,Learning All Dynamics: Traffic Forecasting via Locality-Aware Spatio-Temporal Joint Transformer,2022,0.0032167505945566812,1
W2902363804,Stable Forecasting of Environmental Time Series via Long Short Term Memory Recurrent Neural Network,2018,0.0032116406722656056,1
W4408754018,Evaluating Large Language Models in Translation: A Theoretical and Practical Analysis Based on Skopos Theory,2025,0.0032018136138574696,1
W4226361124,Graph Pre-training for AMR Parsing and Generation,2022,0.0031195821659786922,1
W3024761859,A review on the long short-term memory model,2020,0.0031010994962135073,1
W4226288657,NeuroLogic A*esque Decoding: Constrained Text Generation with Lookahead Heuristics,2022,0.003097195233943789,1
W4323923311,A novel XGBoost-based featurization approach to forecast renewable energy consumption with deep learning models,2023,0.0030894754093070452,1
W4390876416,Knowledge Graph Enhanced Transformers for Diagnosis Generation of Chinese Medicine,2024,0.0030282557355126613,1
W4385570075,NaSGEC: a Multi-Domain Chinese Grammatical Error Correction Dataset from Native Speaker Texts,2023,0.0030098852338358486,1
W4375857395,"Neural machine translation in EFL classrooms: learners’ vocabulary improvement, immediate vocabulary retention and delayed vocabulary retention",2023,0.0029630857273940225,1
W4408971054,Medical Text Classification with Data Augmentation Based on Baichuan2,2025,0.002948158496971284,1
W3025111163,Reassessing Claims of Human Parity and Super-Human Performance in Machine Translation at WMT 2019,2020,0.002939943693836535,1
W4385571550,Augmenting Large Language Model Translators via Translation Memories,2023,0.0029241978677348023,1
W2962946486,Graph Convolutional Networks for Text Classification,2019,0.002892192313005633,1
W4293187584,Explainability-Based Mix-Up Approach for Text Data Augmentation,2022,0.0028874681660696396,1
W4381463374,A Neural Attention-Based Encoder-Decoder Approach for English to Bangla Translation,2023,0.002879739795007931,1
W2901739041,Mixed-Precision Training for NLP and Speech Recognition with OpenSeq2Seq,2018,0.0028643071134949964,1
W4391850361,UCFN Net: Ulcerative colitis evaluation based on fine-grained lesion learner and noise suppression gating,2024,0.002853922298769671,1
W4205163778,Automatic Arabic Grammatical Error Correction based on Expectation-Maximization routing and target-bidirectional agreement,2022,0.0028124896427392182,1
W4295950983,Promoting wind energy for sustainable development by precise wind speed prediction based on graph neural networks,2022,0.002807149420603044,1
W2997945091,Multi-Scale Self-Attention for Text Classification,2020,0.0027997335152337936,1
W4321793562,A domain adaptation approach for resume classification using graph attention networks and natural language processing,2023,0.002788811381445243,1
W2606554264,Bayesian Recurrent Neural Networks,2017,0.0027787389902261843,1
W3016504312,End-To-End Deep Learning Architecture for Continuous Blood Pressure Estimation Using Attention Mechanism,2020,0.00276696825191711,1
W4361271286,Wavelet-Seq2Seq-LSTM with attention for time series forecasting of level of dams in hydroelectric power plants,2023,0.0027237463078460633,1
W3004665554,Wind power forecasting using attention-based gated recurrent unit network,2020,0.0026992450612861613,1
W3177237711,End-to-End AMR Corefencence Resolution,2021,0.0026979075721910322,1
W2965981069,Outlier Detection for Time Series with Recurrent Autoencoder Ensembles,2019,0.002690821814233727,1
W4388793551,A dual attention LSTM lightweight model based on exponential smoothing for remaining useful life prediction,2023,0.0026797955490394675,1
W3150584131,Multigraph Transformer for Free-Hand Sketch Recognition,2021,0.0026684591303093455,1
W4384666235,A Review on Dropout Regularization Approaches for Deep Neural Networks within the Scholarly Domain,2023,0.002667700711335598,1
W2884096449,Language Informed Modeling of Code-Switched Text,2018,0.0026649056278600673,1
W2803039862,End-to-End Neural Network Based Automated Speech Scoring,2018,0.0026554948954632842,1
W2951575317,A Hybrid Convolutional Variational Autoencoder for Text Generation,2017,0.0026390974791515643,1
W4404474646,"Decoder-Only Transformers: The Brains Behind Generative AI, Large Language Models and Large Multimodal Models",2024,0.002631648527432459,1
W2601273560,RobustFill: neural program learning under noisy I/O,2017,0.00263149408902941,1
W4285110390,Controlling Translation Formality Using Pre-trained Multilingual Language Models,2022,0.0026124762978582076,1
W4324104316,Exploiting time-varying RFM measures for customer churn prediction with deep neural networks,2023,0.002612196953852134,1
W2949952652,Incorporating Syntactic and Semantic Information in Word Embeddings using Graph Convolutional Networks,2019,0.002574268651407394,1
W3109744225,SemMT: A Semantic-Based Testing Approach for Machine Translation Systems,2022,0.0025738146797418186,1
W4385258623,Transformers in Time-Series Analysis: A Tutorial,2023,0.0025661423109139847,1
W4385767932,Diffusion Models for Non-autoregressive Text Generation: A Survey,2023,0.0025645222279926687,1
W4410500912,Multimodal retrieval‐augmented generation framework for machine translation,2025,0.00255989145489577,1
W4379799065,A review on big data based on deep neural network approaches,2023,0.0025537898888599643,1
W4386465411,Improving position encoding of transformers for multivariate time series classification,2023,0.0025412458929689715,1
W4397035966,Natural Language Processing,2023,0.0025378986670215133,1
W2896556401,Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks,2018,0.0025268819641720433,1
W4289825471,Short-Term Weather Forecasting Using Spatial Feature Attention Based LSTM Model,2022,0.0025246300634056175,1
W2510842514,Hierarchical Multiscale Recurrent Neural Networks,2016,0.002499164712115349,1
W4285280911,Can Transformer be Too Compositional? Analysing Idiom Processing in Neural Machine Translation,2022,0.002478251046790982,1
W4306362399,Automatic Correction of Indonesian Grammatical Errors Based on Transformer,2022,0.002473961268639372,1
W2758846169,Getting the Most out of AMR Parsing,2017,0.002472261231934867,1
W3177318507,Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting,2021,0.0024540287953015274,1
W2972799129,"Enabling Robust Grammatical Error Correction in New Domains: Data Sets, Metrics, and Analyses",2019,0.0024479531083630773,1
W3171218751,NeuroLogic Decoding: (Un)supervised Neural Text Generation with Predicate Logic Constraints,2021,0.002447312872046487,1
W4318594329,Spatiotemporal correlation modelling for machine learning-based traffic state predictions: state-of-the-art and beyond,2023,0.00244499830167183,1
W4205802268,The Routledge Handbook of Translation and Methodology,2022,0.0024372160022129445,1
W4400749119,"Revolutionising Translation Technology: A Comparative Study of Variant Transformer Models - BERT, GPT, and T5",2024,0.002401551858039708,1
W4382202798,Diffuser: Efficient Transformers with Multi-Hop Attention Diffusion for Long Sequences,2023,0.002398781261341494,1
W4382202529,SoftCorrect: Error Correction with Soft Detection for Automatic Speech Recognition,2023,0.0023978410953987817,1
W2951927893,Multistep speed prediction on traffic networks: A deep learning approach considering spatio-temporal dependencies,2019,0.002387407721427634,1
W4394765698,Interlimb and Intralimb Synergy Modeling for Lower Limb Assistive Devices,2024,0.0023752026301843455,1
W2928323670,A Sequence-to-Sequence Air Quality Predictor Based on the n-Step Recurrent Prediction,2019,0.0023669009239185566,1
W3010768098,ReZero is All You Need: Fast Convergence at Large Depth,2020,0.0023624638303202305,1
W2807230608,Multimodal Lexical Translation.,2018,0.002361356665389273,1
W4406241919,A survey of multilingual large language models,2025,0.0023571949384064155,1
W3000884041,Feature Extraction Using an RNN Autoencoder for Skeleton-Based Abnormal Gait Recognition,2020,0.0023562141649834554,1
W3040607188,Dynamic Spatial-Temporal Representation Learning for Traffic Flow Prediction,2020,0.002349577850523691,1
W2962771342,The Case for Learned Index Structures,2018,0.0023283608862021375,1
W2409027918,Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations,2016,0.002305978124936908,1
W4399883732,Addressing the data gap: building a parallel corpus for Kashmiri language,2024,0.002304829809895243,1
W2962716258,Neural optimizer search with reinforcement learning,2017,0.0023043617287825525,1
W3209873929,Hierarchical Transformers Are More Efficient Language Models,2022,0.00229523738039466,1
W4407242298,Leveraging language models for automated distribution of review notes in animated productions,2025,0.0022926863002933544,1
W3116506157,TransQuest: Translation Quality Estimation with Cross-lingual Transformers,2020,0.0022649557867253376,1
W2605887895,A Syntactic Neural Model for General-Purpose Code Generation,2017,0.0022428830219925096,1
W2987395887,Multilingual Whispers: Generating Paraphrases with Translation,2019,0.00223579741608999,1
W4285272557,∞-former: Infinite Memory Transformer-former: Infinite Memory Transformer,2022,0.0022263094499926986,1
W4285135404,Bag-of-Words vs. Graph vs. Sequence in Text Classification: Questioning the Necessity of Text-Graphs and the Surprising Strength of a Wide MLP,2022,0.00219392359245004,1
W3199040194,Deep learning for time series forecasting: The electric load case,2021,0.002182552840606065,1
W4386094835,Graph Representation Learning,2023,0.0021616746184193072,1
W4408362397,The Application of Intelligent Translation System Based on Machine Translation in English Education Curriculum Reforms,2025,0.0021550981392417737,1
W2530887700,Hybrid computing using a neural network with dynamic external memory,2016,0.002136971623373796,1
W3037230882,Grammatical Error Correction Using Pseudo Learner Corpus Considering Learner’s Error Tendency,2020,0.002123597141062006,1
W4362563550,Generating Natural Language From Logic Expressions With Structural Representation,2023,0.0021037268035806545,1
W4385574095,Revisiting Grammatical Error Correction Evaluation and Beyond,2022,0.002076860107493869,1
W4385763767,Transformers in Time Series: A Survey,2023,0.002052935776520462,1
W2786148476,Word Mover’s Embedding: From Word2Vec to Document Embedding,2018,0.0020454468540569578,1
W3104804488,Long short-term memory networks in memristor crossbar arrays,2018,0.0020421653174630054,1
W3126720815,Machine Learning with Neural Networks,2021,0.0020347088214114884,1
W2942870440,Domain-specific machine translation with recurrent neural network for software localization,2019,0.002026272879307585,1
W2890330768,Deep Learning-Based Multivariate Probabilistic Forecasting for Short-Term Scheduling in Power Markets,2018,0.0020259397441225553,1
W2971120958,Findings of the WMT 2019 Shared Tasks on Quality Estimation,2019,0.002018530640722785,1
W4401380102,Automatic language ability assessment method based on natural language processing,2024,0.0020161167443996245,1
W2963748792,On the State of the Art of Evaluation in Neural Language Models,2018,0.002011331067683424,1
W3037511795,LSTM networks based on attention ordered neurons for gear remaining life prediction,2020,0.002007491618664322,1
W4399808999,"Large language models ""ad referendum"": How good are they at machine translation in the legal domain?",2024,0.0019909444898029267,1
W4410494118,Applying convolutional attention mechanisms and Human Memory Search for effective English-Urdu translation,2025,0.0019783918468487837,1
W3046584416,Multi-step ahead forecasting of regional air quality using spatial-temporal deep neural networks: A case study of Huaihai Economic Zone,2020,0.0019723549075234834,1
W2964972381,Graph-based Neural Sentence Ordering,2019,0.0019692812648823142,1
W4283725425,Hierarchical Graph Convolutional Networks for Structured Long Document Classification,2022,0.001964115020344665,1
W4395003231,Translation model based on discrete Fourier transform and Skipping Sub-Layer methods,2024,0.0019229837123546265,1
W4385569744,DiffusionBERT: Improving Generative Masked Language Models with Diffusion Models,2023,0.0019047581272153174,1
W4367676272,Translating Akkadian to English with neural machine translation,2023,0.0018994913047104258,1
W3198765931,Translation Error Detection as Rationale Extraction,2022,0.0018186344823107278,1
W4409125889,Negative Language Transfer Identification in the English Writing of Chinese and Farsi Native Speakers,2025,0.0018177903992209505,1
W3035620341,NAS-Bench-NLP: Neural Architecture Search Benchmark for Natural Language Processing,2022,0.0018131774327745387,1
W3034438872,Syntax-Aware Opinion Role Labeling with Dependency Graph Convolutional Networks,2020,0.0017904430882504372,1
W3013382035,Recurrent Neural Networks: An Embedded Computing Perspective,2020,0.001782886567886022,1
W2591264712,Character-Word LSTM Language Models,2017,0.0017716765212059241,1
W3012621877,Backpropagation algorithms and Reservoir Computing in Recurrent Neural Networks for the forecasting of complex spatiotemporal dynamics,2020,0.0017469450456170973,1
W4386805190,LSTM-Based Machine Translation for Madurese-Indonesian,2023,0.0017449887295205482,1
W2963153906,Recurrent neural network for text classification with multi-task learning,2016,0.0017060907320844611,1
W4313908847,Online portfolio management via deep reinforcement learning with high-frequency data,2023,0.0016709926759738041,1
W4406769409,Interval evaluation of temporal (in)stability for neural machine translation,2025,0.0016657501572268924,1
W4409407626,GERA: A Corpus of Russian School Texts Annotated for Grammatical Error Correction,2025,0.001665663315991775,1
W3036677371,Understanding the societal impacts of machine translation: a critical review of the literature on medical and legal use cases,2020,0.0016613189662777776,1
W2970183009,Text Level Graph Neural Network for Text Classification,2019,0.001656800647729534,1
W2788667846,Large-Scale Hierarchical Text Classification with Recursively Regularized Deep Graph-CNN,2018,0.0016559943883963017,1
W2964109882,An overview of word and sense similarity,2019,0.001652936690366346,1
W3205531882,Transformer Acceleration with Dynamic Sparse Attention,2021,0.0016456853608480722,1
W4225759408,"Representing Context in FrameNet: A Multidimensional, Multimodal Approach",2022,0.0016405830586633998,1
W2883386157,Error Classification and Analysis for Machine Translation Quality Assessment,2018,0.0016338517053338367,1
W4410056673,"Evaluating Free Legal Translation Tools between Arabic and English: A Comparative Study of Google Translate, ChatGPT, and Gemini",2025,0.0016151931901941116,1
W2798944827,Inherent Biases in Reference-based Evaluation for Grammatical Error Correction,2018,0.0016115469404947476,1
W3005630930,BAT: Deep Learning Methods on Network Intrusion Detection Using NSL-KDD Dataset,2020,0.0015953330847921507,1
W4220697067,LSTM-Based Attentional Embedding for English Machine Translation,2022,0.0015731198335174233,1
W3148339758,UA-GEC: Grammatical Error Correction and Fluency Corpus for the Ukrainian Language,2023,0.001549633800806989,1
W2734777338,A deep learning framework for financial time series using stacked autoencoders and long-short term memory,2017,0.0015413742803161263,1
W2173051530,Neural GPUs Learn Algorithms,2015,0.0015338418838127584,1
W3187800134,A Structure Self-Aware Model for Discourse Parsing on Multi-Party Dialogues,2021,0.001527456614282841,1
W4376645491,MultiGED-2023 shared task at NLP4CALL: Multilingual Grammatical Error Detection,2023,0.0015057109417015793,1
W2953083125,Context is Key: Grammatical Error Detection with Contextual Word Representations,2019,0.0014944220685404654,1
W3142358935,An attention‐based category‐aware GRU model for the next POI recommendation,2021,0.0014934654382942536,1
W4392251697,Hierarchical Multi-Granularity Interaction Graph Convolutional Network for Long Document Classification,2024,0.0014875695519847654,1
W4366091323,"Deep learning modelling techniques: current progress, applications, advantages, and challenges",2023,0.001483090369981925,1
W3081886688,Measurement of Text Similarity: A Survey,2020,0.001467928240664514,1
W3016004348,Residual Shuffle-Exchange Networks for Fast Processing of Long Sequences,2021,0.0014554123012294044,1
W2890585661,SQL-to-Text Generation with Graph-to-Sequence Model,2018,0.0014517436848112124,1
W4385573965,Linguistic Rules-Based Corpus Generation for Native Chinese Grammatical Error Correction,2022,0.001425460540617514,1
W2884873108,Convolutional Sequence to Sequence Model with Non-Sequential Greedy Decoding for Grapheme to Phoneme Conversion,2018,0.001406713526544526,1
W4408484065,Translator Chatbot in Cloud Environment Using Amazon Translate and Amazon Lex,2025,0.001346177253271573,1
W4221155853,Neural Grapheme-To-Phoneme Conversion with Pre-Trained Grapheme Models,2022,0.001344094512357182,1
W2944851425,A Review of Recurrent Neural Networks: LSTM Cells and Network Architectures,2019,0.0013421605867547106,1
W4392616472,Exploring Human-Like Translation Strategy with Large Language Models,2024,0.0013368090093673745,1
W2997162759,Tensor Graph Convolutional Networks for Text Classification,2020,0.0013242497639478874,1
W4394814366,Artificial Intelligence in Academic Translation: A Comparative Study of Large Language Models and Google Translate,2024,0.0013156521587856112,1
W4409772377,Transformers to the rescue: alleviating data scarcity in arabic grammatical error correction with pre-trained models,2025,0.0013131812020507514,1
W4408545849,Error Analysis and Instructional Strategy Adjustment in a Corpus of English Language Learners,2025,0.0012958236209170422,1
W3160936371,Parallel spatio-temporal attention-based TCN for multivariate time series prediction,2021,0.0012790101291757945,1
W2613328025,A Dual-Stage Attention-Based Recurrent Neural Network for Time Series Prediction,2017,0.0012781120482043217,1
W4389520033,"Efficient Long-Range Transformers: You Need to Attend More, but Not Necessarily at Every Layer",2023,0.0012739975791222456,1
W4399563755,Exploring the frontier: Transformer-based models in EEG signal analysis for brain-computer interfaces,2024,0.0012694097657207958,1
W4225003277,Transformer-based map-matching model with limited labeled data using transfer-learning approach,2022,0.0012259416943366274,1
W2964248669,Cross-linguistic differences and similarities in image descriptions,2017,0.0012148651430749836,1
W2563976356,Addressing a Question Answering Challenge by Combining Statistical Methods with Inductive Rule Learning and Reasoning,2016,0.001212743401351315,1
W2950527268,Learning Differentially Private Recurrent Language Models,2017,0.0011996755359698198,1
W3098124506,Demographic Inference and Representative Population Estimates from Multilingual Social Media Data,2019,0.0011869265322768663,1
W2981982720,Knowledge Transfer for Rotary Machine Fault Diagnosis,2019,0.0011633508705683367,1
W4380368768,Hierarchical graph-based text classification framework with contextual node embedding and BERT-based dynamic fusion,2023,0.0011498136197332289,1
W1598796236,A Critical Review of Recurrent Neural Networks for Sequence Learning,2015,0.0011489457688941556,1
W4386402121,Artificial intelligence literacy for the language industry – with particular emphasis on recent large language models such as GPT-4,2023,0.001129351541953969,1
W3173753074,BertGCN: Transductive Text Classification by Combining GNN and BERT,2021,0.0011279978886409754,1
W4366815213,Recent advances in deep learning models: a systematic literature review,2023,0.0011121509285491487,1
W2955926951,Post-editese: an Exacerbated Translationese,2019,0.001106316614139541,1
W4319777762,"A Systematic Literature Review on Multimodal Machine Learning: Applications, Challenges, Gaps and Future Directions",2023,0.0011050045155801796,1
W4225370732,Characterization of groundwater contamination: A transformer-based deep learning model,2022,0.0011033847811971985,1
W3171884590,Temporal Fusion Transformers for interpretable multi-horizon time series forecasting,2021,0.0010937345557478894,1
W4410036785,Context-Aware Encoder with Adaptive Tuning for Neural Machine Translation,2025,0.0010922903600224254,1
W3012798438,Dynamic Sampling and Selective Masking for Communication-Efficient Federated Learning,2021,0.0010773923186669233,1
W3213920537,Log Sequence Anomaly Detection Based on Local Information Extraction and Globally Sparse Transformer Model,2021,0.0010533967195947768,1
W2786167576,Memory Architectures in Recurrent Neural Network Language Models,2018,0.0010503565675583353,1
W3184127157,Learning Graph Structures With Transformer for Multivariate Time-Series Anomaly Detection in IoT,2021,0.0010360228366388723,1
W2963066159,Graph Convolutional Networks with EigenPooling,2019,0.001035424413902299,1
W4284675318,Improving machine translation systems via isotopic replacement,2022,0.001013981773296526,1
W4392163668,Neural machine translation of clinical text: an empirical investigation into multilingual pre-trained language models and transfer-learning,2024,0.0010032798884350442,1
W2968397098,DeepGCNs: Can GCNs Go as Deep as CNNs?,2019,0.0010022461758149375,1
W3016661780,RootPainter: Deep Learning Segmentation of Biological Images with Corrective Annotation,2020,0.0010019788573949044,1
W2963042606,Unitary Evolution Recurrent Neural Networks,2015,0.0010010780586046854,1
W4285186957,Convolutional Transformer: An Enhanced Attention Mechanism Architecture for Remaining Useful Life Estimation of Bearings,2022,0.0009898168557874916,1
W4280582438,Contrastive Graph Convolutional Networks with adaptive augmentation for text classification,2022,0.0009767929174940672,1
W4399009424,How Ready Are Generative Pre-trained Large Language Models for Explaining Bengali Grammatical Errors?,2024,0.0009729823755254668,1
W4385570074,ChatBack: Investigating Methods of Providing Grammatical Error Feedback in a GUI-based Language Learning Chatbot,2023,0.0009702875450343592,1
W4385808309,Learning the Language of NMR: Structure Elucidation from NMR spectra using Transformer Models,2023,0.0009692291465720858,1
W4396779890,Exploring Sentence-level Revision Capabilities of LLMs in English for Academic Purposes Writing Assistance,2024,0.0009568793700858441,1
W4200157346,Machine remaining life prediction based on multi-layer self-attention and temporal convolution network,2021,0.0009544903759767627,1
W2809398771,Risk Prediction on Electronic Health Records with Prior Medical Knowledge,2018,0.000944347470146243,1
W3214933191,SIGMORPHON 2021 Shared Task on Morphological Reinflection: Generalization Across Languages,2021,0.0009404059207586461,1
W2905032972,Hierarchical Attention Networks for Sentence Ordering,2019,0.0009403554362752043,1
W4407445115,A transformer-based semi-autoregressive framework for high-speed and accurate de novo peptide sequencing,2025,0.0009359100192695293,1
W4382119071,MLog: Mogrifier LSTM-Based Log Anomaly Detection Approach Using Semantic Representation,2023,0.0009349863483386069,1
W4409524670,ResDNViT: A hybrid architecture for Netflow-based attack detection using a residual dense network and Vision Transformer,2025,0.0009273942612185128,1
W2950179609,Retrieve and Refine: Improved Sequence Generation Models For Dialogue,2018,0.0009243731788331199,1
W4361268002,Text classification on heterogeneous information network via enhanced GCN and knowledge,2023,0.0009192642818915281,1
W4385626821,Twitter Bot Detection Using Neural Networks and Linguistic Embeddings,2023,0.0009178962145240065,1
W4213025374,Transformer Network for Remaining Useful Life Prediction of Lithium-Ion Batteries,2022,0.000914955195512811,1
W4207078300,Graph Convolutional Network Based on Multi-Head Pooling for Short Text Classification,2022,0.000910537476753394,1
W4224281298,ATP: AMRize Then Parse! Enhancing AMR Parsing with PseudoAMRs,2022,0.0009099327710867757,1
W3049450989,Fine-grained learning performance prediction via adaptive sparse self-attention networks,2020,0.0009039396524529485,1
W4320232838,RPConvformer: A novel Transformer-based deep neural networks for traffic flow prediction,2023,0.0008969001339313723,1
W2992505801,Why ADAM Beats SGD for Attention Models,2019,0.0008719829431204295,1
W2969210779,Deep Temporal Convolutional Networks for Short-Term Traffic Flow Forecasting,2019,0.0008543256532863173,1
W4396762170,Fairness Testing of Machine Translation Systems,2024,0.0008453121847093095,1
W3092879656,Pop Music Transformer,2020,0.0008440674816591991,1
W4395468431,A Joint Time-Frequency Domain Transformer for multivariate time series forecasting,2024,0.0008411270641961282,1
W4387428001,Towards Making the Most of LLM for Translation Quality Estimation,2023,0.0008374722990028273,1
W3175925542,Spatial-temporal graph neural network for traffic forecasting: An overview and open research issues,2021,0.0008254614011494342,1
W4312410594,InducT-GCN: Inductive Graph Convolutional Networks for Text Classification,2022,0.0008231853758728007,1
W4308150438,Recurrent attention unit: A new gated recurrent unit for long-term memory of important parts in sequential data,2022,0.000805020873159831,1
W3192770664,Correcting Arabic Soft Spelling Mistakes using BiLSTM-based Machine Learning,2022,0.000804749488669963,1
W3184465100,A novel temporal convolutional network via enhancing feature extraction for the chiller fault diagnosis,2021,0.0008041873531615014,1
W2971330564,Learning to Learn and Predict: A Meta-Learning Approach for Multi-Label Classification,2019,0.0008024258724661738,1
W3041279471,Stacked bidirectional and unidirectional LSTM recurrent neural network for forecasting network-wide traffic state with missing values,2020,0.0007998486111468277,1
W3080670519,TAdaNet: Task-Adaptive Network for Graph-Enriched Meta-Learning,2020,0.000783475847815653,1
W2173027866,Convolutional Networks on Graphs for Learning Molecular Fingerprints,2015,0.0007809906044297419,1
W4312863243,Multivariate Time Series Imputation With Transformers,2022,0.0007805659558241309,1
W4408536479,A new evaluation method: evaluation data and metrics for Chinese grammatical error correction,2025,0.0007648411949555557,1
W4312254454,Unleashing Transformers: Parallel Token Prediction with Discrete Absorbing Diffusion for Fast High-Resolution Image Generation from Vector-Quantized Codes,2022,0.0007627047565304808,1
W4387875671,Design of a Modified Transformer Architecture Based on Relative Position Coding,2023,0.0007557228985287297,1
W4387967410,Applicability analysis of transformer to wind speed forecasting by a novel deep learning framework with multiple atmospheric variables,2023,0.0007536612532364487,1
W4404633977,"Opportunities and Challenges in Transformer Neural Networks for Battery State Estimation: Charge, Health, Lifetime, and Safety",2024,0.0007527856031542583,1
W4401330063,Multimodal Machine Translation Based on Enhanced Knowledge Distillation and Feature Fusion,2024,0.0007500773739596359,1
W4407002324,Word embedding factor based multi-head attention,2025,0.0007408322963142913,1
W4320001385,CNN-Based Transformer Model for Fault Detection in Power System Networks,2023,0.0007354908968474294,1
W4401551179,Sensitive Analysis of Natural Language Processing Using for MOORA Method,2024,0.0007294653222632956,1
W4408538777,A hybrid re-fusion model for text classification,2025,0.0007269848184462065,1
W3181655313,Improving the accuracy of global forecasting models using time series data augmentation,2021,0.0007163490002629407,1
W3106229813,Be More with Less: Hypergraph Attention Networks for Inductive Text Classification,2020,0.0007124968208495733,1
W4399556159,TriChronoNet: Advancing electricity price prediction with Multi-module fusion,2024,0.0007118291224020866,1
W3034749137,Traffic transformer: Capturing the continuity and periodicity of time series for traffic forecasting,2020,0.0007062170562302911,1
W2550143307,Temporal Convolutional Networks for Action Segmentation and Detection,2017,0.0006878168265778805,1
W3175663427,Compound Word Transformer: Learning to Compose Full-Song Music over Dynamic Directed Hypergraphs,2021,0.0006854307719492258,1
W2963172229,Contextualized Non-Local Neural Networks for Sequence Learning,2019,0.0006814906929226019,1
W4365813991,Exploring the potential of time-series transformers for process modeling and control in chemical systems: An inevitable paradigm shift?,2023,0.0006813671128550052,1
W4385261005,Applying QNLP to Sentiment Analysis in Finance,2023,0.0006759516596545451,1
W3100270150,Recurrent Neural Networks for Short-Term Load Forecasting,2017,0.0006700799874732073,1
W3121356850,Graph Deep Learning: State of the Art and Challenges,2021,0.0006661350442447321,1
W4390841728,DAO-LGBM: dual annealing optimization with light gradient boosting machine for advocates prediction in online customer engagement,2024,0.000663794229637523,1
W4365420380,A Lightweight Transformer-Based Approach of Specific Emitter Identification for the Automatic Identification System,2023,0.0006602696858888562,1
W4285114401,Contrastive Learning-Enhanced Nearest Neighbor Mechanism for Multi-Label Text Classification,2022,0.0006563764080791768,1
W4392523455,Application of Quantum Recurrent Neural Network in Low-Resource Language Text Classification,2024,0.0006530108640838534,1
W2622068151,Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs,2017,0.0006445370246483477,1
W2175402905,Unitary Evolution Recurrent Neural Networks,2015,0.0006438419889391471,1
W4362466625,Synthetized Multilanguage OCR Using CRNN and SVTR Models for Realtime Collaborative Tools,2023,0.0006426637637510632,1
W4403296460,Translating classical Arabic verse: human translation vs. AI large language models (Gemini and ChatGPT),2024,0.0006414524754108371,1
W3186283138,English Grammar Error Detection Using Recurrent Neural Networks,2021,0.000639992251926824,1
W4316039505,Robust recurrent neural networks for time series forecasting,2023,0.0006390948688999411,1
W4388116457,Hidformer: Hierarchical dual-tower transformer using multi-scale mergence for long-term time series forecasting,2023,0.0006390139157966624,1
W4407666365,Research progress on Chinese and English text error correction,2025,0.0006388439917752099,1
W4312056220,Fast training of a transformer for global multi-horizon time series forecasting on tensor processing units,2022,0.0006289463259385258,1
W3134307371,Pretrained Transformers as Universal Computation Engines,2021,0.0006256493923477638,1
W2962893388,Explicit Interaction Model towards Text Classification,2019,0.0006244858528689898,1
W2528639018,Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction,2017,0.0006236370185622047,1
W4320921439,High ECG diagnosis rate using novel machine learning techniques with Distributed Arithmetic (DA) based gated recurrent units,2023,0.0006084557635289737,1
W4224211827,A multi-head attention-based transformer model for traffic flow forecasting with a comparative analysis to recurrent neural networks,2022,0.0006082347765980798,1
W4385256302,Fuzzy clustering analysis for the loan audit short texts,2023,0.0006079634169031591,1
W4395071168,Transformer encoder based self-supervised learning for HVAC fault detection with unlabeled data,2024,0.0006042668135507415,1
W4382203079,Are Transformers Effective for Time Series Forecasting?,2023,0.0005974670413807572,1
W2886951144,Deep Patient Similarity Learning for Personalized Healthcare,2018,0.0005961373126123449,1
W2953118818,Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting,2015,0.000594508710590942,1
W2963684275,The Reversible Residual Network: Backpropagation Without Storing Activations,2017,0.0005890658979672892,1
W3157175643,A survey on long short-term memory networks for time series prediction,2021,0.0005773300235069553,1
W2794371820,Data-assisted reduced-order modeling of extreme events in complex dynamical systems,2018,0.0005659497574042844,1
W3193812480,Learning Dynamic and Hierarchical Traffic Spatiotemporal Features With Transformer,2021,0.0005649466951887688,1
W3138501833,Fault detection in Tennessee Eastman process with temporal deep learning models,2021,0.0005625512548116062,1
W4406049444,Physics-informed radial basis function neural network for efficiently modeling oil–water two-phase Darcy flow,2025,0.0005611170919579897,1
W2996331899,Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting,2019,0.0005601058979195701,1
W3038981236,Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting,2020,0.0005552787930961484,1
W4406256786,Optimizing Stock Predictions With Bi-Directional LSTM and Levy Flight Fuzzy Social Spider Optimization (LFFSSO),2025,0.0005533508307028331,1
W4313004671,MVSTT: A Multiview Spatial-Temporal Transformer Network for Traffic-Flow Forecasting,2022,0.0005500639568866114,1
W4395956828,Deep dive into predictive excellence: Transformer's impact on groundwater level prediction,2024,0.0005477632691990007,1
W4225284516,Graph correlated attention recurrent neural network for multivariate time series forecasting,2022,0.0005456128626886756,1
W4408482320,Combining transformer and 3DCNN models to achieve co-design of structures and sequences of antibodies in a diffusional manner,2025,0.0005405574390079637,1
W4321490471,Design and Proofreading of the English-Chinese Computer-Aided Translation System by the Neural Network,2023,0.0005285540324009555,1
W3137613462,Remaining useful life estimation via transformer encoder enhanced by a gated convolutional unit,2021,0.0005282697591416028,1
W3123883114,Prediction of aerodynamic flow fields using convolutional neural networks,2019,0.0005237195420036133,1
W4317625837,An integrated multi-head dual sparse self-attention network for remaining useful life prediction,2023,0.0005222007698110142,1
W4281998028,A watershed water quality prediction model based on attention mechanism and Bi-LSTM,2022,0.0005138661138450808,1
W4382364617,CrystalGPT: Enhancing system-to-system transferability in crystallization prediction and control using time-series-transformers,2023,0.0005071675416429774,1
W4366779109,Transformer-enhanced periodic temporal convolution network for long short-term traffic flow forecasting,2023,0.0005070517799258093,1
W4322101461,CLformer: Locally grouped auto-correlation and convolutional transformer for long-term multivariate time series forecasting,2023,0.0005066634845714549,1
W3035568641,Every Document Owns Its Structure: Inductive Text Classification via Graph Neural Networks,2020,0.0005008689506091638,1
W3003741609,Exploring a Long Short-Term Memory based Encoder-Decoder framework for multi-step-ahead flood forecasting,2020,0.0005005189121359556,1
W3035690777,Hierarchy-Aware Global Model for Hierarchical Text Classification,2020,0.0004949097119025181,1
W4391543346,Spatiotemporal Fusion Transformer for large-scale traffic forecasting,2024,0.0004946492461598513,1
W3156039010,MedPath: Augmenting Health Risk Prediction via Medical Knowledge Paths,2021,0.000487585794922031,1
W4399813745,A lightweight CNN-transformer model for learning traveling salesman problems,2024,0.0004738550450386774,1
W4400261301,Graph neural networks for text classification: a survey,2024,0.0004735638113546746,1
W4322732473,A transformer with layer-cross decoding for remaining useful life prediction,2023,0.00047159127988316985,1
W4280617006,Prediction of protein–protein interaction using graph neural networks,2022,0.0004585032622865312,1
W4406322062,Time-series Forecasting in Industrial Environments: A Performance Study and a Novel Late Fusion Framework,2025,0.0004533554917352539,1
W3123909522,Graph neural network for traffic forecasting: A survey,2022,0.0004450173978614665,1
W4391849633,Fading memory as inductive bias in residual recurrent networks,2024,0.0004362765475897722,1
W4310145190,Automated Rule-Based Data Cleaning Using NLP,2022,0.0004347823560673632,1
W4389010438,"FurChat: An Embodied Conversational Agent using LLMs, Combining Open and Closed-Domain Dialogue with Facial Expressions",2023,0.0004336608487423496,1
W2904832339,Spatiotemporal Multi-Graph Convolution Network for Ride-Hailing Demand Forecasting,2019,0.00043313784036619406,1
W2995837271,Hierarchical Taxonomy-Aware and Attentional Graph Capsule RCNNs for Large-Scale Multi-Label Text Classification,2019,0.0004327297765810034,1
W4406080987,A systematic review for transformer-based long-term series forecasting,2025,0.0004311193105429386,1
W4389503368,ICFormer: A Deep Learning model for informed lithium-ion battery diagnosis and early knee detection,2023,0.0004285726281068981,1
W2739996966,Deep Learning for Extreme Multi-label Text Classification,2017,0.00042676268051968717,1
W4289656058,Interpretable Transformer Model for Capturing Regime Switching Effects of Real-Time Electricity Prices,2022,0.00042448799563388846,1
W2782791108,Deep Bidirectional and Unidirectional LSTM Recurrent Neural Network for Network-wide Traffic Speed Prediction,2018,0.00042442239385426424,1
W4366377753,Multi-Scale Adaptive Graph Neural Network for Multivariate Time Series Forecasting,2023,0.00041597498527169686,1
W4384936350,Deep learning methods for atmospheric PM2.5 prediction: A comparative study of transformer and CNN-LSTM-attention,2023,0.0004133742948311658,1
W4360976562,Text classification using embeddings: a survey,2023,0.00041237992111321336,1
W4391344861,A lightweight multi-layer perceptron for efficient multivariate time series forecasting,2024,0.00041107921128978435,1
W4362586828,A new convolutional dual-channel Transformer network with time window concatenation for remaining useful life prediction of rolling bearings,2023,0.00041012554221374526,1
W4400602210,Confined attention mechanism enabled Recurrent Neural Network framework to improve traffic flow prediction,2024,0.00041007132683132825,1
W3120358876,Dynamic Embedding Projection-Gated Convolutional Neural Networks for Text Classification,2021,0.0004079537728868702,1
W4280581965,Intelligent tool wear prediction based on Informer encoder and stacked bidirectional gated recurrent unit,2022,0.00040755709511661783,1
W4361981113,A Survey on Data-Driven Runoff Forecasting Models Based on Neural Networks,2023,0.00040751204462629925,1
W3133780103,Topology-Aware Graph Pooling Networks,2021,0.00040612530590102903,1
W2173183968,Order Matters: Sequence to sequence for sets,2015,0.00040470741952516317,1
W4205347394,Augmentation and heterogeneous graph neural network for AAAI2021-COVID-19 fake news detection,2022,0.0004040355709913457,1
W3005741980,Comparative study of landslide susceptibility mapping with different recurrent neural networks,2020,0.00040305309607915196,1
W3000127803,Backward Feature Correction: How Deep Learning Performs Deep Learning,2020,0.00039885002622476646,1
W2750384459,A Multi-view Deep Learning Method for Epileptic Seizure Detection using Short-time Fourier Transform,2017,0.0003982618198962867,1
W4382203122,Time Series Anomaly Detection Using Transformer-Based GAN With Two-Step Masking,2023,0.00039303369704708606,1
W3192648431,Temporal convolutional autoencoder for unsupervised anomaly detection in time series,2021,0.00039149919246316223,1
W3129918875,Cognitive structure learning model for hierarchical multi-label text classification,2021,0.00038690299981456453,1
W4398174014,RNN-LSTM: From applications to modeling techniques and beyond—Systematic review,2024,0.0003833468405758178,1
W4406848965,Enhancing Transformer-based models for long sequence time series forecasting via structured matrix,2025,0.00038068626790793117,1
W3076947077,A Hybrid BERT Model That Incorporates Label Semantics via Adjustive Attention for Multi-Label Text Classification,2020,0.0003801404990825356,1
W2950817888,Urban Traffic Prediction from Spatio-Temporal Data Using Deep Meta Learning,2019,0.000379619582984761,1
W4394575959,Towards efficient similarity embedded temporal Transformers via extended timeframe analysis,2024,0.00037754406551198825,1
W4391248393,Hierarchical text classification with multi-label contrastive learning and KNN,2024,0.00037676267775705463,1
W4392094097,Transformer based Kalman Filter with EM algorithm for time series prediction and anomaly detection of complex systems,2024,0.00037193858065833553,1
W4392516232,GRAformer: A gated residual attention transformer for multivariate time series forecasting,2024,0.0003676405812293247,1
W4313443611,Spatio-temporal wind speed forecasting using graph networks and novel Transformer architectures,2022,0.0003663096551791814,1
W4396694481,A novel hybrid model based on Empirical Mode Decomposition and Echo State Network for wind power forecasting,2024,0.00036307476278122703,1
W4391597917,A Transformer based approach to electricity load forecasting,2024,0.0003617351380617487,1
W4385569983,Augmenters at SemEval-2023 Task 1: Enhancing CLIP in Handling Compositionality and Ambiguity for Zero-Shot Visual WSD through Prompt Augmentation and Text-To-Image Diffusion,2023,0.0003616330141605903,1
W4372342073,Preformer: Predictive Transformer with Multi-Scale Segment-Wise Correlations for Long-Term Time Series Forecasting,2023,0.0003567748584253508,1
W2963311488,EA-LSTM: Evolutionary attention-based LSTM for time series prediction,2019,0.00035343785641618744,1
W4403577901,DIFN: A Dual Intention-aware Network for Repurchase Recommendation with Hierarchical Spatio-temporal Fusion,2024,0.0003495724916787405,1
W4391994338,"Evaluating Time-Series Prediction of Temperature, Relative Humidity, and CO2 in the Greenhouse with Transformer-Based and RNN-Based Models",2024,0.000346300621942151,1
W2612810742,An overview and comparative analysis of Recurrent Neural Networks for Short Term Load Forecasting,2017,0.0003449915976169785,1
W3047555776,Study of Various Methods for Tokenization,2020,0.00034353390720436527,1
W4406902818,Adaptive transformer-based multi-task learning framework for synchronous prediction of substation flooding and outage risks,2025,0.00034248992204280487,1
W3011624874,AMalNet: A deep learning framework based on graph convolutional networks for malware detection,2020,0.0003424531679336057,1
W3217689614,Structural Rotor Fault Diagnosis Using Attention-Based Sensor Fusion and Transformers,2021,0.0003417077663569769,1
W4386760021,Trend-augmented and temporal-featured Transformer network with multi-sensor signals for remaining useful life prediction,2023,0.00034149457088494285,1
W3213097325,Graph Fusion Network for Text Classification,2021,0.00033781397626583945,1
W4289866548,Anomaly Detection in Time Series with Robust Variational Quasi-Recurrent Autoencoders,2022,0.00033704902496974217,1
W4313887285,A Stochastic Recurrent Encoder Decoder Network for Multistep Probabilistic Wind Power Predictions,2023,0.000336210720012362,1
W2951605425,Full-Capacity Unitary Recurrent Neural Networks,2016,0.0003353394466899225,1
W3134371412,GIKT: A Graph-Based Interaction Model for Knowledge Tracing,2021,0.0003333916072950604,1
W4324258826,Trans-Lighter: A light-weight federated learning-based architecture for Remaining Useful Lifetime prediction,2023,0.0003318977725313502,1
W4391486486,STFormer: A dual-stage transformer model utilizing spatio-temporal graph embedding for multivariate time series forecasting,2024,0.000329729349210431,1
W2807482674,Period-aware content attention RNNs for time series forecasting with missing values,2018,0.0003284997494244678,1
W4408854639,From innovativeness to insecurity: unveiling the facets of translation technology use behavior among EFL learners using TRI 2.0,2025,0.0003260827018781524,1
W4391224777,"TAXN: Translate Align Extract Normalize, a Multilingual Extraction Tool for Clinical Texts",2024,0.00032544508756298437,1
W4306168631,DAFA-BiLSTM: Deep Autoregression Feature Augmented Bidirectional LSTM network for time series prediction,2022,0.00032460615130138143,1
W4323664841,ODformer: Spatial–temporal transformers for long sequence Origin–Destination matrix forecasting against cross application scenario,2023,0.0003233533514499461,1
W4394824429,Deep learning-based spatial-temporal graph neural networks for price movement classification in crude oil and precious metal markets,2024,0.0003231635590363242,1
W4285245990,Improved Transformer Model for Enhanced Monthly Streamflow Predictions of the Yangtze River,2022,0.0003205434291143355,1
W4368359023,A Multichannel Convolutional Decoding Network for Graph Classification,2023,0.00031956853903846474,1
W4382934573,Exploring transformers for behavioural biometrics: A case study in gait recognition,2023,0.00031905999681184163,1
W4386986621,Integrated Multi-Head Self-Attention Transformer model for electricity demand prediction incorporating local climate variables,2023,0.00031779896896187823,1
W4313177352,Transformers discover an elementary calculation system exploiting local attention and grid-like problem representation,2022,0.00031731167032226755,1
W4379106999,MrCAN: Multi-relations aware convolutional attention network for multivariate time series forecasting,2023,0.00031657340817653837,1
W4403016694,ProTformer: Transformer-based model for superior prediction of protein content in lablab bean (Lablab purpureus L.) using Near-Infrared Reflectance spectroscopy,2024,0.0003152560471012748,1
W4409694971,Hierarchical contrastive learning for multi-label text classification,2025,0.0003112400972747193,1
W4390520556,Improving deep-learning methods for area-based traffic demand prediction via hierarchical reconciliation,2024,0.0003110138507850726,1
W3196788510,A customized deep learning approach to integrate network-scale online traffic data imputation and prediction,2021,0.0003099972416835801,1
W3213938648,Deep Attention Diffusion Graph Neural Networks for Text Classification,2021,0.00030704180856630715,1
W4367310799,DESCINet: A hierarchical deep convolutional neural network with skip connection for long time series forecasting,2023,0.00030455084779571764,1
W3193078993,Correlation-Guided Representation for Multi-Label Text Classification,2021,0.00030324539288005846,1
W4205659634,Review of Graph Neural Network in Text Classification,2021,0.00030065393022936935,1
W4388036918,A multi-state fusion informer integrating transfer learning for metal tube bending early wrinkling prediction,2023,0.00029906793887160066,1
W4385666331,DyGCN-LSTM: A dynamic GCN-LSTM based encoder-decoder framework for multistep traffic prediction,2023,0.0002985579661886265,1
W4407922782,STAT-LSTM: A multivariate spatiotemporal feature aggregation model for SPEI-based drought prediction,2025,0.0002970914927829158,1
W4387490353,Variational Continuous Label Distribution Learning for Multi-Label Text Classification,2023,0.0002961202679546733,1
W4375858432,Hybrid deep neural network with dimension attention for state-of-health estimation of Lithium-ion Batteries,2023,0.0002959697683413426,1
W3106786448,Attention-gating for improved radio galaxy classification,2020,0.0002958044735209474,1
W4319068974,An Efficient Federated Learning Framework for Machinery Fault Diagnosis With Improved Model Aggregation and Local Model Training,2023,0.0002958044735209474,1
W4391621245,SageFormer: Series-Aware Framework for Long-Term Multivariate Time-Series Forecasting,2024,0.0002884260041287289,1
W3138415243,Multi-disease prediction using LSTM recurrent neural networks,2021,0.0002880344454289401,1
W4392671492,A regularized constrained two-stream convolution augmented Transformer for aircraft engine remaining useful life prediction,2024,0.00028782123551738186,1
W2992063672,A spatio-temporal decomposition based deep neural network for time series forecasting,2019,0.0002872119838588982,1
W3047331772,"Foundations of Population-based SHM, Part II: Heterogeneous populations – Graphs, networks, and communities",2020,0.00028659056265718027,1
W4378229377,Landslide Susceptibility Mapping Based on Deep Learning Algorithms Using Information Value Analysis Optimization,2023,0.0002849241661278148,1
W2784733489,Bayesian deep convolutional encoder–decoder networks for surrogate modeling and uncertainty quantification,2018,0.00028470545764057925,1
W3132015041,Remaining useful life prediction of roller bearings based on improved 1D-CNN and simple recurrent unit,2021,0.0002842233025224991,1
W3014676873,"A Hybrid Deep Learning Model to Forecast Particulate Matter Concentration Levels in Seoul, South Korea",2020,0.00028297245384098924,1
W4392452799,An encoder–decoder architecture with Fourier attention for chaotic time series multi-step prediction,2024,0.0002802058333058195,1
W4206023940,Deep-learning-based short-term electricity load forecasting: A real case application,2022,0.0002788985295410392,1
W4289313402,Label prompt for multi-label text classification,2022,0.0002786831712171758,1
W4323020850,Enhancing Text Classification by Graph Neural Networks With Multi-Granular Topic-Aware Graph,2023,0.0002767464769195898,1
W3137262131,An Experimental Review on Deep Learning Architectures for Time Series Forecasting,2020,0.0002763988856281623,1
W4402469109,A Critical Review of RNN and LSTM Variants in Hydrological Time Series Predictions,2024,0.0002751658258200106,1
W4309154825,Transformer neural networks for interpretable flood forecasting,2022,0.0002743416702438642,1
W4392180639,MAgNET: A graph U-Net architecture for mesh-based simulations,2024,0.00027371848128777667,1
W4306319588,Image-based time series forecasting: A deep convolutional neural network approach,2022,0.00027325338795429157,1
W3111294584,Deep Learning-Based Weather Prediction: A Survey,2020,0.00027199686508934157,1
W4280569535,Simplified-Boosting Ensemble Convolutional Network for Text Classification,2022,0.00027150971824386745,1
W2793820729,A hybrid deep learning based traffic flow prediction method and its understanding,2018,0.0002695470179967437,1
W4319996212,Energformer: A New Transformer Model for Energy Disaggregation,2023,0.00026848883308743643,1
W3188872815,A Transformer-based Framework for Multivariate Time Series Representation Learning,2021,0.00026704175102651174,1
W4281621698,An intelligent approach for Arabic handwritten letter recognition using convolutional neural network,2022,0.0002661886218247295,1
W4408667798,Symmetric KL-divergence by Stein’s Method,2025,0.0002661886218247295,1
W4285402398,Stock market index prediction using deep Transformer model,2022,0.000265146332810446,1
W4381326995,LightCTS: A Lightweight Framework for Correlated Time Series Forecasting,2023,0.0002650025809428498,1
W4366378735,A Fault Diagnosis Method for Rolling Bearing Based on 1D-ViT Model,2023,0.00026345997763491076,1
W4392345811,Ensemble of temporal Transformers for financial time series,2024,0.0002631339159328979,1
W3127228978,Overcoming Catastrophic Forgetting in Graph Neural Networks with Experience Replay,2021,0.0002628877500776979,1
W4389130441,Introducing Hybrid Modeling with Time-Series-Transformers: A Comparative Study of Series and Parallel Approach in Batch Crystallization,2023,0.0002616699092663697,1
W4396878152,TKAN: Temporal Kolmogorov-Arnold Networks,2024,0.00026143177748579396,1
W3172787012,EEG-GNN: Graph Neural Networks for Classification of Electroencephalogram (EEG) Signals,2021,0.0002609844730881223,1
W2978015420,Sparse Binary Compression: Towards Distributed Deep Learning with minimal Communication,2019,0.0002602569565669042,1
W4393145324,"A Hybrid Method of Self-Supervised Graph Embedding, Siamese Networks, and Transformers for Sentiment Analysis in Persian Language",2024,0.0002585076076227656,1
W4409759066,DNN-Schedule: A Predictive Scheduler for Minimizing Interference of Co-located DNN Workload,2025,0.00025787608458120454,1
W4406668349,MFFCNN: multi-scale fractional Fourier transform convolutional neural network for multivariate time series forecasting,2025,0.0002577295830471205,1
W4394060534,Advancing climate-resilient flood mitigation: Utilizing transformer-LSTM for water level forecasting at pumping stations,2024,0.0002528724211705425,1
W2804025582,Wave2Vec: Deep representation learning for clinical temporal data,2018,0.0002522372101413009,1
W4392106667,TCDformer: A transformer framework for non-stationary time series forecasting based on trend and change-point detection,2024,0.0002490302533456042,1
W4226283934,Sparse Structure Learning via Graph Neural Networks for Inductive Document Classification,2022,0.00024815599065755486,1
W4407242470,Automatic Evaluation of English Translation Based on Multi-granularity Interaction Fusion,2025,0.0002476246194458319,1
W3186647146,Ensemble of recurrent neural networks with long short-term memory cells for high-rate structural health monitoring,2021,0.00024741066510272397,1
W4319998033,A Parallel Hybrid Neural Network With Integration of Spatial and Temporal Features for Remaining Useful Life Prediction in Prognostics,2023,0.00024672456818478305,1
W3209002790,Hierarchical Heterogeneous Graph Representation Learning for Short Text Classification,2021,0.0002446360710366598,1
W4383752905,DifFormer: Multi-Resolutional Differencing Transformer With Dynamic Ranging for Time Series Analysis,2023,0.0002440192914433353,1
W4406728187,Charge diagnostics and state estimation of Battery Energy Storage Systems through Transformer models,2025,0.00024384120514314725,1
W4297423466,STGHTN: Spatial-temporal gated hybrid transformer network for traffic flow forecasting,2022,0.0002432769236577371,1
W4319811730,BiT-MAC: Mortality prediction by bidirectional time and multi-feature attention coupled network on multivariate irregular time series,2023,0.00024060149998176385,1
W3176189116,Search to aggregate neighborhood for graph neural network,2021,0.00023918698606749527,1
W2973171206,Personalized re-ranking for recommendation,2019,0.00023885713790574195,1
W4293428450,Fine-Grained Vessel Traffic Flow Prediction With a Spatio-Temporal Multigraph Convolutional Network,2022,0.00023747485550017937,1
W4406331643,TTSNet: Transformer–Temporal Convolutional Network–Self-Attention with Feature Fusion for Prediction of Remaining Useful Life of Aircraft Engines,2025,0.0002371695420253086,1
W4318317809,Interpretable local flow attention for multi-step traffic flow prediction,2023,0.00023628249148221797,1
W4406681264,Multilingual pretrained based multi-feature fusion model for English text classification,2025,0.00023328321123970307,1
W3109995084,milliEgo,2020,0.00023205101704303784,1
W2781626870,Recent Advances in Recurrent Neural Networks,2018,0.00023083799713237028,1
W4402128251,Evaluating the Effectiveness of Time Series Transformers for Demand Forecasting in Retail,2024,0.00023029962371769967,1
W3120117568,Forecasting of COVID-19 cases using deep learning models: Is it reliable and practically significant?,2021,0.00022994940410524275,1
W4390534762,A Lightweight Group Transformer-Based Time Series Reduction Network for Edge Intelligence and Its Application in Industrial RUL Prediction,2024,0.00022937990159402132,1
W4385805582,Continual Deep Learning for Time Series Modeling,2023,0.00022706834519745596,1
W4290948450,Causal Attention for Interpretable and Generalizable Graph Classification,2022,0.00022575835204417731,1
W2890672150,Short‐Term Traffic Speed Forecasting Based on Attention Convolutional Neural Network for Arterials,2018,0.0002253037063609482,1
W4288720745,Survey of Graph Neural Networks and Applications,2022,0.00022444103082007292,1
W4285262293,Water Quality Prediction for Smart Aquaculture Using Hybrid Deep Learning Models,2022,0.00022440311992902575,1
W3019433526,Temporal convolutional neural (TCN) network for an effective weather forecasting using time-series data from the local weather station,2020,0.0002242244425076328,1
W2896370767,Detecting Cyber Attacks in Industrial Control Systems Using Convolutional Neural Networks,2018,0.00022348044794577487,1
W4396978893,Dynamic spatial aware graph transformer for spatiotemporal traffic flow forecasting,2024,0.00022164939154965913,1
W4408078410,A remaining useful life prediction method of rolling bearings by RSA-BAFT combined with Copula Entropy feature selection,2025,0.00022075441079270476,1
W4407033379,Combining Graph NN and LLM for Improved Text-Based Emotion Recognition,2025,0.0002193205016730516,1
W2889347686,Uncertainty Prediction of Remaining Useful Life Using Long Short-Term Memory Network Based on Bootstrap Method,2018,0.0002177972771793202,1
W2997653844,ConCare: Personalized Clinical Feature Embedding via Capturing the Healthcare Context,2020,0.0002172728966138278,1
W4283809531,Wasserstein Adversarial Transformer for Cloud Workload Prediction,2022,0.00021663881882700092,1
W3193741318,A Deep Learning Approach for Flight Delay Prediction Through Time-Evolving Graphs,2021,0.00021622597326350553,1
W3047286661,Predicting Alzheimer's disease progression using deep recurrent neural networks,2020,0.0002157100606239747,1
W4388242026,Explainable Spatio-Temporal Graph Neural Networks for multi-site photovoltaic energy production,2023,0.00021548996909732457,1
W4391129999,Multi-Scale Transformer Pyramid Networks for Multivariate Time Series Forecasting,2024,0.0002150177997730009,1
W4408817468,A customized dual-transformer framework for remaining useful life prediction of mechanical systems with degraded state,2025,0.00021381932529427713,1
W4406678260,Text Classification Using Graph Convolutional Networks: A Comprehensive Survey,2025,0.0002130836193539101,1
W4210767179,Recurrent neural network model for high-speed train vibration prediction from time series,2022,0.00021281425482056856,1
W3109365969,Deep Learning for Time Series Forecasting: A Survey,2020,0.0002118072491666736,1
W4392976240,LCDFormer: Long-term correlations dual-graph transformer for traffic forecasting,2024,0.0002113186793721264,1
W4225161501,Light-weight federated learning-based anomaly detection for time-series data in industrial control systems,2022,0.00021014627370111256,1
W4407414419,An Evaluation of Physics-Informed Learning With General Neural Operator Transformers,2025,0.00020925018375603008,1
W3010005261,Text Classification Using Long Short-Term Memory With GloVe Features,2020,0.00020916811317816617,1
W4210263262,Variational transformer-based anomaly detection approach for multivariate time series,2022,0.00020903903569934626,1
W4402526753,Dictionary domain adaptation transformer for cross-machine fault diagnosis of rolling bearings,2024,0.0002087099890423254,1
W4406940594,Fine-Tuning Large Language Models Using Nlp and a Self-Organizing Map for Genre-Based Automated Writing Evaluation,2025,0.00020835071144764932,1
W4389783325,From Turing to Transformers: A Comprehensive Review and Tutorial on the Evolution and Applications of Generative Transformer Models,2023,0.00020795944281565724,1
W2969685114,Attention-based recurrent neural networks for accurate short-term and long-term dissolved oxygen prediction,2019,0.00020738954116501806,1
W4311765452,A novel convolutional informer network for deterministic and probabilistic state-of-charge estimation of lithium-ion batteries,2022,0.00020632473316592462,1
W3213650470,A hybrid partitioned deep learning methodology for moving interface and fluid–structure interaction,2021,0.00020628648264685217,1
W4406692092,Attention-based Deep learning Models for Predicting Anomalous Shock of Wastewater Treatment Plants,2025,0.0002059679234386518,1
W4386064855,A long-term water quality prediction model for marine ranch based on time-graph convolutional neural network,2023,0.0002044074787993134,1
W4405185121,Contrastive multi-graph learning with neighbor hierarchical sifting for semi-supervised text classification,2024,0.00020349557321524368,1
W4322588511,Expanding the prediction capacity in long sequence time-series forecasting,2023,0.00020162564468036788,1
W2998486497,Multi-Label Patent Categorization with Non-Local Attention-Based Graph Convolutional Network,2020,0.0002013583667045767,1
W3106543020,Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding,2018,0.00020101647756227105,1
W4281674262,A Review on Deep Sequential Models for Forecasting Time Series Data,2022,0.00020051065020447925,1
W2971092323,Label-Specific Document Representation for Multi-Label Text Classification,2019,0.0002001761953530206,1
W4387967494,NOA-LSTM: An efficient LSTM cell architecture for time series forecasting,2023,0.00019762608743487855,1
W3133663379,AST-GCN: Attribute-Augmented Spatiotemporal Graph Convolutional Network for Traffic Forecasting,2021,0.00019718285197889069,1
W2969724595,TabNet: Attentive Interpretable Tabular Learning,2019,0.00019521301614934091,1
W2972317931,GNNExplainer: Generating Explanations for Graph Neural Networks,2019,0.00019455392876721622,1
W3005644236,Geom-GCN: Geometric Graph Convolutional Networks,2020,0.0001940090820551978,1
W4318014921,ProtInteract: A deep learning framework for predicting protein–protein interactions,2023,0.00019391807009013705,1
W2971278153,Latent Ordinary Differential Equations for Irregularly-Sampled Time Series,2019,0.00019276502458732386,1
W4391653525,Modelling monthly rainfall of India through transformer-based deep learning architecture,2024,0.00019169666831075484,1
W4280591062,TFGAN: Traffic forecasting using generative adversarial network with multi-graph convolutional network,2022,0.00019098018003576228,1
W4213346784,Multi-channel fusion LSTM for medical event prediction using EHRs,2022,0.00019094673173258687,1
W3215493153,A Long Short-Term Memory-based correlated traffic data prediction framework,2021,0.0001897243536785478,1
W2995509042,Geom-GCN: Geometric Graph Convolutional Networks,2020,0.00018972099081994887,1
W4353094384,Feedback on a shared big dataset for intelligent TBM Part I: Feature extraction and machine learning methods,2023,0.0001893109992240774,1
W3041181542,Deep Learning for Arabic Error Detection and Correction,2020,0.00018853906693762303,1
W4393033598,Predicting ICU Interventions: A Transparent Decision Support Model Based on Multivariate Time Series Graph Convolutional Neural Network,2024,0.00018730238184397842,1
W4375928748,Nonlinear Spiking Neural Systems With Autapses for Predicting Chaotic Time Series,2023,0.00018663715526342573,1
W3208180646,A Unified View on Graph Neural Networks as Graph Signal Denoising,2021,0.00018595455185998344,1
W4392123654,Diffusion models in text generation: a survey,2024,0.00018550839927770825,1
W4280552892,Trend attention fully convolutional network for remaining useful life estimation,2022,0.00018462622102956985,1
W4390610528,STGAFormer: Spatial–temporal Gated Attention Transformer based Graph Neural Network for traffic flow forecasting,2024,0.00018410669268296667,1
W4309835665,A novel transformer-based multi-variable multi-step prediction method for chemical process fault prognosis,2022,0.0001839741937852969,1
W3082184637,Cooperative Deep Dynamic Feature Extraction and Variable Time-Delay Estimation for Industrial Quality Prediction,2020,0.0001839269876666693,1
W3184237885,Energy consumption prediction of appliances using machine learning and multi-objective binary grey wolf optimization for feature selection,2021,0.0001839269876666693,1
W3175924508,EnhanceNet: Plugin Neural Networks for Enhancing Correlated Time Series Forecasting,2021,0.00018275122673365205,1
W3120283405,A Hybrid Residual Dilated LSTM and Exponential Smoothing Model for Midterm Electric Load Forecasting,2021,0.00018254982818264681,1
W3207149528,Melons: Generating Melody With Long-Term Structure Using Transformers And Structure Graph,2022,0.00018102079090437593,1
W4403117273,Remaining Useful Life Prediction of Aero-engine via Temporal Convolutional Network with Gated Convolution and Channel Selection Unit,2024,0.00017932730924002168,1
W4403682256,An efficient class-dependent learning label approach using feature selection to improve multi-label classification algorithms,2024,0.0001784849926316321,1
W4385756443,MG-GCN: Multi-Granularity Graph Convolutional Neural Network for Multi-Label Classification in Multi-Label Information System,2023,0.0001780576280169763,1
W4220712276,Attention-based Conv-LSTM and Bi-LSTM networks for large-scale traffic speed prediction,2022,0.00017606836448180483,1
W2978540646,Convolution and Long Short-Term Memory Hybrid Deep Neural Networks for Remaining Useful Life Prognostics,2019,0.00017476566459734107,1
W4226209484,Learning to Solve 3-D Bin Packing Problem via Deep Reinforcement Learning and Constraint Programming,2021,0.00017277421592836332,1
W4379209990,VDGCNeT: A novel network-wide Virtual Dynamic Graph Convolution Neural network and Transformer-based traffic prediction model,2023,0.0001724734135259291,1
W4401463408,The Use of Attention-Enhanced CNN-LSTM Models for Multi-Indicator and Time-Series Predictions of Surface Water Quality,2024,0.00017181748641299793,1
W4408853303,Text Classification Model Based on Dependency Attention Graph Convolution,2024,0.00017146681447143658,1
W4364302133,Triple Alliance Prototype Orthotist Network for Long-Tailed Multi-Label Text Classification,2023,0.00017126642945166113,1
W4393032946,Graph Receptive Transformer Encoder for Text Classification,2024,0.00017095396975421866,1
W4393152681,Improved Graph Contrastive Learning for Short Text Classification,2024,0.00016937311969283177,1
W2966153025,Multivariate Temporal Convolutional Network: A Deep Neural Networks Approach for Multivariate Time Series Forecasting,2019,0.00016923346221851333,1
W4221151676,Incorporating Hierarchy into Text Encoder: a Contrastive Learning Approach for Hierarchical Text Classification,2022,0.0001689633948160374,1
W4383106791,GBT: Two-stage transformer framework for non-stationary time series forecasting,2023,0.00016895212916419458,1
W2946084162,Multiple convolutional neural networks for multivariate time series prediction,2019,0.00016748185753004524,1
W3004999940,Anomaly Detection Based on Convolutional Recurrent Autoencoder for IoT Time Series,2020,0.0001671091015708137,1
W2963166639,A Multimodal Anomaly Detector for Robot-Assisted Feeding Using an LSTM-Based Variational Autoencoder,2018,0.00016656140593594815,1
W2929376427,Deep neural network for hierarchical extreme multi-label text classification,2019,0.00016491417801363698,1
W4323644143,Dual Channel Feature Attention-Based Approach for RUL Prediction Considering the Spatiotemporal Difference of Multisensor Data,2023,0.00016267623460145239,1
W4281650942,Distance self-attention network method for remaining useful life estimation of aeroengine with parallel computing,2022,0.00016263324044577475,1
W4310064234,Predicting hourly PM2.5 concentrations in wildfire-prone areas using a SpatioTemporal Transformer model,2022,0.00016224112481111599,1
W4283817628,Graph Neural Controlled Differential Equations for Traffic Forecasting,2022,0.00016134748363549303,1
W2962736999,A Deep Neural Network for Unsupervised Anomaly Detection and Diagnosis in Multivariate Time Series Data,2019,0.00016034013540322704,1
W4401198529,MGSFformer: A Multi-Granularity Spatiotemporal Fusion Transformer for Air Quality Prediction,2024,0.000160288801277687,1
W2460144244,Group sparse regularization for deep neural networks,2017,0.00016007447907033688,1
W4386147356,Deep learning-powered vessel traffic flow prediction with spatial-temporal attributes and similarity grouping,2023,0.00015983592330708266,1
W4396661345,Local spatial and temporal relation discovery model based on attention mechanism for traffic forecasting,2024,0.0001575222004081908,1
W2905388713,A Deep Neural Network Model for Short-Term Load Forecast Based on Long Short-Term Memory Network and Convolutional Neural Network,2018,0.00015702600640884947,1
W4385452886,State-of-Charge Estimation and Health Prognosis for Lithium-Ion Batteries Based on Temperature-Compensated Bi-LSTM Network and Integrated Attention Mechanism,2023,0.00015639296992724612,1
W4226031225,Electric Vehicle Velocity and Energy Consumption Predictions Using Transformer and Markov-Chain Monte Carlo,2022,0.00015627066771277417,1
W4387641291,RT-GCN: Gaussian-based spatiotemporal graph convolutional network for robust traffic prediction,2023,0.00015495711713903504,1
W4406015732,CoGraphNet for enhanced text classification using word-sentence heterogeneous graph representations and improved interpretability,2025,0.00015494227502679868,1
W4289781031,Self-training method based on GCN for semi-supervised short text classification,2022,0.00015452402671894716,1
W4390969131,Graph Neural Network-Based EEG Classification: A Survey,2024,0.00015423239394207777,1
W3102124851,HSCNN: A Hybrid-Siamese Convolutional Neural Network for Extremely Imbalanced Multi-label Text Classification,2020,0.00015409591062600636,1
W4360770771,DLformer: A Dynamic Length Transformer-Based Network for Efficient Feature Representation in Remaining Useful Life Prediction,2023,0.0001537957823526176,1
W3176676637,Hierarchy-aware Label Semantics Matching Network for Hierarchical Text Classification,2021,0.0001532121457744653,1
W4400605513,A novel method for ship carbon emissions prediction under the influence of emergency events,2024,0.00015310466935304347,1
W4408596469,Log-Cumulative feature alignment for enhanced Prognosis of Aero-Engine remaining Useful life,2025,0.00015297886784567397,1
W4387987111,TreeCN: Time Series Prediction With the Tree Convolutional Network for Traffic Prediction,2023,0.0001522082803559147,1
W3086834600,Towards efficient unconstrained handwriting recognition using Dilated Temporal Convolution Network,2020,0.00015195097912614958,1
W4320480791,A contrastive learning framework enhanced by unlabeled samples for remaining useful life prediction,2023,0.00015126284032538717,1
W3118419305,A novel one-stage framework for visual pulse rate estimation using deep neural networks,2021,0.00015044108046493538,1
W4362009348,Remaining Useful Life Prediction of Turbofan Engines Using CNN-LSTM-SAM Approach,2023,0.0001496600201012224,1
W4323975488,Attention-augmented recalibrated and compensatory network for machine remaining useful life prediction,2023,0.00014906612707952293,1
W4220930802,Echo state network with logistic mapping and bias dropout for time series prediction,2022,0.00014686464761091172,1
W2998423439,Learning Backtrackless Aligned-Spatial Graph Convolutional Networks for Graph Classification,2020,0.00014631767666554456,1
W3002730961,Hourly Heat Load Prediction Model Based on Temporal Convolutional Neural Network,2020,0.00014590596230905676,1
W3185234777,Temporal convolutional network with soft thresholding and attention mechanism for machinery prognostics,2021,0.000145455452685303,1
W3090516321,Short-Term Load Forecasting for Industrial Customers Based on TCN-LightGBM,2020,0.0001450158231717031,1
W4390704115,A deep learning-based hybrid approach for multi-time-ahead streamflow prediction in an arid region of Northwest China,2024,0.00014486860847815212,1
W4408470385,Hierarchical Text Classification: Fine-tuned GPT-2 vs BERT-BiLSTM,2025,0.00014422076002511817,1
W3194396612,"Industrial Dataspace for smart manufacturing: connotation, key technologies, and framework",2021,0.00014379895391358072,1
W4210450738,RUL Prediction of Wind Turbine Gearbox Bearings Based on Self-Calibration Temporal Convolutional Network,2022,0.00014317456451662787,1
W4327718158,Identifying performance anomalies in fluctuating cloud environments: A robust correlative-GNN-based explainable approach,2023,0.00014309947974834486,1
W4400723670,A novel approach to forecast water table rise in arid regions using stacked ensemble machine learning and deep artificial intelligence models,2024,0.00014272835938924875,1
W4309774299,State of health estimation of lithium-ion batteries with a temporal convolutional neural network using partial load profiles,2022,0.00014213695108892263,1
W2911742574,The implicit bias of gradient descent on separable data,2018,0.0001419397641135286,1
W3128976925,Multimodal approach to analysing big social and news media data,2021,0.00014143199955614352,1
W4386129879,Dynamic adaptive encoder-decoder deep learning networks for multivariate time series forecasting of building energy consumption,2023,0.0001413406152154734,1
W4388798200,Improved deep bidirectional recurrent neural network for learning the cross-sensitivity rules of gas sensor array,2023,0.0001413406152154734,1
W4322501311,Development and Analysis of a CNN- and Transfer-Learning-Based Classification Model for Automated Dairy Cow Feeding Behavior Recognition from Accelerometer Data,2023,0.0001413406152154734,1
W4409917064,Prediction of stress-strain behavior of rock materials under biaxial compression using a deep learning approach,2025,0.00014115472459353328,1
W4293275470,Advanced deep learning approaches to predict supply chain risks under COVID-19 restrictions,2022,0.000140959838430678,1
W4388976461,Forecasting water quality variable using deep learning and weighted averaging ensemble models,2023,0.0001408208250701413,1
W4378697395,STAGED: A Spatial-Temporal Aware Graph Encoder–Decoder for Fault Diagnosis in Industrial Processes,2023,0.0001406729227913169,1
W4379387130,A contrastive learning-based framework for wind power forecast,2023,0.00013962023440132796,1
W2946179063,Incorporating Syntactic and Semantic Information in Word Embeddings using Graph Convolutional Networks,2018,0.00013894635266886612,1
W4408067834,Language Intelligence in Law: NLP Solutions for Legal Excellence,2025,0.00013878262264113692,1
W4382199756,Interpretation and explanation of convolutional neural network-based fault diagnosis model at the feature-level for building energy systems,2023,0.00013878262264113692,1
W4408987952,A Transformer-Based Robot Autonomous Exploration Method,2025,0.00013878262264113692,1
W4399264264,Power Customer Satisfaction Based on Power Big Data and NLP,2024,0.00013878262264113692,1
W4322615356,A method for assisting the accident consequence prediction and cause investigation in petrochemical industries based on natural language processing technology,2023,0.00013878262264113692,1
W4389937650,Multi-label text classification based on semantic-sensitive graph convolutional network,2023,0.000138362307218502,1
W4362471447,A multi-semantic passing framework for semi-supervised long text classification,2023,0.00013821738755274776,1
W2565330852,Structured Sequence Modeling with Graph Convolutional Recurrent Networks,2018,0.00013765616227259125,1
W4292814179,Multistep short-term wind speed forecasting using transformer,2022,0.0001376536660416748,1
W4306408437,Differential attention net: Multi-directed differential attention based hybrid deep learning model for solar power forecasting,2022,0.00013675624246082082,1
W4388018399,Improve label embedding quality through global sensitive GAT for hierarchical text classification,2023,0.00013592249001026746,1
W4313473147,A Combined Model Based on Recurrent Neural Networks and Graph Convolutional Networks for Financial Time Series Forecasting,2023,0.00013465745145075245,1
W4381548641,An improved GNN using dynamic graph embedding mechanism: A novel end-to-end framework for rolling bearing fault diagnosis under variable working conditions,2023,0.00013465745145075245,1
W2965485674,Classification of Hand Movements From EEG Using a Deep Attention-Based LSTM Network,2019,0.00013409238627735238,1
W4214606007,Relational Graph Convolutional Network for Text-Mining-Based Accident Causal Classification,2022,0.00013280808064318006,1
W3172514114,Principles and algorithms for forecasting groups of time series: Locality and globality,2021,0.0001316749923537668,1
W4317906736,Medium-long-term prediction of water level based on an improved spatio-temporal attention mechanism for long short-term memory networks,2023,0.00013112256846072593,1
W4211067021,A Digital Twin of a Water Distribution System by Using Graph Convolutional Networks for Pump Speed-Based State Estimation,2022,0.00013091832990550452,1
W4317103791,Forecasting Short-Term Passenger Flow of Subway Stations Based on the Temporal Pattern Attention Mechanism and the Long Short-Term Memory Network,2023,0.000130591777582237,1
W4283318673,TranAD,2022,0.00013018144884610042,1
W4407719259,A location-centric transformer framework for multi-location short-term wind speed forecasting,2025,0.00012971048273866008,1
W4213154819,"Accurate workload prediction for edge data centers: Savitzky-Golay filter, CNN and BiLSTM with attention mechanism",2022,0.00012931660521672464,1
W4401437587,State of health estimation for lithium-ion batteries based on incremental capacity analysis and Transformer modeling,2024,0.00012879175168684025,1
W2963622218,HeteroMed,2018,0.0001274943659088756,1
W4283771810,FedHGCDroid: An Adaptive Multi-Dimensional Federated Learning for Privacy-Preserving Android Malware Classification,2022,0.00012745624321563968,1
W3209973822,Graph neural network initialisation of quantum approximate optimisation,2022,0.00012745624321563968,1
W3201047833,Spatial-Temporal Traffic Data Imputation via Graph Attention Convolutional Network,2021,0.00012745624321563968,1
W4407058560,TaintAttack: rapid attack investigation based on information flow tracking,2025,0.00012745624321563968,1
W4393118497,A two-stage adversarial Transformer based approach for multivariate industrial time series anomaly detection,2024,0.00012675497730590596,1
W3197963420,Building interpretable models for business process prediction using shared and specialised attention mechanisms,2022,0.0001262347667673238,1
W3133841585,An Attention-Based Multilayer GRU Model for Multistep-Ahead Short-Term Load Forecasting,2021,0.0001262347667673238,1
W4406305410,Hierarchical graph-based integration network for propaganda detection in textual news articles on social media,2025,0.00012618701876786415,1
W4407320464,Assimilation of the chronology of mineral system components in prospectivity analysis procedure for mineral exploration targeting: Adaptation of recurrent neural networks,2025,0.00012575881502241377,1
W4321615273,Time-series quantum reservoir computing with weak and projective measurements,2023,0.00012572588475969713,1
W4406083334,Design of IoT energy consumption forecasting model for residential buildings based on improved long short-term memory (LSTM),2025,0.00012572588475969713,1
W4385270114,"Towards Long-Term Time-Series Forecasting: Feature, Pattern, and Distribution",2023,0.00012572044777451049,1
W4407190631,Multi-Subgraph Fusion: An Innovative Approach for Block Matrix Graph Convolutional Networks,2025,0.0001244280966754094,1
W4407732814,ADCL: An attention feature enhancement network based on adversarial contrastive learning for short text classification,2025,0.00012379332928872156,1
W4320516656,A concise self-adapting deep learning network for machine remaining useful life prediction,2023,0.00012273768559876858,1
W4390097263,EHR-HGCN: An Enhanced Hybrid Approach for Text Classification Using Heterogeneous Graph Convolutional Networks in Electronic Health Records,2023,0.00012035376206871643,1
W2805713564,Heart Sound Segmentation—An Event Detection Approach Using Deep Recurrent Neural Networks,2018,0.00012004047549373386,1
W2944992190,Wireless Network Intrusion Detection Based on Improved Convolutional Neural Network,2019,0.00012004047549373386,1
W4297509495,RUL prediction of machinery using convolutional-vector fusion network through multi-feature dynamic weighting,2022,0.00011923120654013115,1
W3005857605,Robot Navigation in Crowds by Graph Convolutional Networks With Attention Learned From Human Gaze,2020,0.0001180621036781517,1
W4310790298,A Hybrid-Convolution Spatial–Temporal Recurrent Network For Traffic Flow Prediction,2022,0.00011754503033249671,1
W3158381863,History-based attention in Seq2Seq model for multi-label text classification,2021,0.0001166239897004274,1
W4386263530,"Short-Term Traffic Prediction Using Deep Learning Long Short-Term Memory: Taxonomy, Applications, Challenges, and Future Trends",2023,0.00011519365237737409,1
W2922329508,Short-Term Load Forecasts Using LSTM Networks,2019,0.00011457793648221732,1
W2963360736,Estimating Missing Data in Temporal Data Streams Using Multi-Directional Recurrent Neural Networks,2018,0.00011426699448464242,1
W4213219213,DarknetSec: A novel self-attentive deep learning method for darknet traffic classification and application identification,2022,0.00011371656356072831,1
W4383955240,Deep Learning Framework for Lithium-ion Battery State of Charge Estimation: Recent Advances and Future Perspectives,2023,0.00011315672133179726,1
W3131110071,On Short-Term Load Forecasting Using Machine Learning Techniques and a Novel Parallel Deep LSTM-CNN Approach,2021,0.00011291031582475491,1
W3173549089,PhyCRNet: Physics-informed convolutional-recurrent network for solving spatiotemporal PDEs,2021,0.00011232917498531317,1
W4406618530,A Multi-Model Fusion Network for Enhanced Blind Well Lithology Prediction,2025,0.00011149552648713125,1
W3158304688,Dynamic Graph Convolutional Recurrent Network for Traffic Prediction: Benchmark and Solution,2022,0.0001114372734637998,1
W4319264941,Text FCG: Fusing Contextual Information via Graph Learning for text classification,2023,0.00011140170460720858,1
W4386021093,Transformers are Short-Text Classifiers,2023,0.00011133003165034517,1
W4396558249,Multi-Label Text Classification model integrating Label Attention and Historical Attention,2024,0.00011074771084860055,1
W4362558555,Generating Music with Data: Application of Deep Learning Models for Symbolic Music Composition,2023,0.00010930546963481012,1
W4394779417,Deep learning and structural health monitoring: Temporal Fusion Transformers for anomaly detection in masonry towers,2024,0.00010914492573803255,1
W4396498890,How good are different machine and deep learning models in forecasting the future price of metals? Full sample versus sub-sample,2024,0.00010775251927965116,1
W2950191616,Discriminative Embeddings of Latent Variable Models for Structured Data,2016,0.0001066670968919255,1
W2754252319,Short-Term Residential Load Forecasting Based on LSTM Recurrent Neural Network,2017,0.000106313882362527,1
W4392365138,Transformer-based multivariate time series anomaly detection using inter-variable attention mechanism,2024,0.0001057392700318192,1
W3201524630,A keyphrase-based approach for interpretable ICD-10 code classification of Spanish medical reports,2021,0.00010563472930731636,1
W4308951285,Multivariate wind speed forecasting based on multi-objective feature selection approach and hybrid deep learning model,2022,0.00010455148798989905,1
W4210443567,Multi-dimensional recurrent neural network for remaining useful life prediction under variable operating conditions and multiple fault modes,2022,0.00010429501316774,1
W3027664001,Temporal Multi-Graph Convolutional Network for Traffic Flow Prediction,2020,0.00010426462677157511,1
W2908623803,Causal Discovery with Attention-Based Convolutional Neural Networks,2019,0.00010324577246841084,1
W4396769114,Temporal Fusion Transformers for streamflow Prediction: Value of combining attention with recurrence,2024,0.00010200815747210872,1
W4391642338,Argo data anomaly detection based on transformer and Fourier transform,2024,0.00010104059529370655,1
W4293833044,A CNN-Bi_LSTM parallel network approach for train travel time prediction,2022,0.00010074749590039883,1
W4317569465,Forecasting energy consumption demand of customers in smart grid using Temporal Fusion Transformer (TFT),2023,0.00010018571717084988,1
W4362670671,Classification of Research Papers on Radio Frequency Electromagnetic Field (RF-EMF) Using Graph Neural Networks (GNN),2023,9.980363602299972e-05,1
W4394770053,Label-text bi-attention capsule networks model for multi-label text classification,2024,9.960591767158932e-05,1
W4225341287,Event-Aware Multimodal Mobility Nowcasting,2022,9.928433926775544e-05,1
W2911831256,Mining Likely Analogical APIs Across Third-Party Libraries via Large-Scale Unsupervised API Semantics Embedding,2019,9.907074687337067e-05,1
W4400090517,Automatically Categorizing Construction Accident Narratives Using the Deep-Learning Model with a Class-Imbalance Treatment Technique,2024,9.874747843611594e-05,1
W3117204221,Health indicator construction by quadratic function-based deep convolutional auto-encoder and its application into bearing RUL prediction,2020,9.87390728616386e-05,1
W4400980292,A dual-stream spatio-temporal fusion network with multi-sensor signals for remaining useful life prediction,2024,9.872031155127488e-05,1
W3102696737,StageNet: Stage-Aware Neural Networks for Health Risk Prediction,2020,9.786997157673601e-05,1
W4406539492,A Hybrid CNN-Transformer Surrogate Model for the Multi-Objective Robust Optimization of Geological Carbon Sequestration,2025,9.775465726889884e-05,1
W4400441570,Multi-domain encoder–decoder neural networks for latent data assimilation in dynamical systems,2024,9.775465726889884e-05,1
W2971487518,Computational Segmentation and Classification of Diabetic Glomerulosclerosis,2019,9.743734672916726e-05,1
W3196530826,Recurrent neural networks for atmospheric noise removal from InSAR time series with missing values,2021,9.741183251431404e-05,1
W4406919111,Artificial intelligence methods applied to longitudinal data from electronic health records for prediction of cancer: a scoping review,2025,9.741183251431404e-05,1
W4392460704,Mining construction accident reports via unsupervised NLP and Accimap for systemic risk analysis,2024,9.682340967813681e-05,1
W3116103134,Time-Series Regeneration With Convolutional Recurrent Generative Adversarial Network for Remaining Useful Life Estimation,2020,9.562961532039402e-05,1
W4399527010,A Deep Learning-Based Approach for Part of Speech (PoS) Tagging in the Pashto Language,2024,9.378477374739822e-05,1
W3215560629,Bert-Enhanced Text Graph Neural Network for Classification,2021,9.363276741626077e-05,1
W4200547309,Meta Graph Transformer: A Novel Framework for Spatial–Temporal Traffic Prediction,2021,9.347431465597942e-05,1
W4410056584,Improving machine translation accuracy for underrepresented languages in linguistic research using transformer models,2025,9.317344963492352e-05,1
W4391880899,A Hybrid Model Based on Convolutional Neural Network and Long Short-Term Memory for Multi-label Text Classification,2024,9.202293655611907e-05,1
W4387164353,TGCN-Bert Emoji Prediction in Information Systems Using TCN and GCN Fusing Features Based on BERT,2023,9.186425845741175e-05,1
W4410215172,An Improved Deep Learning Model for Word Embeddings Based Clustering for Large Text Datasets,2025,9.142696668553e-05,1
W4283765700,Remaining useful life prediction of bearings by a new reinforced memory GRU network,2022,9.077225013059398e-05,1
W2611552022,A Generalization of Convolutional Neural Networks to Graph-Structured Data,2017,9.041931165892842e-05,1
W3170962599,Semantics aware adversarial malware examples generation for black-box attacks,2021,9.016266765811732e-05,1
W4364382428,SwiftR: Cross-platform ransomware fingerprinting using hierarchical neural networks on hybrid features,2023,9.013459484898732e-05,1
W4210907736,Multi-level text document similarity estimation and its application for plagiarism detection,2022,9.004938611106167e-05,1
W4392828127,Quality Prediction Modeling for Industrial Processes Using Multiscale Attention-Based Convolutional Neural Network,2024,8.99886188945068e-05,1
W4382202724,Continual Graph Convolutional Network for Text Classification,2023,8.986769601286321e-05,1
W4283741809,A gated graph convolutional network with multi-sensor signals for remaining useful life prediction,2022,8.974226091792275e-05,1
W4385287316,A novel hybrid deep learning model with ARIMA Conv-LSTM networks and shuffle attention layer for short-term traffic flow prediction,2023,8.919968754842168e-05,1
W4284892020,Recognizing Medical Search Query Intent by Few-shot Learning,2022,8.909934538292156e-05,1
W4399469388,Efficiently localizing system anomalies for cloud infrastructures: a novel Dynamic Graph Transformer based Parallel Framework,2024,8.88554970668081e-05,1
W3160886584,Autoencoder Quasi-Recurrent Neural Networks for Remaining Useful Life Prediction of Engineering Systems,2021,8.773887714389211e-05,1
W4379117136,Coupled Attention Networks for Multivariate Time Series Anomaly Detection,2023,8.741012062486728e-05,1
W4396888881,Contrastive BiLSTM-enabled Health Representation Learning for Remaining Useful Life Prediction,2024,8.724323760895481e-05,1
W4381620565,Self-supervised Health Representation Decomposition based on contrast learning,2023,8.676693807842362e-05,1
W4380742759,Anomaly detection for multivariate times series through the multi-scale convolutional recurrent variational autoencoder,2023,8.55393137758377e-05,1
W4387686310,An attention-based temporal convolutional network method for predicting remaining useful life of aero-engine,2023,8.54540531285516e-05,1
W3037422790,Taming Pretrained Transformers for Extreme Multi-label Text Classification,2020,8.513117557204465e-05,1
W4408372743,Research on multi-label short text categorization method for online education under deep learning,2025,8.511542121301095e-05,1
W4311421441,Bearing remaining useful life prediction using self-adaptive graph convolutional networks with self-attention mechanism,2022,8.402700453085471e-05,1
W3190748826,Unsupervised Deep Anomaly Detection for Multi-Sensor Time-Series Signals,2021,8.39649204704954e-05,1
W4213355816,RicENN: Prediction of Rice Enhancers with Neural Network Based on DNA Sequences,2022,8.368723923139783e-05,1
W4410486486,DocNet: Semantic Structure in Inductive Bias Detection Models,2025,8.223544507576506e-05,1
W4224324825,Slow-Varying Dynamics-Assisted Temporal Capsule Network for Machinery Remaining Useful Life Estimation,2022,8.211090529753026e-05,1
W4200099066,Traffic flow prediction models – A review of deep learning techniques,2021,8.192913819279135e-05,1
W4205270295,Dynamic Prototype Network based on Sample Adaptation for Few-Shot Malware Detection,2022,8.171614718190932e-05,1
W4386474260,A novel EMD and causal convolutional network integrated with Transformer for ultra short-term wind power forecasting,2023,8.159688344441588e-05,1
W4392883897,LSTTN: A Long-Short Term Transformer-based spatiotemporal neural network for traffic flow forecasting,2024,8.157918878583175e-05,1
W4387566946,State of health estimation of lithium-ion batteries based on Mixers-bidirectional temporal convolutional neural network,2023,8.133343142063663e-05,1
W3185889262,A hybrid deep learning model with 1DCNN-LSTM-Attention networks for short-term traffic flow prediction,2021,8.106247055049297e-05,1
W3033688252,Citywide Traffic Flow Prediction Based on Multiple Gated Spatio-temporal Convolutional Neural Networks,2020,8.087096410172814e-05,1
W4389497068,"Explainable, interpretable, and trustworthy AI for an intelligent digital twin: A case study on remaining useful life",2023,8.056344046429901e-05,1
W4285187956,Aircraft Engines Remaining Useful Life Prediction Based on A Hybrid Model of Autoencoder and Deep Belief Network,2022,8.056344046429901e-05,1
W4406209594,Intelligent identification of hydropower engineering safety hazards: research on text classification method based on deep learning,2025,8.049428827890173e-05,1
W4317436033,Multi-scale integrated deep self-attention network for predicting remaining useful life of aero-engine,2023,8.0286248278706e-05,1
W4390414087,An adversarial contrastive autoencoder for robust multivariate time series anomaly detection,2023,7.939735883768436e-05,1
W4406015697,Personalized tourism recommendation model based on temporal multilayer sequential neural network,2025,7.91234637555203e-05,1
W2947812485,Predicting Station-Level Short-Term Passenger Flow in a Citywide Metro Network Using Spatiotemporal Graph Convolutional Neural Networks,2019,7.880259387002225e-05,1
W4392481514,A novel data augmentation framework for remaining useful life estimation with dense convolutional regression network,2024,7.786410910211008e-05,1
W4406846597,Forecasting chaotic time series: Comparative performance of LSTM-based and Transformer-based neural network,2025,7.764768785079474e-05,1
W4321374739,Short-Term Traffic Flow Prediction Based on a K-Nearest Neighbor and Bidirectional Long Short-Term Memory Model,2023,7.756007627411906e-05,1
W2740759433,Effective Deep Memory Networks for Distant Supervised Relation Extraction,2017,7.668454407228888e-05,1
W4210562913,Aircraft engine remaining useful life estimation via a double attention-based data-driven architecture,2022,7.616653262025057e-05,1
W2750304600,Forecasting day-ahead electricity prices in Europe: The importance of considering market integration,2017,7.574135544625349e-05,1
W4286433681,Real-Time Locational Detection of Stealthy False Data Injection Attack in Smart Grid: Using Multivariate-Based Multi-Label Classification Approach,2022,7.572766611804203e-05,1
W3131017962,The automated prediction of solar flares from SDO images using deep learning,2021,7.569602897592575e-05,1
W4386947607,A feature decomposition-based deep transfer learning framework for concrete dam deformation prediction with observational insufficiency,2023,7.569602897592575e-05,1
W4205438547,A Comparison of TCN and LSTM Models in Detecting Anomalies in Time Series Data,2021,7.563791108213535e-05,1
W3088611441,Deep Learning for Spatio-Temporal Data Mining: A Survey,2020,7.549520518740901e-05,1
W4281929036,GTAD: Graph and Temporal Neural Network for Multivariate Time Series Anomaly Detection,2022,7.532698439428572e-05,1
W4403284445,Enhancing road traffic flow in sustainable cities through transformer models: Advancements and challenges,2024,7.503116702814286e-05,1
W2890207295,A Time-Distributed Spatiotemporal Feature Learning Method for Machine Health Monitoring with Multi-Sensor Time Series,2018,7.444227820354331e-05,1
W4399864464,MHGNN: Multi-view fusion based Heterogeneous Graph Neural Network,2024,7.322281712936227e-05,1
W4409343151,Properties of neural networks identifying strongly lensed gravitational waves in time domain,2025,7.293105965280401e-05,1
W2998409174,AdaCare: Explainable Clinical Health Status Representation Learning via Scale-Adaptive Feature Extraction and Recalibration,2020,7.268762974192003e-05,1
W4366378747,DCAT: Combining Multisemantic Dual-Channel Attention Fusion for Text Classification,2023,7.157256232518397e-05,1
W3161072801,Heterogeneous Graph Propagation Network,2021,7.152458590103316e-05,1
W4399154202,Graph Kernel Neural Networks,2024,7.096823280954531e-05,1
W4409051266,Generality-aware self-supervised transformer for multivariate time series anomaly detection,2025,7.088111728098836e-05,1
W4313427720,Malware Detection Using Deep Learning and Correlation-Based Feature Selection,2023,7.035858884915915e-05,1
W4224315779,A Semi-Supervised VAE Based Active Anomaly Detection Framework in Multivariate Time Series for Online Systems,2022,6.939484803169536e-05,1
W3142970463,Short-term wind power prediction based on multidimensional data cleaning and feature reconfiguration,2021,6.930646291086711e-05,1
W4362723506,A piecewise method for bearing remaining useful life estimation using temporal convolutional networks,2023,6.910383294036502e-05,1
W4406237835,Rethinking the message passing for graph-level classification tasks in a category-based view,2025,6.860054097724781e-05,1
W4390919300,Unsupervised Deep Anomaly Detection for Industrial Multivariate Time Series Data,2024,6.828651601588442e-05,1
W3166531985,HTCInfoMax: A Global Model for Hierarchical Text Classification via Information Maximization,2021,6.764196434576456e-05,1
W3111914315,PhyGeoNet: Physics-informed geometry-adaptive convolutional neural networks for solving parameterized steady-state PDEs on irregular domain,2020,6.754226069853552e-05,1
W4387846859,Reasoning beyond Triples: Recent Advances in Knowledge Graph Embeddings,2023,6.700047726810068e-05,1
W4387341818,Transformer and Graph Convolutional Network for Text Classification,2023,6.669711044193536e-05,1
W4390628459,A hybrid deep learning approach for remaining useful life prediction of lithium-ion batteries based on discharging fragments,2024,6.622827394900171e-05,1
W4313368113,Multi-step ahead voltage prediction and voltage fault diagnosis based on gated recurrent unit neural network and incremental training,2022,6.622827394900171e-05,1
W4387846860,Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer SOTA for Traffic Forecasting,2023,6.545217507393682e-05,1
W4407666369,Text Classification Method Based on Graph Neural Networks,2025,6.500851722443295e-05,1
W4308500886,Handwritten computer science words vocabulary recognition using concatenated convolutional neural networks,2022,6.445489234783278e-05,1
W4407272113,Combining informed data-driven anomaly detection with knowledge graphs for root cause analysis in predictive maintenance,2025,6.416301114351217e-05,1
W4381245607,TSMixer: Lightweight MLP-Mixer Model for Multivariate Time Series Forecasting,2023,6.381582144497272e-05,1
W2896827527,Deep Learning with Long Short-Term Memory for Time Series Prediction,2019,6.310757601172152e-05,1
W4410033944,Multiscale session-enhanced long time series modeling for power transformer oil temperature prediction,2025,6.303745153168281e-05,1
W3155328257,A Graph-Based Temporal Attention Framework for Multi-Sensor Traffic Flow Forecasting,2021,6.095405729832313e-05,1
W4296188488,Combining knowledge graph into metro passenger flow prediction: A split-attention relational graph convolutional network,2022,5.970558757312171e-05,1
W4406893043,Application of Transformer Models for Advanced Process Optimization and Process Mining,2025,5.9318437176637865e-05,1
W4391612940,Adaptive micro- and macro-knowledge incorporation for hierarchical text classification,2024,5.816986629725689e-05,1
W4290927906,CAT: Beyond Efficient Transformer for Content-Aware Anomaly Detection in Event Sequences,2022,5.762189443064141e-05,1
W4295699310,Deep multi-view graph-based network for citywide ride-hailing demand prediction,2022,5.753653474066972e-05,1
W4387848755,DSformer: A Double Sampling Transformer for Multivariate Time Series Long-term Prediction,2023,5.631100526279933e-05,1
W4283726963,Efficient temporal flow Transformer accompanied with multi-head probsparse self-attention mechanism for remaining useful life prognostics,2022,5.5779164444224794e-05,1
W3170851865,A survey on anomaly detection for technical systems using LSTM networks,2021,5.563158366342337e-05,1
W4407870846,Routeformer:Transformer utilizing routing mechanism for traffic flow forecasting,2025,5.511809530314553e-05,1
W4407894718,Novel model for medium to long term photovoltaic power prediction using interactive feature trend transformer,2025,5.310554735378785e-05,1
W4382318973,AirFormer: Predicting Nationwide Air Quality in China with Transformers,2023,5.2741861406174894e-05,1
W4409919402,Memory-enhanced hierarchical and temporal semantic learning for multi-label patent classification,2025,5.2325303196503865e-05,1
W4397293650,Probing the limit of hydrologic predictability with the Transformer network,2024,5.170920970325419e-05,1
W4320036691,Time-series anomaly detection with stacked Transformer representations and 1D convolutional network,2023,5.124181203618073e-05,1
W4409530322,From News to Trends: A Financial Time Series Forecasting Framework with LLM-Driven News Sentiment Analysis and Selective State Spaces,2025,5.104181129544128e-05,1
W3177232285,LightXML: Transformer with Dynamic Negative Sampling for High-Performance Extreme Multi-label Text Classification,2021,5.0666739878777276e-05,1
W2801761896,Electricity Price Forecasting Using Recurrent Neural Networks,2018,5.052813305844412e-05,1
W4389388534,An Advanced Real-Time Job Recommendation System and Resume Analyser,2023,4.9606421234222144e-05,1
W4223651176,A novel approach to ultra-short-term multi-step wind power predictions based on encoder–decoder architecture in natural language processing,2022,4.96063703924511e-05,1
W4385565515,Sparse Binary Transformers for Multivariate Time Series Modeling,2023,4.9391374286202524e-05,1
W4396758709,UniTime: A Language-Empowered Unified Model for Cross-Domain Time Series Forecasting,2024,4.937887159947133e-05,1
W3091791608,A ship movement classification based on Automatic Identification System (AIS) data using Convolutional Neural Network,2020,4.9317082318584494e-05,1
W4406798421,Data Augmentation Strategies for Improved PM2.5 Forecasting Using Transformer Architectures,2025,4.9025271764564905e-05,1
W4285275791,Multitask Hypergraph Convolutional Networks: A Heterogeneous Traffic Prediction Framework,2022,4.872429770635188e-05,1
W3209662019,An integrated deep multiscale feature fusion network for aeroengine remaining useful life prediction with multisensor data,2021,4.8608896143546433e-05,1
W4281657308,Impact of preprocessing and word embedding on extreme multi-label patent classification tasks,2022,4.7070962845778884e-05,1
W4285682826,A systematic exploration of reservoir computing for forecasting complex spatiotemporal dynamics,2022,4.6860893263187114e-05,1
W3113920925,mmFall: Fall Detection Using 4-D mmWave Radar and a Hybrid Variational RNN AutoEncoder,2020,4.623776884868212e-05,1
W2897065501,Knowledge-enhanced document embeddings for text classification,2018,4.6024990008028503e-05,1
W4220732012,Wind speed estimation using novelty hybrid adaptive estimation model based on decomposition and deep learning methods (ICEEMDAN-CNN),2022,4.594484768663758e-05,1
W4213130097,A GAN-Based Short-Term Link Traffic Prediction Approach for Urban Road Networks Under a Parallel Learning Framework,2022,4.57226576787775e-05,1
W3134482564,Very short-term forecasting of wind power generation using hybrid deep learning model,2021,4.5399155777249116e-05,1
W4283399618,Short-term multi-hour ahead country-wide wind power prediction for Germany using gated recurrent unit deep learning,2022,4.3678799654421175e-05,1
W4313151162,A Review of Neural Networks for Anomaly Detection,2022,4.354249586870024e-05,1
W4205268692,Gait Recognition Based on Deep Learning: A Survey,2022,4.3302244770308534e-05,1
W4283739673,Bidirectional Spatial-Temporal Adaptive Transformer for Urban Traffic Flow Forecasting,2022,4.298032926156055e-05,1
W4385700549,Adventures in data analysis: a systematic review of Deep Learning techniques for pattern recognition in cyber-physical-social systems,2023,4.237972993759734e-05,1
W2912812282,Deep Long Short-Term Memory: A New Price and Load Forecasting Scheme for Big Data in Smart Cities,2019,4.214270380532586e-05,1
W3004515714,DDP-GCN: Multi-graph convolutional network for spatiotemporal traffic forecasting,2021,4.0968127553204874e-05,1
W3175301415,Label-Specific Dual Graph Neural Network for Multi-Label Text Classification,2021,4.08428254738172e-05,1
W4382202983,Label-Specific Feature Augmentation for Long-Tailed Multi-Label Text Classification,2023,4.0310891930172466e-05,1
W4409606464,Research on Wearable Devices for Pedestrian Navigation Based on the Informer Model Zero-Velocity Update Architecture,2025,3.9710744916613864e-05,1
W4394018559,A task-oriented deep learning framework based on target-related transformer network for industrial quality prediction applications,2024,3.9710744916613864e-05,1
W4407390185,Traffic prediction by graph transformer embedded with subgraphs,2025,3.945742931567474e-05,1
W4323519319,Transfer Learning With Spatial–Temporal Graph Convolutional Network for Traffic Prediction,2023,3.9305786261688336e-05,1
W3042316884,Deep learning methods for forecasting COVID-19 time-Series data: A Comparative study,2020,3.894986344290717e-05,1
W2972641997,Deep separable convolutional network for remaining useful life prediction of machinery,2019,3.863418725817862e-05,1
W4408083944,LM-Hunter: An NLP-Powered Graph Method for Detecting Adversary Lateral Movements in APT Cyber-Attacks at Scale,2025,3.850751027239364e-05,1
W4389515566,GT-LSTM: A spatio-temporal ensemble network for traffic flow prediction,2023,3.843771893119782e-05,1
W4223944214,Threat intelligence ATT&amp;CK extraction based on the attention transformer hierarchical recurrent neural network,2022,3.747424198907613e-05,1
W4361025967,BTAD: A binary transformer deep neural network model for anomaly detection in multivariate time series data,2023,3.727597615939244e-05,1
W3216307239,Dynamical time series embeddings in recurrent neural networks,2021,3.6368142096164216e-05,1
W3207461654,Traffic Flow Forecasting with Spatial-Temporal Graph Diffusion Network,2021,3.589604996162678e-05,1
W2767094836,DeepLog,2017,3.488837368971013e-05,1
W4226322096,Interpretable Memristive LSTM Network Design for Probabilistic Residential Load Forecasting,2022,3.4775490872430815e-05,1
W4322760879,MA-GCN: A Memory Augmented Graph Convolutional Network for traffic prediction,2023,3.458017085712564e-05,1
W4308871212,Hydrological Drought Forecasting Using a Deep Transformer Model,2022,3.405706581274455e-05,1
W2999301586,Optimized Graph Convolution Recurrent Neural Network for Traffic Prediction,2020,3.375835135736205e-05,1
W4361190416,Self‐Curable Synaptic Ferroelectric FET Arrays for Neuromorphic Convolutional Neural Network,2023,3.3589570349437736e-05,1
W4407020552,"ScaloAdaptAlert, a novel framework for supervised anomaly detection in industrial acoustic data, integrating power scalograms, adaptive filter banks, and convolutional neural networks — A case study",2025,3.322031473618948e-05,1
W4401115759,Prediction and analysis of sea surface temperature based on LSTM-transformer model,2024,3.322031473618948e-05,1
W4387705023,Neural Networks for Constitutive Modeling: From Universal Function Approximators to Advanced Models and the Integration of Physics,2023,3.322031473618948e-05,1
W4406521352,Transformer-Based Intelligent Prediction Model for Multimodal Multi-Objective Optimization,2025,3.322031473618948e-05,1
W3017116930,A CNN–LSTM model for gold price time-series forecasting,2020,3.165526304906564e-05,1
W3200891745,The challenges of modern computing and new opportunities for optics,2021,2.8268816251323566e-05,1
W3158464467,Fusing stacked autoencoder and long short-term memory for regional multistep-ahead flood inundation forecasts,2021,2.8232994019480737e-05,1
W3196345400,Using SARIMA–CNN–LSTM approach to forecast daily tourism demand,2021,2.819431694152127e-05,1
W4404486476,TTG-Text: A Graph-Based Text Representation Framework Enhanced by Typical Testors for Improved Classification,2024,2.8155202806527483e-05,1
W4385571355,Enhancing Hierarchical Text Classification through Knowledge Graph Integration,2023,2.7271679484916223e-05,1
W4390905463,PGCN: Progressive Graph Convolutional Networks for Spatial–Temporal Traffic Forecasting,2024,2.6881119612318313e-05,1
W3172722713,An entity linking model based on candidate features,2021,2.6747586417941028e-05,1
W3108827348,Deep Learning Algorithms for Cybersecurity Applications: A Technological and Status Review,2020,2.609256147294389e-05,1
W3130456109,A graph-based CNN-LSTM stock price prediction algorithm with leading indicators,2021,2.5073756490647612e-05,1
W2922268266,Novel Deep Learning Model with CNN and Bi-Directional LSTM for Improved Stock Market Index Prediction,2019,2.494229936659705e-05,1
W4407031014,LLM-Augmented Linear Transformer–CNN for Enhanced Stock Price Prediction,2025,2.494229936659705e-05,1
W4313594913,A convolutional Transformer-based truncated Gaussian density network with data denoising for wind speed forecasting,2023,2.434068619667229e-05,1
W4280605518,An ensemble and shared selective adversarial network for partial domain fault diagnosis of machinery,2022,2.2202493675046425e-05,1
W3035113230,Hyperbolic Capsule Networks for Multi-Label Classification,2020,2.2200718451932974e-05,1
W2990495794,CTS-LSTM: LSTM-based neural networks for correlatedtime series prediction,2019,2.2142237890467148e-05,1
W4362733507,Graph Neural Networks and Open-Government Data to Forecast Traffic Flow,2023,2.1884472879991183e-05,1
W4389060462,RUL prediction of rolling bearings across working conditions based on multi-scale convolutional parallel memory domain adaptation network,2023,2.1837866090938853e-05,1
W4386070139,SafetyMed: A Novel IoMT Intrusion Detection System Using CNN-LSTM Hybridization,2023,2.1718651712558768e-05,1
W4309763546,Multi-Aspect co-Attentional Collaborative Filtering for extreme multi-label text classification,2022,2.105632407838054e-05,1
W4390905466,WindTrans: Transformer-Based Wind Speed Forecasting Method for High-Speed Railway,2024,2.0682227371685464e-05,1
W4311557029,Eleven quick tips for data cleaning and feature engineering,2022,2.0441129263840496e-05,1
W4322755838,Long-term traffic flow forecasting using a hybrid CNN-BiLSTM model,2023,2.0286116728980315e-05,1
W4388841071,Refining one-class representation: A unified transformer for unsupervised time-series anomaly detection,2023,2.0230060272866438e-05,1
W4224981792,Short-term wind speed forecasting based on spatial-temporal graph transformer networks,2022,1.9443599102798705e-05,1
W3090066802,A Semantic-aware Representation Framework for Online Log Analysis,2020,1.858098935066479e-05,1
W4408058742,Using tide for rainfall runoff simulation with feature projection and reversible instance normalization,2025,1.8160216353926225e-05,1
W2997513934,Semi-Supervised Hierarchical Recurrent Graph Neural Network for City-Wide Parking Availability Prediction,2020,1.8130870598310952e-05,1
W4406059659,MSTDFGRN: A Multi-view Spatio-Temporal Dynamic Fusion Graph Recurrent Network for traffic flow prediction,2025,1.810063251909666e-05,1
W3092476034,A Multi-Stream Feature Fusion Approach for Traffic Prediction,2020,1.805296749497701e-05,1
W4387557574,Interpreting runoff forecasting of long short-term memory network: An investigation using the integrated gradient method on runoff data from the Han River Basin,2023,1.799723567324667e-05,1
W4387063334,Deep learning-based algorithms for long-term prediction of chlorophyll-a in catchment streams,2023,1.7898675028648074e-05,1
W2894178883,Recurrent convolutional neural network based multimodal disease risk prediction,2018,1.7881025900724206e-05,1
W4309651348,When do contrastive learning signals help spatio-temporal graph forecasting?,2022,1.7848049626644742e-05,1
W4290927794,Spatio-Temporal Graph Few-Shot Learning with Cross-City Knowledge Transfer,2022,1.7545861647856745e-05,1
W4290944372,Selective Cross-City Transfer Learning for Traffic Prediction via Source City Region Re-Weighting,2022,1.7373337951937273e-05,1
W3194075177,Spatio-Temporal Graph Contrastive Learning,2021,1.70880169274912e-05,1
W3080466448,AutoST: Efficient Neural Architecture Search for Spatio-Temporal Prediction,2020,1.70880169274912e-05,1
W4385568303,Transferable Graph Structure Learning for Graph-based Traffic Forecasting Across Cities,2023,1.6855759033864587e-05,1
W3021538729,Interpretable spatio-temporal attention LSTM model for flood forecasting,2020,1.676580213465387e-05,1
W4391723614,TLC-XML: Transformer with Label Correlation for Extreme Multi-label Text Classification,2024,1.6680297887892514e-05,1
W4280565829,Dynamic graph convolutional networks based on spatiotemporal data embedding for traffic flow forecasting,2022,1.5810012979554693e-05,1
W4406189876,LogSD: log anomaly detection via topic words awareness semantic augmentation and category-guided Mixup data augmentation,2025,1.5694374801663425e-05,1
W4393153277,Feature Transportation Improves Graph Neural Networks,2024,1.541154004649559e-05,1
W3135794967,Deep sequence to sequence Bi-LSTM neural networks for day-ahead peak load forecasting,2021,1.4902469376155192e-05,1
W4210439489,Spatiotemporal Graph Convolutional Network for Multi-Scale Traffic Forecasting,2022,1.4770994109937052e-05,1
W4320015890,Semantics-Aware Dynamic Graph Convolutional Network for Traffic Flow Forecasting,2023,1.400473635915608e-05,1
W2995416727,Phrase2Vec: Phrase embedding based on parsing,2019,1.390524600396469e-05,1
W2994901268,TrafficGAN: Network-Scale Deep Traffic Prediction With Generative Adversarial Nets,2019,1.3720470008299007e-05,1
W3117196003,DECAF: Deep Extreme Classification with Label Features,2021,1.3543105834987039e-05,1
W4384665479,Incorporating multimodal context information into traffic speed forecasting through graph deep learning,2023,1.2888745402335185e-05,1
W4406047825,Few‐label aerial target intention recognition based on self‐supervised contrastive learning,2025,1.2631007273292276e-05,1
W4407923384,A multi-factor clustering integration paradigm for wind speed point-interval prediction based on feature selection and optimized inverted transformer,2025,1.2589516724745883e-05,1
W4394844796,M2BIST-SPNet: RUL prediction for railway signaling electromechanical devices,2024,1.2556345446795955e-05,1
W4324032752,A multi-modal pre-training transformer for universal transfer learning in metal–organic frameworks,2023,1.2444476892609824e-05,1
W4392432892,Achieving robustness in hybrid models: A physics-informed regularization approach for spatiotemporal parameter estimation in PDEs,2024,1.2441218274965973e-05,1
W4394687230,Multi-scale feature enhanced spatio-temporal learning for traffic flow forecasting,2024,1.2331691940318686e-05,1
W4385069426,STN-GCN: Spatial and Temporal Normalization Graph Convolutional Neural Networks for Traffic Flow Forecasting,2023,1.2219661410110938e-05,1
W3024360037,Streamflow Prediction Using Deep Learning Neural Network: Case Study of Yangtze River,2020,1.2070923934543847e-05,1
W4409972024,Missing Traffic Data Imputation based on Tensor Completion and Graph Network Fusion,2025,1.1884274082044114e-05,1
W2908541468,Physics-constrained deep learning for high-dimensional surrogate modeling and uncertainty quantification without labeled data,2019,1.1179361145088546e-05,1
W4395447244,A Fuzzy C-Means Clustering-Based Hybrid Multivariate Time Series Prediction Framework With Feature Selection,2024,1.1026835083153865e-05,1
W3185906304,Day-ahead electricity price prediction applying hybrid models of LSTM-based deep learning methods and feature selection algorithms under consideration of market coupling,2021,1.0845891235547746e-05,1
W4221044734,RR-Former: Rainfall-runoff modeling based on Transformer,2022,1.0526024568710915e-05,1
W4206626673,Multivariate Correlation-aware Spatio-temporal Graph Convolutional Networks for Multi-scale Traffic Prediction,2022,1.0429117816180858e-05,1
W3047827241,A novel deep learning framework for state of health estimation of lithium-ion battery,2020,1.0214823464441687e-05,1
W4200379301,Spatio-Temporal Spectrum Load Prediction Using Convolutional Neural Network and ResNet,2021,1.0091605531316489e-05,1
W3005377970,Beyond Expectation: Deep Joint Mean and Quantile Regression for Spatiotemporal Problems,2020,1.0091605531316489e-05,1
W4392693783,MatchXML: An Efficient Text-label Matching Framework for Extreme Multi-label Text Classification,2024,9.716185766572048e-06,1
W4388040908,How Does It Function? Characterizing Long-term Trends in Production Serverless Workloads,2023,9.668126682856623e-06,1
W4410119725,Knowledge-guided Adaptive Spatial-Temporal Graph Contrastive Learning Framework: Regional Crop Diseases Prediction based on Electronic Medical Records,2025,9.639140314463555e-06,1
W4378979493,Dual-interactive fusion for code-mixed deep representation learning in tag recommendation,2023,9.484112284773907e-06,1
W4391540437,On the Value of Head Labels in Multi-Label Text Classification,2024,9.462524416418755e-06,1
W4221153174,Learning physics-constrained subgrid-scale closures in the small-data regime for stable and accurate LES,2022,9.33902130836344e-06,1
W4392921739,A Novel Transformer-Based Anomaly Detection Approach for ECG Monitoring Healthcare System,2024,9.193505776938487e-06,1
W4382318655,Federated Learning on Non-IID Graphs via Structural Knowledge Sharing,2023,8.985442449762566e-06,1
W3114079967,DeepXML: A Deep Extreme Multi-Label Learning Framework Applied to Short Text Documents,2021,8.802208199530363e-06,1
W3165920028,Generalized Zero-Shot Extreme Multi-label Learning,2021,8.802208199530344e-06,1
W2782920454,Predicting Multi-step Citywide Passenger Demands Using Attention-based Neural Networks,2018,8.67701517912931e-06,1
W4394853400,AI-powered COVID-19 forecasting: a comprehensive comparison of advanced deep learning methods,2024,8.5906922775224e-06,1
W4316664875,Robust framework based on hybrid deep learning approach for short term load forecasting of building electricity demand,2023,8.301700769370474e-06,1
W4391906156,An LSTM-SA model for SOC estimation of lithium-ion batteries under various temperatures and aging levels,2024,8.250009916065934e-06,1
W4322773459,Modeling and predictive control of nonlinear processes using transfer learning method,2023,8.206913021856079e-06,1
W2900880305,Deep learning-based feature engineering for stock price movement prediction,2018,8.123734985188793e-06,1
W4396518138,Anomaly Detection for Asynchronous Multivariate Time Series of Nuclear Power Plants Using a Temporal-Spatial Transformer,2024,8.054670717159798e-06,1
W4290098428,Memory-augmented dynamic graph convolution networks for traffic data imputation with diverse missing patterns,2022,7.960584250258714e-06,1
W4225526013,TSMAE: A Novel Anomaly Detection Approach for Internet of Things Time Series Data Using Memory-Augmented Autoencoder,2022,7.942242145868142e-06,1
W3158058297,Transfer Learning with Graph Neural Networks for Short-Term Highway Traffic Forecasting,2021,7.837248877737834e-06,1
W4224983774,Time-series analysis with smoothed Convolutional Neural Network,2022,7.783466555014232e-06,1
W4390671307,"Physics-Guided, Physics-Informed, and Physics-Encoded Neural Networks and Operators in Scientific Computing: Fluid and Solid Mechanics",2024,7.698620040599586e-06,1
W4386314827,PAOLTransformer: Pruning-adaptive optimal lightweight Transformer model for aero-engine remaining useful life prediction,2023,7.479865220309103e-06,1
W4386322034,ES-dRNN: A Hybrid Exponential Smoothing and Dilated Recurrent Neural Network Model for Short-Term Load Forecasting,2023,7.020976901719966e-06,1
W3045857695,Transferable convolutional neural network based remaining useful life prediction of bearing under multiple failure behaviors,2020,7.013785422283634e-06,1
W4385076171,API-MalDetect: Automated malware detection framework for windows based on API calls and deep learning techniques,2023,7.000527918402827e-06,1
W4297973310,An LSTM-Autoencoder Architecture for Anomaly Detection Applied on Compressors Audio Data,2022,6.867942809600362e-06,1
W4409999318,BiG: A Bidirectional Group-Wise Contrastive Learning Method for Multi-Label Text Classification,2025,6.728859286851649e-06,1
W4366714851,A cyber-physical robotic mobile fulfillment system in smart manufacturing: The simulation aspect,2023,6.595030944265039e-06,1
W4366813964,Optimized Seq2Seq model based on multiple methods for short-term power load forecasting,2023,6.472671725231294e-06,1
W3152560880,Interpreting and Unifying Graph Neural Networks with An Optimization Framework,2021,6.430091607064574e-06,1
W4381618831,A deep learning based health indicator construction and fault prognosis with uncertainty quantification for rolling bearings,2023,5.879807799132312e-06,1
W4318476430,HFCM-LSTM: A novel hybrid framework for state-of-health estimation of lithium-ion battery,2023,5.719281121268209e-06,1
W4317733620,Prediction of Electric Vehicles Charging Demand: A Transformer-Based Deep Learning Approach,2023,5.666159821683221e-06,1
W4200069638,Fault diagnosis based on SPBO-SDAE and transformer neural network for rotating machinery,2021,5.560092800152351e-06,1
W4319074069,MFSJMI: Multi-label feature selection considering join mutual information and interaction weight,2023,5.556836535976422e-06,1
W4319297852,XTM: A Novel Transformer and LSTM-Based Model for Detection and Localization of Formally Verified FDI Attack in Smart Grid,2023,5.5466459544017825e-06,1
W4380716409,Android Malware Detection Methods Based on Convolutional Neural Network: A Survey,2023,5.542979897911401e-06,1
W4307725013,Parallel Deep Learning with a hybrid BP-PSO framework for feature extraction and malware classification,2022,5.541528454651953e-06,1
W4384926261,Harnessing the power of AI: Advanced deep learning models optimization for accurate SARS-CoV-2 forecasting,2023,5.412845858124561e-06,1
W3070581385,Cryptocurrency malware hunting: A deep Recurrent Neural Network approach,2020,5.26569564288202e-06,1
W4313059808,Dual-Attention-Based Multiscale Convolutional Neural Network With Stage Division for Remaining Useful Life Prediction of Rolling Bearings,2022,5.043551881980139e-06,1
W3200809940,Comparing Prophet and Deep Learning to ARIMA in Forecasting Wholesale Food Prices,2021,4.9848884177911094e-06,1
W4306811603,Deep transfer learning based on Bi-LSTM and attention for remaining useful life prediction of rolling bearing,2022,4.712757132994926e-06,1
W4226108926,Health Assessment of Rotating Equipment With Unseen Conditions Using Adversarial Domain Generalization Toward Self-Supervised Regularization Learning,2022,4.6176347925555465e-06,1
W3199222954,Rapid ultracapacitor life prediction with a convolutional neural network,2021,4.599261054897689e-06,1
W4387469767,Lithium-ion battery state of health estimation using a hybrid model based on a convolutional neural network and bidirectional gated recurrent unit,2023,4.513096335881519e-06,1
W4387182867,MCA-DTCN: A novel dual-task temporal convolutional network with multi-channel attention for first prediction time detection and remaining useful life prediction,2023,4.435399372055214e-06,1
W4409245690,Advances in meta-learning and zero-shot learning for multi-label classification: A review,2025,4.285661812650363e-06,1
W4392173954,EEG Emotion Recognition Model Based on Attention and GAN,2024,4.223213622367222e-06,1
W3009157386,A multi-label text classification method via dynamic semantic representation model and deep neural network,2020,4.157719842498958e-06,1
W4386495226,Event-Based Dynamic Graph Representation Learning for Patent Application Trend Prediction,2023,4.105073063624552e-06,1
W4391589817,Unmanned Aerial Vehicles anomaly detection model based on sensor information fusion and hybrid multimodal neural network,2024,3.9533096654015806e-06,1
W4390939135,Survey on Multi-Task Learning in Smart Transportation,2024,3.6318728373444074e-06,1
W2998769790,Multi-energy load forecasting for regional integrated energy systems considering temporal dynamic and coupling characteristics,2020,3.575376215256171e-06,1
W2997833886,Carbon futures price forecasting based with ARIMA-CNN-LSTM model,2019,3.4274347795942957e-06,1
W4387340756,Cardiovascular disease identification using a hybrid CNN-LSTM model with explainable AI,2023,3.4274347795942957e-06,1
W4388584848,Rolling bearing intelligent fault diagnosis towards variable speed and imbalanced samples using multiscale dynamic supervised contrast learning,2023,3.198749109474263e-06,1
W4365790371,A Novel Two-Stage Deep Learning Model for Network Intrusion Detection: LSTM-AE,2023,3.1852023220148893e-06,1
W4283799781,Construction-Accident Narrative Classification Using Shallow and Deep Learning,2022,3.1647002944254443e-06,1
W4321465178,An unsupervised latent/output physics-informed convolutional-LSTM network for solving partial differential equations using peridynamic differential operator,2023,2.914344460548171e-06,1
W4390841447,Multi-resolution partial differential equations preserved learning framework for spatiotemporal dynamics,2024,2.910653988209461e-06,1
W4387775568,Label correlations-based multi-label feature selection with label enhancement,2023,2.80254746486228e-06,1
W4410540086,Multi-label feature selection via exploring reliable instance similarities,2025,2.758607592179759e-06,1
W3193693507,Multilabel Feature Selection With Constrained Latent Structure Shared Term,2021,2.758607592179714e-06,1
W3175204360,Multi-label feature selection considering label supplementation,2021,2.7139681964935903e-06,1
W4391407085,Neural Architecture Search for Anomaly Detection in Time-Series Data of Smart Buildings: A Reinforcement Learning Approach for Optimal Autoencoder Design,2024,2.7041357128437194e-06,1
W4392137397,Unsupervised feature selection using chronological fitting with Shapley Additive explanation (SHAP) for industrial time-series anomaly detection,2024,2.6952729799819845e-06,1
W4210334299,Learning multi-label label-specific features via global and local label correlations,2022,2.6686177720371367e-06,1
W3196227100,Feature selection for label distribution learning via feature similarity and label correlation,2021,2.6686177720371367e-06,1
W3006240412,Multi-label feature selection based on label distribution and feature complementarity,2020,2.6686177720371367e-06,1
W3116425023,A ranking-based feature selection for multi-label classification with fuzzy relative discernibility,2020,2.6686177720371367e-06,1
W2966110735,An Optimized Heterogeneous Structure LSTM Network for Electricity Price Forecasting,2019,2.5804160390888044e-06,1
W4221023673,A Novel Transfer Learning Approach in Remaining Useful Life Prediction for Incomplete Dataset,2022,2.421777158374993e-06,1
W3115103108,"Multi-hour and multi-site air quality index forecasting in Beijing using CNN, LSTM, CNN-LSTM, and spatiotemporal clustering",2020,2.3826675570583314e-06,1
W4293370556,Incremental Learning for Remaining Useful Life Prediction via Temporal Cascade Broad Learning System With Newly Acquired Data,2022,2.2562825598366465e-06,1
W4311750276,Domain generalization via adversarial out-domain augmentation for remaining useful life prediction of bearings under unseen conditions,2022,2.2387787451820222e-06,1
W4401334701,Regularization in machine learning models for MVT Pb-Zn prospectivity mapping: applying lasso and elastic-net algorithms,2024,2.0350112573787636e-06,1
W4361011553,Spatial–temporal multi-feature fusion network for long short-term traffic prediction,2023,1.9592413064475933e-06,1
W4391553729,Contrastive feature-based learning-guided elevated deep reinforcement learning: Developing an imbalanced fault quantitative diagnosis under variable working conditions,2024,1.954827569609745e-06,1
W4366606077,Graph convolutional network-based feature selection for high-dimensional and low-sample size data,2023,1.9475474592700382e-06,1
W4312201182,ST-3DGMR: Spatio-temporal 3D grouped multiscale ResNet network for region-based urban traffic flow prediction,2022,1.9020969618140025e-06,1
W3140618672,State of Charge and State of Energy Estimation for Lithium-Ion Batteries Based on a Long Short-Term Memory Neural Network,2021,1.8315656954479457e-06,1
W4205729691,A Multiagent Deep Reinforcement Learning Based Approach for the Optimization of Transformer Life Using Coordinated Electric Vehicles,2022,1.7621120481472403e-06,1
W3158547118,Hybrid wind speed forecasting model based on multivariate data secondary decomposition approach and deep learning algorithm with attention mechanism,2021,1.6918373077636135e-06,1
W4294350997,Pavement anomaly detection based on transformer and self-supervised learning,2022,1.646735623032555e-06,1
W3208645139,Power Consumption Predicting and Anomaly Detection Based on Transformer and K-Means,2021,1.635024541526743e-06,1
W4406019758,Prediction of Electricity Consumption in Residential Areas using Temporal Fusion Transformer and Convolutional Neural Network,2025,1.6211910253361884e-06,1
W4393902231,A component diagnostic and prognostic framework for pump bearings based on deep learning with data augmentation,2024,1.5977816328883405e-06,1
W4409657370,<scp>UniDEC</scp> : Unified Dual Encoder and Classifier Training for Extreme Multi-Label Classification,2025,1.5967331867863756e-06,1
W3095093830,Deep Learning–Based Segmentation and Quantification in Experimental Kidney Histopathology,2020,1.5767172857630172e-06,1
W4327977707,A meta network pruning framework for remaining useful life prediction of rocket engine bearings with temporal distribution discrepancy,2023,1.572448887180205e-06,1
W4296191071,Train wheel degradation generation and prediction based on the time series generation adversarial network,2022,1.5474648332303714e-06,1
W4206266728,DeepAG: Attack Graph Construction and Threats Prediction With Bi-Directional Deep Learning,2022,1.4883566816107136e-06,1
W4385895548,Adaptive filters in Graph Convolutional Neural Networks,2023,1.4631524404674312e-06,1
W4391490399,Deep signal separation for adaptive estimation of instantaneous phase from vibration signals,2024,1.4197780303980065e-06,1
W4282980267,M2TNet: Multi-modal multi-task Transformer network for ultra-short-term wind power multi-step forecasting,2022,1.3203891619581254e-06,1
W4379053920,Sensing prior constraints in deep neural networks for solving exploration geophysical problems,2023,1.2738620876969724e-06,1
W4292664320,High Speed Simulation and Freeform Optimization of Nanophotonic Devices with Physics-Augmented Deep Learning,2022,1.2738620876969724e-06,1
W3034504400,Intelligent monitoring and diagnostics using a novel integrated model based on deep learning and multi-sensor feature fusion,2020,1.2247538551542986e-06,1
W3136408793,Deep learning-based tool wear prediction and its application for machining process using multi-scale feature fusion and channel attention mechanism,2021,1.2247538551529889e-06,1
W2897079037,On Prediction of User Destination by Sub-Trajectory Understanding,2018,1.221652672276092e-06,1
W4401111001,Modeling and compensation of small-sample thermal error in precision machine tool spindles using spatial–temporal feature interaction fusion network,2024,1.1182283956524067e-06,1
W4407032389,FE-PIRBN:Feature-Enhanced physics-informed radial basis neural networks for solving high-frequency electromagnetic scattering problems,2025,1.0929592557449342e-06,1
W4406144302,Anomaly detection in virtual machine logs against irrelevant attribute interference,2025,8.652336275010054e-07,1
W3087462960,Inter-hours rolling scheduling of behind-the-meter storage operating systems using electricity price forecasting based on deep convolutional neural network,2020,8.593949875977602e-07,1
W4321783721,Complex domain extension network with multi-channels information fusion for remaining useful life prediction of rotating machinery,2023,7.336488761114698e-07,1
W4388459526,Medical image analysis using deep learning algorithms,2023,7.237167497637384e-07,1
W2888902882,Cross-spectral iris recognition using CNN and supervised discrete hashing,2018,7.007107657755082e-07,1
W4385835130,The Personal Health Applications of Machine Learning Techniques in the Internet of Behaviors,2023,6.974938434729848e-07,1
W4294982617,Temporal-Spatial Quantum Graph Convolutional Neural Network Based on Schrödinger Approach for Traffic Congestion Prediction,2022,6.857827619667532e-07,1
W4211206835,Bearing Remaining Useful Life Prediction Based on Regression Shapalet and Graph Neural Network,2022,6.268767148167247e-07,1
W3199657116,ConAnomaly: Content-Based Anomaly Detection for System Logs,2021,5.738445719392853e-07,1
W4365513119,Automatic Parsing and Utilization of System Log Features in Log Analysis: A Survey,2023,5.738445719391052e-07,1
W4402263650,R-CAID: Embedding Root Cause Analysis within Provenance-based Intrusion Detection,2024,5.738445719389991e-07,1
W4410076829,A Novel Approach for Advanced Persistent Threats Detection via Graph Transformer,2025,5.738445719387715e-07,1
W4319924564,MDFULog: Multi-Feature Deep Fusion of Unstable Log Anomaly Detection Model,2023,5.645587006967749e-07,1
W4312454513,A Survey of Deep Anomaly Detection for System Logs,2022,5.645587006967749e-07,1
W4391225283,Automation and Orchestration of Zero Trust Architecture: Potential Solutions and Challenges,2024,5.645587006967749e-07,1
W4392714183,Explainability and Interpretability in Electric Load Forecasting Using Machine Learning Techniques – A Review,2024,5.627320470034339e-07,1
W4303644832,Egg Freshness Prediction Model Using Real-Time Cold Chain Storage Condition Based on Transfer Learning,2022,5.507969516813753e-07,1
W4384701513,Fast simulation and prediction of urban pluvial floods using a deep convolutional neural network model,2023,4.5686229350085644e-07,1
W4289933203,Online public opinion prediction based on a novel seasonal grey decomposition and ensemble model,2022,4.56236426526885e-07,1
W4399975443,Graph transformer embedded deep learning for short-term passenger flow prediction in urban rail transit systems: A multi-gate mixture-of-experts model,2024,3.583025441407644e-07,1
W3216280806,An uncertainty-informed framework for trustworthy fault diagnosis in safety-critical applications,2022,3.5337724297280136e-07,1
W4283160683,Hydrological concept formation inside long short-term memory (LSTM) networks,2022,2.912287078259972e-07,1
W4401474425,"Interpretable prediction, classification and regulation of water quality: A case study of Poyang Lake, China",2024,2.89709674703738e-07,1
W3116268267,On the eigenvector bias of Fourier feature networks: From regression to solving multi-scale PDEs with physics-informed neural networks,2021,2.2806233949088286e-07,1
W4366823268,What’s the next word in large language models?,2023,2.0137475503561729e-07,1
W4406112800,A priori physical information to aid generalization capabilities of neural networks for hydraulic modeling,2025,1.8090283195142392e-07,1
W4398193394,State-of-charge estimation of sodium-ion batteries: A fusion deep learning approach,2024,1.6533811459775474e-07,1
W4288046368,Multi-modal knowledge graphs representation learning via multi-headed self-attention,2022,1.5347055601914569e-07,1
W3049737176,"Time series prediction for the epidemic trends of COVID-19 using the improved LSTM deep learning method: Case studies in Russia, Peru and Iran",2020,1.39013360536549e-07,1
W4285791425,Health state assessment of bearing with feature enhancement and prediction error compensation strategy,2022,1.052902433267681e-07,1
W3201749075,"DexRay: A Simple, yet Effective Deep Learning Approach to Android Malware Detection Based on Image Representation of Bytecode",2021,8.969571230250796e-08,1
W4386351122,A novel short-term multi-energy load forecasting method for integrated energy system based on feature separation-fusion technology and improved CNN,2023,5.785622937154888e-08,1
W4285227013,RTIDS: A Robust Transformer-Based Approach for Intrusion Detection System,2022,5.155599099450278e-08,1
W2911535432,Deep-Resp-Forest: A deep forest model to predict anti-cancer drug response,2019,4.535042445646759e-08,1
W4295125731,SOC estimation for lithium-ion battery using the LSTM-RNN with extended input and constrained output,2022,2.9645898423846992e-08,1
W4293259034,A novel adversarial domain adaptation transfer learning method for tool wear state prediction,2022,1.9818792682291097e-08,1
W4316038338,Fault diagnosis of wind turbine based on multi-signal CNN-GRU model,2023,1.981879268161071e-08,1
W4285006563,Deep imbalanced regression using cost-sensitive learning and deep feature transfer for bearing remaining useful life estimation,2022,1.1871801762099501e-08,1
W4406241648,Enhancing prediction of dissolved oxygen over Santa Margarita River: Long short-term memory incorporated with multi-objective observer-teacher-learner optimization,2025,4.6880407489464044e-09,1
W4283385419,SOC estimation of Li-ion battery using convolutional neural network with U-Net architecture,2022,2.675477853240238e-09,1
W4406946743,"A Transformer-Based Model for Network Intrusion Detection: Architecture, Classification Heads, and Transformer Blocks",2025,8.34271714131629e-10,1
W4401164045,A Novel Technique for Extracting Entity Relations,2024,4.797257112137833e-10,1
