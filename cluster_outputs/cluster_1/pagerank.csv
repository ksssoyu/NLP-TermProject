id,title,year,pagerank,cluster
W2964308564,Neural Machine Translation by Jointly Learning to Align and Translate,2015,0.09754068099826091,1
W2100664567,On Using Very Large Target Vocabulary for Neural Machine Translation,2015,0.03630921351388226,1
W2118434577,Addressing the Rare Word Problem in Neural Machine Translation,2015,0.0320949981338341,1
W1902237438,Effective Approaches to Attention-based Neural Machine Translation,2015,0.022144665997436253,1
W2962784628,Neural Machine Translation of Rare Words with Subword Units,2016,0.020836108725299892,1
W2963403868,Attention is All you Need,2017,0.019091707361112473,1
W2251743902,Multi-Task Learning for Multiple Language Translation,2015,0.01386140703670489,1
W2525778437,Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation,2016,0.011686526082324166,1
W2963216553,Improving Neural Machine Translation Models with Monolingual Data,2016,0.008188910479286722,1
W2963266340,A theoretically grounded application of dropout in recurrent neural networks,2016,0.006605589282517154,1
W2951559648,Character-Aware Neural Language Models,2016,0.006294201928154917,1
W1915251500,On Using Monolingual Corpora in Neural Machine Translation,2015,0.006183967835442104,1
W2528639018,Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction,2017,0.005172358680361439,1
W1026270304,Training Very Deep Networks,2015,0.005095741484938292,1
W1938755728,Character-Aware Neural Language Models,2015,0.0050613693191120445,1
W2952339051,Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer,2017,0.0048429533212619655,1
W2962732637,Character-based Neural Machine Translation,2016,0.004633002969285358,1
W2739996966,Deep Learning for Extreme Multi-label Text Classification,2017,0.004552283281750478,1
W2962801832,Edinburgh Neural Machine Translation Systems for WMT 16,2016,0.004539802563243041,1
W2252272516,Montreal Neural Machine Translation Systems for WMT’15,2015,0.0043915941714433426,1
W2212703438,A Theoretically Grounded Application of Dropout in Recurrent Neural Networks,2015,0.00424716433330955,1
W3204406378,Stanford neural machine translation systems for spoken language domains.,2015,0.0038908032924280596,1
W1800356822,A Simple Way to Initialize Recurrent Networks of Rectified Linear Units,2015,0.0038191465936995945,1
W2963463964,Minimum Risk Training for Neural Machine Translation,2016,0.003816478743667011,1
W2964110616,Transformer-XL: Attentive Language Models beyond a Fixed-Length Context,2019,0.003325428311502406,1
W2963247703,"Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism",2016,0.0032232286477569217,1
W2963532001,A Call for Clarity in Reporting BLEU Scores,2018,0.003208743661943225,1
W2550821151,Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation,2017,0.0031950218410418474,1
W2964010366,Recurrent Neural Networks for Multivariate Time Series with Missing Values,2018,0.003188826431455132,1
W2613328025,A Dual-Stage Attention-Based Recurrent Neural Network for Time Series Prediction,2017,0.002864977225042878,1
W2792764867,An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling,2018,0.002855416857792012,1
W2963506925,Six Challenges for Neural Machine Translation,2017,0.0027519774779592113,1
W2594229957,Nematus: a Toolkit for Neural Machine Translation,2017,0.002719945483861314,1
W1847088711,Gated Feedback Recurrent Neural Networks,2015,0.0026880136918341143,1
W581956982,An Empirical Exploration of Recurrent Network Architectures,2015,0.0026683234758443854,1
W2964034111,Multi-Source Neural Translation,2016,0.0026524838248952994,1
W3177318507,Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting,2021,0.0026238268326696755,1
W2963260202,Modeling Coverage for Neural Machine Translation,2016,0.002590103620613319,1
W2949335953,Effective Approaches to Attention-based Neural Machine Translation,2015,0.0025795006992899465,1
W2933138175,"fairseq: A Fast, Extensible Toolkit for Sequence Modeling",2019,0.0024769313496216324,1
W2940744433,Generating Long Sequences with Sparse Transformers.,2019,0.002459577797812788,1
W2962946486,Graph Convolutional Networks for Text Classification,2019,0.0024575848125167267,1
W2963088995,Transfer Learning for Low-Resource Neural Machine Translation,2016,0.002387012545265757,1
W2567070169,Language Modeling with Gated Convolutional Networks,2016,0.0023725424989610045,1
W2963251942,A Character-level Decoder without Explicit Segmentation for Neural Machine Translation,2016,0.002246730354770198,1
W2760656271,Findings of the 2017 Conference on Machine Translation (WMT17),2017,0.0021077617630876995,1
W2525332836,Pointer Sentinel Mixture Models,2016,0.0020862420194340788,1
W2963347649,Using the Output Embedding to Improve Language Models,2017,0.0020652394133242693,1
W2963876447,Linguistic Input Features Improve Neural Machine Translation,2016,0.002025267416649456,1
W2954731415,Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting,2019,0.002024020396722366,1
W2963970792,Language modeling with gated convolutional networks,2017,0.0020008118401395924,1
W2963212250,OpenNMT: Open-Source Toolkit for Neural Machine Translation,2017,0.0019887429403026256,1
W2600702321,Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling,2017,0.001963211912667172,1
W2963324947,Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models,2016,0.0019255138259173916,1
W2788667846,Large-Scale Hierarchical Text Classification with Recursively Regularized Deep Graph-CNN,2018,0.0019038155957109583,1
W1598796236,A Critical Review of Recurrent Neural Networks for Sequence Learning,2015,0.001886158208247978,1
W2531207078,Fully Character-Level Neural Machine Translation without Explicit Segmentation,2017,0.0018720484718967084,1
W2963069010,Grammar as a foreign language,2015,0.0018279263610899625,1
W2963807318,Scaling Neural Machine Translation,2018,0.0017954988037065815,1
W2552839021,A Convolutional Encoder Model for Neural Machine Translation,2017,0.0017922217872567417,1
W2953118818,Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting,2015,0.0017861800744231396,1
W2903193068,Findings of the 2018 Conference on Machine Translation (WMT18),2018,0.0017578610998855361,1
W2964007535,Zero-Resource Translation with Multi-Lingual Neural Machine Translation,2016,0.0016948101099311331,1
W2964093087,Exploiting Cross-Sentence Context for Neural Machine Translation,2017,0.0016604682308007036,1
W2785047343,A Multilayer Convolutional Encoder-Decoder Neural Network for Grammatical Error Correction,2018,0.001658368172292166,1
W2963653811,Graph Convolutional Encoders for Syntax-aware Neural Machine Translation,2017,0.0015932504343676135,1
W2963333747,Incorporating Structural Alignment Biases into an Attentional Neural Translation Model,2016,0.001587087377129418,1
W2963641561,Neural versus Phrase-Based Machine Translation Quality: a Case Study,2016,0.0015807847039836411,1
W2409027918,Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations,2016,0.001570196037408971,1
W2793820729,A hybrid deep learning based traffic flow prediction method and its understanding,2018,0.0015356623255410131,1
W2963909453,Multi30K: Multilingual English-German Image Descriptions,2016,0.0015337136115048005,1
W2964045208,The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation,2018,0.0015153350911533987,1
W2594990650,Massive Exploration of Neural Machine Translation Architectures,2017,0.0015049162104604455,1
W3006585575,Machine Remaining Useful Life Prediction via an Attention-Based Deep Learning Approach,2020,0.0014835818724055509,1
W2400065810,The AMU-UEDIN Submission to the WMT16 News Translation Task: Attention-based NMT Models as Feature Functions in Phrase-based SMT,2016,0.0014569558443430451,1
W2964189376,DiSAN: Directional Self-Attention Network for RNN/CNN-Free Language Understanding,2018,0.0014455806656268463,1
W2549416390,Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling,2016,0.00143948019978784,1
W2509282593,A Shared Task on Multimodal Machine Translation and Crosslingual Image Description,2016,0.001406164462497705,1
W2963736842,Sequence-Level Knowledge Distillation,2016,0.0014057199859114702,1
W2734777338,A deep learning framework for financial time series using stacked autoencoders and long-short term memory,2017,0.001397334434859571,1
W2963661253,Tree-to-Sequence Attentional Neural Machine Translation,2016,0.0013948625796067877,1
W2889326796,Understanding Back-Translation at Scale,2018,0.0013903820320790067,1
W2527845440,Is Neural Machine Translation Ready for Deployment? A Case Study on 30 Translation Directions,2016,0.0013838560595619404,1
W3152893301,Graph neural networks: A review of methods and applications,2020,0.0013813084752901798,1
W2929376427,Deep neural network for hierarchical extreme multi-label text classification,2019,0.0013712256290753727,1
W2963912736,Joint Embedding of Words and Labels for Text Classification,2018,0.0013530282203306826,1
W2537667581,SYSTRAN's Pure Neural Machine Translation Systems,2016,0.0013480568516824967,1
W2767206889,Non-Autoregressive Neural Machine Translation,2017,0.0013407187129657312,1
W2767094836,DeepLog,2017,0.001335278191308802,1
W2972641997,Deep separable convolutional network for remaining useful life prediction of machinery,2019,0.0013346879733544504,1
W4385763767,Transformers in Time Series: A Survey,2023,0.0013312439821945902,1
W2904832339,Spatiotemporal Multi-Graph Convolution Network for Ride-Hailing Demand Forecasting,2019,0.001304355171432657,1
W3014146531,Remaining Useful Life Prediction Using a Novel Feature-Attention-Based End-to-End Approach,2020,0.0012768041890823558,1
W2229833550,"Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism",2016,0.0012710897732841383,1
W2561274697,Exploiting Source-side Monolingual Data in Neural Machine Translation,2016,0.0012597343960405627,1
W4382203079,Are Transformers Effective for Time Series Forecasting?,2023,0.0012278483598359537,1
W2546938941,Dual Learning for Machine Translation,2016,0.0012203852166112776,1
W2963206679,Phrase-Based &amp; Neural Unsupervised Machine Translation,2018,0.001204477092389997,1
W2951672049,Improving Neural Language Models with a Continuous Cache,2016,0.0011895210404175485,1
W2784733489,Bayesian deep convolutional encoder–decoder networks for surrogate modeling and uncertainty quantification,2018,0.0011490150455368859,1
W2890096158,Temporal pattern attention for multivariate time series forecasting,2019,0.0011458710957982857,1
W2964301648,Baseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms,2018,0.0011373809671978803,1
W3171884590,Temporal Fusion Transformers for interpretable multi-horizon time series forecasting,2021,0.0011341470128430437,1
W2963434219,Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement,2018,0.0011115826951855188,1
W2946567085,Adaptive Attention Span in Transformers,2019,0.0011096407120644543,1
W2555745756,Toward Multilingual Neural Machine Translation with Universal Encoder and Decoder,2016,0.001106513466058292,1
W2964343359,Marian: Fast Neural Machine Translation in C++,2018,0.0011005606469137708,1
W3105136071,Large-Scale Learnable Graph Convolutional Networks,2018,0.0010921540300644073,1
W3035338169,A Hybrid Deep Learning Model With Attention-Based Conv-LSTM Networks for Short-Term Traffic Flow Prediction,2020,0.001073945150327741,1
W2962901607,A Nested Attention Neural Hybrid Model for Grammatical Error Correction,2017,0.001062993762597428,1
W3099136959,Dipole,2017,0.0010597631218758365,1
W2950817888,Urban Traffic Prediction from Spatio-Temporal Data Using Deep Meta Learning,2019,0.0010588503125269822,1
W2594047108,Learning to Parse and Translate Improves Neural Machine Translation,2017,0.0010506479185447282,1
W2963816901,Log-linear Combinations of Monolingual and Bilingual Neural Machine Translation Models for Automatic Post-Editing,2016,0.001042188895018345,1
W2267186426,Long Short-Term Memory-Networks for Machine Reading,2016,0.001033791381201226,1
W2964082031,Approaching Neural Grammatical Error Correction as a Low-Resource Machine Translation Task,2018,0.0010229839431818394,1
W2905224888,Graph Neural Networks: A Review of Methods and Applications,2018,0.0010018562889266558,1
W2799051177,Context-Aware Neural Machine Translation Learns Anaphora Resolution,2018,0.0009870667291270734,1
W2963551569,Neural Machine Translation with Reconstruction,2017,0.0009768106451452955,1
W2963166639,A Multimodal Anomaly Detector for Robot-Assisted Feeding Using an LSTM-Based Variational Autoencoder,2018,0.0009682557495304117,1
W2963042606,Unitary Evolution Recurrent Neural Networks,2015,0.000957883986594004,1
W2962708992,Incorporating Discrete Translation Lexicons into Neural Machine Translation,2016,0.0009569250603581426,1
W2962802109,Neural Machine Translation with Extended Context,2017,0.000950552605947441,1
W2971724044,Recurrent Neural Networks for Time Series Forecasting: Current status and future directions,2020,0.0009498144708671806,1
W2963088785,Character-Level Language Modeling with Deeper Self-Attention,2019,0.0009429507542410206,1
W2417549359,Does Multimodality Help Human and Machine for Translation and Image Captioning?,2016,0.0009422381823375216,1
W2339995566,Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models,2016,0.0009327521913437425,1
W2963532813,Attend and Diagnose: Clinical Time Series Analysis Using Attention Models,2018,0.0009288099273320748,1
W2994673210,Reformer: The Efficient Transformer,2020,0.0009227543759471406,1
W2983902802,Transformer Dissection: An Unified Understanding for Transformer’s Attention via the Lens of Kernel,2019,0.0009202916646215856,1
W2963497309,Sentence-State LSTM for Text Representation,2018,0.0009195225420019073,1
W2767989436,Weighted Transformer Network for Machine Translation,2017,0.000898518392968106,1
W2754252319,Short-Term Residential Load Forecasting Based on LSTM Recurrent Neural Network,2017,0.0008904545559191601,1
W2963983719,Recurrent Highway Networks,2017,0.0008858130652996422,1
W3038981236,Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting,2020,0.0008831716580444753,1
W2970868759,The BEA-2019 Shared Task on Grammatical Error Correction,2019,0.0008825350882245864,1
W3037422790,Taming Pretrained Transformers for Extreme Multi-label Text Classification,2020,0.0008686908992392003,1
W2970183009,Text Level Graph Neural Network for Text Classification,2019,0.000861835521548712,1
W2944815030,MASS: Masked Sequence to Sequence Pre-training for Language Generation,2019,0.00086182507283695,1
W2567571499,Fast Domain Adaptation for Neural Machine Translation,2016,0.0008586458810878195,1
W2743945814,Regularizing and Optimizing LSTM Language Models,2017,0.0008471382894630198,1
W2891534142,Document-Level Neural Machine Translation with Hierarchical Attention Networks,2018,0.0008412696309474627,1
W2944851425,A Review of Recurrent Neural Networks: LSTM Cells and Network Architectures,2019,0.0008358181999398345,1
W2513263213,Attention-based Multimodal Neural Machine Translation,2016,0.000821503777721027,1
W2963748792,On the State of the Art of Evaluation in Neural Language Models,2018,0.0008209843316527498,1
W2988975212,Mask-Predict: Parallel Decoding of Conditional Masked Language Models,2019,0.0008136496021306145,1
W2767019613,Evaluating Discourse Phenomena in Neural Machine Translation,2018,0.0008108287159582515,1
W2798931235,Phrase-Based & Neural Unsupervised Machine Translation.,2018,0.0008067243551773126,1
W2999089077,"Progress in Neural NLP: Modeling, Learning, and Reasoning",2020,0.000800110118580733,1
W3082674894,Sockeye: A Toolkit for Neural Machine Translation,2017,0.0007983815129273933,1
W3031696893,Attention in Natural Language Processing,2020,0.0007878518514228679,1
W2467834614,Controlling Politeness in Neural Machine Translation via Side Constraints,2016,0.0007869790635088563,1
W2963542740,Learning Deep Transformer Models for Machine Translation,2019,0.0007850422727685324,1
W2951927893,Multistep speed prediction on traffic networks: A deep learning approach considering spatio-temporal dependencies,2019,0.0007809023372439834,1
W2964190861,Classical Structured Prediction Losses for Sequence to Sequence Learning,2018,0.000779485937496569,1
W2963993537,Universal Neural Machine Translation for Extremely Low Resource Languages,2018,0.0007777867245992026,1
W2963304263,Recurrent Batch Normalization,2016,0.0007679352708349545,1
W3133618741,A review of irregular time series data handling with gated recurrent neural networks,2021,0.0007655735286513264,1
W2962736999,A Deep Neural Network for Unsupervised Anomaly Detection and Diagnosis in Multivariate Time Series Data,2019,0.0007605844317531245,1
W2888539709,Why Self-Attention? A Targeted Evaluation of Neural Machine Translation Architectures,2018,0.0007570144983766169,1
W2767899794,Synthetic and Natural Noise Both Break Neural Machine Translation,2017,0.0007529646861109974,1
W2986815055,DSTP-RNN: A dual-stage two-phase attention-based recurrent neural network for long-term and multivariate time series prediction,2019,0.0007475538869212439,1
W2952809536,Pay Less Attention with Lightweight and Dynamic Convolutions,2019,0.0007467587264279428,1
W2908541468,Physics-constrained deep learning for high-dimensional surrogate modeling and uncertainty quantification without labeled data,2019,0.0007434098964590213,1
W2555428947,Unsupervised Pretraining for Sequence to Sequence Learning,2017,0.0007393732691512525,1
W2963881719,Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data,2019,0.0007371986292945732,1
W2952468927,MASS: Masked Sequence to Sequence Pre-training for Language Generation,2019,0.0007356185545331589,1
W3004665554,Wind power forecasting using attention-based gated recurrent unit network,2020,0.0007300934144767141,1
W2573119710,A Multifaceted Evaluation of Neural versus Phrase-Based Machine Translation for 9 Language Directions,2017,0.0007279740980139362,1
W2952436057,Quasi-Recurrent Neural Networks,2016,0.0007230924865351897,1
W2970279348,Findings of the 2019 Conference on Machine Translation (WMT19),2019,0.0007226313327120199,1
W3106298483,Blockwise Self-Attention for Long Document Understanding,2020,0.0007217712692589451,1
W2963975242,Near Human-Level Performance in Grammatical Error Correction with Hybrid Machine Translation,2018,0.0007211689098090005,1
W2866343820,Universal Transformers,2018,0.000719721425287358,1
W2964116568,Neural AMR: Sequence-to-Sequence Models for Parsing and Generation,2017,0.0007184559497122611,1
W1816079941,When Are Tree Structures Necessary for Deep Learning of Representations?,2015,0.0007098346935293451,1
W2919290281,Massively Multilingual Neural Machine Translation,2019,0.0007054922421370412,1
W2798749466,Graph-to-Sequence Learning using Gated Graph Neural Networks,2018,0.0007045104607949749,1
W3037798801,Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention,2020,0.0006982537773354349,1
W2550143307,Temporal Convolutional Networks for Action Segmentation and Detection,2017,0.0006935332675147129,1
W2953333557,Depthwise Separable Convolutions for Neural Machine Translation,2017,0.0006934086379359494,1
W2574872930,OpenNMT: Open-source Toolkit for Neural Machine Translation,2017,0.0006891517677281602,1
W2244807774,Gated Graph Sequence Neural Networks,2016,0.0006891094076201755,1
W2964013027,Unsupervised Neural Machine Translation with Weight Sharing,2018,0.0006853736373072335,1
W2962712961,Improving the Transformer Translation Model with Document-Level Context,2018,0.0006835804013529566,1
W2948335087,Neural Grammatical Error Correction Systems with Unsupervised Pre-training on Synthetic Data,2019,0.0006832142245379368,1
W2981982720,Knowledge Transfer for Rotary Machine Fault Diagnosis,2019,0.0006793416207236482,1
W2963331233,Findings of the Second Shared Task on Multimodal Machine Translation and Multilingual Image Description,2017,0.0006764535587405239,1
W2963842551,Learning to Remember Translation History with a Continuous Cache,2018,0.0006709386332021341,1
W2530887700,Hybrid computing using a neural network with dynamic external memory,2016,0.0006651853403723471,1
W2964085268,When and Why Are Pre-Trained Word Embeddings Useful for Neural Machine Translation?,2018,0.0006627711099085494,1
W3085139254,Efficient Transformers: A Survey,2022,0.0006595848993215879,1
W2510842514,Hierarchical Multiscale Recurrent Neural Networks,2016,0.0006590141668186401,1
W2890007195,Unsupervised Statistical Machine Translation,2018,0.0006579925440662136,1
W2888159079,Has Machine Translation Achieved Human Parity? A Case for Document-level Evaluation,2018,0.0006550069289565385,1
W2621975677,Pushing the Limits of Translation Quality Estimation,2017,0.0006451398043293266,1
W3106543020,Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding,2018,0.0006450246793177983,1
W2782791108,Deep Bidirectional and Unidirectional LSTM Recurrent Neural Network for Network-wide Traffic Speed Prediction,2018,0.0006436160396423001,1
W2885588803,How Grammatical is Character-level Neural Machine Translation? Assessing MT Quality with Contrastive Translation Pairs,2017,0.0006403974870833172,1
W2963648186,Towards String-To-Tree Neural Machine Translation,2017,0.0006341613914611668,1
W2175402905,Unitary Evolution Recurrent Neural Networks,2015,0.0006320306411176842,1
W3109365969,Deep Learning for Time Series Forecasting: A Survey,2020,0.0006309662129226956,1
W2922158773,Attaining the Unattainable? Reassessing Claims of Human Parity in Neural Machine Translation,2018,0.0006299101471972719,1
W3019166713,A Survey of the Usages of Deep Learning for Natural Language Processing,2020,0.0006276833679153403,1
W3128634608,Multivariate Time-Series Anomaly Detection via Graph Attention Network,2020,0.0006216454936771765,1
W2798416860,Fluency Boost Learning and Inference for Neural Grammatical Error Correction,2018,0.0006193502574344222,1
W3098341425,Data Augmentation for Low-Resource Neural Machine Translation,2017,0.0006177987677885504,1
W2173027866,Convolutional Networks on Graphs for Learning Molecular Fingerprints,2015,0.0006173678917289813,1
W3131922516,Efficient Content-Based Sparse Attention with Routing Transformers,2021,0.0006091009656559541,1
W2951184134,Google's Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation,2016,0.0006087812388784547,1
W2796108585,Training Tips for the Transformer Model,2018,0.0006072145897035427,1
W2963713328,Variational Neural Machine Translation,2016,0.0006053553084302374,1
W2963598809,Supervised Attentions for Neural Machine Translation,2016,0.0006047860834952686,1
W2888520903,Training Deeper Neural Machine Translation Models with Transparent Attention,2018,0.0006014435464235822,1
W3006381853,Incorporating BERT into Neural Machine Translation,2020,0.0006009983690328997,1
W2939208918,Self-Attention Graph Pooling,2019,0.0005988898422470967,1
W2566564022,Improved Neural Machine Translation with SMT Features,2016,0.0005961429337318798,1
W2581101319,Incorporating Global Visual Features into Attention-based Neural Machine Translation.,2017,0.0005950061012857701,1
W2792376130,An Analysis of Neural Language Modeling at Multiple Scales,2018,0.0005938620814407337,1
W3173753074,BertGCN: Transductive Text Classification by Combining GNN and BERT,2021,0.0005934344602943162,1
W2964289193,Document Context Neural Machine Translation with Memory Networks,2018,0.000593184305812818,1
W2963109131,Grammatical Error Correction with Neural Reinforcement Learning,2017,0.0005911368100288404,1
W2963716836,Order Matters: Sequence to sequence for sets,2015,0.0005825596728021997,1
W2756566411,Copied Monolingual Data Improves Low-Resource Neural Machine Translation,2017,0.0005792278975385295,1
W2963011474,Stronger Baselines for Trustable Results in Neural Machine Translation,2017,0.0005718154691204278,1
W2997162759,Tensor Graph Convolutional Networks for Text Classification,2020,0.0005645079436640712,1
W2962834107,Neural Machine Translation with Supervised Attention,2016,0.0005635371581666656,1
W3188872815,A Transformer-based Framework for Multivariate Time Series Representation Learning,2021,0.0005625438662052395,1
W2963919854,On the Impact of Various Types of Noise on Neural Machine Translation,2018,0.0005558051941937952,1
W2963112338,Mixed Precision Training,2017,0.0005549185045773258,1
W2964302946,Modeling Localness for Self-Attention Networks,2018,0.0005548819991041073,1
W2958953787,Massively Multilingual Neural Machine Translation in the Wild: Findings and Challenges,2019,0.000554632024178548,1
W2744813330,An Empirical Comparison of Domain Adaptation Methods for Neural Machine Translation,2017,0.0005544094891328173,1
W2201092681,Feed-Forward Networks with Attention Can Solve Some Long-Term Memory Problems,2015,0.0005500279006097972,1
W3034749137,Traffic transformer: Capturing the continuity and periodicity of time series for traffic forecasting,2020,0.00054952385613865,1
W2887920589,Rapid Adaptation of Neural Machine Translation to New Languages,2018,0.0005475193842078168,1
W2789543585,Fast Decoding in Sequence Models using Discrete Latent Variables,2018,0.0005450717509230645,1
W2963153906,Recurrent neural network for text classification with multi-task learning,2016,0.0005443058996067142,1
W3034772996,On Layer Normalization in the Transformer Architecture,2020,0.0005442506182279655,1
W2903012348,Sogou Neural Machine Translation Systems for WMT17,2017,0.0005409428354579518,1
W2946375144,Levenshtein Transformer,2019,0.0005393135301063474,1
W2988533489,A survey of word embeddings based on deep learning,2019,0.000538127962700644,1
W3123909522,Graph neural network for traffic forecasting: A survey,2022,0.000533043412471444,1
W2532807140,Pre-Translation for Neural Machine Translation,2016,0.0005305652894293955,1
W3184127157,Learning Graph Structures With Transformer for Multivariate Time-Series Anomaly Detection in IoT,2021,0.0005286708324142334,1
W2888541716,Meta-Learning for Low-Resource Neural Machine Translation,2018,0.0005285171225757491,1
W2911109671,Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context,2019,0.000525224866055798,1
W2890207295,A Time-Distributed Spatiotemporal Feature Learning Method for Machine Health Monitoring with Multi-Sensor Time Series,2018,0.000524436837153694,1
W2741040846,Visualizing and Understanding Neural Machine Translation,2017,0.0005243679109366661,1
W2610245951,A Teacher-Student Framework for Zero-Resource Neural Machine Translation,2017,0.0005235574264199007,1
W3037162118,"GECToR – Grammatical Error Correction: Tag, Not Rewrite",2020,0.0005215914666092458,1
W2962822108,Multi-Head Attention with Disagreement Regularization,2018,0.0005214669693600749,1
W2963407669,Attention Strategies for Multi-Source Sequence-to-Sequence Learning,2017,0.0005172189130577245,1
W2593341061,Doubly-Attentive Decoder for Multi-modal Neural Machine Translation,2017,0.0005167053528289003,1
W2995837271,Hierarchical Taxonomy-Aware and Attentional Graph Capsule RCNNs for Large-Scale Multi-Label Text Classification,2019,0.0005125929651843785,1
W2936597270,Corpora Generation for Grammatical Error Correction,2019,0.0005086472732914963,1
W2963311488,EA-LSTM: Evolutionary attention-based LSTM for time series prediction,2019,0.0005080620098233957,1
W2751185861,Training RNNs as Fast as CNNs,2017,0.0005080456839485453,1
W2963631431,Deep architectures for Neural Machine Translation,2017,0.0005067765579589476,1
W2888519496,SwitchOut: an Efficient Data Augmentation Algorithm for Neural Machine Translation,2018,0.0005065160390983379,1
W2970295111,Facebook FAIR’s WMT19 News Translation Task Submission,2019,0.0005033684321442954,1
W2979636403,Transformers without Tears: Improving the Normalization of Self-Attention,2019,0.0005010002903043746,1
W2962893388,Explicit Interaction Model towards Text Classification,2019,0.0004995398706224175,1
W2759173152,Improving Word Sense Disambiguation in Neural Machine Translation with Sense Embeddings,2017,0.0004984978054264805,1
W3089472875,Neural Machine Translation: A Review,2020,0.0004981701073893029,1
W2810035278,Reaching Human-level Performance in Automatic Grammatical Error Correction: An Empirical Study,2018,0.0004981039715399826,1
W2971092323,Label-Specific Document Representation for Multi-Label Text Classification,2019,0.0004973367483441167,1
W2964253663,Addressing the Data Sparsity Issue in Neural AMR Parsing,2017,0.0004964387023691733,1
W2964130895,A Challenge Set Approach to Evaluating Machine Translation,2017,0.0004951759608515096,1
W3021293129,Synthesizer: Rethinking Self-Attention in Transformer Models,2020,0.0004949003198067303,1
W2946084162,Multiple convolutional neural networks for multivariate time series prediction,2019,0.0004945675243428243,1
W3111914315,PhyGeoNet: Physics-informed geometry-adaptive convolutional neural networks for solving parameterized steady-state PDEs on irregular domain,2020,0.0004927516696237962,1
W2789910672,Neural Interactive Translation Prediction,2016,0.0004884436855892814,1
W4306955484,A survey of transformers,2022,0.00048811422524560596,1
W3190748826,Unsupervised Deep Anomaly Detection for Multi-Sensor Time-Series Signals,2021,0.00048746439490425216,1
W3035568641,Every Document Owns Its Structure: Inductive Text Classification via Graph Neural Networks,2020,0.0004873145374498312,1
W2443536229,Zero-Resource Translation with Multi-Lingual Neural Machine Translation,2016,0.0004872896275042015,1
W2962931466,Exploiting Deep Representations for Neural Machine Translation,2018,0.00048592754145874485,1
W3093871477,Beyond English-Centric Multilingual Machine Translation,2020,0.00048586337101861596,1
W2606134370,Neural Monkey: An Open-source Tool for Sequence Learning,2017,0.0004852620289964443,1
W2890230387,Neural Quality Estimation of Grammatical Error Correction,2018,0.0004852278459796493,1
W2962906084,RIGA at SemEval-2016 Task 8: Impact of Smatch Extensions and Character-Level Neural Translation on AMR Parsing Accuracy,2016,0.00048413638154665807,1
W2911379778,GILE: A Generalized Input-Label Embedding for Text Classification,2019,0.00048351250710033217,1
W2963599677,Deep Neural Machine Translation with Linear Associative Unit,2017,0.00048321604573461435,1
W2978540646,Convolution and Long Short-Term Memory Hybrid Deep Neural Networks for Remaining Useful Life Prognostics,2019,0.0004820315067600428,1
W2963331137,A Teacher-Student Framework for Zero-Resource Neural Machine Translation,2017,0.00048190118756343084,1
W2890964657,Layer-Wise Coordination between Encoder and Decoder for Neural Machine Translation,2018,0.0004817052924923328,1
W2803237843,Noising and Denoising Natural Language: Diverse Backtranslation for Grammar Correction,2018,0.00048137238048692955,1
W2971120622,The FLORES Evaluation Datasets for Low-Resource Machine Translation: Nepali–English and Sinhala–English,2019,0.0004809465604024691,1
W2963536265,Non-Autoregressive Machine Translation with Auxiliary Regularization,2019,0.0004771597911662255,1
W2889347686,Uncertainty Prediction of Remaining Useful Life Using Long Short-Term Memory Network Based on Bootstrap Method,2018,0.0004692268032633404,1
W4224211827,A multi-head attention-based transformer model for traffic flow forecasting with a comparative analysis to recurrent neural networks,2022,0.00046707159898332334,1
W2804604520,RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Networks on Electronic Medical Records,2018,0.00046669076205769344,1
W2900013662,Translation Quality and Productivity: A Study on Rich Morphology Languages.,2017,0.000462765742895518,1
W2751262944,Tree-structured decoding with doubly-recurrent neural networks,2017,0.00046263083867636534,1
W2955227499,Augmenting Self-attention with Persistent Memory,2019,0.0004579354734726263,1
W3017116930,A CNN–LSTM model for gold price time-series forecasting,2020,0.0004558732892962956,1
W3158464467,Fusing stacked autoencoder and long short-term memory for regional multistep-ahead flood inundation forecasts,2021,0.00045316602240704987,1
W3037511795,LSTM networks based on attention ordered neurons for gear remaining life prediction,2020,0.0004525249052735601,1
W2964029788,Lexically Constrained Decoding for Sequence Generation Using Grid Beam Search,2017,0.0004507178733611328,1
W2965981069,Outlier Detection for Time Series with Recurrent Autoencoder Ensembles,2019,0.0004493881965783737,1
W2970521905,An Empirical Study of Incorporating Pseudo Data into Grammatical Error Correction,2019,0.0004492418954827953,1
W2902918014,Findings of the WMT 2018 Shared Task on Parallel Corpus Filtering,2018,0.00044848113603468214,1
W2964125283,Neural Machine Translation with Recurrent Attention Modeling,2017,0.0004473105166463057,1
W2786167576,Memory Architectures in Recurrent Neural Network Language Models,2018,0.00044723414673706615,1
W3162090017,FNet: Mixing Tokens with Fourier Transforms,2022,0.0004453551441276619,1
W2988226917,DSANet,2019,0.00044392355313408415,1
W2801761896,Electricity Price Forecasting Using Recurrent Neural Networks,2018,0.00044135435432156176,1
W2995575179,Compressive Transformers for Long-Range Sequence Modelling,2020,0.00043967077373997104,1
W2586559132,Neural Machine Translation with Source-Side Latent Graph Parsing,2017,0.00043950126793070406,1
W3160886584,Autoencoder Quasi-Recurrent Neural Networks for Remaining Useful Life Prediction of Engineering Systems,2021,0.00043874543092808,1
W3158304688,Dynamic Graph Convolutional Recurrent Network for Traffic Prediction: Benchmark and Solution,2022,0.0004384339030807962,1
W2951605425,Full-Capacity Unitary Recurrent Neural Networks,2016,0.00043629811899991404,1
W2963122608,Domain Control for Neural Machine Translation,2017,0.00043549604225831887,1
W2964048171,Towards Robust Neural Machine Translation,2018,0.0004341992033569093,1
W2669742347,THUMT: An Open Source Toolkit for Neural Machine Translation,2017,0.00043321493185390867,1
W4210562913,Aircraft engine remaining useful life estimation via a double attention-based data-driven architecture,2022,0.000432753483036824,1
W2970777192,Adaptively Sparse Transformers,2019,0.00043099493876974827,1
W2970076840,A Neural Grammatical Error Correction System Built On Better Pre-training and Sequential Transfer Learning,2019,0.0004261972629560431,1
W2785806165,A Multi-Task Framework for Monitoring Health Conditions via Attention-based Recurrent Neural Networks.,2017,0.00042598544393900294,1
W2963913268,Modeling Source Syntax for Neural Machine Translation,2017,0.0004242377845344448,1
W2798389157,Filtering and Mining Parallel Data in a Joint Multilingual Space,2018,0.00042279602452669314,1
W2890501761,Semi-Autoregressive Neural Machine Translation,2018,0.0004179998788955186,1
W2970398671,Heterogeneous Graph Attention Networks for Semi-supervised Short Text Classification,2019,0.00041114363328245755,1
W2463507112,Sequence-Level Knowledge Distillation,2016,0.00041111348534191483,1
W3216107495,Transformers for modeling physical systems,2021,0.00041024749342313734,1
W3035690777,Hierarchy-Aware Global Model for Hierarchical Text Classification,2020,0.0004087828249543132,1
W2612810742,An overview and comparative analysis of Recurrent Neural Networks for Short Term Load Forecasting,2017,0.00040831619457151427,1
W2962969034,Non-Autoregressive Neural Machine Translation with Enhanced Decoder Input,2019,0.0004072798673339776,1
W2962943802,Selective Attention for Context-aware Neural Machine Translation,2019,0.0004072459934907061,1
W2963277143,Context-dependent word representation for neural machine translation,2017,0.0004066778479847366,1
W2963641307,Modeling Recurrence for Transformer,2019,0.000405408732623294,1
W2994928925,Incorporating BERT into Neural Machine Translation,2020,0.0004052544117163442,1
W3132607382,Position Information in Transformers: An Overview,2022,0.00040502289815277194,1
W2963888305,Improved Neural Machine Translation with a Syntax-Aware Encoder and Decoder,2017,0.00040458170358002366,1
W2622068151,Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs,2017,0.0004041026298838728,1
W3021538729,Interpretable spatio-temporal attention LSTM model for flood forecasting,2020,0.0004038737869661244,1
W2750304600,Forecasting day-ahead electricity prices in Europe: The importance of considering market integration,2017,0.0004035011776937994,1
W2963109507,Joint Training for Neural Machine Translation Models with Monolingual Data,2018,0.0004030442954310506,1
W2765961751,Unsupervised Machine Translation Using Monolingual Corpora Only,2017,0.0004025588271804396,1
W2892213699,End-to-End Non-Autoregressive Neural Machine Translation with Connectionist Temporal Classification,2018,0.00040245629418944004,1
W2952136670,Frustratingly Short Attention Spans in Neural Language Modeling,2017,0.00040227157280450885,1
W2963174729,Simple Recurrent Units for Highly Parallelizable Recurrence,2018,0.00040211045132356273,1
W2319453305,Minimal gated unit for recurrent neural networks,2016,0.00040027139797888157,1
W2952446148,"When a Good Translation is Wrong in Context: Context-Aware Machine Translation Improves on Deixis, Ellipsis, and Lexical Cohesion",2019,0.0003985807089198561,1
W3045733172,Big Bird: Transformers for Longer Sequences,2020,0.0003982305021124347,1
W2922349260,compare-mt: A Tool for Holistic Comparison of Language Generation Systems,2019,0.00039760523799265747,1
W3171665133,SCINet: Time Series Modeling and Forecasting with Sample Convolution and Interaction,2021,0.0003950803949880459,1
W2964213727,Accelerating Neural Transformer via an Average Attention Network,2018,0.00039397983808153817,1
W2922329508,Short-Term Load Forecasts Using LSTM Networks,2019,0.0003927834640165798,1
W2539201987,Neural Machine Translation Advised by Statistical Machine Translation,2017,0.00039193774901998273,1
W2222235228,Mutual Information and Diverse Decoding Improve Neural Machine Translation,2016,0.00039063980733033667,1
W3174864715,R-Drop: Regularized Dropout for Neural Networks,2021,0.0003895882008737138,1
W2808508619,Modeling Coherence for Neural Machine Translation with Dynamic and Topic Caches,2017,0.0003894522541886901,1
W2963366389,Dynamic Data Selection for Neural Machine Translation,2017,0.00038725772553761307,1
W2173183968,Order Matters: Sequence to sequence for sets,2015,0.0003857491899343305,1
W3103682594,Long Range Arena: A Benchmark for Efficient Transformers,2020,0.0003850394539483186,1
W2625092622,Six Challenges for Neural Machine Translation,2017,0.00038470261218281383,1
W2970429618,Parallel Iterative Edit Models for Local Sequence Transduction,2019,0.0003845085814360078,1
W3116103134,Time-Series Regeneration With Convolutional Recurrent Generative Adversarial Network for Remaining Useful Life Estimation,2020,0.00038116431693848763,1
W2885185669,SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing,2018,0.0003805884201152686,1
W3003741609,Exploring a Long Short-Term Memory based Encoder-Decoder framework for multi-step-ahead flood forecasting,2020,0.00037826062413445245,1
W2962863357,Regularization techniques for fine-tuning in neural machine translation,2017,0.00037730907086950866,1
W2963699608,Coverage Embedding Models for Neural Machine Translation,2016,0.0003768630209025262,1
W2766182427,Unsupervised Neural Machine Translation,2017,0.0003767840769698816,1
W2950359962,Dual Learning for Machine Translation,2016,0.00037402562957068324,1
W3169369929,The <scp>Flores-101</scp> Evaluation Benchmark for Low-Resource and Multilingual Machine Translation,2022,0.00037341224439530726,1
W2173051530,Neural GPUs Learn Algorithms,2015,0.0003728838575645732,1
W2525246036,Multiplicative LSTM for sequence modelling,2016,0.00037254377214361427,1
W2756978580,Instance Weighting for Neural Machine Translation Domain Adaptation,2017,0.0003709524944047337,1
W2785093437,Dual Transfer Learning for Neural Machine Translation with Marginal Distribution Regularization,2018,0.0003698668845245201,1
W2886095922,Iterative Back-Translation for Neural Machine Translation,2018,0.000369806168028845,1
W2963633299,"Transfer Learning across Low-Resource, Related Languages for Neural Machine Translation",2017,0.00036895026178749066,1
W2552124255,"Multi-way, multilingual neural machine translation",2016,0.0003674424430111702,1
W2896370767,Detecting Cyber Attacks in Industrial Control Systems Using Convolutional Neural Networks,2018,0.0003665379135341,1
W2963281280,Dual Conditional Cross-Entropy Filtering of Noisy Parallel Corpora,2018,0.00036569648264126207,1
W3010232603,LIUM-CVC Submissions for WMT18 Multimodal Translation Task,2018,0.00036549319156991113,1
W2963357083,Semi-Supervised Learning for Neural Machine Translation,2016,0.0003633227364387005,1
W2788330850,Search Engine Guided Neural Machine Translation,2018,0.00036224636130987594,1
W2963352809,Fast Lexically Constrained Decoding with Dynamic Beam Allocation for Neural Machine Translation,2018,0.0003619509675428502,1
W2798761464,How Much Attention Do You Need? A Granular Analysis of Neural Machine Translation Architectures,2018,0.00036073951177515714,1
W3000514857,Reformer: The Efficient Transformer,2020,0.0003599839684391686,1
W2597891111,On integrating a language model into neural machine translation,2017,0.00035830032027688345,1
W2791366550,Independently Recurrent Neural Network (IndRNN): Building A Longer and Deeper RNN,2018,0.00035805594547930566,1
W3196788510,A customized deep learning approach to integrate network-scale online traffic data imputation and prediction,2021,0.00035796923083366124,1
W2601324753,Improving Neural Machine Translation with Conditional Sequence Generative Adversarial Nets,2018,0.00035651371225450893,1
W2951305674,Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences,2016,0.0003563784392421548,1
W3105238007,ETC: Encoding Long and Structured Inputs in Transformers,2020,0.00035596801060595043,1
W3137613462,Remaining useful life estimation via transformer encoder enhanced by a gated convolutional unit,2021,0.00035542144352875254,1
W2970925270,"Simple, Scalable Adaptation for Neural Machine Translation",2019,0.0003534575682459562,1
W2460144244,Group sparse regularization for deep neural networks,2017,0.0003524999878562708,1
W2565330852,Structured Sequence Modeling with Graph Convolutional Recurrent Networks,2018,0.0003511338134072173,1
W3209662019,An integrated deep multiscale feature fusion network for aeroengine remaining useful life prediction with multisensor data,2021,0.0003498254045765877,1
W3012621877,Backpropagation algorithms and Reservoir Computing in Recurrent Neural Networks for the forecasting of complex spatiotemporal dynamics,2020,0.0003473994915429701,1
W2964120396,A Large-Scale Test Set for the Evaluation of Context-Aware Pronoun Translation in Neural Machine Translation,2018,0.0003472991209944023,1
W2970529093,Microsoft Translator at WMT 2019: Towards Large-Scale Document-Level Neural Machine Translation,2019,0.00034704455878461365,1
W3193812480,Learning Dynamic and Hierarchical Traffic Spatiotemporal Features With Transformer,2021,0.00034663645756280085,1
W2573834658,Zero-resource machine translation by multimodal encoder–decoder network with multimedia pivot,2017,0.00034656089073088563,1
W2809398771,Risk Prediction on Electronic Health Records with Prior Medical Knowledge,2018,0.0003458336115008795,1
W3203619751,Long-Range Transformers for Dynamic Spatiotemporal Forecasting,2021,0.0003456561398303302,1
W2757920198,Controlling the Voice of a Sentence in Japanese-to-English Neural Machine Translation.,2016,0.0003452949988447188,1
W2741917668,Maximum Expected Likelihood Estimation for Zero-resource Neural Machine Translation,2017,0.0003438829379884502,1
W2410539690,Modeling Coverage for Neural Machine Translation,2016,0.00034388135912095355,1
W2962735107,Margin-based Parallel Corpus Mining with Multilingual Sentence Embeddings,2019,0.00034376736365214315,1
W2896556401,Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks,2018,0.00034344480395933095,1
W2990495794,CTS-LSTM: LSTM-based neural networks for correlatedtime series prediction,2019,0.00034048689557715625,1
W2964240726,Microsoft’s Submission to the WMT2018 News Translation Task: How I Learned to Stop Worrying and Love the Data,2018,0.0003390271314017937,1
W2950513705,Mixture Models for Diverse Machine Translation: Tricks of the Trade,2019,0.0003380402137791544,1
W2903343986,Findings of the Third Shared Task on Multimodal Machine Translation,2018,0.0003363633712860484,1
W3100753857,Non-Autoregressive Machine Translation with Latent Alignments,2020,0.0003352217719352841,1
W2963374482,A Graph-to-Sequence Model for AMR-to-Text Generation,2018,0.00033476218946594885,1
W2970858854,Findings of the WMT 2019 Shared Task on Parallel Corpus Filtering for Low-Resource Conditions,2019,0.0003346307127637768,1
W2963066159,Graph Convolutional Networks with EigenPooling,2019,0.00033407040949235615,1
W2789541106,Self-Attention with Relative Position Representations,2018,0.000334037362808745,1
W2963684275,The Reversible Residual Network: Backpropagation Without Storing Activations,2017,0.00033328559588340653,1
W3140618672,State of Charge and State of Energy Estimation for Lithium-Ion Batteries Based on a Long Short-Term Memory Neural Network,2021,0.00033283638809515544,1
W2888456631,Contextual Parameter Generation for Universal Neural Machine Translation,2018,0.00033173179361075566,1
W2757592053,Multi-Domain Neural Machine Translation through Unsupervised Adaptation,2017,0.0003315847347590147,1
W2969724595,TabNet: Attentive Interpretable Tabular Learning,2019,0.00032956047957640887,1
W4283318673,TranAD,2022,0.00032941496775603654,1
W2923622379,Competence-based Curriculum Learning for Neural Machine Translation,2019,0.00032903430575475487,1
W2963823140,Robust Neural Machine Translation with Doubly Adversarial Inputs,2019,0.00032666794261755475,1
W4213025374,Transformer Network for Remaining Useful Life Prediction of Lithium-Ion Batteries,2022,0.0003260214060780139,1
W2962729168,Reinforced Self-Attention Network: a Hybrid of Hard and Soft Attention for Sequence Modeling,2018,0.00032591846653425867,1
W2962947230,AMR Parsing as Graph Prediction with Latent Alignment,2018,0.0003253200469338524,1
W2740743644,Sentence Embedding for Neural Machine Translation Domain Adaptation,2017,0.0003252413852425991,1
W2970290486,Improving Deep Transformer with Depth-Scaled Initialization and Merged Attention,2019,0.0003251382273376174,1
W2797913374,Investigating Backtranslation in Neural Machine Translation,2018,0.0003249157962853503,1
W2963988211,Imagination improves Multimodal Translation,2017,0.0003243378678569771,1
W2962778428,A neural interlingua for multilingual machine translation,2018,0.0003239668833523384,1
W3041279471,Stacked bidirectional and unidirectional LSTM recurrent neural network for forecasting network-wide traffic state with missing values,2020,0.0003222505838552491,1
W2797371199,Approaching Neural Grammatical Error Correction as a Low-Resource Machine Translation Task,2018,0.0003216405901041685,1
W3024761859,A review on the long short-term memory model,2020,0.0003213768935389911,1
W2963841178,One Sentence One Model for Neural Machine Translation,2018,0.0003212654448878516,1
W2781626870,Recent Advances in Recurrent Neural Networks,2018,0.0003205714288910683,1
W2949973181,Revisiting Low-Resource Neural Machine Translation: A Case Study,2019,0.0003192060424060102,1
W2921280978,The Missing Ingredient in Zero-Shot Neural Machine Translation,2019,0.00031771199870251417,1
W3173407600,Dual-Aspect Self-Attention Based on Transformer for Remaining Useful Life Prediction,2022,0.00031653756163273184,1
W3017454464,Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation,2020,0.0003157777310073022,1
W2969262604,An Introductory Survey on Attention Mechanisms in NLP Problems,2019,0.00031537218596327263,1
W3097294131,Adversarial Sparse Transformer for Time Series Forecasting,2020,0.0003150354746659799,1
W3011624874,AMalNet: A deep learning framework based on graph convolutional networks for malware detection,2020,0.00031439782106270654,1
W2963829526,Guiding Neural Machine Translation with Retrieved Translation Pieces,2018,0.00031407657927235436,1
W2970744242,"Encode, Tag, Realize: High-Precision Text Editing",2019,0.00031312932350432705,1
W3066373881,Very Deep Transformers for Neural Machine Translation,2020,0.00031261794557125444,1
W3045857695,Transferable convolutional neural network based remaining useful life prediction of bearing under multiple failure behaviors,2020,0.0003099237206225754,1
W3175925542,Spatial-temporal graph neural network for traffic forecasting: An overview and open research issues,2021,0.00030903354385939194,1
W3034504400,Intelligent monitoring and diagnostics using a novel integrated model based on deep learning and multi-sensor feature fusion,2020,0.0003071162693387992,1
W2964247056,MTNT: A Testbed for Machine Translation of Noisy Text,2018,0.00030565216626769434,1
W3035010485,Encoder-Decoder Models Can Benefit from Pre-trained Masked Language Models in Grammatical Error Correction,2020,0.0003052847044889484,1
W2783419700,Translating Pro-Drop Languages With Reconstruction Models,2018,0.00030475385465867836,1
W2963091079,Asynchronous Bidirectional Decoding for Neural Machine Translation,2018,0.00030411757258740215,1
W2888726123,Semantic-Unit-Based Dilated Convolution for Multi-Label Text Classification,2018,0.000304027209201827,1
W3132015041,Remaining useful life prediction of roller bearings based on improved 1D-CNN and simple recurrent unit,2021,0.000303790141265479,1
W2899423466,Convolutional Self-Attention Networks,2019,0.00030285117844886363,1
W2838081464,deepQuest: A Framework for Neural-based Quality Estimation,2018,0.0003018533542407172,1
W3123883114,Prediction of aerodynamic flow fields using convolutional neural networks,2019,0.0003015630817028208,1
W3117196003,DECAF: Deep Extreme Classification with Label Features,2021,0.0003013739346552968,1
W2899310090,Weakly Supervised Grammatical Error Correction using Iterative Decoding,2018,0.00030037201524670746,1
W2889606145,Beyond Error Propagation in Neural Machine Translation: Characteristics of Language Also Matter,2018,0.0003000284360954623,1
W4387063334,Deep learning-based algorithms for long-term prediction of chlorophyll-a in catchment streams,2023,0.00029983471761489195,1
W2758846169,Getting the Most out of AMR Parsing,2017,0.0002998301979485911,1
W2928406799,Grammar Error Correction in Morphologically Rich Languages: The Case of Russian,2019,0.0002994988849655723,1
W3024360037,Streamflow Prediction Using Deep Learning Neural Network: Case Study of Yangtze River,2020,0.00029938918589513604,1
W2952509486,"fairseq: A Fast, Extensible Toolkit for Sequence Modeling.",2019,0.00029887415729892895,1
W2960374072,WikiMatrix: Mining 135M Parallel Sentences in 1620 Language Pairs from Wikipedia,2019,0.00029875141858290194,1
W2897983179,Neural Machine Translation with Deep Attention,2018,0.00029856666304913063,1
W2796167946,Graph2Seq: Graph to Sequence Learning with Attention-based Neural Networks,2018,0.0002985308726720386,1
W3123615524,Random Feature Attention,2021,0.0002982959332488229,1
W3004999940,Anomaly Detection Based on Convolutional Recurrent Autoencoder for IoT Time Series,2020,0.00029812592451732066,1
W2963593215,Prior Knowledge Integration for Neural Machine Translation using Posterior Regularization,2017,0.0002980620493588595,1
W2758310181,Using Target-side Monolingual Data for Neural Machine Translation through Multi-task Learning,2017,0.00029776209367447733,1
W2998486497,Multi-Label Patent Categorization with Non-Local Attention-Based Graph Convolutional Network,2020,0.0002976855591281353,1
W2890672150,Short‐Term Traffic Speed Forecasting Based on Attention Convolutional Neural Network for Arterials,2018,0.00029741335352357506,1
W2964345285,Bridging the Gap between Training and Inference for Neural Machine Translation,2019,0.0002972670701579119,1
W2798944827,Inherent Biases in Reference-based Evaluation for Grammatical Error Correction,2018,0.00029686568446584186,1
W2963086938,Improving Lexical Choice in Neural Machine Translation,2018,0.00029600978977468165,1
W2971120958,Findings of the WMT 2019 Shared Tasks on Quality Estimation,2019,0.0002959389910189369,1
W2913659301,The FLoRes Evaluation Datasets for Low-Resource Machine Translation: Nepali-English and Sinhala-English.,2019,0.00029553019390348914,1
W2998104826,Multi-level convolutional autoencoder networks for parametric prediction of spatio-temporal dynamics,2020,0.00029524476695691167,1
W3005007700,A novel transformer-based neural network model for tool wear estimation,2020,0.00029476254085677013,1
W2970015022,Tagged Back-Translation,2019,0.00029453281079577104,1
W3104804488,Long short-term memory networks in memristor crossbar arrays,2018,0.0002942628026573821,1
W2902463012,Findings of the WMT 2018 Shared Task on Quality Estimation,2018,0.00029405351024997726,1
W2741838462,Curriculum Learning and Minibatch Bucketing in Neural Machine Translation,2017,0.00029360736741761856,1
W2963964898,Exploiting Semantics in Neural Machine Translation with Graph Convolutional Networks,2018,0.0002932006391194491,1
W2970832665,FlowSeq: Non-Autoregressive Conditional Sequence Generation with Generative Flow,2019,0.000292276274232755,1
W2750384459,A Multi-view Deep Learning Method for Epileptic Seizure Detection using Short-time Fourier Transform,2017,0.00029165051430294974,1
W3040607188,Dynamic Spatial-Temporal Representation Learning for Traffic Flow Prediction,2020,0.00029106149222173484,1
W2966153025,Multivariate Temporal Convolutional Network: A Deep Neural Networks Approach for Multivariate Time Series Forecasting,2019,0.00029095994542575567,1
W2970686691,Low-Resource Corpus Filtering Using Multilingual Sentence Embeddings,2019,0.00029088004459286226,1
W3090066802,A Semantic-aware Representation Framework for Online Log Analysis,2020,0.000290494982597982,1
W3091156754,Rethinking Attention with Performers,2020,0.00029016594990873397,1
W3104652516,Trivial Transfer Learning for Low-Resource Neural Machine Translation,2018,0.00028932273835391876,1
W3036677371,Understanding the societal impacts of machine translation: a critical review of the literature on medical and legal use cases,2020,0.00028774525719530553,1
W3010768098,ReZero is All You Need: Fast Convergence at Large Depth,2020,0.0002876393919459402,1
W2952650870,Multilingual Neural Machine Translation with Knowledge Distillation,2019,0.000287606340023854,1
W3186290349,Multi-label text classification via joint learning from label embedding and label correlation,2021,0.0002867257899776851,1
W3042316884,Deep learning methods for forecasting COVID-19 time-Series data: A Comparative study,2020,0.0002865742606779141,1
W2922709902,Pre-trained language model representations for language generation,2019,0.00028580849163976983,1
W2609278920,An Empirical Analysis of NMT-Derived Interlingual Embeddings and Their Use in Parallel Sentence Identification,2017,0.0002855763458339169,1
W2566623769,Neural Machine Translation by Minimising the Bayes-risk with Respect to Syntactic Translation Lattices,2017,0.0002851070461109356,1
W3106229813,Be More with Less: Hypergraph Attention Networks for Inductive Text Classification,2020,0.00028473368702733147,1
W2903810591,Tied Transformers: Neural Machine Translation with Shared Encoder and Decoder,2019,0.0002846828903920464,1
W4312410594,InducT-GCN: Inductive Graph Convolutional Networks for Text Classification,2022,0.00028369018733036353,1
W2750588180,Neural Machine Translation Training in a Multi-Domain Scenario,2017,0.0002821835446109206,1
W2963643655,Compression of Neural Machine Translation Models via Pruning,2016,0.00028203895516304325,1
W2963652649,Context-Aware Self-Attention Networks,2019,0.0002817028636237338,1
W2911742574,The implicit bias of gradient descent on separable data,2018,0.00028159072021347834,1
W3115103108,"Multi-hour and multi-site air quality index forecasting in Beijing using CNN, LSTM, CNN-LSTM, and spatiotemporal clustering",2020,0.0002814397320410129,1
W2947812485,Predicting Station-Level Short-Term Passenger Flow in a Citywide Metro Network Using Spatiotemporal Graph Convolutional Neural Networks,2019,0.00028122086909984677,1
W2563976356,Addressing a Question Answering Challenge by Combining Statistical Methods with Inductive Rule Learning and Reasoning,2016,0.0002801336687343559,1
W2963413917,Unsupervised Neural Machine Translation with SMT as Posterior Regularization,2019,0.00028007715971772927,1
W2985694911,Insertion-based Decoding with Automatically Inferred Generation Order,2019,0.0002800663670710293,1
W2900880305,Deep learning-based feature engineering for stock price movement prediction,2018,0.00027944087266183905,1
W2963983698,Parameter Sharing Methods for Multilingual Self-Attentional Translation Models,2018,0.00027929640617465115,1
W2964093309,Depth Growing for Neural Machine Translation,2019,0.0002791327046785885,1
W2950191616,Discriminative Embeddings of Latent Variable Models for Structured Data,2016,0.0002783185094723145,1
W2803728065,From Feature To Paradigm: Deep Learning In Machine Translation,2018,0.00027758541029377227,1
W2962780935,Pre-Translation for Neural Machine Translation.,2016,0.0002773686381613496,1
W3082760180,Transforming machine translation: a deep learning system reaches news translation quality comparable to human professionals,2020,0.000277131339774059,1
W3125658501,A dual‐stage attention‐based Conv‐LSTM network for spatio‐temporal correlation and multivariate time series prediction,2021,0.00027685713864224014,1
W3104132024,Fine-Grained Human Evaluation of Neural Versus Phrase-Based Machine Translation,2017,0.0002766891968335019,1
W4385700549,Adventures in data analysis: a systematic review of Deep Learning techniques for pattern recognition in cyber-physical-social systems,2023,0.00027654178276650477,1
W2962739703,Towards Bidirectional Hierarchical Representations for Attention-based Neural Machine Translation,2017,0.0002758681589237349,1
W4285227013,RTIDS: A Robust Transformer-Based Approach for Intrusion Detection System,2022,0.0002754505538414333,1
W2994901268,TrafficGAN: Network-Scale Deep Traffic Prediction With Generative Adversarial Nets,2019,0.0002754247661751577,1
W3033943443,Masked Language Modeling for Proteins via Linearly Scalable Long-Context Transformers,2020,0.000275085809335797,1
W2897507397,An Analysis of Attention Mechanisms: The Case of Word Sense Disambiguation in Neural Machine Translation,2018,0.0002747043694473913,1
W4310790298,A Hybrid-Convolution Spatial–Temporal Recurrent Network For Traffic Flow Prediction,2022,0.0002742979030549013,1
W2767982226,Neural machine translation for low-resource languages without parallel corpora,2017,0.0002739074598169201,1
W3099405210,Semantic Neural Machine Translation Using AMR,2019,0.000273848357741695,1
W2739894144,Sequence-to-Dependency Neural Machine Translation,2017,0.00027336488845789304,1
W3047827241,A novel deep learning framework for state of health estimation of lithium-ion battery,2020,0.00027314573296237713,1
W3005644236,Geom-GCN: Geometric Graph Convolutional Networks,2020,0.00027271708129452305,1
W2970871182,Findings of the WMT 2019 Shared Task on Automatic Post-Editing,2019,0.00027230701396418187,1
W2963382396,Correcting Length Bias in Neural Machine Translation,2018,0.00027182025333520073,1
W2971347700,Context-Aware Monolingual Repair for Neural Machine Translation,2019,0.0002715863903556355,1
W2998702685,Graph Transformer for Graph-to-Sequence Learning,2020,0.00027133119750527443,1
W2996854111,Towards Making the Most of BERT in Neural Machine Translation,2020,0.00027076230020398143,1
W2962714778,Neural Machine Translation Decoding with Terminology Constraints,2018,0.00026969804066883025,1
W2896538705,KAME,2018,0.00026943599140153465,1
W2888442053,A Study of Reinforcement Learning for Neural Machine Translation,2018,0.0002692043602704755,1
W2963672008,Learning Joint Multilingual Sentence Representations with Neural Machine Translation,2017,0.0002690592764819375,1
W2755989362,A Context-Aware Recurrent Encoder for Neural Machine Translation,2017,0.0002690107966111708,1
W3204263062,Anomaly Transformer: Time Series Anomaly Detection with Association Discrepancy,2021,0.00026895689121887397,1
W3121592593,Long Range Arena : A Benchmark for Efficient Transformers,2021,0.0002684910849732622,1
W2902767466,CUNI Transformer Neural MT System for WMT18,2018,0.00026845051255783075,1
W3000884041,Feature Extraction Using an RNN Autoencoder for Skeleton-Based Abnormal Gait Recognition,2020,0.00026835230631389154,1
W2887516053,Enhancement of Encoder and Attention Using Target Monolingual Corpora in Neural Machine Translation,2018,0.0002679484557202893,1
W4289313402,Label prompt for multi-label text classification,2022,0.0002660273319436871,1
W3175441946,A Simple Recipe for Multilingual Grammatical Error Correction,2021,0.00026587356412488853,1
W3023672669,VGCN-BERT: Augmenting BERT with Graph Embedding for Text Classification,2020,0.0002658726206264495,1
W2948798935,Learning Deep Transformer Models for Machine Translation,2019,0.0002655968983408245,1
W2971332944,Learning to combine Grammatical Error Corrections,2019,0.00026535405126385035,1
W3035664258,Improving Graph Neural Network Expressivity via Subgraph Isomorphism Counting,2022,0.00026489531534231125,1
W3106504817,Fixed Encoder Self-Attention Patterns in Transformer-Based Machine Translation,2020,0.00026402538933479,1
W2963887123,Revisiting Character-Based Neural Machine Translation with Capacity and Compression,2018,0.0002639223730350256,1
W3177232285,LightXML: Transformer with Dynamic Negative Sampling for High-Performance Extreme Multi-label Text Classification,2021,0.00026375374843523933,1
W2962890089,Denoising Neural Machine Translation Training with Trusted Data and Online Data Selection,2018,0.0002626814833451925,1
W2996987694,Fine-Tuning by Curriculum Learning for Non-Autoregressive Neural Machine Translation,2020,0.00026218567071245146,1
W4324032752,A multi-modal pre-training transformer for universal transfer learning in metal–organic frameworks,2023,0.0002619742069106867,1
W3007332492,Benchmarking Graph Neural Networks,2020,0.0002618917078249097,1
W2741900445,Detecting Cross-Lingual Semantic Divergence for Neural Machine Translation,2017,0.0002614813535128991,1
W3098507616,NMTPY: A Flexible Toolkit for Advanced Neural Machine Translation Systems,2017,0.0002612634214295586,1
W2807535859,Multilingual Neural Machine Translation with Task-Specific Attention,2018,0.0002612632969335866,1
W2963062480,Sparse and Constrained Attention for Neural Machine Translation,2018,0.0002608829080065647,1
W3126170988,A Transformer Self-attention Model for Time Series Forecasting,2021,0.0002605520403088414,1
W3006983028,Sparse Sinkhorn Attention,2020,0.0002602316579496376,1
W2963499882,On The Alignment Problem In Multi-Head Attention-Based Neural Machine Translation,2018,0.0002600309502760443,1
W2759511005,Neural Machine Translation for Cross-Lingual Pronoun Prediction,2017,0.00025975369088374875,1
W3133663379,AST-GCN: Attribute-Augmented Spatiotemporal Graph Convolutional Network for Traffic Forecasting,2021,0.0002590748409374182,1
W2890212927,Better Transition-Based AMR Parsing with a Refined Search Space,2018,0.0002587358966353647,1
W2986388218,Grammatical Error Correction in Low-Resource Scenarios,2019,0.0002584158577795787,1
W2768763386,Syntax-Directed Attention for Neural Machine Translation,2018,0.0002580085006711754,1
W3046368065,Multilingual Translation with Extensible Multilingual Pretraining and Finetuning,2020,0.00025778154980516743,1
W3176676637,Hierarchy-aware Label Semantics Matching Network for Hierarchical Text Classification,2021,0.00025708576581983593,1
W2968397098,DeepGCNs: Can GCNs Go as Deep as CNNs?,2019,0.0002569249020773308,1
W2984864519,BP-Transformer: Modelling Long-Range Context via Binary Partitioning,2019,0.00025671832230876265,1
W4206023940,Deep-learning-based short-term electricity load forecasting: A real case application,2022,0.0002566448977222454,1
W2996843693,Latent-Variable Non-Autoregressive Neural Machine Translation with Deterministic Inference Using a Delta Posterior,2020,0.0002563506916787652,1
W2995999067,Understanding Knowledge Distillation in Non-autoregressive Machine Translation,2019,0.0002562042586042475,1
W2759932073,Guiding Neural Machine Translation Decoding with External Knowledge,2017,0.00025554808157849827,1
W2999301586,Optimized Graph Convolution Recurrent Neural Network for Traffic Prediction,2020,0.0002543952774484985,1
W2771291973,Making sense of neural machine translation,2017,0.0002540944971148103,1
W3102475290,Dynamic Context-guided Capsule Network for Multimodal Machine Translation,2020,0.00025382240487503656,1
W2971330564,Learning to Learn and Predict: A Meta-Learning Approach for Multi-Label Classification,2019,0.00025373279496591667,1
W2963898017,CUNI System for the WMT17 Multimodal Translation Task,2017,0.00025355999985593187,1
W3015712039,A Spatial–Temporal Attention Approach for Traffic Prediction,2020,0.0002535419521383952,1
W2527133236,Lattice-Based Recurrent Neural Network Encoders for Neural Machine Translation,2017,0.0002534984910934508,1
W3034640977,Unsupervised Domain Clusters in Pretrained Language Models,2020,0.0002532444301393151,1
W2410082850,Linguistic Input Features Improve Neural Machine Translation,2016,0.0002528125265465196,1
W2757222607,When to Finish? Optimal Beam Search for Neural Text Generation (modulo beam size),2017,0.0002522929635386822,1
W3027664001,Temporal Multi-Graph Convolutional Network for Traffic Flow Prediction,2020,0.00025205507767392507,1
W2624054409,Comparing Language Related Issues for NMT and PBMT between German and English,2017,0.00025160816170566026,1
W2946179063,Incorporating Syntactic and Semantic Information in Word Embeddings using Graph Convolutional Networks,2018,0.00025135627375045714,1
W3033688252,Citywide Traffic Flow Prediction Based on Multiple Gated Spatio-temporal Convolutional Neural Networks,2020,0.00025133138113406537,1
W3114079967,DeepXML: A Deep Extreme Multi-Label Learning Framework Applied to Short Text Documents,2021,0.00025097658362443223,1
W2973065121,How to evaluate machine translation: A review of automated and human metrics,2019,0.00025089457671131644,1
W2986562961,On the use of BERT for Neural Machine Translation,2019,0.00025034854417099126,1
W2970045405,Jointly Learning to Align and Translate with Transformer Models,2019,0.0002501260272826878,1
W4385572225,Prompting PaLM for Translation: Assessing Strategies and Performance,2023,0.0002490042640636758,1
W2542860122,Bridging Neural Machine Translation and Bilingual Dictionaries,2016,0.0002486845313216453,1
W2886342729,Regularized Training Objective for Continued Training for Domain Adaptation in Neural Machine Translation,2018,0.00024850128211183713,1
W3213097325,Graph Fusion Network for Text Classification,2021,0.0002479176491940877,1
W2945735543,Improved Lexically Constrained Decoding for Translation and Monolingual Rewriting,2019,0.00024775445755522156,1
W2945383715,Overcoming Catastrophic Forgetting During Domain Adaptation of Neural Machine Translation,2019,0.0002470468715507279,1
W2972317931,GNNExplainer: Generating Explanations for Graph Neural Networks,2019,0.00024672368711310195,1
W2963665552,Breaking the Beam Search Curse: A Study of (Re-)Scoring Methods and Stopping Criteria for Neural Machine Translation,2018,0.0002457915763639567,1
W2963443683,An Effective Approach to Unsupervised Machine Translation,2019,0.00024572675808725615,1
W2956480774,R-Transformer: Recurrent Neural Network Enhanced Transformer,2019,0.00024547098380631193,1
W2889903020,Adversarial Evaluation of Multimodal Machine Translation,2018,0.00024538545489001756,1
W2913917571,Using Wikipedia Edits in Low Resource Grammatical Error Correction,2018,0.0002453322390625842,1
W3175924508,EnhanceNet: Plugin Neural Networks for Enhancing Correlated Time Series Forecasting,2021,0.00024502757878322223,1
W2963913356,Extreme Adaptation for Personalized Neural Machine Translation,2018,0.0002447291175322056,1
W2422843715,Semi-supervised Learning for Neural Machine Translation,2019,0.00024368110728706515,1
W2946068894,Soft Contextual Data Augmentation for Neural Machine Translation,2019,0.00024358839915318564,1
W4211206835,Bearing Remaining Useful Life Prediction Based on Regression Shapalet and Graph Neural Network,2022,0.00024354011228624125,1
W2886951144,Deep Patient Similarity Learning for Personalized Healthcare,2018,0.00024331636582330406,1
W2607987856,Adversarial Neural Machine Translation,2017,0.00024298524937498955,1
W4362723506,A piecewise method for bearing remaining useful life estimation using temporal convolutional networks,2023,0.0002426176698483751,1
W2963360627,Probing the Need for Visual Context in Multimodal Machine Translation,2019,0.00024227914996407027,1
W4244167344,Joint Training for Pivot-based Neural Machine Translation,2017,0.00024208045066615905,1
W2902031175,CUNI System for the WMT18 Multimodal Translation Task,2018,0.00024205510399058993,1
W2611552022,A Generalization of Convolutional Neural Networks to Graph-Structured Data,2017,0.00024159951239816828,1
W2740718109,Cost Weighting for Neural Machine Translation Domain Adaptation,2017,0.00024096918438249712,1
W2952444318,Understanding Back-Translation at Scale,2018,0.0002408771709694903,1
W3040573126,GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding,2020,0.0002408096011418576,1
W3035812575,"Deep Encoder, Shallow Decoder: Reevaluating the Speed-Quality Tradeoff in Machine Translation",2020,0.00024066452423705491,1
W2962945603,Translating Phrases in Neural Machine Translation,2017,0.00024015930465841114,1
W4389520065,Document-Level Machine Translation with Large Language Models,2023,0.0002401037549349431,1
W3175301415,Label-Specific Dual Graph Neural Network for Multi-Label Text Classification,2021,0.00023950459873332253,1
W2970963828,Pushing the Limits of Low-Resource Morphological Inflection,2019,0.00023932998052181653,1
W3099845049,TeMP: Temporal Message Passing for Temporal Knowledge Graph Completion,2020,0.00023815346672411105,1
W3175863856,Adaptive Nearest Neighbor Machine Translation,2021,0.0002373704294257721,1
W3204663006,CRAN: An Hybrid CNN-RNN Attention-Based Model for Arabic Machine Translation,2021,0.0002371366146333144,1
W3034773362,Multimodal Transformer for Multimodal Machine Translation,2020,0.00023707464216088332,1
W2594978815,Data Noising as Smoothing in Neural Network Language Models,2017,0.00023677961980128924,1
W2964098600,OpenNMT: Neural Machine Translation Toolkit,2018,0.00023609723330377086,1
W3035207248,BPE-Dropout: Simple and Effective Subword Regularization,2020,0.00023569771141740653,1
W3154414470,On the diversity of multi-head attention,2021,0.00023562499256596625,1
W2988451549,CCMatrix: Mining Billions of High-Quality Parallel Sentences on the WEB,2019,0.00023538486599516338,1
W4280581965,Intelligent tool wear prediction based on Informer encoder and stacked bidirectional gated recurrent unit,2022,0.00023519381191007403,1
W3198794504,TCCT: Tightly-coupled convolutional transformer on time series forecasting,2022,0.00023432052870118016,1
W3034871396,A Novel Graph-based Multi-modal Fusion Encoder for Neural Machine Translation,2020,0.0002342886386447847,1
W2798362442,A Call for Clarity in Reporting BLEU Scores.,2018,0.00023409901469790615,1
W2903035303,Prompsit’s submission to WMT 2018 Parallel Corpus Filtering shared task,2018,0.0002339990251240532,1
W4211185538,Neural Machine Translation,2020,0.00023373569432742398,1
W3119881489,Findings of the WMT 2023 Shared Task on Quality Estimation,2023,0.00023360383696481685,1
W2962826395,MS-UEdin Submission to the WMT2018 APE Shared Task: Dual-Source Transformer for Automatic Post-Editing,2018,0.00023337607878837747,1
W2948981900,Understanding and Improving Transformer From a Multi-Particle Dynamic System Point of View,2019,0.00023332140703735208,1
W2623559126,Using Word Embeddings to Enforce Document-Level Lexical Consistency in Machine Translation,2017,0.0002333071934233449,1
W2891924676,Three Strategies to Improve One-to-Many Multilingual Translation,2018,0.0002329373138128099,1
W2919188216,Reinforcement Learning based Curriculum Optimization for Neural Machine Translation,2019,0.00023219037751543171,1
W2909737760,Hallucinations in Neural Machine Translation,2018,0.00023187577429927198,1
W2786058094,A Bag of Useful Tricks for Practical Neural Machine Translation: Embedding Layer Initialization and Large Batch Size,2017,0.00023125980503979821,1
W2962700074,Neural System Combination for Machine Translation,2017,0.0002309839196048014,1
W2950886580,Latent Variable Model for Multi-modal Translation,2019,0.0002307456216627224,1
W2952614664,Effective Cross-lingual Transfer of Neural Machine Translation Models without Shared Vocabularies,2019,0.00023034959257302795,1
W3172787012,EEG-GNN: Graph Neural Networks for Classification of Electroencephalogram (EEG) Signals,2021,0.000229536382684886,1
W2963360736,Estimating Missing Data in Temporal Data Streams Using Multi-Directional Recurrent Neural Networks,2018,0.00022946646095407857,1
W2962807144,Multilingual Neural Machine Translation with Task-Specific Attention,2018,0.0002292236624292149,1
W2997636815,MaskGEC: Improving Neural Grammatical Error Correction via Dynamic Masking,2020,0.00022905166018690438,1
W3084095723,Unsupervised Quality Estimation for Neural Machine Translation,2020,0.00022817855929598902,1
W2946379889,Curriculum Learning for Domain Adaptation in Neural Machine Translation,2019,0.0002280473986077757,1
W2964078338,Incremental Decoding and Training Methods for Simultaneous Translation in Neural Machine Translation,2018,0.00022749558405612687,1
W4292814179,Multistep short-term wind speed forecasting using transformer,2022,0.00022736861050660201,1
W3092879656,Pop Music Transformer,2020,0.00022716164007502245,1
W3144451117,Towards achieving a delicate blending between rule-based translator and neural machine translator,2021,0.00022690573457686262,1
W3173162544,Neural Machine Translation for Low-resource Languages: A Survey,2022,0.00022639706626423648,1
W3196345400,Using SARIMA–CNN–LSTM approach to forecast daily tourism demand,2021,0.00022639336644867045,1
W2950207430,Distilling Translations with Visual Awareness,2019,0.0002262992210609504,1
W4313594913,A convolutional Transformer-based truncated Gaussian density network with data denoising for wind speed forecasting,2023,0.00022625634542478349,1
W2970925677,Multilingual Neural Machine Translation with Language Clustering,2019,0.00022611728238786308,1
W2758137671,Neural Machine Translation with Source Dependency Representation,2017,0.00022557527385157338,1
W2963824830,“Bilingual Expert” Can Find Translation Errors,2019,0.00022539218468847958,1
W2970038984,APE at Scale and Its Implications on MT Evaluation Biases,2019,0.000225211779516323,1
W2952564229,Massive Exploration of Neural Machine Translation Architectures,2017,0.0002251773555410166,1
W2952682849,On the Word Alignment from Neural Machine Translation,2019,0.0002248375771797861,1
W2997763445,Acquiring Knowledge from Pre-Trained Model to Neural Machine Translation,2020,0.00022482286030486336,1
W2912070261,Adding Interpretable Attention to Neural Translation Models Improves Word Alignment,2019,0.00022428780093892398,1
W3173549089,PhyCRNet: Physics-informed convolutional-recurrent network for solving spatiotemporal PDEs,2021,0.0002236432272419818,1
W3016635207,Understanding the Difficulty of Training Transformers,2020,0.00022363439357172383,1
W3166531985,HTCInfoMax: A Global Model for Hierarchical Text Classification via Information Maximization,2021,0.0002235710565781186,1
W2963569817,Bi-Directional Neural Machine Translation with Synthetic Parallel Data,2018,0.0002235421120005566,1
W4309154825,Transformer neural networks for interpretable flood forecasting,2022,0.0002229956435886852,1
W2905388713,A Deep Neural Network Model for Short-Term Load Forecast Based on Long Short-Term Memory Network and Convolutional Neural Network,2018,0.00022262844086022696,1
W2807482674,Period-aware content attention RNNs for time series forecasting with missing values,2018,0.00022226333085038794,1
W2612881151,Graph Convolutional Encoders for Syntax-aware Neural Machine Translation,2017,0.0002220653472912527,1
W2889545026,The MeMAD Submission to the WMT18 Multimodal Translation Task,2018,0.0002218269349537063,1
W2964053711,Linguistically Motivated Vocabulary Reduction for Neural Machine Translation from Turkish to English,2017,0.0002217247460598406,1
W3203898572,Deep learning approach towards accurate state of charge estimation for lithium-ion batteries using self-supervised transformer model,2021,0.0002216905875995476,1
W3010212250,Automated text classification of near-misses from safety reports: An improved deep learning approach,2020,0.0002212859650648201,1
W4382318973,AirFormer: Predicting Nationwide Air Quality in China with Transformers,2023,0.00022111492115945924,1
W2963897095,A Survey of Domain Adaptation for Neural Machine Translation,2018,0.00022089514373020675,1
W2969685114,Attention-based recurrent neural networks for accurate short-term and long-term dissolved oxygen prediction,2019,0.00022080665392566943,1
W3157175643,A survey on long short-term memory networks for time series prediction,2021,0.00022066011177889887,1
W2757291580,Neural Machine Translation,2020,0.00022065090494836326,1
W2971087717,Modeling Graph Structure in Transformer for Better AMR-to-Text Generation,2019,0.0002202581464913421,1
W2951309718,Densely Connected Graph Convolutional Networks for Graph-to-Sequence Learning,2019,0.0002202372832436879,1
W2897065501,Knowledge-enhanced document embeddings for text classification,2018,0.00022000245138002815,1
W3035520602,Towards Making the Most of Context in Neural Machine Translation,2020,0.00021988575508583678,1
W2963261349,Ensembling Factored Neural Machine Translation Models for Automatic Post-Editing and Quality Estimation,2017,0.00021982052089368094,1
W2964073484,Consistency by Agreement in Zero-Shot Neural Machine Translation,2019,0.00021978905037176326,1
W2951391755,AMR Parsing as Sequence-to-Graph Transduction,2019,0.00021975964681782926,1
W2962830144,Zero-Resource Neural Machine Translation with Multi-Agent Communication Game,2018,0.00021953689514466444,1
W3004515714,DDP-GCN: Multi-graph convolutional network for spatiotemporal traffic forecasting,2021,0.00021940391846380906,1
W2798060623,A novel channel-aware attention framework for multi-channel EEG seizure detection via multi-view deep learning,2018,0.0002191201846659321,1
W2963773505,A Stable and Effective Learning Strategy for Trainable Greedy Decoding,2018,0.0002190912821773792,1
W2970692082,On NMT Search Errors and Model Errors: Cat Got Your Tongue?,2019,0.00021901641026575257,1
W2976965654,Hint-Based Training for Non-Autoregressive Machine Translation,2019,0.0002189730075440042,1
W2740759433,Effective Deep Memory Networks for Distant Supervised Relation Extraction,2017,0.00021888674984917397,1
W2964204137,Multilingual Hierarchical Attention Networks for Document Classification,2017,0.00021804468043230534,1
W2789954303,On extended long short-term memory and dependent bidirectional recurrent neural network,2019,0.00021784993198445743,1
W3106321930,Pre-training Multilingual Neural Machine Translation by Leveraging Alignment Information,2020,0.00021782000345213617,1
W2992063672,A spatio-temporal decomposition based deep neural network for time series forecasting,2019,0.00021781995452233136,1
W2952103439,Translationese in Machine Translation Evaluation,2019,0.0002177116675401385,1
W2984051011,Training on Synthetic Noise Improves Robustness to Natural Noise in Machine Translation,2019,0.00021762917862255978,1
W2962717763,Exploiting Linguistic Resources for Neural Machine Translation Using Multi-task Learning,2017,0.00021705096746503532,1
W3096648221,Data Weighted Training Strategies for Grammatical Error Correction,2020,0.000215719190699637,1
W4308951285,Multivariate wind speed forecasting based on multi-objective feature selection approach and hybrid deep learning model,2022,0.0002156486656275559,1
W4285402398,Stock market index prediction using deep Transformer model,2022,0.0002155657496866932,1
W4210263262,Variational transformer-based anomaly detection approach for multivariate time series,2022,0.0002154955716656571,1
W2971487518,Computational Segmentation and Classification of Diabetic Glomerulosclerosis,2019,0.0002153928096219159,1
W3117204221,Health indicator construction by quadratic function-based deep convolutional auto-encoder and its application into bearing RUL prediction,2020,0.0002153928096219159,1
W4288720745,Survey of Graph Neural Networks and Applications,2022,0.0002153928096219159,1
W3096631793,Towards the Natural Language Processing as Spelling Correction for Offline Handwritten Text Recognition Systems,2020,0.0002153928096219159,1
W3070581385,Cryptocurrency malware hunting: A deep Recurrent Neural Network approach,2020,0.0002153928096219159,1
W4312863243,Multivariate Time Series Imputation With Transformers,2022,0.0002153928096219159,1
W3136408793,Deep learning-based tool wear prediction and its application for machining process using multi-scale feature fusion and channel attention mechanism,2021,0.0002153928096219159,1
W2964109882,An overview of word and sense similarity,2019,0.0002153928096219159,1
W2966110735,An Optimized Heterogeneous Structure LSTM Network for Electricity Price Forecasting,2019,0.0002153928096219159,1
W2998769790,Multi-energy load forecasting for regional integrated energy systems considering temporal dynamic and coupling characteristics,2020,0.0002153928096219159,1
W4396558249,Multi-Label Text Classification model integrating Label Attention and Historical Attention,2024,0.0002153928096219159,1
W3122836184,Word Alignment by Fine-tuning Embeddings on Parallel Corpora,2021,0.0002153928096219159,1
W4401474425,"Interpretable prediction, classification and regulation of water quality: A case study of Poyang Lake, China",2024,0.0002153928096219159,1
W4226322096,Interpretable Memristive LSTM Network Design for Probabilistic Residential Load Forecasting,2022,0.0002153928096219159,1
W4295125731,SOC estimation for lithium-ion battery using the LSTM-RNN with extended input and constrained output,2022,0.0002153928096219159,1
W4317569465,Forecasting energy consumption demand of customers in smart grid using Temporal Fusion Transformer (TFT),2023,0.0002153928096219159,1
W2963406157,Information Aggregation for Multi-Head Attention with Routing-by-Agreement,2019,0.00021521882474093092,1
W2962678612,ESCAPE: a Large-scale Synthetic Corpus for Automatic Post-Editing,2018,0.00021457404190872682,1
W2995154514,Generalization through Memorization: Nearest Neighbor Language Models,2020,0.00021445373285690545,1
W2952355681,The Evolved Transformer,2019,0.00021427385929444605,1
W2963172229,Contextualized Non-Local Neural Networks for Sequence Learning,2019,0.00021412949625502792,1
W2962915948,Imitation Learning for Non-Autoregressive Neural Machine Translation,2019,0.00021395958217996852,1
W2924961378,Structural Neural Encoders for,2019,0.00021374909431657433,1
W4367599042,Grammatical Error Correction: A Survey of the State of the Art,2023,0.0002134008345492004,1
W4220732012,Wind speed estimation using novelty hybrid adaptive estimation model based on decomposition and deep learning methods (ICEEMDAN-CNN),2022,0.00021322850838268137,1
W3122154272,DeLighT: Deep and Light-weight Transformer,2021,0.00021317373030369812,1
W3213920537,Log Sequence Anomaly Detection Based on Local Information Extraction and Globally Sparse Transformer Model,2021,0.00021296562571394682,1
W3005857605,Robot Navigation in Crowds by Graph Convolutional Networks With Attention Learned From Human Gaze,2020,0.0002129656257139468,1
W2552838200,Neural Machine Translation with Reconstruction,2016,0.0002129159102978002,1
W2998353611,Neural Machine Translation with Byte-Level Subwords,2020,0.000212827108361911,1
W3035586188,AMR Parsing via Graph-Sequence Iterative Inference,2020,0.00021272413837739395,1
W3214581470,Improving Neural Machine Translation by Bidirectional Training,2021,0.00021247155266562157,1
W2971302374,Improving Back-Translation with Uncertainty-based Confidence Estimation,2019,0.00021210695510813962,1
W4389777735,Hallucinations in Large Multilingual Translation Models,2023,0.00021154719421644035,1
W2786148476,Word Mover’s Embedding: From Word2Vec to Document Embedding,2018,0.0002110288627737521,1
W4283817628,Graph Neural Controlled Differential Equations for Traffic Forecasting,2022,0.00021075269781610154,1
W3174724858,Multilingual Translation from Denoising Pre-Training,2021,0.0002101582568768518,1
W2622101571,"A Linguistic Evaluation of Rule-Based, Phrase-Based, and Neural MT Engines",2017,0.00020990027639216142,1
W3090350559,A Survey of Multilingual Neural Machine Translation,2020,0.0002095200187479788,1
W2757041753,Target-side Word Segmentation Strategies for Neural Machine Translation,2017,0.0002094746238427251,1
W3101672304,A Multilingual View of Unsupervised Machine Translation,2020,0.0002090968181459678,1
W2754753494,Predictor-Estimator,2017,0.00020906629414637205,1
W2969210779,Deep Temporal Convolutional Networks for Short-Term Traffic Flow Forecasting,2019,0.00020905414464499544,1
W3119872155,Findings of the WMT 2020 Shared Task on Parallel Corpus Filtering and Alignment,2020,0.0002086689808685195,1
W2904829696,DTMT: A Novel Deep Transition Architecture for Neural Machine Translation,2019,0.00020833759478862054,1
W3173506780,Analyzing the Source and Target Contributions to Predictions in Neural Machine Translation,2021,0.00020813578200951807,1
W2965575120,Dynamic Layer Aggregation for Neural Machine Translation with Routing-by-Agreement,2019,0.000207907765138968,1
W2592864539,Neural Machine Translation and Sequence-to-sequence Models: A Tutorial,2017,0.0002077731798421765,1
W3034561418,Do Transformers Need Deep Long-Range Memory?,2020,0.0002075105016420897,1
W3164316202,Synthetic Data Generation for Grammatical Error Correction with Tagged Corruption Models,2021,0.00020729009570356183,1
W3091540052,Data Diversification: A Simple Strategy For Neural Machine Translation,2019,0.0002070898139524457,1
W3185234777,Temporal convolutional network with soft thresholding and attention mechanism for machinery prognostics,2021,0.00020704903877462045,1
W2885213066,Youdao’s Winning Solution to the NLPCC-2018 Task 2 Challenge: A Neural Machine Translation Approach to Chinese Grammatical Error Correction,2018,0.00020694122123173845,1
W2896827527,Deep Learning with Long Short-Term Memory for Time Series Prediction,2019,0.00020693533369559128,1
W3100270150,Recurrent Neural Networks for Short-Term Load Forecasting,2017,0.00020689072165788963,1
W3035214886,"On Exposure Bias, Hallucination and Domain Shift in Neural Machine Translation",2020,0.00020652987171113047,1
W2414484917,Sequence-to-Sequence Learning as Beam-Search Optimization,2016,0.0002060703625874385,1
W3034716087,On The Evaluation of Machine Translation Systems Trained With Back-Translation,2020,0.0002060524138182798,1
W2916835973,Improving Robustness of Machine Translation with Synthetic Noise,2019,0.00020600137357760438,1
W3106274667,OCR Post Correction for Endangered Language Texts,2020,0.0002059825123708762,1
W2962697716,Handling Homographs in Neural Machine Translation,2018,0.00020590740030777653,1
W2983864285,Graph Convolutional Networks with Motif-based Attention,2019,0.00020580643701895247,1
W2951977278,Assessing the Ability of Self-Attention Networks to Learn Word Order,2019,0.0002057661199897518,1
W2995416727,Phrase2Vec: Phrase embedding based on parsing,2019,0.00020571055426285115,1
W2970731908,The NiuTrans Machine Translation Systems for WMT19,2019,0.00020551559107749145,1
W2809456172,A Comparison of Transformer and Recurrent Neural Networks on Multilingual Neural Machine Translation,2018,0.0002053920236492661,1
W2952479981,Interactive Attention for Neural Machine Translation,2016,0.00020538403743787428,1
W2889404673,A Tree-based Decoder for Neural Machine Translation,2018,0.00020526939704925348,1
W2970796523,Broad-Coverage Semantic Parsing as Transduction,2019,0.00020522545743205747,1
W3174339925,An Efficient Transformer Decoder with Compressed Sub-layers,2021,0.0002052249794860393,1
W2970694516,Simple and Effective Noisy Channel Modeling for Neural Machine Translation,2019,0.00020510050794587422,1
W2997513934,Semi-Supervised Hierarchical Recurrent Graph Neural Network for City-Wide Parking Availability Prediction,2020,0.0002048611635444521,1
W2891713103,Encoding Gated Translation Memory into Neural Machine Translation,2018,0.00020473463083738245,1
W3039805635,Non-Autoregressive Machine Translation with Disentangled Context Transformer,2020,0.00020444619890855488,1
W2989571009,MUSE: Parallel Multi-Scale Attention for Sequence to Sequence Learning,2019,0.00020439896881500706,1
W2962882341,Contextual Neural Model for Translating Bilingual Multi-Speaker Conversations,2018,0.00020431906706932308,1
W3034938700,Norm-Based Curriculum Learning for Neural Machine Translation,2020,0.00020415283568053883,1
W4327977707,A meta network pruning framework for remaining useful life prediction of rocket engine bearings with temporal distribution discrepancy,2023,0.00020402589556876638,1
W2953083125,Context is Key: Grammatical Error Detection with Contextual Word Representations,2019,0.0002037836871537446,1
W4310064234,Predicting hourly PM2.5 concentrations in wildfire-prone areas using a SpatioTemporal Transformer model,2022,0.00020372868868251455,1
W2741049976,Paraphrasing Revisited with Neural Machine Translation,2017,0.000203390479307022,1
W3034351728,A Simple and Effective Unified Encoder for Document-Level Machine Translation,2020,0.00020325746826934936,1
W3105425516,CCAligned: A Massive Collection of Cross-Lingual Web-Document Pairs,2020,0.00020310114297985004,1
W3180521376,Progress in Machine Translation,2021,0.00020306517361454846,1
W4317436033,Multi-scale integrated deep self-attention network for predicting remaining useful life of aero-engine,2023,0.0002026286329998391,1
W4361190416,Self‐Curable Synaptic Ferroelectric FET Arrays for Neuromorphic Convolutional Neural Network,2023,0.00020253934294049876,1
W3116506157,TransQuest: Translation Quality Estimation with Cross-lingual Transformers,2020,0.00020233319549131656,1
W2963149635,Non-Parametric Adaptation for Neural Machine Translation,2019,0.0002022865128650511,1
W2952153923,Improved Zero-shot Neural Machine Translation via Ignoring Spurious Correlations,2019,0.00020226495346086762,1
W3213938648,Deep Attention Diffusion Graph Neural Networks for Text Classification,2021,0.0002022056955616086,1
W3034955736,Hard-Coded Gaussian Attention for Neural Machine Translation,2020,0.00020220186339714176,1
W3103334733,Understanding the Difficulty of Training Transformers,2020,0.00020216039909439902,1
W3015162217,Aligned Cross Entropy for Non-Autoregressive Machine Translation,2020,0.00020215745456040763,1
W2886776719,Regularizing Neural Machine Translation by Target-Bidirectional Agreement,2019,0.0002021473315167375,1
W2739978843,Joint Training for Pivot-Based Neural Machine Translation,2019,0.00020179913843044268,1
W3120117568,Forecasting of COVID-19 cases using deep learning models: Is it reliable and practically significant?,2021,0.00020164211358847275,1
W2963714898,Variational Recurrent Neural Machine Translation,2018,0.00020155395441035238,1
W2766184602,Emergent Translation in Multi-Agent Communication,2017,0.0002014234715450514,1
W4285245990,Improved Transformer Model for Enhanced Monthly Streamflow Predictions of the Yangtze River,2022,0.0002013167147513606,1
W2885928764,A Sequence to Sequence Learning for Chinese Grammatical Error Correction,2018,0.0002008640524601813,1
W3116890009,Synthetic data with neural machine translation for automatic correction in arabic grammar,2020,0.00020049991797391916,1
W2949920209,Freezing Subnetworks to Analyze Domain Adaptation in Neural Machine Translation,2018,0.00020042387572715323,1
W3102507836,Enhancing Context Modeling with a Query-Guided Capsule Network for Document-level Translation,2019,0.00020028614685320742,1
W4205659634,Review of Graph Neural Network in Text Classification,2021,0.0002001310699608825,1
W2951456627,STACL: Simultaneous Translation with Implicit Anticipation and Controllable Latency using Prefix-to-Prefix Framework,2019,0.00020006603676179122,1
W2768123736,Neural versus phrase-based MT quality: An in-depth analysis on English–German and English–French,2017,0.00020004840914867615,1
W4200069638,Fault diagnosis based on SPBO-SDAE and transformer neural network for rotating machinery,2021,0.0001999519381457453,1
W2970109976,Pivot-based Transfer Learning for Neural Machine Translation between Non-English Languages,2019,0.00019991093613957022,1
W2737638662,Predicting Target Language CCG Supertags Improves Neural Machine Translation,2017,0.00019970786169440618,1
W2890330768,Deep Learning-Based Multivariate Probabilistic Forecasting for Short-Term Scheduling in Power Markets,2018,0.00019959226854762894,1
W3175301726,CCMatrix: Mining Billions of High-Quality Parallel Sentences on the Web,2021,0.00019940008802949607,1
W3093345276,Incorporating BERT into Parallel Sequence Decoding with Adapters,2020,0.00019905749772734983,1
W3035289598,Jointly Masked Sequence-to-Sequence Model for Non-Autoregressive Neural Machine Translation,2020,0.00019895455511698842,1
W3080098168,HiTANet: Hierarchical Time-Aware Attention Networks for Risk Prediction on Electronic Health Records,2020,0.00019889197438178414,1
W3207377511,The Dawn of Quantum Natural Language Processing,2022,0.00019889197438178414,1
W2963499433,A Comparison of Transformer and Recurrent Neural Networks on Multilingual Neural Machine Translation,2018,0.0001984892950633777,1
W2798485145,Multi-Input Attention for Unsupervised OCR Correction,2018,0.00019818597478139265,1
W2952926545,Device Placement Optimization with Reinforcement Learning,2017,0.00019808951821835073,1
W4221044734,RR-Former: Rainfall-runoff modeling based on Transformer,2022,0.00019806693261977757,1
W2988249555,Domain Robustness in Neural Machine Translation,2019,0.00019802165337269275,1
W3092327118,Pre-training Multilingual Neural Machine Translation by Leveraging Alignment Information,2020,0.00019747787388025269,1
W3101997094,Learning a Deep Listwise Context Model for Ranking Refinement,2018,0.0001974658801252254,1
W2805493160,Marian: Cost-effective High-Quality Neural Machine Translation in C++,2018,0.00019745147842222365,1
W4392772180,Evaluation of Instagram's Neural Machine Translation for Literary Texts: An MQM-Based Analysis,2024,0.00019743625633742546,1
W3172669006,The Curious Case of Hallucinations in Neural Machine Translation,2021,0.00019692386498164179,1
W3090988182,Structure-invariant testing for machine translation,2020,0.00019680078298096073,1
W3091407209,Automatic testing and improvement of machine translation,2020,0.00019680078298096073,1
W2962982474,Scheduled Multi-Task Learning: From Syntax to Translation,2018,0.00019673717909916662,1
W3019433526,Temporal convolutional neural (TCN) network for an effective weather forecasting using time-series data from the local weather station,2020,0.00019669186301643325,1
W2587694128,Ensemble Distillation for Neural Machine Translation,2017,0.000196572382220938,1
W3035691519,Improving Transformer Models by Reordering their Sublayers,2020,0.00019597430631611447,1
W2963684875,Sequence to Sequence Mixture Model for Diverse Machine Translation,2018,0.00019597349510703475,1
W3000840023,Semi-Autoregressive Training Improves Mask-Predict Decoding,2020,0.00019585055096208213,1
W2794371820,Data-assisted reduced-order modeling of extreme events in complex dynamical systems,2018,0.00019549391691062737,1
W3155806510,RoFormer: Enhanced Transformer with Rotary Position Embedding,2021,0.00019544365328736724,1
W2605887895,A Syntactic Neural Model for General-Purpose Code Generation,2017,0.00019536190992485672,1
W2971319154,Erroneous data generation for Grammatical Error Correction,2019,0.00019527216875215786,1
W3175164646,Guiding Non-Autoregressive Neural Machine Translation Decoding with Reordering Information,2021,0.0001951990655154446,1
W2971278086,Hierarchical Modeling of Global Context for Document-Level Neural Machine Translation,2019,0.00019518036544112304,1
W4327718158,Identifying performance anomalies in fluctuating cloud environments: A robust correlative-GNN-based explainable approach,2023,0.00019509389390226877,1
W2997653844,ConCare: Personalized Clinical Feature Embedding via Capturing the Healthcare Context,2020,0.00019502495907597182,1
W4321617771,Machine translation and its evaluation: a study,2023,0.00019495715982452194,1
W2986922898,Compressive Transformers for Long-Range Sequence Modelling,2019,0.0001948488513970942,1
W4386566643,Looking for a Needle in a Haystack: A Comprehensive Study of Hallucinations in Neural Machine Translation,2023,0.00019484516311283787,1
W3023986361,Leveraging Monolingual Data with Self-Supervision for Multilingual Neural Machine Translation,2020,0.00019413237983728464,1
W2997833886,Carbon futures price forecasting based with ARIMA-CNN-LSTM model,2019,0.00019321822330814676,1
W3192648431,Temporal convolutional autoencoder for unsupervised anomaly detection in time series,2021,0.0001930386459031146,1
W4385565080,Searching for Needles in a Haystack: On the Role of Incidental Bilingualism in PaLM’s Translation Capability,2023,0.00019251104056458321,1
W3120358876,Dynamic Embedding Projection-Gated Convolutional Neural Networks for Text Classification,2021,0.00019244938338977956,1
W2963174344,Simple Fusion: Return of the Language Model,2018,0.00019229476570410537,1
W2945059185,Syntax-Enhanced Neural Machine Translation with Syntax-Aware Word Representations,2019,0.00019183732024786375,1
W2953173959,Soft Contextual Data Augmentation for Neural Machine Translation,2019,0.00019155682820268618,1
W2950940239,Domain Adaptation of Neural Machine Translation by Lexicon Induction,2019,0.00019145023493322556,1
W2902614977,Using Monolingual Data in Neural Machine Translation: a Systematic Study,2018,0.00019142779848464728,1
W3156404059,<i>Samanantar</i>: The Largest Publicly Available Parallel Corpora Collection for 11 Indic Languages,2022,0.0001910833224171936,1
W2619122421,A Regularized Framework for Sparse and Structured Neural Attention,2017,0.0001907301652277555,1
W4319029136,Learning from flowsheets: A generative transformer model for autocompletion of flowsheets,2023,0.00019071805925969908,1
W3119688269,Short-term origin-destination demand prediction in urban rail transit systems: A channel-wise attentive split-convolutional neural network method,2021,0.00019064155676171824,1
W3035464238,Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation,2020,0.0001903126409205783,1
W2970316683,Investigating Multilingual NMT Representations at Scale,2019,0.0001902116515308822,1
W4387846860,Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer SOTA for Traffic Forecasting,2023,0.00018981651499971167,1
W3035072529,On the Inference Calibration of Neural Machine Translation,2020,0.00018974944454840396,1
W2963194310,Learning to Jointly Translate and Predict Dropped Pronouns with a Shared Reconstruction Mechanism,2018,0.00018972932731384034,1
W3158381863,History-based attention in Seq2Seq model for multi-label text classification,2021,0.00018950037879156693,1
W4382364617,CrystalGPT: Enhancing system-to-system transferability in crystallization prediction and control using time-series-transformers,2023,0.00018942796480773372,1
W4290098428,Memory-augmented dynamic graph convolution networks for traffic data imputation with diverse missing patterns,2022,0.00018940713169327927,1
W3102124851,HSCNN: A Hybrid-Siamese Convolutional Neural Network for Extremely Imbalanced Multi-label Text Classification,2020,0.00018926648715837392,1
W2902608666,Alibaba Submission for WMT18 Quality Estimation Task,2018,0.00018911561903186075,1
W2553397501,Quasi-Recurrent Neural Networks,2018,0.00018910668739271442,1
W3099230264,Machine Translation using Semantic Web Technologies: A Survey,2018,0.00018908652193209283,1
W2970947975,Baidu Neural Machine Translation Systems for WMT19,2019,0.0001890739243542193,1
W2760452458,Effective Domain Mixing for Neural Machine Translation,2017,0.00018876814180432216,1
W2801219566,Human versus automatic quality evaluation of NMT and PBSMT,2018,0.00018867479184007257,1
W3101683892,Dynamic Context Selection for Document-level Neural Machine Translation via Reinforcement Learning,2020,0.00018831018702918643,1
W2970550739,Self-Attention with Structural Position Representations,2019,0.00018807007555727724,1
W3105038888,Multi-task Learning for Multilingual Neural Machine Translation,2020,0.00018802557789794697,1
W3120929527,Findings of the 2020 Conference on Machine Translation (WMT20),2020,0.00018791865564080196,1
W2963141266,Trainable Greedy Decoding for Neural Machine Translation,2017,0.00018781168823853528,1
W3174851730,Instantaneous Grammatical Error Correction with Shallow Aggressive Decoding,2021,0.00018774577399567483,1
W3209002790,Hierarchical Heterogeneous Graph Representation Learning for Short Text Classification,2021,0.00018765926294667278,1
W2948197522,Syntactically Supervised Transformers for Faster Neural Machine Translation,2019,0.00018760454781533673,1
W3023166997,Distilling Knowledge Learned in BERT for Text Generation,2019,0.00018752589591205845,1
W2971043182,The Effect of Translationese in Machine Translation Test Sets,2019,0.00018739114289054122,1
W3076947077,A Hybrid BERT Model That Incorporates Label Semantics via Adjustive Attention for Multi-Label Text Classification,2020,0.00018704156857606892,1
W3176395632,Good for Misconceived Reasons: An Empirical Revisiting on the Need for Visual Context in Multimodal Machine Translation,2021,0.00018700080868625627,1
W3170796112,Hash Layers For Large Sparse Models,2021,0.00018666901333253604,1
W3193077216,A Survey on Low-Resource Neural Machine Translation,2021,0.00018636346157211236,1
W2970558573,Findings of the First Shared Task on Machine Translation Robustness,2019,0.00018616190154213924,1
W4251616496,Proceedings of the Third Workshop on Discourse in Machine Translation,2017,0.0001861291762182888,1
W3035629723,Does Multi-Encoder Help? A Case Study on Context-Aware Neural Machine Translation,2020,0.00018608433286478168,1
W2970810442,Encoders Help You Disambiguate Word Senses in Neural Machine Translation,2019,0.00018583725667990756,1
W2945542139,Rethinking Complex Neural Network Architectures for Document Classification,2019,0.00018519281171698175,1
W3132134318,What has changed with neural machine translation? A critical review of human factors,2021,0.0001849583049608702,1
W3131110071,On Short-Term Load Forecasting Using Machine Learning Techniques and a Novel Parallel Deep LSTM-CNN Approach,2021,0.0001849360455691123,1
W2983108239,When and Why is Document-level Context Useful in Neural Machine Translation?,2019,0.00018474751132415988,1
W3125056032,Rethinking Attention with Performers,2021,0.0001846748898802883,1
W3038287124,Multi-Head Attention: Collaborate Instead of Concatenate,2021,0.00018458238096865094,1
W2971134989,Naver Labs Europe’s Systems for the WMT19 Machine Translation Robustness Task,2019,0.00018445864973928074,1
W4285114401,Contrastive Learning-Enhanced Nearest Neighbor Mechanism for Multi-Label Text Classification,2022,0.00018441946086893436,1
W4225161501,Light-weight federated learning-based anomaly detection for time-series data in industrial control systems,2022,0.00018405492020225143,1
W3035144493,Leveraging Monolingual Data with Self-Supervision for Multilingual Neural Machine Translation,2020,0.0001840329794696533,1
W2982026991,Controlling the Output Length of Neural Machine Translation,2019,0.00018393781199900464,1
W4283741809,A gated graph convolutional network with multi-sensor signals for remaining useful life prediction,2022,0.00018358126621116833,1
W3035618017,Improving Transformer Optimization Through Better Initialization,2020,0.00018349702018524602,1
W2962705709,One-Shot Neural Cross-Lingual Transfer for Paradigm Completion,2017,0.00018334646821362483,1
W3104681546,Seq2Edits: Sequence Transduction Using Span-level Edit Operations,2020,0.00018327540814793716,1
W2971141904,The MuCoW Test Suite at WMT 2019: Automatically Harvested Multilingual Contrastive Word Sense Disambiguation Test Sets for Machine Translation,2019,0.0001832329155488571,1
W2903728819,Context-Aware Self-Attention Networks,2019,0.00018300789137635655,1
W2935811960,Synchronous Bidirectional Neural Machine Translation,2019,0.00018262739406923358,1
W4283799781,Construction-Accident Narrative Classification Using Shallow and Deep Learning,2022,0.00018239113914165234,1
W3137262131,An Experimental Review on Deep Learning Architectures for Time Series Forecasting,2020,0.00018239113914165234,1
W4200099066,Traffic flow prediction models – A review of deep learning techniques,2021,0.00018239113914165234,1
W3194203264,Fastformer: Additive Attention Can Be All You Need,2021,0.00018239113914165234,1
W2970917831,Core Semantic First: A Top-down Approach for AMR Parsing,2019,0.0001820971308870046,1
W3035317912,Distilling Knowledge Learned in BERT for Text Generation,2020,0.00018203292961915357,1
W2741239863,Improved Neural Machine Translation with Source Syntax,2017,0.00018184299706100425,1
W3119175506,XLM-T: Scaling up Multilingual Machine Translation with Pretrained Cross-lingual Transformer Encoders,2020,0.0001817018253378757,1
W3193693507,Multilabel Feature Selection With Constrained Latent Structure Shared Term,2021,0.00018117754718766782,1
W2577986441,Hashtag recommendation using attention-based convolutional neural network,2016,0.00018117754718766782,1
W3105306115,Improving the Efficiency of Grammatical Error Correction with Erroneous Span Detection and Correction,2020,0.00018116758572569528,1
W2995971510,Encoding word order in complex embeddings,2019,0.00018074276312191889,1
W2888808532,Back-Translation Sampling by Targeting Difficult Words in Neural Machine Translation,2018,0.00018074173076002413,1
W3127887696,Multilingual Neural Machine Translation for Low-Resource Languages,2018,0.00018061759423276865,1
W3153395274,Machine translation systems and quality assessment: a systematic review,2021,0.00018050532939992302,1
W4280552892,Trend attention fully convolutional network for remaining useful life estimation,2022,0.00018043307694475533,1
W2936627440,Code-Switching for Enhancing NMT with Pre-Specified Translation,2019,0.0001802113166229622,1
W2964174820,What does Attention in Neural Machine Translation Pay Attention to,2017,0.00018000379354304297,1
W4283160683,Hydrological concept formation inside long short-term memory (LSTM) networks,2022,0.00017996395523368325,1
W2740553716,Neural vs. Phrase-Based Machine Translation in a Multi-Domain Scenario,2017,0.00017913145778531187,1
W2963246629,Bag-of-Words as Target for Neural Machine Translation,2018,0.0001787898260857423,1
W4383106791,GBT: Two-stage transformer framework for non-stationary time series forecasting,2023,0.00017834198380678088,1
W2997517014,Efficient Content-Based Sparse Attention with Routing Transformers,2020,0.00017813916840430296,1
W3084827186,Quality Expectations of Machine Translation,2018,0.00017796534099518468,1
W2953190730,A Compact and Language-Sensitive Multilingual Translation Method,2019,0.00017787560230025755,1
W2782920454,Predicting Multi-step Citywide Passenger Demands Using Attention-based Neural Networks,2018,0.00017785451494075507,1
W2561792472,Interactive neural machine translation,2016,0.0001777265439649176,1
W3092850823,PopMAG,2020,0.00017765913435462713,1
W3158547118,Hybrid wind speed forecasting model based on multivariate data secondary decomposition approach and deep learning algorithm with attention mechanism,2021,0.00017761024878056665,1
W2885249278,Automatic Reference-Based Evaluation of Pronoun Translation Misses the Point,2018,0.00017754839499188837,1
W3035747971,Lipschitz Constrained Parameter Initialization for Deep Transformers,2020,0.0001774264800377569,1
W3194396612,"Industrial Dataspace for smart manufacturing: connotation, key technologies, and framework",2021,0.00017740567950398577,1
W2951476960,Generalized Data Augmentation for Low-Resource Translation,2019,0.00017738240042543772,1
W2950428495,Unsupervised Bilingual Word Embedding Agreement for Unsupervised Neural Machine Translation,2019,0.0001771934438605685,1
W3175665465,Glancing Transformer for Non-Autoregressive Neural Machine Translation,2021,0.00017710879339189443,1
W2950737607,Cross-Sentence Grammatical Error Correction,2019,0.00017694365424166666,1
W3087105636,Arabic Machine Translation: A survey of the latest trends and challenges,2020,0.0001767377788492427,1
W3088611441,Deep Learning for Spatio-Temporal Data Mining: A Survey,2020,0.0001764576664339663,1
W2888902882,Cross-spectral iris recognition using CNN and supervised discrete hashing,2018,0.00017644554240064258,1
W3170851865,A survey on anomaly detection for technical systems using LSTM networks,2021,0.00017644554240064258,1
W2950858167,Sparse Sequence-to-Sequence Models,2019,0.00017612675693069185,1
W3035490389,Task-Level Curriculum Learning for Non-Autoregressive Neural Machine Translation,2020,0.00017610535934307073,1
W2997518171,Cross-Lingual Pre-Training Based Transfer for Zero-Shot Neural Machine Translation,2020,0.00017558282811278253,1
W4297509495,RUL prediction of machinery using convolutional-vector fusion network through multi-feature dynamic weighting,2022,0.00017542420181833205,1
W3019932981,Beyond 512 Tokens: Siamese Multi-depth Transformer-based Hierarchical Encoder for Long-Form Document Matching,2020,0.00017530804243391917,1
W4294982617,Temporal-Spatial Quantum Graph Convolutional Neural Network Based on Schrödinger Approach for Traffic Congestion Prediction,2022,0.00017529289161411066,1
W2964248669,Cross-linguistic differences and similarities in image descriptions,2017,0.00017503575176988049,1
W2995460523,Data-dependent Gaussian Prior Objective for Language Generation,2020,0.00017492334749023017,1
W2985301125,Exploiting Multilingualism through Multistage Fine-Tuning for Low-Resource Neural Machine Translation,2019,0.00017489374673694883,1
W4317625837,An integrated multi-head dual sparse self-attention network for remaining useful life prediction,2023,0.00017474342993203335,1
W2980216782,Unsupervised Multi-Modal Neural Machine Translation,2019,0.00017473498573910055,1
W4389519421,"Large Language Models Effectively Leverage Document-level Context for Literary Translation, but Critical Errors Persist",2023,0.0001747198433129538,1
W4385258623,Transformers in Time-Series Analysis: A Tutorial,2023,0.00017470672982227442,1
W3158058297,Transfer Learning with Graph Neural Networks for Short-Term Highway Traffic Forecasting,2021,0.00017463341753043895,1
W4221151676,Incorporating Hierarchy into Text Encoder: a Contrastive Learning Approach for Hierarchical Text Classification,2022,0.0001745619557730314,1
W3197111027,Tool wear estimation using a CNN-transformer model with semi-supervised learning,2021,0.0001745282678800499,1
W2963583256,Code-Switching for Enhancing,2019,0.00017436255892012818,1
W3208180646,A Unified View on Graph Neural Networks as Graph Signal Denoising,2021,0.00017433449470081818,1
W2911831256,Mining Likely Analogical APIs Across Third-Party Libraries via Large-Scale Unsupervised API Semantics Embedding,2019,0.00017433449470081818,1
W4289779195,Muformer: A long sequence time-series forecasting model based on modified multi-head attention,2022,0.00017428613997955567,1
W3135794967,Deep sequence to sequence Bi-LSTM neural networks for day-ahead peak load forecasting,2021,0.00017414072152158647,1
W4323975488,Attention-augmented recalibrated and compensatory network for machine remaining useful life prediction,2023,0.0001740473682943569,1
W3102516861,Beam Search Strategies for Neural Machine Translation,2017,0.0001739515403331097,1
W4283726963,Efficient temporal flow Transformer accompanied with multi-head probsparse self-attention mechanism for remaining useful life prognostics,2022,0.00017303781126191652,1
W3024508854,A Comprehensive Survey of Grammar Error Correction,2020,0.00017294301023098582,1
W2894741346,Seq2Slate: Re-ranking and Slate Optimization with RNNs,2018,0.00017292712956760192,1
W2972799129,"Enabling Robust Grammatical Error Correction in New Domains: Data Sets, Metrics, and Analyses",2019,0.000172912452702028,1
W4280582438,Contrastive Graph Convolutional Networks with adaptive augmentation for text classification,2022,0.00017274525808009001,1
W3036839309,Cross-lingual Retrieval for Iterative Self-Supervised Training,2020,0.00017247006011101624,1
W3155328257,A Graph-Based Temporal Attention Framework for Multi-Sensor Traffic Flow Forecasting,2021,0.00017233155337327197,1
W2902537726,Coreference and Coherence in Neural Machine Translation: A Study Using Oracle Experiments,2018,0.00017213365341291163,1
W3170261818,DA-Transformer: Distance-aware Transformer,2021,0.00017181317001465317,1
W3003446182,AMR-To-Text Generation with Graph Transformer,2020,0.00017180703719576774,1
W3035463087,End-to-End Neural Word Alignment Outperforms GIZA++,2020,0.00017175485468017219,1
W3163644064,Testing Machine Translation via Referential Transparency,2021,0.0001714381775484002,1
W2889841884,Cross-lingual Decompositional Semantic Parsing,2018,0.0001713655529776089,1
W3174794493,Hi-Transformer: Hierarchical Interactive Transformer for Efficient and Effective Long Document Modeling,2021,0.00017130593990607833,1
W4226283934,Sparse Structure Learning via Graph Neural Networks for Inductive Document Classification,2022,0.0001712276324134095,1
W2983981554,From Research to Production and Back: Ludicrously Fast Neural Machine Translation,2019,0.00017118909517375546,1
W2994772196,Multimodal machine translation through visuals and speech,2020,0.00017117454699475452,1
W2970682957,Multi-Granularity Self-Attention for Neural Machine Translation,2019,0.0001709488179928099,1
W3201295503,"BERT, mBERT, or BiBERT? A Study on Contextualized Embeddings for Neural Machine Translation",2021,0.00017091058844130328,1
W2963792777,Memory-augmented Neural Machine Translation,2017,0.00017086788772467543,1
W2971287409,One Model to Learn Both: Zero Pronoun Prediction and Translation,2019,0.00017082175591644303,1
W2975711469,Monotonic Multihead Attention,2019,0.00017068228463053392,1
W4293370556,Incremental Learning for Remaining Useful Life Prediction via Temporal Cascade Broad Learning System With Newly Acquired Data,2022,0.00017058152101224146,1
W3153224075,Applying the Transformer to Character-level Transduction,2021,0.00017058152101224146,1
W3176120057,Selective Knowledge Distillation for Neural Machine Translation,2021,0.00017029796123560153,1
W4200585851,A Comprehensive Survey of Grammatical Error Correction,2021,0.00017026840938886087,1
W3092632253,MLQE-PE: A Multilingual Quality Estimation and Post-Editing Dataset.,2020,0.00017004469566131886,1
W4283739673,Bidirectional Spatial-Temporal Adaptive Transformer for Urban Traffic Flow Forecasting,2022,0.00016919047094954694,1
W4294350997,Pavement anomaly detection based on transformer and self-supervised learning,2022,0.00016919047094954694,1
W2605202026,Neural Lattice-to-Sequence Models for Uncertain Inputs,2017,0.00016904782075739938,1
W3041269366,Massive Exploration of Pseudo Data for Grammatical Error Correction,2020,0.00016894125008207756,1
W2899490399,Improving Zero-Shot Translation of Low-Resource Languages,2018,0.00016892124309758247,1
W3177172118,Fully Non-autoregressive Neural Machine Translation: Tricks of the Trade,2021,0.0001689095774516487,1
W3129918875,Cognitive structure learning model for hierarchical multi-label text classification,2021,0.00016885379967509863,1
W3042199843,Better Document-Level Machine Translation with Bayes’ Rule,2020,0.00016869327608513303,1
W2985204668,Zero-Resource Neural Machine Translation with Monolingual Pivot Data,2019,0.0001686232265746552,1
W2952524847,Exploiting Sentential Context for Neural Machine Translation,2019,0.0001686223821956439,1
W4224921333,MuCGEC: a Multi-Reference Multi-Source Evaluation Dataset for Chinese Grammatical Error Correction,2022,0.0001684704202624678,1
W4313059808,Dual-Attention-Based Multiscale Convolutional Neural Network With Stage Division for Remaining Useful Life Prediction of Rolling Bearings,2022,0.0001684572644950117,1
W2951338945,Shared-Private Bilingual Word Embeddings for Neural Machine Translation,2019,0.00016841744781815032,1
W4205163778,Automatic Arabic Grammatical Error Correction based on Expectation-Maximization routing and target-bidirectional agreement,2022,0.0001683395744155592,1
W3181262653,Long-Short Transformer: Efficient Transformers for Language and Vision,2021,0.00016826349450720725,1
W2970328625,Controlling Text Complexity in Neural Machine Translation,2019,0.00016825828386825989,1
W3119000810,The Tatoeba Translation Challenge – Realistic Data Sets for Low Resource and Multilingual MT,2020,0.00016791886014567715,1
W2988390689,Minimally-Augmented Grammatical Error Correction,2019,0.00016773331511848934,1
W4224981792,Short-term wind speed forecasting based on spatial-temporal graph transformer networks,2022,0.0001674701284285205,1
W3000965575,PMIndia -- A Collection of Parallel Corpora of Languages of India,2020,0.00016666339305709458,1
W2885950361,The Sockeye 2 Neural Machine Translation Toolkit at AMTA 2020,2020,0.00016665071040981587,1
W2971270287,Novel positional encodings to enable tree-based transformers,2019,0.0001666272609702259,1
W2950651087,Effective Adversarial Regularization for Neural Machine Translation,2019,0.00016660792279689864,1
W2984500026,Data augmentation using back-translation for context-aware neural machine translation,2019,0.00016653044464516942,1
W2798465082,Adaptive Knowledge Sharing in Multi-Task Learning: Improving Low-Resource Neural Machine Translation,2018,0.00016617834608677792,1
W4307646385,Multimodality information fusion for automated machine translation,2022,0.00016611935496470834,1
W3111507638,Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting,2020,0.00016609388289495734,1
W3102696737,StageNet: Stage-Aware Neural Networks for Health Risk Prediction,2020,0.00016608276202025932,1
W2224454470,Language to Logical Form with Neural Attention,2016,0.00016606663266036808,1
W4286433681,Real-Time Locational Detection of Stealthy False Data Injection Attack in Smart Grid: Using Multivariate-Based Multi-Label Classification Approach,2022,0.00016589030390152062,1
W3109714359,Step-Wise Deep Learning Models for Solving Routing Problems,2020,0.00016589030390152062,1
W2998423439,Learning Backtrackless Aligned-Spatial Graph Convolutional Networks for Graph Classification,2020,0.00016589030390152062,1
W3142970463,Short-term wind power prediction based on multidimensional data cleaning and feature reconfiguration,2021,0.00016589030390152062,1
W4389130441,Introducing Hybrid Modeling with Time-Series-Transformers: A Comparative Study of Series and Parallel Approach in Batch Crystallization,2023,0.00016589030390152062,1
W3199657116,ConAnomaly: Content-Based Anomaly Detection for System Logs,2021,0.00016589030390152062,1
W4401334701,Regularization in machine learning models for MVT Pb-Zn prospectivity mapping: applying lasso and elastic-net algorithms,2024,0.00016589030390152062,1
W3201749075,"DexRay: A Simple, yet Effective Deep Learning Approach to Android Malware Detection Based on Image Representation of Bytecode",2021,0.00016589030390152062,1
W4382119071,MLog: Mogrifier LSTM-Based Log Anomaly Detection Approach Using Semantic Representation,2023,0.00016589030390152062,1
W3007385124,Using a thousand optimization tasks to learn hyperparameter search strategies,2020,0.00016589030390152062,1
W3005741980,Comparative study of landslide susceptibility mapping with different recurrent neural networks,2020,0.00016589030390152062,1
W4280605518,An ensemble and shared selective adversarial network for partial domain fault diagnosis of machinery,2022,0.00016589030390152062,1
W4309774299,State of health estimation of lithium-ion batteries with a temporal convolutional neural network using partial load profiles,2022,0.00016589030390152062,1
W4323020850,Enhancing Text Classification by Graph Neural Networks With Multi-Granular Topic-Aware Graph,2023,0.00016589030390152062,1
W4321793562,A domain adaptation approach for resume classification using graph attention networks and natural language processing,2023,0.00016589030390152062,1
W4387967410,Applicability analysis of transformer to wind speed forecasting by a novel deep learning framework with multiple atmospheric variables,2023,0.00016589030390152062,1
W3101036738,Sparse Communication for Distributed Gradient Descent,2017,0.00016589030390152062,1
W3170962599,Semantics aware adversarial malware examples generation for black-box attacks,2021,0.00016589030390152062,1
W3026718724,Malware-Detection Method with a Convolutional Recurrent Neural Network Using Opcode Sequences,2020,0.00016589030390152062,1
W2946575095,Interpretable deep learning to map diagnostic texts to ICD-10 codes,2019,0.00016589030390152062,1
W4402263650,R-CAID: Embedding Root Cause Analysis within Provenance-based Intrusion Detection,2024,0.00016589030390152062,1
W4283385419,SOC estimation of Li-ion battery using convolutional neural network with U-Net architecture,2022,0.00016589030390152062,1
W4385452886,State-of-Charge Estimation and Health Prognosis for Lithium-Ion Batteries Based on Temperature-Compensated Bi-LSTM Network and Integrated Attention Mechanism,2023,0.00016589030390152062,1
W4400261301,Graph neural networks for text classification: a survey,2024,0.0001658903039015206,1
W4384936350,Deep learning methods for atmospheric PM2.5 prediction: A comparative study of transformer and CNN-LSTM-attention,2023,0.0001658903039015206,1
W3119746927,Efficient Object-Level Visual Context Modeling for Multimodal Machine Translation: Masking Irrelevant Objects Helps Grounding,2021,0.0001658003332369191,1
W3105912780,CSP:Code-Switching Pre-training for Neural Machine Translation,2020,0.00016566598606446655,1
W2901987885,Translators’ perceptions of literary post-editing using statistical and neural machine translation,2018,0.0001655449608341338,1
W3041181542,Deep Learning for Arabic Error Detection and Correction,2020,0.0001655097524402892,1
W3035577668,AdvAug: Robust Adversarial Augmentation for Neural Machine Translation,2020,0.00016540433233487473,1
W3093816530,Enriching the transfer learning with pre-trained lexicon embedding for low-resource neural machine translation,2021,0.00016539018791427392,1
W3113715281,Understanding and Improving Lexical Choice in Non-Autoregressive Translation,2020,0.00016528258176743576,1
W2964334713,Neural Machine Translation Leveraging Phrase-based Models in a Hybrid Search,2017,0.00016517324705358612,1
W3035531963,Bilingual Dictionary Based Neural Machine Translation without Using Parallel Sentences,2020,0.00016513841893285355,1
W2951451051,Massively Multilingual Neural Machine Translation,2019,0.00016492022177047217,1
W2995746049,Revisiting Self-Training for Neural Sequence Generation,2020,0.0001643052688235188,1
W3035019713,Balancing Training for Multilingual Neural Machine Translation,2020,0.00016382748774231907,1
W3092476034,A Multi-Stream Feature Fusion Approach for Traffic Prediction,2020,0.00016382488905243846,1
W2971154170,Towards Understanding Neural Machine Translation with Word Importance,2019,0.00016371185372602765,1
W3034789084,Dynamic Programming Encoding for Subword Segmentation in Neural Machine Translation,2020,0.00016370871029911763,1
W4385569744,DiffusionBERT: Improving Generative Masked Language Models with Diffusion Models,2023,0.0001635330417243589,1
W4385571393,SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control,2023,0.0001635330417243589,1
W4388116457,Hidformer: Hierarchical dual-tower transformer using multi-scale mergence for long-term time series forecasting,2023,0.0001635330417243589,1
W2971031524,Explicit Cross-lingual Pre-training for Unsupervised Machine Translation,2019,0.0001635278946690739,1
W2890560993,FRAGE: Frequency-Agnostic Word Representation,2018,0.00016348512985700384,1
W4388018399,Improve label embedding quality through global sensitive GAT for hierarchical text classification,2023,0.00016321606275815538,1
W4365813991,Exploring the potential of time-series transformers for process modeling and control in chemical systems: An inevitable paradigm shift?,2023,0.00016296919546989605,1
W4385573965,Linguistic Rules-Based Corpus Generation for Native Chinese Grammatical Error Correction,2022,0.00016269488445414885,1
W3030384960,Benchmarking Neural and Statistical Machine Translation on Low-Resource African Languages,2020,0.00016267795642480024,1
W2978824654,Controlling the Reading Level of Machine Translation Output,2019,0.00016249468607990264,1
W2992505801,Why ADAM Beats SGD for Attention Models,2019,0.0001624915660193518,1
W2883386157,Error Classification and Analysis for Machine Translation Quality Assessment,2018,0.00016232716570616844,1
W3116864188,Improving Grammatical Error Correction with Data Augmentation by Editing Latent Representation,2020,0.00016200607113052396,1
W2971254483,NICT’s Unsupervised Neural and Statistical Machine Translation Systems for the WMT19 News Translation Task,2019,0.00016200167660344753,1
W2995558462,Neural Machine Translation with Universal Visual Representation,2020,0.00016190594168756875,1
W4280565829,Dynamic graph convolutional networks based on spatiotemporal data embedding for traffic flow forecasting,2022,0.00016176509509148766,1
W3113146152,Encoder-Decoder Models Can Benefit from Pre-trained Masked Language Models in Grammatical Error Correction,2020,0.00016175819385768147,1
W3088331602,Decoding Strategies for Improving Low-Resource Machine Translation,2020,0.0001616805094224531,1
W3101155369,Self-Paced Learning for Neural Machine Translation,2020,0.00016156747501564882,1
W3175663427,Compound Word Transformer: Learning to Compose Full-Song Music over Dynamic Directed Hypergraphs,2021,0.0001615086210394579,1
W3212044575,Multi-Class Grammatical Error Detection for Correction: A Tale of Two Systems,2021,0.0001614164638399588,1
W2971296520,Saliency-driven Word Alignment Interpretation for Neural Machine Translation,2019,0.0001614011593115501,1
W3111294584,Deep Learning-Based Weather Prediction: A Survey,2020,0.0001612501920957062,1
W3215560629,Bert-Enhanced Text Graph Neural Network for Classification,2021,0.00016114006345360388,1
W2740087922,Chunk-based Decoder for Neural Machine Translation,2017,0.0001610273022252395,1
W2995428172,Monotonic Multihead Attention,2020,0.00016097704962389354,1
W3104890489,Improving AMR Parsing with Sequence-to-Sequence Pre-training,2020,0.00016094556282641225,1
W3181655313,Improving the accuracy of global forecasting models using time series data augmentation,2021,0.00016094005332948106,1
W3102657423,"If beam search is the answer, what was the question?",2020,0.0001608692707676005,1
W2995273672,Are Transformers universal approximators of sequence-to-sequence functions?,2020,0.00016083102160201603,1
W3134307371,Pretrained Transformers as Universal Computation Engines,2021,0.0001607955356266375,1
W3120329789,BERT Enhanced Neural Machine Translation and Sequence Tagging Model for Chinese Grammatical Error Diagnosis,2020,0.0001607676320594525,1
W3016697633,ETC: Encoding Long and Structured Inputs in Transformers,2020,0.00016042738672817627,1
W3120283405,A Hybrid Residual Dilated LSTM and Exponential Smoothing Model for Midterm Electric Load Forecasting,2021,0.00016039002548814334,1
W3176913643,Neural Machine Translation with Monolingual Translation Memory,2021,0.00016030983551545348,1
W2759461255,Adapting Neural Machine Translation with Parallel Synthetic Data,2017,0.0001602297668106926,1
W2884083742,Dependency-to-Dependency Neural Machine Translation,2018,0.0001598596945703421,1
W3046835050,DeLighT: Very Deep and Light-weight Transformer,2020,0.0001598419116221615,1
W3034201598,Uncertainty-Aware Curriculum Learning for Neural Machine Translation,2020,0.00015980756584806053,1
W2890585661,SQL-to-Text Generation with Graph-to-Sequence Model,2018,0.00015970502771948817,1
W4287855135,Frustratingly Easy System Combination for Grammatical Error Correction,2022,0.00015966954764189928,1
W2995509042,Geom-GCN: Geometric Graph Convolutional Networks,2020,0.00015963841852156976,1
W2962878352,Fine-grained attention mechanism for neural machine translation,2018,0.00015959816204363272,1
W3098985395,Scheduled DropHead: A Regularization Method for Transformer Models,2020,0.0001595930439048151,1
W3173190788,Contrastive Learning for Many-to-many Multilingual Neural Machine Translation,2021,0.00015950508623969236,1
W3035254119,"In Neural Machine Translation, What Does Transfer Learning Transfer?",2020,0.00015931472298293554,1
W4291910369,Learning All Dynamics: Traffic Forecasting via Locality-Aware Spatio-Temporal Joint Transformer,2022,0.00015928996980546788,1
W2998547639,Generating Diverse Translation by Manipulating Multi-Head Attention,2020,0.00015926200773892972,1
W3100268441,Sequence-Level Mixed Sample Data Augmentation,2020,0.00015921795148797895,1
W2949745489,Neural Machine Translation with Reordering Embeddings,2019,0.00015903178942643282,1
W2985165968,"Domain, Translationese and Noise in Synthetic Data for Neural Machine Translation",2019,0.00015878374865434554,1
W3002730961,Hourly Heat Load Prediction Model Based on Temporal Convolutional Neural Network,2020,0.00015877190288283058,1
W3126425262,Nearest Neighbor Machine Translation,2021,0.00015858071208968354,1
W2525907473,Semantic Tagging with Deep Residual Networks,2016,0.0001584717943559679,1
W2892244498,Multi-Domain Neural Machine Translation with Word-Level Domain Context Discrimination,2018,0.00015835306186389868,1
W2970646865,Auto-Encoding Variational Neural Machine Translation,2019,0.00015830082553646742,1
W2937808806,Mask-Predict: Parallel Decoding of Conditional Masked Language Models.,2019,0.00015776210612594146,1
W4320480791,A contrastive learning framework enhanced by unlabeled samples for remaining useful life prediction,2023,0.00015763988628145472,1
W4214606007,Relational Graph Convolutional Network for Text-Mining-Based Accident Causal Classification,2022,0.0001576398862814547,1
W4389937650,Multi-label text classification based on semantic-sensitive graph convolutional network,2023,0.0001576398862814547,1
W4320036691,Time-series anomaly detection with stacked Transformer representations and 1D convolutional network,2023,0.0001576398862814547,1
W3174160883,Fast and Accurate Neural Machine Translation with Translation Memory,2021,0.00015762076819025321,1
W3106146701,A Set of Recommendations for Assessing Human–Machine Parity in Language Translation,2020,0.0001574684366737856,1
W3164747806,TranSmart: A Practical Interactive Machine Translation System,2021,0.00015737144372344168,1
W2952474700,Dynamically Composing Domain-Data Selection with Clean-Data Selection by “Co-Curricular Learning” for Neural Machine Translation,2019,0.0001572133699265393,1
W3173691187,G-Transformer for Document-Level Machine Translation,2021,0.00015719958855062944,1
W3113488190,Optimizing Transformer for Low-Resource Neural Machine Translation,2020,0.00015702196066380954,1
W3120951354,Two-Phase Cross-Lingual Language Model Fine-Tuning for Machine Translation Quality Estimation.,2020,0.00015668823465647943,1
W3136101012,Wind Power Forecasting Using Attention-Based Recurrent Neural Networks: A Comparative Study,2021,0.00015660659262565292,1
W3163721282,Relative Positional Encoding for Transformers with Linear Complexity,2021,0.0001566028673131832,1
W4392623252,Unsupervised Multimodal Machine Translation for Low-resource Distant Language Pairs,2024,0.00015646125519287385,1
W4293428450,Fine-Grained Vessel Traffic Flow Prediction With a Spatio-Temporal Multigraph Convolutional Network,2022,0.00015642629432747015,1
W4320232838,RPConvformer: A novel Transformer-based deep neural networks for traffic flow prediction,2023,0.00015642629432747015,1
W2964972381,Graph-based Neural Sentence Ordering,2019,0.00015635152582483774,1
W2970311224,Exploiting Monolingual Data at Scale for Neural Machine Translation,2019,0.0001563317588141635,1
W4292595872,Improving Readability for Automatic Speech Recognition Transcription,2022,0.00015618228937031416,1
W4322755838,Long-term traffic flow forecasting using a hybrid CNN-BiLSTM model,2023,0.00015598980275744153,1
W2972529197,Sequence-to-sequence Pre-training with Data Augmentation for Sentence Rewriting,2019,0.00015598371899489964,1
W3118026775,Is MAP Decoding All You Need? The Inadequacy of the Mode in Neural Machine Translation,2020,0.00015598216503692609,1
W2951352467,A Retrieve-and-Edit Framework for Predicting Structured Outputs,2018,0.00015593294562220268,1
W2921311659,Neutron: An Implementation of the Transformer Translation Model and its Variants,2019,0.00015553913514494515,1
W2964091381,Addressing word-order Divergence in Multilingual Neural Machine Translation for extremely Low Resource Languages,2019,0.0001555364310180587,1
W3034881347,Simple and Effective Retrieve-Edit-Rerank Text Generation,2020,0.0001555012869842197,1
W2951563833,Leveraging Local and Global Patterns for Self-Attention Networks,2019,0.00015548952910506933,1
W3181186005,Combiner: Full Attention Transformer with Sparse Computation Cost,2021,0.00015536477111955776,1
W2902582221,A Pronoun Test Suite Evaluation of the English–German MT Systems at WMT 2018,2018,0.00015534020522873143,1
W3183572711,Spatio-Temporal Graph Neural Networks for Multi-Site PV Power Forecasting,2021,0.00015528262410429303,1
W3153805297,Recipes for Adapting Pre-trained Monolingual and Multilingual Models to Machine Translation,2021,0.0001552730541629277,1
W2949952652,Incorporating Syntactic and Semantic Information in Word Embeddings using Graph Convolutional Networks,2019,0.00015509997341465456,1
W3156394741,Cross-lingual Visual Pre-training for Multimodal Machine Translation,2021,0.00015504193962564457,1
W4319998033,A Parallel Hybrid Neural Network With Integration of Spatial and Temporal Features for Remaining Useful Life Prediction in Prognostics,2023,0.00015494337011352224,1
W3034425996,ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine Translation,2020,0.00015492175241299262,1
W3174255604,Rejuvenating Low-Frequency Words: Making the Most of Parallel Data in Non-Autoregressive Translation,2021,0.00015484107688211929,1
W2885301267,Automatic Spelling Correction for Resource-Scarce Languages using Deep Learning,2018,0.00015479871393259202,1
W2564861257,Source sentence simplification for statistical machine translation,2016,0.0001545302925351708,1
W3104273515,Language Model Prior for Low-Resource Neural Machine Translation,2020,0.00015449749336822813,1
W3173367141,Progressive Multi-Granularity Training for Non-Autoregressive Translation,2021,0.00015440072476062167,1
W4224983774,Time-series analysis with smoothed Convolutional Neural Network,2022,0.0001543501713703958,1
W2570431255,Aspect-augmented Adversarial Networks for Domain Adaptation,2017,0.0001542541058448483,1
W2947898088,A Generalized Framework of Sequence Generation with Application to Undirected Sequence Models,2019,0.00015415476149431714,1
W4283765700,Remaining useful life prediction of bearings by a new reinforced memory GRU network,2022,0.00015415236460812623,1
W3103544486,Reference Language based Unsupervised Neural Machine Translation,2020,0.00015414967404951883,1
W2920812691,Cloze-driven Pretraining of Self-attention Networks,2019,0.00015408320955634174,1
W4285006563,Deep imbalanced regression using cost-sensitive learning and deep feature transfer for bearing remaining useful life estimation,2022,0.00015408068577210971,1
W3194075177,Spatio-Temporal Graph Contrastive Learning,2021,0.00015403549673849895,1
W3080466448,AutoST: Efficient Neural Architecture Search for Spatio-Temporal Prediction,2020,0.00015403549673849895,1
W3104976898,Statistical Power and Translationese in Machine Translation Evaluation,2020,0.00015384779320557276,1
W4308150438,Recurrent attention unit: A new gated recurrent unit for long-term memory of important parts in sequential data,2022,0.00015371111598618523,1
W3172096628,UniDrop: A Simple yet Effective Technique to Improve Transformer without Extra Cost,2021,0.00015359100292954527,1
W3035313462,Unsupervised Multimodal Neural Machine Translation with Pseudo Visual Pivoting,2020,0.00015347558745664177,1
W3174401451,Shortformer: Better Language Modeling using Shorter Inputs,2021,0.00015345618457091698,1
W3174481817,Self-Training Sampling with Monolingual Data Uncertainty for Neural Machine Translation,2021,0.00015330888697225674,1
W2799493995,Post-editing Effort of a Novel With Statistical and Neural Machine Translation,2018,0.00015327729009321096,1
W3014432386,Low Resource Neural Machine Translation: A Benchmark for Five African Languages,2020,0.00015323966387478777,1
W2899181341,Learning to Actively Learn Neural Machine Translation,2018,0.00015314432473460178,1
W2970247882,Incorporating Source Syntax into Transformer-Based Neural Machine Translation,2019,0.0001530076705535485,1
W3198189804,Survey of Low-Resource Machine Translation,2022,0.0001529428887134329,1
W2964022663,Identifying Semantic Divergences in Parallel Text without Annotations,2018,0.0001528487782905344,1
W4318317809,Interpretable local flow attention for multi-step traffic flow prediction,2023,0.00015268963570941516,1
W3176189116,Search to aggregate neighborhood for graph neural network,2021,0.00015243052241172307,1
W4285186957,Convolutional Transformer: An Enhanced Attention Mechanism Architecture for Remaining Useful Life Estimation of Bearings,2022,0.00015233673001873347,1
W3035113230,Hyperbolic Capsule Networks for Multi-Label Classification,2020,0.00015213960786807746,1
W2902545332,The Word Sense Disambiguation Test Suite at WMT18,2018,0.00015184630856118024,1
W2962955856,Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback,2017,0.00015183446923908793,1
W2963777589,Robust Neural Machine Translation with Joint Textual and Phonetic Embedding,2019,0.000151745116954019,1
W3037230882,Grammatical Error Correction Using Pseudo Learner Corpus Considering Learner’s Error Tendency,2020,0.00015167895368771637,1
W2899015110,Multilingual NMT with a Language-Independent Attention Bridge,2019,0.00015153395566227894,1
W4285241608,On Vision Features in Multimodal Machine Translation,2022,0.00015149059993221234,1
W2803739890,Sentence Selection and Weighting for Neural Machine Translation Domain Adaptation,2018,0.00015141750669284596,1
W2593543827,Enabling Multi-Source Neural Machine Translation By Concatenating Source Sentences In Multiple Languages.,2017,0.00015140398441862364,1
W4386600757,Towards better Chinese-centric neural machine translation for low-resource languages,2023,0.00015132741283910392,1
W2890244613,Addressing Troublesome Words in Neural Machine Translation,2018,0.00015128712993340662,1
W2805490244,Meaningless yet meaningful: Morphology grounded subword-level NMT,2018,0.0001512306999329182,1
W2971073020,NICT’s Supervised Neural Machine Translation Systems for the WMT19 News Translation Task,2019,0.00015113201355803138,1
W3035636774,Improving Neural Machine Translation with Soft Template Prediction,2020,0.00015111580724764696,1
W3176948526,RealFormer: Transformer Likes Residual Attention,2021,0.00015104801122051598,1
W4381245607,TSMixer: Lightweight MLP-Mixer Model for Multivariate Time Series Forecasting,2023,0.000151039552185402,1
W3122317902,GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding,2021,0.0001510308475936835,1
W2946028745,Improving Neural Machine Translation with Neural Syntactic Distance,2019,0.0001506359998264796,1
W4287889965,Quality-Aware Decoding for Neural Machine Translation,2022,0.00015058492264547884,1
W2807230608,Multimodal Lexical Translation.,2018,0.00015053820200905543,1
W4387641291,RT-GCN: Gaussian-based spatiotemporal graph convolutional network for robust traffic prediction,2023,0.0001503323735322535,1
W2989276524,Recycling a Pre-trained BERT Encoder for Neural Machine Translation,2019,0.0001502451454331799,1
W3035540807,Lexically Constrained Neural Machine Translation with Levenshtein Transformer,2020,0.00015021875908183074,1
W2988435740,Low-Rank and Locality Constrained Self-Attention for Sequence Modeling,2019,0.00015020481249193823,1
W4385571264,In-context Examples Selection for Machine Translation,2023,0.00015013824213969037,1
W3171649327,A Survey of Transformers.,2021,0.00015010389972384,1
W3034363136,A Study of Non-autoregressive Model for Sequence Generation,2020,0.00014994048733443674,1
W3207091856,Why don’t people use character-level machine translation?,2022,0.00014985043283720004,1
W3034474651,Tagged Back-translation Revisited: Why Does It Really Work?,2020,0.0001496596427387089,1
W2971046749,INMT: Interactive Neural Machine Translation Prediction,2019,0.00014957523048273158,1
W3102823002,Gradient-guided Unsupervised Lexically Constrained Text Generation,2020,0.00014945983548020567,1
W3160936371,Parallel spatio-temporal attention-based TCN for multivariate time series prediction,2021,0.0001494499649303687,1
W4285791425,Health state assessment of bearing with feature enhancement and prediction error compensation strategy,2022,0.00014938946866138882,1
W4225526013,TSMAE: A Novel Anomaly Detection Approach for Internet of Things Time Series Data Using Memory-Augmented Autoencoder,2022,0.00014938946866138882,1
W3216280806,An uncertainty-informed framework for trustworthy fault diagnosis in safety-critical applications,2022,0.00014938946866138882,1
W4319074069,MFSJMI: Multi-label feature selection considering join mutual information and interaction weight,2023,0.00014938946866138882,1
W4381195314,Artificial Intelligence based Arabic-to-English machine versus human translation of poetry: An analytical study of outcomes,2023,0.00014938946866138882,1
W4312254454,Unleashing Transformers: Parallel Token Prediction with Discrete Absorbing Diffusion for Fast High-Resolution Image Generation from Vector-Quantized Codes,2022,0.00014938946866138882,1
W4391880899,A Hybrid Model Based on Convolutional Neural Network and Long Short-Term Memory for Multi-label Text Classification,2024,0.00014938946866138882,1
W3161072801,Heterogeneous Graph Propagation Network,2021,0.00014938946866138882,1
W4206266728,DeepAG: Attack Graph Construction and Threats Prediction With Bi-Directional Deep Learning,2022,0.00014938946866138882,1
W2981025102,A Novel Machine Learning Method Based Approach for Li-Ion Battery Prognostic and Health Management,2019,0.00014938946866138882,1
W3131623996,Relational Graph Learning for Crowd Navigation,2020,0.00014938946866138882,1
W4320016113,A Voyage on Neural Machine Translation for Indic Languages,2023,0.00014938946866138882,1
W3116268267,On the eigenvector bias of Fourier feature networks: From regression to solving multi-scale PDEs with physics-informed neural networks,2021,0.00014938946866138882,1
W4385835130,The Personal Health Applications of Machine Learning Techniques in the Internet of Behaviors,2023,0.00014938946866138882,1
W4288046368,Multi-modal knowledge graphs representation learning via multi-headed self-attention,2022,0.00014938946866138882,1
W4394814366,Artificial Intelligence in Academic Translation: A Comparative Study of Large Language Models and Google Translate,2024,0.00014938946866138882,1
W4280591062,TFGAN: Traffic forecasting using generative adversarial network with multi-graph convolutional network,2022,0.00014938946866138882,1
W4387775568,Label correlations-based multi-label feature selection with label enhancement,2023,0.00014938946866138882,1
W4387557574,Interpreting runoff forecasting of long short-term memory network: An investigation using the integrated gradient method on runoff data from the Han River Basin,2023,0.00014938946866138882,1
W4394844796,M2BIST-SPNet: RUL prediction for railway signaling electromechanical devices,2024,0.00014938946866138882,1
W4324258826,Trans-Lighter: A light-weight federated learning-based architecture for Remaining Useful Lifetime prediction,2023,0.00014938946866138882,1
W4406171371,Transformer-Based Re-Ranking Model for Enhancing Contextual and Syntactic Translation in Low-Resource Neural Machine Translation,2025,0.00014938946866138882,1
W3090516321,Short-Term Load Forecasting for Industrial Customers Based on TCN-LightGBM,2020,0.00014938946866138882,1
W4313004671,MVSTT: A Multiview Spatial-Temporal Transformer Network for Traffic-Flow Forecasting,2022,0.00014938946866138882,1
W4389515566,GT-LSTM: A spatio-temporal ensemble network for traffic flow prediction,2023,0.00014938946866138882,1
W3016504312,End-To-End Deep Learning Architecture for Continuous Blood Pressure Estimation Using Attention Mechanism,2020,0.00014938946866138882,1
W4361011553,Spatial–temporal multi-feature fusion network for long short-term traffic prediction,2023,0.00014938946866138882,1
W4225593490,"Neural Natural Language Generation: A Survey on Multilinguality, Multimodality, Controllability and Learning",2022,0.00014938946866138882,1
W3108827348,Deep Learning Algorithms for Cybersecurity Applications: A Technological and Status Review,2020,0.00014938946866138882,1
W3191119619,Transformer-Encoder-GRU (T-E-GRU) for Chinese Sentiment Analysis on Chinese Comment Text,2022,0.00014938946866138882,1
W3035620341,NAS-Bench-NLP: Neural Architecture Search Benchmark for Natural Language Processing,2022,0.00014938946866138882,1
W2965485674,Classification of Hand Movements From EEG Using a Deep Attention-Based LSTM Network,2019,0.00014938946866138882,1
W4402128251,Evaluating the Effectiveness of Time Series Transformers for Demand Forecasting in Retail,2024,0.00014938946866138882,1
W4391723614,TLC-XML: Transformer with Label Correlation for Extreme Multi-label Text Classification,2024,0.00014938946866138882,1
W4226383734,Czech Grammar Error Correction with a Large and Diverse Corpus,2022,0.00014924937522767148,1
W3015504467,When Does Unsupervised Machine Translation Work?,2020,0.00014924876915631253,1
W3130868440,When Attention Meets Fast Recurrence: Training Language Models with Reduced Compute,2021,0.00014920813267247726,1
W3207461654,Traffic Flow Forecasting with Spatial-Temporal Graph Diffusion Network,2021,0.00014909809186860229,1
W2951635603,Lattice Transformer for Speech Translation,2019,0.0001490979013171582,1
W3133652505,"Neural machine translation: A review of methods, resources, and tools",2020,0.00014896682031692907,1
W4225341287,Event-Aware Multimodal Mobility Nowcasting,2022,0.00014871435015490817,1
W2890908793,Top-down Tree Structured Decoding with Syntactic Connections for Neural Machine Translation and Parsing,2018,0.00014863888398181758,1
W2883900035,Incorporating Statistical Machine Translation Word Knowledge Into Neural Machine Translation,2018,0.00014858648343381287,1
W4225370732,Characterization of groundwater contamination: A transformer-based deep learning model,2022,0.00014856442689938223,1
W3085422212,Cluster-Former: Clustering-based Sparse Transformer for Long-Range Dependency Encoding,2020,0.0001485363959589194,1
W2987998469,Pretrained Language Models for Document-Level Neural Machine Translation,2019,0.00014838198224338233,1
W2781918655,A Hierarchy-to-Sequence Attentional Neural Machine Translation Model,2018,0.00014832648452447347,1
W3160523328,FastCorrect: Fast Error Correction with Edit Alignment for Automatic Speech Recognition,2021,0.00014828228005611265,1
W2963680955,What Level of Quality Can Neural Machine Translation Attain on Literary Text?,2018,0.00014819323826602848,1
W3176366152,Improving Zero-Shot Translation by Disentangling Positional Information,2021,0.00014818500155181765,1
W3175204360,Multi-label feature selection considering label supplementation,2021,0.00014817587670740428,1
W2911535432,Deep-Resp-Forest: A deep forest model to predict anti-cancer drug response,2019,0.00014817587670740428,1
W3037838322,From Speech-to-Speech Translation to Automatic Dubbing,2020,0.00014791955372725244,1
W3175374354,Learning Language Specific Sub-network for Multilingual Machine Translation,2021,0.00014759991573755967,1
W3019527251,Lite Transformer with Long-Short Range Attention,2020,0.00014742474389307185,1
W4385567238,SynGEC: Syntax-Enhanced Grammatical Error Correction with a Tailored GEC-Oriented Parser,2022,0.00014715243638748827,1
W3127901106,Understanding and Improving Lexical Choice in Non-Autoregressive Translation,2021,0.00014712115305855203,1
W3138833245,Continual learning for recurrent neural networks: An empirical evaluation,2021,0.0001470234662678762,1
W4210443567,Multi-dimensional recurrent neural network for remaining useful life prediction under variable operating conditions and multiple fault modes,2022,0.00014693011304064664,1
W3217545443,Unsupervised time series outlier detection with diversity-driven convolutional ensembles,2021,0.00014676828643786694,1
W3089276103,"Neural machine translation: Challenges, progress and future",2020,0.00014676180009466934,1
W2949830548,Negative Lexically Constrained Decoding for Paraphrase Generation,2019,0.00014670219115179404,1
W2979303251,Future-Aware Knowledge Distillation for Neural Machine Translation,2019,0.00014665105084571073,1
W2804145368,Theory and Experiments on Vector Quantized Autoencoders,2018,0.0001466139395395182,1
W2738371943,Towards Decoding as Continuous Optimisation in Neural Machine Translation,2017,0.00014630307018293937,1
W3174089676,On the Copying Behaviors of Pre-Training for Neural Machine Translation,2021,0.00014626604552961858,1
W2971248291,Evaluating Pronominal Anaphora in Machine Translation: An Evaluation Measure and a Test Suite,2019,0.00014615092212798186,1
W2885616807,Document-Level Adaptation for Neural Machine Translation,2018,0.00014607529769277225,1
W3123673616,Addressing Some Limitations of Transformers with Feedback Memory,2020,0.00014602024219130663,1
W3166567197,Towards Continual Learning for Multilingual Machine Translation via Vocabulary Substitution,2021,0.00014599788399941363,1
W2998135987,Alignment-Enhanced Transformer for Constraining NMT with Pre-Specified Translations,2020,0.00014593724802740735,1
W3093260394,Memformer: The Memory-Augmented Transformer,2021,0.00014582312962987555,1
W4285121328,Rethinking Document-level Neural Machine Translation,2022,0.00014578759737675834,1
W4285127897,Ensembling and Knowledge Distilling of Large Sequence Taggers for Grammatical Error Correction,2022,0.00014578286120764476,1
W3135335819,"Deep Encoder, Shallow Decoder: Reevaluating Non-autoregressive Machine Translation",2020,0.0001457776579684057,1
W4390938901,Encoder-Decoder Calibration for Multimodal Machine Translation,2024,0.00014555879811951127,1
W3035169973,AMR Parsing with Latent Structural Information,2020,0.0001454653009962406,1
W3185889262,A hybrid deep learning model with 1DCNN-LSTM-Attention networks for short-term traffic flow prediction,2021,0.0001454529292849185,1
W4322101461,CLformer: Locally grouped auto-correlation and convolutional transformer for long-term multivariate time series forecasting,2023,0.00014536114644097173,1
W2952356761,Retrieving Sequential Information for Non-Autoregressive Neural Machine Translation,2019,0.00014510606331253874,1
W3133780103,Topology-Aware Graph Pooling Networks,2021,0.00014470703275624232,1
W2997003477,Neural Machine Translation With GRU-Gated Attention Model,2020,0.00014467535441536056,1
W3033962033,Modeling Discourse Structure for Document-level Neural Machine Translation,2020,0.00014463949400542162,1
W3101221466,XL-AMR: Enabling Cross-Lingual AMR Parsing with Transfer Learning Techniques,2020,0.00014456750539266146,1
W4320516656,A concise self-adapting deep learning network for machine remaining useful life prediction,2023,0.0001444392180893493,1
W3103878009,Long-Short Term Masking Transformer: A Simple but Effective Baseline for Document-level Neural Machine Translation,2020,0.00014443171991226087,1
W3082017874,When and Why is Unsupervised Neural Machine Translation Useless?,2020,0.00014404742132556492,1
W4281650942,Distance self-attention network method for remaining useful life estimation of aeroengine with parallel computing,2022,0.0001439792616348521,1
W3175810841,Mask-Align: Self-Supervised Neural Word Alignment,2021,0.00014392193461247132,1
W4287258879,BlonDe: An Automatic Evaluation Metric for Document-level Machine Translation,2022,0.0001437635156873789,1
W3198957252,LM-Critic: Language Models for Unsupervised Grammatical Error Correction,2021,0.0001436133620948342,1
W3175204760,Adapting High-resource NMT Models to Translate Low-resource Related Languages without Parallel Data,2021,0.00014361240782621775,1
W3169012807,Luna: Linear Unified Nested Attention,2021,0.00014360447839588552,1
W4387490353,Variational Continuous Label Distribution Learning for Multi-Label Text Classification,2023,0.00014348465959668338,1
W3089025530,Energy-Based Reranking: Improving Neural Machine Translation Using Energy-Based Models,2021,0.00014326741093474658,1
W3156246620,EDITOR: An Edit-Based Transformer with Repositioning for Neural Machine Translation with Soft Lexical Constraints,2021,0.00014319400118548617,1
W3202201199,On the Complementarity between Pre-Training and Back-Translation for Neural Machine Translation,2021,0.00014316461343819923,1
W2955926951,Post-editese: an Exacerbated Translationese,2019,0.00014311749838871398,1
W2950037171,Lattice-Based Transformer Encoder for Neural Machine Translation,2019,0.0001430756833322536,1
W2585253991,Neural Multi-Source Morphological Reinflection,2017,0.0001430299954832797,1
W2998681865,Neuron Interaction Based Representation Composition for Neural Machine Translation,2020,0.00014298962889049057,1
W3106144205,Vocabulary Adaptation for Domain Adaptation in Neural Machine Translation,2020,0.00014292787951205083,1
W4360770771,DLformer: A Dynamic Length Transformer-Based Network for Efficient Feature Representation in Remaining Useful Life Prediction,2023,0.0001427891345653361,1
W4226108926,Health Assessment of Rotating Equipment With Unseen Conditions Using Adversarial Domain Generalization Toward Self-Supervised Regularization Learning,2022,0.0001427663294156551,1
W3133264589,Do Transformer Modifications Transfer Across Implementations and Applications?,2021,0.00014271572249949054,1
W3103182178,Finding the Optimal Vocabulary Size for Neural Machine Translation,2020,0.00014271223322864118,1
W2997908677,Visual Agreement Regularized Training for Multi-Modal Machine Translation,2020,0.0001425787734980191,1
W3005724337,A Survey of Deep Learning Techniques for Neural Machine Translation,2020,0.000142514658446735,1
W3034700448,Efficient Context-Aware Neural Machine Translation with Layer-Wise Weighting and Input-Aware Gating,2020,0.00014237718958327593,1
W2962889503,Multi-Source Neural Machine Translation with Missing Data,2018,0.00014235705123662488,1
W3200409031,Do Long-Range Language Models Actually Use Long-Range Context?,2021,0.00014234376940891022,1
W3046531489,Document-level Neural MT: A Systematic Comparison,2020,0.0001422555546235771,1
W4306362399,Automatic Correction of Indonesian Grammatical Errors Based on Transformer,2022,0.00014221032522829632,1
W2991324852,Single Headed Attention RNN: Stop Thinking With Your Head,2019,0.00014216583819689547,1
W3177804148,Can Transformers Jump Around Right in Natural Language? Assessing Performance Transfer from SCAN,2021,0.00014208274694186082,1
W3176846012,On Compositional Generalization of Neural Machine Translation,2021,0.00014208274694186082,1
W3034786666,Contextual Neural Machine Translation Improves Translation of Cataphoric Pronouns,2020,0.00014205917765355787,1
W2971162405,The Unreasonable Effectiveness of Transformer Language Models in Grammatical Error Correction,2019,0.0001420132374565874,1
W2951065878,Target Conditioned Sampling: Optimizing Data Selection for Multilingual Neural Machine Translation,2019,0.00014197455326062238,1
W2905032972,Hierarchical Attention Networks for Sentence Ordering,2019,0.00014188908900678347,1
W2970845336,CUED@WMT19:EWC&amp;LMs,2019,0.0001418277807468495,1
W3009157386,A multi-label text classification method via dynamic semantic representation model and deep neural network,2020,0.00014181826100214846,1
W4281657308,Impact of preprocessing and word embedding on extreme multi-label patent classification tasks,2022,0.00014181826100214846,1
W3035512170,Generalized Entropy Regularization or: There’s Nothing Special about Label Smoothing,2020,0.00014176313278473993,1
W4224247818,Multilingual fine-tuning for Grammatical Error Correction,2022,0.0001416602973869586,1
W4285105102,CipherDAug: Ciphertext based Data Augmentation for Neural Machine Translation,2022,0.000141639418155117,1
W2970544750,Combining Local and Document-Level Context: The LMU Munich Neural Machine Translation System at WMT19,2019,0.0001416299337249802,1
W3155609600,Word Alignment by Fine-tuning Embeddings on Parallel Corpora,2021,0.0001416006672112406,1
W3172044616,Neural Quality Estimation with Multiple Hypotheses for Grammatical Error Correction,2021,0.00014154461133643182,1
W2950300355,Regularizing Neural Networks by Penalizing Confident Output Distributions,2017,0.00014133058981978742,1
W3166514234,Harnessing Multilinguality in Unsupervised Machine Translation for Rare Languages,2021,0.00014115521328936876,1
W2951560313,Pre-trained Language Model Representations for Language Generation,2019,0.00014115499105099124,1
W4366779109,Transformer-enhanced periodic temporal convolution network for long short-term traffic flow forecasting,2023,0.00014113905104132295,1
W2949558560,Bridging the Gap: Attending to Discontinuity in Identification of Multiword Expressions,2019,0.00014113905104132295,1
W4365790371,A Novel Two-Stage Deep Learning Model for Network Intrusion Detection: LSTM-AE,2023,0.00014113905104132295,1
W2894178883,Recurrent convolutional neural network based multimodal disease risk prediction,2018,0.00014113905104132295,1
W4407242298,Leveraging language models for automated distribution of review notes in animated productions,2025,0.00014113905104132295,1
W4205268692,Gait Recognition Based on Deep Learning: A Survey,2022,0.00014113905104132295,1
W4381620565,Self-supervised Health Representation Decomposition based on contrast learning,2023,0.00014113905104132295,1
W4386495226,Event-Based Dynamic Graph Representation Learning for Patent Application Trend Prediction,2023,0.00014113905104132295,1
W4386147356,Deep learning-powered vessel traffic flow prediction with spatial-temporal attributes and similarity grouping,2023,0.00014113905104132295,1
W4395956828,Deep dive into predictive excellence: Transformer's impact on groundwater level prediction,2024,0.00014113905104132295,1
W4321374739,Short-Term Traffic Flow Prediction Based on a K-Nearest Neighbor and Bidirectional Long Short-Term Memory Model,2023,0.00014113905104132295,1
W4221023673,A Novel Transfer Learning Approach in Remaining Useful Life Prediction for Incomplete Dataset,2022,0.00014113905104132295,1
W2578396138,Hashtag recommendation with topical attention-based LSTM,2016,0.00014113905104132295,1
W3047555776,Study of Various Methods for Tokenization,2020,0.00014113905104132295,1
W4394575959,Towards efficient similarity embedded temporal Transformers via extended timeframe analysis,2024,0.00014113905104132295,1
W3049737176,"Time series prediction for the epidemic trends of COVID-19 using the improved LSTM deep learning method: Case studies in Russia, Peru and Iran",2020,0.00014113905104132295,1
W4392251697,Hierarchical Multi-Granularity Interaction Graph Convolutional Network for Long Document Classification,2024,0.00014113905104132295,1
W3010005261,Text Classification Using Long Short-Term Memory With GloVe Features,2020,0.00014113905104132295,1
W4293275470,Advanced deep learning approaches to predict supply chain risks under COVID-19 restrictions,2022,0.00014113905104132295,1
W4210439489,Spatiotemporal Graph Convolutional Network for Multi-Scale Traffic Forecasting,2022,0.00014113905104132295,1
W3101177651,Learning Private Neural Language Modeling with Attentive Aggregation,2019,0.00014113905104132295,1
W3040538742,Conditional Set Generation with Transformers,2020,0.00014113905104132295,1
W4282980267,M2TNet: Multi-modal multi-task Transformer network for ultra-short-term wind power multi-step forecasting,2022,0.00014113905104132295,1
W4392693783,MatchXML: An Efficient Text-label Matching Framework for Extreme Multi-label Text Classification,2024,0.00014113905104132295,1
W4285209801,Adjusting the Precision-Recall Trade-Off with Align-and-Predict Decoding for Grammatical Error Correction,2022,0.00014113879997424528,1
W3099417250,Token-level Adaptive Training for Neural Machine Translation,2020,0.00014103330528503493,1
W3192500523,The Paradox of the Compositionality of Natural Language: A Neural Machine Translation Case Study,2022,0.0001408554898922733,1
W3167739156,Rethinking Perturbations in Encoder-Decoders for Fast Training,2021,0.00014077575077937613,1
W3176957840,Discriminative Reranking for Neural Machine Translation,2021,0.0001404201895431077,1
W3035702572,Heterogeneous Graph Transformer for Graph-to-Sequence Learning,2020,0.00014039257243772524,1
W2982588609,Document-level Neural Machine Translation with Inter-Sentence Attention.,2019,0.0001403720777821673,1
W4387332734,Toward automatic generation of control structures for process flow diagrams with large language models,2023,0.00014026002835124902,1
W4223967157,ODE Transformer: An Ordinary Differential Equation-Inspired Model for Sequence Generation,2022,0.00014021896365925814,1
W4221155857,Neural Machine Translation with Phrase-Level Universal Visual Representations,2022,0.0001400666066390764,1
W3102138045,On Long-Tailed Phenomena in Neural Machine Translation,2020,0.00013998834420776232,1
W3156993586,Document-level grammatical error correction,2021,0.0001399687991606486,1
W4366091323,"Deep learning modelling techniques: current progress, applications, advantages, and challenges",2023,0.00013995653541214168,1
W2944852028,Is Word Segmentation Necessary for Deep Learning of Chinese Representations?,2019,0.00013993711270913963,1
W3034216012,Learning to Recover from Multi-Modality Errors for Non-Autoregressive Neural Machine Translation,2020,0.0001398875846088394,1
W2964108048,From Bilingual to Multilingual Neural Machine Translation by Incremental Training,2019,0.00013986826328217254,1
W2949405462,Unsupervised Parallel Sentence Extraction with Parallel Segment Detection Helps Machine Translation,2019,0.00013986747721643716,1
W3174805484,Meta-Curriculum Learning for Domain Adaptation in Neural Machine Translation,2021,0.00013981085955646334,1
W2962929176,Input Combination Strategies for Multi-Source Transformer Decoder,2018,0.0001398008222383311,1
W2952518244,Meta-Learning for Low-Resource Neural Machine Translation,2018,0.0001397832988515176,1
W2810953419,English–Mizo Machine Translation using neural and statistical approaches,2018,0.00013970618152822672,1
W2741823585,Analyzing Neural MT Search and Model Performance,2017,0.0001396862063061972,1
W2971152344,Improving Zero-shot Translation with Language-Independent Constraints,2019,0.00013961425851233538,1
W3208413651,Structure-aware Fine-tuning of Sequence-to-sequence Transformers for Transition-based AMR Parsing,2021,0.00013953182682962178,1
W3200230461,Non-Parametric Unsupervised Domain Adaptation for Neural Machine Translation,2021,0.0001394982818531088,1
W4285170631,Efficient Machine Translation Domain Adaptation,2022,0.0001394982818531088,1
W3134357720,A Survey on Document-level Neural Machine Translation,2021,0.00013948208435359246,1
W3171218751,NeuroLogic Decoding: (Un)supervised Neural Text Generation with Predicate Logic Constraints,2021,0.00013947230490494704,1
W4322773459,Modeling and predictive control of nonlinear processes using transfer learning method,2023,0.00013943153456368295,1
W4289521458,An Efficient Method for Generating Synthetic Data for Low-Resource Machine Translation,2022,0.0001394130738523547,1
W3173677700,One SPRING to Rule Them Both: Symmetric AMR Semantic Parsing and Generation without a Complex Pipeline,2021,0.00013938435501479032,1
W4309763546,Multi-Aspect co-Attentional Collaborative Filtering for extreme multi-label text classification,2022,0.0001393186631103461,1
W4285600138,A Unified Strategy for Multilingual Grammatical Error Correction with Pre-trained Cross-Lingual Language Model,2022,0.00013930022156757375,1
W3031586918,A Multilingual Parallel Corpora Collection Effort for Indian Languages,2020,0.000139275868627483,1
W4385571532,TemplateGEC: Improving Grammatical Error Correction with Detection Template,2023,0.000139271913835786,1
W3034822304,Structural Information Preserving for Graph-to-Text Generation,2020,0.00013926808834423724,1
W3180936947,"Neural machine translation: past, present, and future",2021,0.00013915674715844954,1
W3035393249,Lexical-Constraint-Aware Neural Machine Translation via Data Augmentation,2020,0.00013912188105745003,1
W2998335012,Explicit Sentence Compression for Neural Machine Translation,2020,0.00013904591068577017,1
W4235805184,Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Papers),2019,0.0001390422871883946,1
W2980462515,Using Whole Document Context in Neural Machine Translation,2019,0.00013898961206917774,1
W2890909908,Surprisingly Easy Hard-Attention for Sequence to Sequence Learning,2018,0.00013897729370379813,1
W3101734317,Online Back-Parsing for AMR-to-Text Generation,2020,0.00013895801958559804,1
W3198765931,Translation Error Detection as Rationale Extraction,2022,0.00013894400375163497,1
W4362586828,A new convolutional dual-channel Transformer network with time window concatenation for remaining useful life prediction of rolling bearings,2023,0.00013878178886416123,1
W3036939249,Multi-branch Attentive Transformer,2020,0.00013856501799629374,1
W4312471667,VALHALLA: Visual Hallucination for Machine Translation,2022,0.0001384671360765863,1
W2952649152,Scheduled Sampling for Transformers,2019,0.00013836399121785694,1
W3203011138,A Transformer-Based Neural Machine Translation Model for Arabic Dialects That Utilizes Subword Units,2021,0.000138302908593467,1
W3016321512,Neural machine translation with Gumbel Tree-LSTM based encoder,2020,0.00013829211539365056,1
W3105178602,Dependency-based syntax-aware word representations,2020,0.00013829211539365056,1
W2963500732,Neural Machine Translation into Language Varieties,2018,0.00013811778459833668,1
W3034214887,Learning a Multi-Domain Curriculum for Neural Machine Translation,2020,0.0001380943023849543,1
W4230252363,Learning Kernel-Smoothed Machine Translation with Retrieved Examples,2021,0.00013790205228432755,1
W2997613748,Unsupervised dialectal neural machine translation,2020,0.00013781174359938912,1
W2798546337,Discourse Representation Structure Parsing,2018,0.00013779937770574754,1
W4385574244,Towards Opening the Black Box of Neural Machine Translation: Source and Target Interpretations of the Transformer,2022,0.00013778610409340697,1
W4395680645,Eliciting the Translation Ability of Large Language Models via Multilingual Finetuning with Translation Instructions,2024,0.00013776388019675053,1
W4392616472,Exploring Human-Like Translation Strategy with Large Language Models,2024,0.00013776388019675053,1
W2887005286,Low-Latency Neural Speech Translation,2018,0.00013774852353194917,1
W3153411045,Domain Adaptation and Multi-Domain Adaptation for Neural Machine Translation: A Survey,2022,0.00013774270942992824,1
W4281679347,Bilingual attention based neural machine translation,2022,0.00013771291115077355,1
W3115711567,Revisiting Low Resource Status of Indian Languages in Machine Translation,2020,0.00013768245888579644,1
W4385574121,Exploring Document-Level Literary Machine Translation with Parallel Paragraphs from World Literature,2022,0.00013764426635394248,1
W4212930502,Knowledge Distillation: A Method for Making Neural Machine Translation More Efficient,2022,0.00013755672846612496,1
W3173417753,Learning Light-Weight Translation Models from Deep Transformer,2021,0.00013736978824608394,1
W3035219095,Evaluating Robustness to Input Perturbations for Neural Machine Translation,2020,0.0001373248407563413,1
W3121071870,Findings of the WMT 2023 Shared Task on Automatic Post-Editing,2023,0.00013729513588148595,1
W3118069529,Continual Lifelong Learning in Natural Language Processing: A Survey,2020,0.00013724372080599042,1
W3020775333,Augmenting Transformers with KNN-Based Composite Memory for Dialogue,2020,0.0001372153080362688,1
W2888799392,Direct Output Connection for a High-Rank Language Model,2018,0.00013716007291820852,1
W3205531882,Transformer Acceleration with Dynamic Sparse Attention,2021,0.00013713170534014808,1
W4289781031,Self-training method based on GCN for semi-supervised short text classification,2022,0.00013701384223128998,1
W4280569535,Simplified-Boosting Ensemble Convolutional Network for Text Classification,2022,0.00013701384223128998,1
W3176466730,Continual Mixed-Language Pre-Training for Extremely Low-Resource Neural Machine Translation,2021,0.000137009181740239,1
W2970392338,Hierarchical Document Encoder for Parallel Corpus Mining,2019,0.00013697395571570425,1
W3155915431,Multilingual Machine Translation: Closing the Gap between Shared and Language-specific Encoder-Decoders,2021,0.00013688636654672496,1
W2963928591,Recurrent Stacking of Layers for Compact Neural Machine Translation Models,2019,0.00013646745783241115,1
W3165920028,Generalized Zero-Shot Extreme Multi-label Learning,2021,0.0001364070462542977,1
W3170427498,Fast Nearest Neighbor Machine Translation,2022,0.00013639706127710778,1
W4382202554,Prompting Neural Machine Translation with Translation Memories,2023,0.0001363888105934062,1
W4385573489,ConsistTL: Modeling Consistency in Transfer Learning for Low-Resource Neural Machine Translation,2022,0.00013631643664043557,1
W2962771342,The Case for Learned Index Structures,2018,0.00013623903932405437,1
W2964101465,Data2Vis: Automatic Generation of Data Visualizations Using Sequence-to-Sequence Recurrent Neural Networks,2019,0.00013618880046928342,1
W4225003277,Transformer-based map-matching model with limited labeled data using transfer-learning approach,2022,0.00013618880046928342,1
W4387686310,An attention-based temporal convolutional network method for predicting remaining useful life of aero-engine,2023,0.00013618880046928342,1
W4366378747,DCAT: Combining Multisemantic Dual-Channel Attention Fusion for Text Classification,2023,0.00013618880046928342,1
W4391621245,SageFormer: Series-Aware Framework for Long-Term Multivariate Time-Series Forecasting,2024,0.00013618880046928342,1
W4290927794,Spatio-Temporal Graph Few-Shot Learning with Cross-City Knowledge Transfer,2022,0.00013618880046928342,1
W3064840847,HiPPO: Recurrent Memory with Optimal Polynomial Projections,2020,0.00013618880046928342,1
W4290944372,Selective Cross-City Transfer Learning for Traffic Prediction via Source City Region Re-Weighting,2022,0.00013618880046928342,1
W4366377753,Multi-Scale Adaptive Graph Neural Network for Multivariate Time Series Forecasting,2023,0.00013618880046928342,1
W2928323670,A Sequence-to-Sequence Air Quality Predictor Based on the n-Step Recurrent Prediction,2019,0.00013618880046928342,1
W4297423466,STGHTN: Spatial-temporal gated hybrid transformer network for traffic flow forecasting,2022,0.00013618880046928342,1
W3208645139,Power Consumption Predicting and Anomaly Detection Based on Transformer and K-Means,2021,0.00013618880046928342,1
W2942870440,Domain-specific machine translation with recurrent neural network for software localization,2019,0.00013618880046928342,1
W4403117273,Remaining Useful Life Prediction of Aero-engine via Temporal Convolutional Network with Gated Convolution and Channel Selection Unit,2024,0.00013618880046928342,1
W2705373224,Sequence-to-sequence models for punctuated transcription combining lexical and acoustic features,2017,0.00013618880046928342,1
W4320001385,CNN-Based Transformer Model for Fault Detection in Power System Networks,2023,0.00013618880046928342,1
W3199040194,Deep learning for time series forecasting: The electric load case,2021,0.00013618880046928342,1
W4318815354,Graph Neural Networks for Natural Language Processing: A Survey,2023,0.00013618880046928342,1
W3152560880,Interpreting and Unifying Graph Neural Networks with An Optimization Framework,2021,0.00013618880046928342,1
W4385666331,DyGCN-LSTM: A dynamic GCN-LSTM based encoder-decoder framework for multistep traffic prediction,2023,0.00013618880046928342,1
W2547418827,Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences,2016,0.00013618880046928342,1
W3172514114,Principles and algorithms for forecasting groups of time series: Locality and globality,2021,0.00013618880046928342,1
W3089072946,Deep Transformers with Latent Depth,2020,0.00013604533425394226,1
W3101299315,"Lightweight, Dynamic Graph Convolutional Networks for AMR-to-Text Generation",2020,0.00013603798198774309,1
W2889411721,Multi-Source Syntactic Neural Machine Translation,2018,0.00013590945630776095,1
W3101286153,Reusing a Pretrained Language Model on Languages with Limited Corpora for Unsupervised NMT,2020,0.0001358574016207441,1
W3016151632,On Optimal Transformer Depth for Low-Resource Language Translation,2020,0.00013578897110816266,1
W4377079846,A Survey on Non-Autoregressive Generation for Neural Machine Translation and Beyond,2023,0.0001356405949165995,1
W4385570671,Knowledge Transfer in Incremental Learning for Multilingual Neural Machine Translation,2023,0.00013563877262794566,1
W4319264941,Text FCG: Fusing Contextual Information via Graph Learning for text classification,2023,0.00013563877262794566,1
W4229853184,Capturing document context inside sentence-level neural machine translation models with self-training,2021,0.00013562624463608956,1
W3035589854,Enhancing Machine Translation with Dependency-Aware Self-Attention,2020,0.00013556418256741045,1
W2951227497,CNNs found to jump around more skillfully than RNNs: Compositional Generalization in Seq2seq Convolutional Networks,2019,0.00013519767750720175,1
W3127719526,Share or Not? Learning to Schedule Language-Specific Capacity for Multilingual Translation,2021,0.0001350901061438298,1
W3200396895,Counter-Interference Adapter for Multilingual Machine Translation,2021,0.00013508375027428468,1
W3104652292,On the Sub-layer Functionalities of Transformer Decoder,2020,0.00013502827798608774,1
W3016004348,Residual Shuffle-Exchange Networks for Fast Processing of Long Sequences,2021,0.00013489915504013742,1
W2949305207,Coherent Comments Generation for Chinese Articles with a Graph-to-Sequence Model,2019,0.00013477222165269722,1
W3202484768,Deep Transformer modeling via grouping skip connection for neural machine translation,2021,0.00013476712269390326,1
W3167880383,Non-Autoregressive Translation by Learning Target Categorical Codes,2021,0.00013475161164885216,1
W2964028737,Adversarial Generation of Natural Language,2017,0.0001345694631901945,1
W4388793551,A dual attention LSTM lightweight model based on exponential smoothing for remaining useful life prediction,2023,0.00013453871694527023,1
W2970009562,Neural Machine Translation of Low-Resource and Similar Languages with Backtranslation,2019,0.00013449844548321028,1
W4386760021,Trend-augmented and temporal-featured Transformer network with multi-sensor signals for remaining useful life prediction,2023,0.00013444536371804065,1
W4386314827,PAOLTransformer: Pruning-adaptive optimal lightweight Transformer model for aero-engine remaining useful life prediction,2023,0.00013444536371804065,1
W4392481514,A novel data augmentation framework for remaining useful life estimation with dense convolutional regression network,2024,0.00013444536371804065,1
W2997244573,On the Linguistic Representational Power of Neural Machine Translation Models,2020,0.0001343456617957481,1
W3156646638,Korean Grammatical Error Correction Based on Transformer with Copying Mechanisms and Grammatical Noise Implantation Methods,2021,0.00013430243838867501,1
W4287597359,Monolingual Adapters for Zero-Shot Neural Machine Translation,2020,0.00013418429939378085,1
W3153854882,Better Neural Machine Translation by Extracting Linguistic Information from BERT,2021,0.00013416595928443886,1
W3162226363,Adaptive Adapters: An Efficient Way to Incorporate BERT Into Neural Machine Translation,2021,0.00013415960870092532,1
W3037793211,Re-translation versus Streaming for Simultaneous Translation,2020,0.00013400341588804852,1
W3215493153,A Long Short-Term Memory-based correlated traffic data prediction framework,2021,0.00013378972865842506,1
W3121416198,Graph-Based Bilingual Word Embedding for Statistical Machine Translation,2018,0.00013375514267232035,1
W3037973456,PowerNorm: Rethinking Batch Normalization in Transformers,2020,0.0001337147752399394,1
W2964325863,Learning Character-level Compositionality with Visual Features,2017,0.00013369313893791797,1
W2769134508,Zero-Shot Style Transfer in Text Using Recurrent Neural Networks.,2017,0.00013367948463863095,1
W2997945091,Multi-Scale Self-Attention for Text Classification,2020,0.00013361008287588087,1
W3125498921,Cluster-Former: Clustering-based Sparse Transformer for Question Answering,2021,0.0001335433239475066,1
W4319598896,The neural machine translation models for the low-resource Kazakh–English language pair,2023,0.00013354080771679446,1
W3034719878,Language-aware Interlingua for Multilingual Neural Machine Translation,2020,0.00013345612367877152,1
W2955666607,The Impact of Preprocessing on Arabic-English Statistical and Neural Machine Translation,2019,0.0001333447875918574,1
W3154987757,Robust Open-Vocabulary Translation from Visual Text Representations,2021,0.00013332169242051407,1
W2949938546,Generating Diverse Translations with Sentence Codes,2019,0.00013320876893623863,1
W3211978535,Encouraging Lexical Translation Consistency for Document-Level Neural Machine Translation,2021,0.00013319192097867766,1
W3113952093,Neural Grammatical Error Correction for Romanian,2020,0.00013310723373004577,1
W2897079037,On Prediction of User Destination by Sub-Trajectory Understanding,2018,0.00013308109153999578,1
W2998409174,AdaCare: Explainable Clinical Health Status Representation Learning via Scale-Adaptive Feature Extraction and Recalibration,2020,0.00013308109153999578,1
W2997732209,Improving Context-Aware Neural Machine Translation Using Self-Attentive Sentence Embedding,2020,0.00013299475765644878,1
W3034438872,Syntax-Aware Opinion Role Labeling with Dependency Graph Convolutional Networks,2020,0.00013295333731837595,1
W2996844526,A Comprehensive Survey of Multilingual Neural Machine Translation,2020,0.00013290519222783242,1
W3034906024,Knowledge Distillation for Multilingual Unsupervised Neural Machine Translation,2020,0.00013289059540939384,1
W3214933191,SIGMORPHON 2021 Shared Task on Morphological Reinflection: Generalization Across Languages,2021,0.00013288863342125705,1
W4390905463,PGCN: Progressive Graph Convolutional Networks for Spatial–Temporal Traffic Forecasting,2024,0.00013288863342125705,1
W2912812282,Deep Long Short-Term Memory: A New Price and Load Forecasting Scheme for Big Data in Smart Cities,2019,0.00013288863342125705,1
W3003504112,Domain Knowledge Guided Deep Learning with Electronic Health Records,2019,0.00013288863342125705,1
W3197022418,Heterogeneity-Aware Twitter Bot Detection with Relational Graph Transformers,2022,0.00013288863342125705,1
W3035376668,Unsupervised Morphological Paradigm Completion,2020,0.00013288863342125705,1
W4284675318,Improving machine translation systems via isotopic replacement,2022,0.00013288863342125705,1
W3109744225,SemMT: A Semantic-Based Testing Approach for Machine Translation Systems,2022,0.00013288863342125705,1
W4362558555,Generating Music with Data: Application of Deep Learning Models for Symbolic Music Composition,2023,0.00013288863342125705,1
W3207290297,Video Background Music Generation with Controllable Music Transformer,2021,0.00013288863342125705,1
W4399586229,Revolutionising Translation with AI: Unravelling Neural Machine Translation and Generative Pre-trained Large Language Models,2024,0.00013288863342125705,1
W2591264712,Character-Word LSTM Language Models,2017,0.00013288863342125705,1
W4321783721,Complex domain extension network with multi-channels information fusion for remaining useful life prediction of rotating machinery,2023,0.00013288863342125705,1
W4317733620,Prediction of Electric Vehicles Charging Demand: A Transformer-Based Deep Learning Approach,2023,0.00013288863342125705,1
W4391892535,The Impact of Artificial Intelligence on Language Translation: A Review,2024,0.00013288863342125705,1
W4308871212,Hydrological Drought Forecasting Using a Deep Transformer Model,2022,0.00013288863342125705,1
W4306168631,DAFA-BiLSTM: Deep Autoregression Feature Augmented Bidirectional LSTM network for time series prediction,2022,0.00013288863342125705,1
W4323644143,Dual Channel Feature Attention-Based Approach for RUL Prediction Considering the Spatiotemporal Difference of Multisensor Data,2023,0.00013288863342125705,1
W2964046661,Recurrent neural network-based semantic variational autoencoder for Sequence-to-sequence learning,2019,0.00013288863342125705,1
W4389518624,Leveraging GPT-4 for Automatic Translation Post-Editing,2023,0.00013288863342125705,1
W3091791608,A ship movement classification based on Automatic Identification System (AIS) data using Convolutional Neural Network,2020,0.00013288863342125705,1
W2973171206,Personalized re-ranking for recommendation,2019,0.00013288863342125705,1
W4289656058,Interpretable Transformer Model for Capturing Regime Switching Effects of Real-Time Electricity Prices,2022,0.00013288863342125705,1
W4396769114,Temporal Fusion Transformers for streamflow Prediction: Value of combining attention with recurrence,2024,0.00013288863342125705,1
W3120749277,Tencent AI Lab Machine Translation Systems for WMT20 Chat Translation Task,2020,0.00013284795578252044,1
W2787026069,Controlling Target Features in Neural Machine Translation via Prefix Constraints,2017,0.00013270556444080472,1
W2983590910,Context-Aware Neural Machine Translation Decoding,2019,0.00013266498182158833,1
W4206232983,A Plug-and-Play Method for Controlled Text Generation,2021,0.0001325688986063851,1
W4220674272,Challenges of Neural Machine Translation for Short Texts,2022,0.00013256220147468513,1
W3116815090,A Theoretical Analysis of the Repetition Problem in Text Generation,2021,0.00013249368666802097,1
W3035291402,Learning Architectures from an Extended Search Space for Language Modeling,2020,0.00013228183744426478,1
W4389524378,ChatGPT MT: Competitive for High- (but Not Low-) Resource Languages,2023,0.00013219589886572135,1
W3023856002,Syntax-Aware Data Augmentation for Neural Machine Translation,2023,0.00013216558114723172,1
W3015078597,Meta-Learning for Few-Shot NMT Adaptation,2020,0.00013212553546864788,1
W3103169714,Dynamic Data Selection and Weighting for Iterative Back-Translation,2020,0.00013210511631747855,1
W3199258042,Cross-Attention is All You Need: Adapting Pretrained Transformers for Machine Translation,2021,0.00013199267702144438,1
W3116179216,Finding Sparse Structures for Domain Specific Neural Machine Translation,2021,0.00013196895642066906,1
W4223651176,A novel approach to ultra-short-term multi-step wind power predictions based on encoder–decoder architecture in natural language processing,2022,0.00013185533976545525,1
W3205067433,MSP: Multi-Stage Prompting for Making Pre-trained Language Models Better Translators,2022,0.0001317100023326762,1
W2885637246,Linguistic Knowledge-Aware Neural Machine Translation,2018,0.00013160721076791,1
W2884806734,What to expect from Neural Machine Translation: a practical in-class translation evaluation exercise,2018,0.0001316011971972978,1
W2970780025,Customizing Neural Machine Translation for Subtitling,2019,0.0001315504720026334,1
W4285270642,Understanding and Improving Sequence-to-Sequence Pretraining for Neural Machine Translation,2022,0.00013146137270188908,1
W4385570274,Lessons on Parameter Sharing across Layers in Transformers,2023,0.00013135602984621847,1
W3105962700,Simulated multiple reference training improves low-resource machine translation,2020,0.00013134898125459683,1
W4231667498,"Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",2019,0.00013133469559434947,1
W3036422752,Neural machine translation of low-resource languages using SMT phrase pair injection,2020,0.00013131823862744835,1
W4316468172,Low-Resource Neural Machine Translation Improvement Using Source-Side Monolingual Data,2023,0.00013130140864849087,1
W4388953014,Low-Resource Neural Machine Translation: A Systematic Literature Review,2023,0.0001312385498972439,1
W4385570486,kNN-TL: k-Nearest-Neighbor Transfer Learning for Low-Resource Neural Machine Translation,2023,0.00013121168738040168,1
W2974078243,Improving tree-based neural machine translation with dynamic lexicalized dependency encoding,2019,0.00013118431297975784,1
W4385574203,GuoFeng: A Benchmark for Zero Pronoun Recovery and Translation,2022,0.00013115957102332272,1
W4378619223,Reduction of Neural Machine Translation Failures by Incorporating Statistical Machine Translation,2023,0.00013107535482344038,1
W2997197207,"MetaMT, a Meta Learning Method Leveraging Multiple Domain Data for Low Resource Machine Translation",2020,0.00013101095451275668,1
W3168577192,Multi-Task Learning with Shared Encoder for Non-Autoregressive Machine Translation,2021,0.000130955608384871,1
W3098041136,Multilingual AMR-to-Text Generation,2020,0.0001308599613028959,1
W4385573825,Improved grammatical error correction by ranking elementary edits,2022,0.0001307540601697754,1
W3163874900,DirectQE: Direct Pretraining for Machine Translation Quality Estimation,2021,0.00013059654560709945,1
W2963836274,Open Information Extraction from Question-Answer Pairs,2019,0.00013053137124409536,1
W4393160356,Hierarchical Text Classification and Its Foundations: A Review of Current Research,2024,0.00013053137124409536,1
W4224315779,A Semi-Supervised VAE Based Active Anomaly Detection Framework in Multivariate Time Series for Online Systems,2022,0.00013053137124409536,1
W3148242325,Correlational graph attention-based Long Short-Term Memory network for multivariate time series prediction,2021,0.00013053137124409536,1
W2995253144,Hierarchical Data Augmentation and the Application in Text Classification,2019,0.00013053137124409536,1
W4309651348,When do contrastive learning signals help spatio-temporal graph forecasting?,2022,0.00013053137124409536,1
W4281998028,A watershed water quality prediction model based on attention mechanism and Bi-LSTM,2022,0.00013053137124409536,1
W4391248393,Hierarchical text classification with multi-label contrastive learning and KNN,2024,0.00013053137124409536,1
W4385571355,Enhancing Hierarchical Text Classification through Knowledge Graph Integration,2023,0.00013053137124409536,1
W3111445527,Time Series Forecasting and Classification Models Based on Recurrent with Attention Mechanism and Generative Adversarial Networks,2020,0.00013053137124409536,1
W4372342073,Preformer: Predictive Transformer with Multi-Scale Segment-Wise Correlations for Long-Term Time Series Forecasting,2023,0.00013053137124409536,1
W4220930802,Echo state network with logistic mapping and bias dropout for time series prediction,2022,0.00013052263102774443,1
W3000127803,Backward Feature Correction: How Deep Learning Performs Deep Learning,2020,0.00013040315390497299,1
W3102885980,Generating Diverse Translation from Model Distribution with Dropout,2020,0.00013032322411343523,1
W3137065374,"Low-Resource Machine Translation for Low-Resource Languages: Leveraging Comparable Data, Code-Switching and Compute Resources.",2021,0.0001302209397938211,1
W4378974641,Transformer: A General Framework from Machine Translation to Others,2023,0.00012992633904514655,1
W2884873108,Convolutional Sequence to Sequence Model with Non-Sequential Greedy Decoding for Grapheme to Phoneme Conversion,2018,0.00012989677297307826,1
W3211986039,The Eval4NLP Shared Task on Explainable Quality Estimation: Overview and Results,2021,0.0001297442591859647,1
W4210767179,Recurrent neural network model for high-speed train vibration prediction from time series,2022,0.00012973396356324022,1
W4206249782,Sometimes We Want Ungrammatical Translations,2021,0.000129707120511762,1
W2950485982,Self-Supervised Neural Machine Translation,2019,0.00012969805770381607,1
W2987188351,Findings of the Fourth Workshop on Neural Generation and Translation,2020,0.0001296375897288697,1
W3034427563,Using Context in Neural Machine Translation Training Objectives,2020,0.00012959584011786764,1
W4389520222,Towards Making the Most of ChatGPT for Machine Translation,2023,0.00012941410785114564,1
W2995538013,Multi-Source Neural Machine Translation With Missing Data,2019,0.000129406560564972,1
W3214532454,Learning to Rewrite for Non-Autoregressive Neural Machine Translation,2021,0.0001293455475185414,1
W3104234009,Simultaneous Machine Translation with Visual Context,2020,0.00012932404233225882,1
W3200578235,Multilingual Translation via Grafting Pre-trained Language Models,2021,0.00012927224409574843,1
W2798308429,Exploiting Semantics in Neural Machine Translation with Graph Convolutional Networks,2018,0.0001292421668391579,1
W3165048362,An Improved English-to-Mizo Neural Machine Translation,2021,0.0001292143583677864,1
W2997753998,Explicit Sparse Transformer: Concentrated Attention Through Explicit Selection,2019,0.0001291431012168048,1
W4385572748,Multilingual Machine Translation with Hyper-Adapters,2022,0.00012913844359395437,1
W2970084653,Speculative Beam Search for Simultaneous Translation,2019,0.00012905769077855734,1
W2807475932,Neural Machine Translation of Indian Languages,2017,0.0001290561616586222,1
W4389519128,"Machine Translation with Large Language Models: Prompting, Few-shot Learning, and Fine-tuning with QLoRA",2023,0.00012898521003111834,1
W4384666235,A Review on Dropout Regularization Approaches for Deep Neural Networks within the Scholarly Domain,2023,0.0001289598631259876,1
W3013382035,Recurrent Neural Networks: An Embedded Computing Perspective,2020,0.0001289598631259876,1
W3081886688,Measurement of Text Similarity: A Survey,2020,0.0001287802545901816,1
W4303856974,A Reverse Positional Encoding Multi-Head Attention-Based Neural Machine Translation Model for Arabic Dialects,2022,0.0001287802545901816,1
W4399365598,Scaling neural machine translation to 200 languages,2024,0.0001287634246112241,1
W4293187584,Explainability-Based Mix-Up Approach for Text Data Augmentation,2022,0.0001287634246112241,1
W4366606077,Graph convolutional network-based feature selection for high-dimensional and low-sample size data,2023,0.0001287634246112241,1
W3214250531,Controlling Machine Translation for Multiple Attributes with Additive Interventions,2021,0.0001287634246112241,1
W4391129999,Multi-Scale Transformer Pyramid Networks for Multivariate Time Series Forecasting,2024,0.0001287634246112241,1
W4320015890,Semantics-Aware Dynamic Graph Convolutional Network for Traffic Flow Forecasting,2023,0.0001287634246112241,1
W3202576380,FastCorrect 2: Fast Error Correction on Multiple Candidates for Automatic Speech Recognition,2021,0.0001287634246112241,1
W3193078993,Correlation-Guided Representation for Multi-Label Text Classification,2021,0.0001287634246112241,1
W4394871646,Are Character-level Translations Worth the Wait? Comparing ByT5 and mT5 for Machine Translation,2024,0.0001287634246112241,1
W4220697067,LSTM-Based Attentional Embedding for English Machine Translation,2022,0.0001287180926462787,1
W3011824510,Unsupervised Neural Machine Translation With Cross-Lingual Language Representation Agreement,2020,0.00012869688618845435,1
W2982644924,Fill in the Blanks: Imputing Missing Sentences for Larger-Context Neural Machine Translation,2019,0.0001284625433700501,1
W4385572987,Chunk-based Nearest Neighbor Machine Translation,2022,0.00012841957894619676,1
W2952180055,Convolutional Self-Attention Networks,2019,0.00012837887828135225,1
W4385574256,Breaking the Representation Bottleneck of Chinese Characters: Neural Machine Translation with Stroke Sequence Modeling,2022,0.00012837207487503266,1
W3113819942,A review of the state-of-the-art in automatic post-editing,2020,0.00012826390003294787,1
W4385574095,Revisiting Grammatical Error Correction Evaluation and Beyond,2022,0.00012802319639232878,1
W3034939458,How Does Selective Mechanism Improve Self-Attention Networks?,2020,0.0001279354678319536,1
W4280557709,An empirical study of low-resource neural machine translation of manipuri in multilingual settings,2022,0.00012792623780391845,1
W4205902821,Document Graph for Neural Machine Translation,2021,0.00012784639207849606,1
W4285180072,An Imitation Learning Curriculum for Text Editing with Non-Autoregressive Models,2022,0.00012769677688583133,1
W2923779212,Selective Attention for Context-aware Neural Machine Translation,2019,0.00012751058733144021,1
W3126910220,Extremely low-resource neural machine translation for Asian languages,2020,0.00012748943544502284,1
W4282937133,Video Pivoting Unsupervised Multi-Modal Machine Translation,2022,0.0001274864547612717,1
W3119866316,Complete Multilingual Neural Machine Translation,2020,0.00012745930034468257,1
W3045622142,Simultaneous Translation and Paraphrase for Language Education,2020,0.00012741845754273245,1
W4394770053,Label-text bi-attention capsule networks model for multi-label text classification,2024,0.0001273883550078798,1
W2911658506,Deep Learning and Its Applications to Natural Language Processing,2019,0.0001273883550078798,1
W4317906736,Medium-long-term prediction of water level based on an improved spatio-temporal attention mechanism for long short-term memory networks,2023,0.0001273883550078798,1
W2983577274,Improving Pre-Trained Multilingual Model with Vocabulary Expansion,2019,0.0001273883550078798,1
W4385569940,Scene Graph as Pivoting: Inference-time Image-free Unsupervised Multimodal Machine Translation with Visual Scene Hallucination,2023,0.0001273883550078798,1
W4381461529,Optimizing the impact of data augmentation for low-resource grammatical error correction,2023,0.0001273883550078798,1
W4362614755,Machine Translation Systems Based on Classical-Statistical-Deep-Learning Approaches,2023,0.0001273844704672794,1
W4281636848,Bi-SimCut: A Simple Strategy for Boosting Neural Machine Translation,2022,0.00012732634711909118,1
W2902214435,Proceedings of the 2nd Workshop on Neural Machine Translation and Generation,2018,0.00012731570165929124,1
W4295950983,Promoting wind energy for sustainable development by precise wind speed prediction based on graph neural networks,2022,0.00012725133398399288,1
W4313443611,Spatio-temporal wind speed forecasting using graph networks and novel Transformer architectures,2022,0.00012725133398399288,1
W2798742628,Improving Beam Search by Removing Monotonic Constraint for Neural Machine Translation,2018,0.0001272425199215747,1
W4205862160,A study of BERT for context-aware neural machine translation,2022,0.00012722626467014654,1
W4317897818,Locally Typical Sampling,2023,0.0001270966784748482,1
W2972677740,Token-Level Ensemble Distillation for Grapheme-to-Phoneme Conversion,2019,0.00012702275618164081,1
W4385570703,"Detecting and Mitigating Hallucinations in Machine Translation: Model Internal Workings Alone Do Well, Sentence Similarity Even Better",2023,0.00012698328806085056,1
W2985010700,Context-aware Neural Machine Translation with Coreference Information,2019,0.00012694334971180592,1
W3169001897,Counterfactual Data Augmentation for Neural Machine Translation,2021,0.000126885607526455,1
W4229040548,A Compression-Based Multiple Subword Segmentation for Neural Machine Translation,2022,0.00012671826197710372,1
W4380995299,Understanding and Detecting Hallucinations in Neural Machine Translation via Model Introspection,2023,0.00012666767661503013,1
W3176626464,Measuring and Increasing Context Usage in Context-Aware Machine Translation,2021,0.00012652931208919878,1
W2979047515,Putting Machine Translation in Context with the Noisy Channel Model,2019,0.0001265218883753345,1
W3024560045,Foundations and Modeling of Dynamic Networks Using Dynamic Graph Neural Networks: A Survey,2021,0.0001264753671409309,1
W2963490187,Learning Representation Mapping for Relation Detection in Knowledge Base Question Answering,2019,0.0001264657809625479,1
W4383752905,DifFormer: Multi-Resolutional Differencing Transformer With Dynamic Ranging for Time Series Analysis,2023,0.00012628829932520436,1
W4200157346,Machine remaining life prediction based on multi-layer self-attention and temporal convolution network,2021,0.00012628829932520436,1
W4200547309,Meta Graph Transformer: A Novel Framework for Spatial–Temporal Traffic Prediction,2021,0.00012628829932520436,1
W2971524460,Adaptively Sparse Transformers,2019,0.00012613951217483693,1
W3199518308,Scalable and Efficient MoE Training for Multitask Multilingual Models,2021,0.00012610348635112682,1
W2769618705,Neural Text Generation: A Practical Guide,2017,0.00012609981209057942,1
W3100113229,Adversarial Grammatical Error Correction,2020,0.00012599950281841674,1
W2890026292,Context and Copying in Neural Machine Translation,2018,0.00012581076444257808,1
W3128651145,Neural machine translation with a polysynthetic low resource language,2020,0.0001257735207024022,1
W3028827502,Comparison of the Evaluation Metrics for Neural Grammatical Error Correction With Overcorrection,2020,0.00012571140896702442,1
W3200388885,AligNART: Non-autoregressive Neural Machine Translation by Jointly Learning to Estimate Alignment and Translate,2021,0.00012567869524295657,1
W3175591469,Semantic Representation for Dialogue Modeling,2021,0.00012563080369852519,1
W3212319100,IST-Unbabel 2021 Submission for the Explainable Quality Estimation Shared Task,2021,0.00012558754274679553,1
W2924677654,Neural Models of Text Normalization for Speech Applications,2019,0.00012556759833644082,1
W3103942011,A Supervised Word Alignment Method based on Cross-Language Span Prediction using Multilingual BERT,2020,0.00012544003785925966,1
W3175216677,XLPT-AMR: Cross-Lingual Pre-Training via Multi-Task Learning for Zero-Shot AMR Parsing and Text Generation,2021,0.0001253882537666517,1
W4387428001,Towards Making the Most of LLM for Translation Quality Estimation,2023,0.0001253882537666517,1
W4226361124,Graph Pre-training for AMR Parsing and Generation,2022,0.0001253882537666517,1
W4362471447,A multi-semantic passing framework for semi-supervised long text classification,2023,0.0001253882537666517,1
W3109387650,Multi-modal neural machine translation with deep semantic interactions,2020,0.0001253882537666517,1
W3118324981,"Machine Translation for English–Inuktitut with Segmentation, Data Acquisition and Pre-Training",2020,0.00012527600080767238,1
W3093404841,Capturing Longer Context for Document-level Neural Machine Translation: A Multi-resolutional Approach.,2020,0.00012503503103290372,1
W3155457266,Multilingual Neural Machine Translation with Deep Encoder and Multiple Shallow Decoders,2021,0.00012501323478392143,1
W2950179609,Retrieve and Refine: Improved Sequence Generation Models For Dialogue,2018,0.00012500186005322245,1
W4283725425,Hierarchical Graph Convolutional Networks for Structured Long Document Classification,2022,0.00012496747592677062,1
W3092173171,Why Skip If You Can Combine: A Simple Knowledge Distillation Technique for Intermediate Layers,2020,0.00012491644008669867,1
W4385567303,A Survey on Zero Pronoun Translation,2023,0.0001249085852074591,1
W4394698525,"DeepNet: Scaling Transformers to 1,000 Layers",2024,0.0001248155097149647,1
W3037915423,Is 42 the Answer to Everything in Subtitling-oriented Speech Translation?,2020,0.00012475171298935377,1
W3158927431,Machine Translation Verbosity Control for Automatic Dubbing,2021,0.00012475171298935377,1
W2988008229,Utilizing Knowledge Graphs for Neural Machine Translation Augmentation,2019,0.00012468866035878355,1
W2971278153,Latent Ordinary Differential Equations for Irregularly-Sampled Time Series,2019,0.00012466589768393856,1
W3127228978,Overcoming Catastrophic Forgetting in Graph Neural Networks with Experience Replay,2021,0.00012463821580119115,1
W4386465411,Improving position encoding of transformers for multivariate time series classification,2023,0.00012463821580119115,1
W3177237711,End-to-End AMR Corefencence Resolution,2021,0.00012463821580119115,1
W3175990774,Self-Attention Networks Can Process Bounded Hierarchical Languages,2021,0.00012463821580119115,1
W4387341818,Transformer and Graph Convolutional Network for Text Classification,2023,0.00012463821580119115,1
W3119303959,Subformer: Exploring Weight Sharing for Parameter Efficiency in Generative Transformers,2021,0.00012463821580119115,1
W4400980292,A dual-stream spatio-temporal fusion network with multi-sensor signals for remaining useful life prediction,2024,0.00012463821580119115,1
W3148339758,UA-GEC: Grammatical Error Correction and Fluency Corpus for the Ukrainian Language,2023,0.00012463821580119115,1
W4361268002,Text classification on heterogeneous information network via enhanced GCN and knowledge,2023,0.00012463821580119115,1
W4207078300,Graph Convolutional Network Based on Multi-Head Pooling for Short Text Classification,2022,0.00012463821580119115,1
W4285227169,Interpretability for Language Learners Using Example-Based Grammatical Error Correction,2022,0.00012446802769734426,1
W4281728254,Universal Conditional Masked Language Pre-training for Neural Machine Translation,2022,0.0001244104384266332,1
W2998081612,Reinforced Curriculum Learning on Pre-Trained Neural Machine Translation Models,2020,0.00012439787771180514,1
W3090145300,Nearest Neighbor Machine Translation,2020,0.00012415683027356647,1
W3006127095,"Deep Learning for Source Code Modeling and Generation: Models, Applications and Challenges.",2020,0.00012400356829195532,1
W4324291650,Pipeline Signed Japanese Translation Using PBSMT and Transformer in a Low-Resource Setting,2023,0.00012400356829195532,1
W4205243694,Arabic Machine Translation: A Survey with Challenges and Future Directions,2021,0.00012400356829195532,1
W3120658156,An Efficient Transformer Decoder with Compressed Sub-layers,2021,0.00012400062285195364,1
W2981040094,Root Mean Square Layer Normalization,2019,0.00012397895968212108,1
W4385571586,Accelerating Transformer Inference for Translation via Parallel Decoding,2023,0.00012369181484378613,1
W3025111163,Reassessing Claims of Human Parity and Super-Human Performance in Machine Translation at WMT 2019,2020,0.00012368461563005495,1
W4386857706,P-Transformer: Towards Better Document-to-Document Neural Machine Translation,2023,0.00012366684044751595,1
W4377291249,A Scenario-Generic Neural Machine Translation Data Augmentation Method,2023,0.00012364030657271538,1
W3105626768,Learning Adaptive Segmentation Policy for Simultaneous Translation,2020,0.00012359934367976643,1
W3166829167,Multi-Hop Transformer for Document-Level Machine Translation,2021,0.00012354182636367905,1
W2983381967,Improving Robustness of Task Oriented Dialog Systems,2019,0.00012351373170770317,1
W3104688854,"Not Low-Resource Anymore: Aligner Ensembling, Batch Filtering, and New Datasets for Bengali-English Machine Translation",2020,0.0001234988411665093,1
W3205328383,NormFormer: Improved Transformer Pretraining with Extra Normalization,2021,0.0001234673718405404,1
W4391311153,Low Resource Arabic Dialects Transformer Neural Machine Translation Improvement through Incremental Transfer of Shared Linguistic Features,2024,0.00012345958471261033,1
W4324142619,Contrastive Adversarial Training for Multi-Modal Machine Translation,2023,0.00012345958471261033,1
W4401330063,Multimodal Machine Translation Based on Enhanced Knowledge Distillation and Feature Fusion,2024,0.00012345958471261033,1
W4401541163,LLMs-based machine translation for E-commerce,2024,0.00012345958471261033,1
W4398174014,RNN-LSTM: From applications to modeling techniques and beyond—Systematic review,2024,0.00012345958471261033,1
W3120964679,The University of Maryland’s Submissions to the WMT20 Chat Translation Task: Searching for More Data to Adapt Discourse-Aware Neural Machine Translation,2020,0.00012317845248735416,1
W3174636484,Importance-based Neuron Allocation for Multilingual Neural Machine Translation,2021,0.0001231495873861921,1
W3173680274,Modeling Bilingual Conversational Characteristics for Neural Chat Translation,2021,0.00012308194867918768,1
W4402332667,Distilling BERT knowledge into Seq2Seq with regularized Mixup for low-resource neural machine translation,2024,0.000122988132277178,1
W4385571312,Subword Segmental Machine Translation: Unifying Segmentation and Target Sentence Generation,2023,0.000122988132277178,1
W3102446692,Losing Heads in the Lottery: Pruning Transformer Attention in Neural Machine Translation,2020,0.000122988132277178,1
W3175212568,Vocabulary Learning via Optimal Transport for Neural Machine Translation,2021,0.000122988132277178,1
W3204470331,Predicting Attention Sparsity in Transformers,2022,0.000122988132277178,1
W3008282111,Tree-structured Attention with Hierarchical Accumulation,2020,0.00012296047151323297,1
W3212651325,Multilingual Unsupervised Neural Machine Translation with Denoising Adapters,2021,0.00012293529082463194,1
W3087346608,Alleviating the Inequality of Attention Heads for Neural Machine Translation,2020,0.00012292473520728752,1
W2995722251,A Survey on Document-level Neural Machine Translation: Methods and Evaluation,2019,0.0001229154176697928,1
W4285255685,IndicBART: A Pre-trained Model for Indic Natural Language Generation,2022,0.00012274541388638106,1
W2740592942,Multilingual Semantic Parsing And Code-Switching,2017,0.00012272569742473742,1
W2898774411,Exploring Neural Methods for Parsing Discourse Representation Structures,2018,0.00012272569742473742,1
W4296540711,Natural Language Processing Challenges and Issues: A Literature Review,2022,0.00012266994611295602,1
W2969696767,Neural Machine Translation With Sentence-Level Topic Context,2019,0.00012265290965673986,1
W3192770664,Correcting Arabic Soft Spelling Mistakes using BiLSTM-based Machine Learning,2022,0.00012240932294013817,1
W4385572691,ELMER: A Non-Autoregressive Pre-trained Language Model for Efficient and Effective Text Generation,2022,0.00012236317357588973,1
W4205476602,End-to-end entity-aware neural machine translation,2022,0.00012223173767870668,1
W4285182954,BiTIIMT: A Bilingual Text-infilling Method for Interactive Machine Translation,2022,0.00012223173767870668,1
W3115362515,Dynamic Curriculum Learning for Low-Resource Neural Machine Translation,2020,0.00012221162238352474,1
W4221152019,Integrating Vectorized Lexical Constraints for Neural Machine Translation,2022,0.00012221162238352474,1
W4385270114,"Towards Long-Term Time-Series Forecasting: Feature, Pattern, and Distribution",2023,0.00012221162238352474,1
W2807925339,Topic-to-Essay Generation with Neural Networks,2018,0.00012211693925442865,1
W3174556939,Attention Calibration for Transformer in Neural Machine Translation,2021,0.0001220190279042984,1
W4281483006,Sequence-to-Action: Grammatical Error Correction with Action Guided Sequence Generation,2022,0.00012188807659450253,1
W2773795499,A user-study on online adaptation of neural machine translation to human post-edits,2018,0.00012188807659450253,1
W4224083781,Learning to Generalize to More: Continuous Semantic Augmentation for Neural Machine Translation,2022,0.00012159858825695638,1
W3106106701,Revisiting Modularized Multilingual NMT to Meet Industrial Demands,2020,0.0001214128429095202,1
W2966045039,DuTongChuan: Context-aware Translation Model for Simultaneous Interpreting,2019,0.00012132876664217506,1
W4225849768,Incorporating rich syntax information in Grammatical Error Correction,2022,0.00012120494681597304,1
W2896667998,On internal language representations in deep learning : an analysis of machine translation and speech recognition,2018,0.00012115118960173021,1
W3104669693,Improving Grammatical Error Correction Models with Purpose-Built Adversarial Examples,2020,0.00012110232253544865,1
W3179639371,Character-based Neural Semantic Parsing,2021,0.0001209373697069638,1
W4385570075,NaSGEC: a Multi-Domain Chinese Grammatical Error Correction Dataset from Native Speaker Texts,2023,0.00012083415885791128,1
W4281770000,One Reference Is Not Enough: Diverse Distillation with Reference Selection for Non-Autoregressive Translation,2022,0.00012074358615104836,1
W3097996341,Detecting Word Sense Disambiguation Biases in Machine Translation for Model-Agnostic Adversarial Attacks,2020,0.00012074350656685661,1
W4399851779,Enhancing Document-Level Translation of Large Language Model Via Translation Mixed-Instructions,2024,0.00012069236389594226,1
W4225388806,Nearest Neighbor Knowledge Distillation for Neural Machine Translation,2022,0.0001206819800960299,1
W3017643757,On Sparsifying Encoder Outputs in Sequence-to-Sequence Models,2020,0.00012064545902148581,1
W2901299405,GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism,2018,0.00012063533907915854,1
W2997205428,Nonlinear Mixup: Out-Of-Manifold Data Augmentation for Text Classification,2020,0.0001205731770600715,1
W3156064004,Zero-Shot Cross-Lingual Transfer of Neural Machine Translation with Multilingual Pretrained Encoders,2021,0.00012026284720432378,1
W3176079416,Bridging Subword Gaps in Pretrain-Finetune Paradigm for Natural Language Generation,2021,0.00012025456058760615,1
W4385571866,Improving Grammatical Error Correction with Multimodal Feature Integration,2023,0.00012021113055364716,1
W3118485656,Diving Deep into Context-Aware Neural Machine Translation,2020,0.0001199723330989375,1
W4237056802,Exploring Methods for Generating Feedback Comments for Writing Learning,2021,0.00011975350334302089,1
W3213720774,Grammatical Error Correction with Contrastive Learning in Low Error Density Domains,2021,0.00011975350334302089,1
W3155618984,Machine Translationese: Effects of Algorithmic Bias on Linguistic Complexity in Machine Translation,2021,0.00011968469014440235,1
W2982434686,A Latent Morphology Model for Open-Vocabulary Neural Machine Translation,2019,0.00011968469014440235,1
W3139537596,Finetuning Pretrained Transformers into RNNs,2021,0.0001194423059192431,1
W2958127121,Facebook FAIR's WMT19 News Translation Task Submission,2019,0.0001194423059192431,1
W4206688402,Finetuning Pretrained Transformers into RNNs,2021,0.0001194423059192431,1
W2972858361,Multilingual multimodal machine translation for Dravidian languages utilizing phonetic transcription,2019,0.00011929971028232499,1
W2981515358,WordNet Gloss Translation for Under-resourced Languages using Multilingual Neural Machine Translation.,2019,0.00011929971028232499,1
W2970611505,Synchronously Generating Two Languages with Interactive Decoding,2019,0.00011925878335853623,1
W3106124812,Graph-to-Tree Neural Networks for Learning Structured Input-Output Translation with Applications to Semantic Parsing and Math Word Problem,2020,0.00011896320691533386,1
W2920359981,Assembling translations from multi-engine machine translation outputs,2019,0.00011892578221839203,1
W4220997127,Enhancing low-resource neural machine translation with syntax-graph guided self-attention,2022,0.00011892578221839203,1
W3182737888,BERT-JAM: Maximizing the utilization of BERT for neural machine translation,2021,0.00011892578221839203,1
W3115860342,RealFormer: Transformer Likes Residual Attention,2020,0.0001188447665005739,1
W3169496116,Mask Attention Networks: Rethinking and Strengthen Transformer,2021,0.0001188447665005739,1
W3135593154,Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth,2021,0.0001188447665005739,1
W3103699753,Character-level Representations Improve DRS-based Semantic Parsing Even in the Age of BERT,2020,0.0001188374516477923,1
W4365802915,HanoiT: Enhancing Context-aware Translation via Selective Context,2023,0.00011877748812633341,1
W3087057727,Document-level Neural Machine Translation with Document Embeddings,2025,0.00011877748812633341,1
W3130523865,Revisiting Multi-Domain Machine Translation,2021,0.00011875582667228297,1
W2740753882,Machine Translation and Automated Analysis of the Sumerian Language,2017,0.00011874506035828696,1
W4285128732,latent-GLAT: Glancing at Latent Variables for Parallel Text Generation,2022,0.0001186963213003049,1
W4376612203,Nearest Neighbor Non-autoregressive Text Generation,2023,0.0001186963213003049,1
W3176297128,Don’t Take It Literally: An Edit-Invariant Sequence Loss for Text Generation,2022,0.0001186963213003049,1
W4285275708,Confidence Based Bidirectional Global Context Aware Training Framework for Neural Machine Translation,2022,0.0001186963213003049,1
W3166029516,Non-Autoregressive Semantic Parsing for Compositional Task-Oriented Dialog,2021,0.0001186963213003049,1
W3177132412,Investigating the Reordering Capability in CTC-based Non-Autoregressive End-to-End Speech Translation,2021,0.0001186963213003049,1
W4385573924,EdiT5: Semi-Autoregressive Text Editing with T5 Warm-Start,2022,0.0001186963213003049,1
W3154504973,Non-Autoregressive Text Generation with Pre-trained Language Models,2021,0.0001186963213003049,1
W3022839720,A Diverse Data Augmentation Strategy for Low-Resource Neural Machine Translation,2020,0.00011848771624029677,1
W4390768253,Improving neural machine translation of languages with little data and rich morphology,2024,0.00011848771624029677,1
W4285258432,Redistributing Low-Frequency Words: Making the Most of Monolingual Data in Non-Autoregressive Translation,2022,0.00011843506303186872,1
W4285242045,Towards Making the Most of Cross-Lingual Transfer for Zero-Shot Neural Machine Translation,2022,0.00011843506303186872,1
W2979190299,Improving Anaphora Resolution in Neural Machine Translation Using Curriculum Learning.,2019,0.00011816022341610402,1
W3119378114,Unsupervised Bitext Mining and Translation via Self-Trained Contextual Embeddings,2020,0.00011802200808426163,1
W3011573365,Syntax-aware Transformer Encoder for Neural Machine Translation,2019,0.00011802200808426163,1
W4225302758,ISOMETRIC MT: Neural Machine Translation for Automatic Dubbing,2022,0.00011798465320436384,1
W4385570335,Improving Long Context Document-Level Machine Translation,2023,0.00011798465320436384,1
W3174659183,Do Context-Aware Translation Models Pay the Right Attention?,2021,0.00011798465320436384,1
W2911265970,Deep Learning for Natural Language Processing,2019,0.00011762457345539988,1
W3173785189,Machine Translation into Low-resource Language Varieties,2021,0.00011747265852474393,1
W3199990076,The Trade-offs of Domain Adaptation for Neural Language Models,2022,0.00011715897164904442,1
W3170463198,Pruning-then-Expanding Model for Domain Adaptation of Neural Machine Translation,2021,0.00011715897164904442,1
W3167056186,Continual Learning for Neural Machine Translation,2021,0.00011715897164904442,1
W3046584416,Multi-step ahead forecasting of regional air quality using spatial-temporal deep neural networks: A case study of Huaihai Economic Zone,2020,0.00011638779818112528,1
W4386129879,Dynamic adaptive encoder-decoder deep learning networks for multivariate time series forecasting of building energy consumption,2023,0.00011638779818112528,1
W4399563755,Exploring the frontier: Transformer-based models in EEG signal analysis for brain-computer interfaces,2024,0.00011638779818112528,1
W4311294852,Towards Energy-Preserving Natural Language Understanding With Spiking Neural Networks,2022,0.00011638779818112528,1
W4353094384,Feedback on a shared big dataset for intelligent TBM Part I: Feature extraction and machine learning methods,2023,0.00011638779818112528,1
W4386351122,A novel short-term multi-energy load forecasting method for integrated energy system based on feature separation-fusion technology and improved CNN,2023,0.00011638779818112528,1
W3193301525,Automated identification of cell populations in flow cytometry data with transformers,2022,0.00011638779818112528,1
W4390969131,Graph Neural Network-Based EEG Classification: A Survey,2024,0.00011638779818112528,1
W4386566380,A Low-Resource Approach to the Grammatical Error Correction of Ukrainian,2023,0.00011638779818112528,1
W4399068029,A neural network transformer model for composite microstructure homogenization,2024,0.00011638779818112528,1
W3174974057,Attention-based model for predicting question relatedness on Stack Overflow,2021,0.00011638779818112528,1
W4407778892,Technical Report of OPPO’s Machine Translation Systems for CCMT 2024,2025,0.00011638779818112528,1
W4388040908,How Does It Function? Characterizing Long-term Trends in Production Serverless Workloads,2023,0.00011638779818112528,1
W4386070139,SafetyMed: A Novel IoMT Intrusion Detection System Using CNN-LSTM Hybridization,2023,0.00011638779818112528,1
W4390414087,An adversarial contrastive autoencoder for robust multivariate time series anomaly detection,2023,0.00011638779818112528,1
W4395003231,Translation model based on discrete Fourier transform and Skipping Sub-Layer methods,2024,0.00011638779818112528,1
W4406241648,Enhancing prediction of dissolved oxygen over Santa Margarita River: Long short-term memory incorporated with multi-objective observer-teacher-learner optimization,2025,0.00011638779818112528,1
W3196896228,Towards Making the Most of Dialogue Characteristics for Neural Chat Translation,2021,0.00011638779818112528,1
W4409831355,Syntax-enhanced Chinese–Vietnamese neural machine translation with linguistic feature template integration,2025,0.00011638779818112528,1
W3099872554,POINTER: Constrained Progressive Text Generation via Insertion-based Generative Pre-training,2020,0.00011638779818112528,1
W4392516232,GRAformer: A gated residual attention transformer for multivariate time series forecasting,2024,0.00011638779818112528,1
W4389518883,MixEdit: Revisiting Data Augmentation and Beyond for Grammatical Error Correction,2023,0.00011638779818112528,1
W4366813964,Optimized Seq2Seq model based on multiple methods for short-term power load forecasting,2023,0.00011638779818112528,1
W4224324825,Slow-Varying Dynamics-Assisted Temporal Capsule Network for Machinery Remaining Useful Life Estimation,2022,0.00011638779818112528,1
W4384665479,Incorporating multimodal context information into traffic speed forecasting through graph deep learning,2023,0.00011638779818112528,1
W4400090517,Automatically Categorizing Construction Accident Narratives Using the Deep-Learning Model with a Class-Imbalance Treatment Technique,2024,0.00011638779818112528,1
W2950129230,Compositional generalization through meta sequence-to-sequence learning,2019,0.00011638779818112528,1
W4409343151,Properties of neural networks identifying strongly lensed gravitational waves in time domain,2025,0.00011638779818112528,1
W4386805190,LSTM-Based Machine Translation for Madurese-Indonesian,2023,0.00011638779818112528,1
W4313908847,Online portfolio management via deep reinforcement learning with high-frequency data,2023,0.00011638779818112528,1
W4407832567,Post-ocr text correction for Bulgarian historical documents,2025,0.00011638779818112528,1
W3049450989,Fine-grained learning performance prediction via adaptive sparse self-attention networks,2020,0.00011638779818112528,1
W4384161799,Supervised Copy Mechanism for Grammatical Error Correction,2023,0.00011638779818112528,1
W4407732814,ADCL: An attention feature enhancement network based on adversarial contrastive learning for short text classification,2025,0.00011638779818112528,1
W2963472176,Unlabeled Data for Morphological Generation With Character-Based Sequence-to-Sequence Models,2017,0.00011638779818112528,1
W4408853303,Text Classification Model Based on Dependency Attention Graph Convolution,2024,0.00011638779818112528,1
W4399808999,"Large language models ""ad referendum"": How good are they at machine translation in the legal domain?",2024,0.00011638779818112528,1
W4393118497,A two-stage adversarial Transformer based approach for multivariate industrial time series anomaly detection,2024,0.00011638779818112528,1
W4200379301,Spatio-Temporal Spectrum Load Prediction Using Convolutional Neural Network and ResNet,2021,0.00011638779818112528,1
W4379117136,Coupled Attention Networks for Multivariate Time Series Anomaly Detection,2023,0.00011638779818112528,1
W4306319588,Image-based time series forecasting: A deep convolutional neural network approach,2022,0.00011638779818112528,1
W4406692092,Attention-based Deep learning Models for Predicting Anomalous Shock of Wastewater Treatment Plants,2025,0.00011638779818112528,1
W4410494118,Applying convolutional attention mechanisms and Human Memory Search for effective English-Urdu translation,2025,0.00011638779818112528,1
W2902604592,Discourse-Related Language Contrasts in English-Croatian Human and Machine Translation,2018,0.00011638779818112528,1
W3106051020,Membership Inference Attacks on Sequence-to-Sequence Models: Is My Data In Your Machine Translation System?,2020,0.00011638779818112528,1
W4401111001,Modeling and compensation of small-sample thermal error in precision machine tool spindles using spatial–temporal feature interaction fusion network,2024,0.00011638779818112528,1
W4225284516,Graph correlated attention recurrent neural network for multivariate time series forecasting,2022,0.00011638779818112528,1
W4410500912,Multimodal retrieval‐augmented generation framework for machine translation,2025,0.00011638779818112528,1
W4406059659,MSTDFGRN: A Multi-view Spatio-Temporal Dynamic Fusion Graph Recurrent Network for traffic flow prediction,2025,0.00011638779818112528,1
W4392365138,Transformer-based multivariate time series anomaly detection using inter-variable attention mechanism,2024,0.00011638779818112528,1
W4324104316,Exploiting time-varying RFM measures for customer churn prediction with deep neural networks,2023,0.00011638779818112528,1
W4407033379,Combining Graph NN and LLM for Improved Text-Based Emotion Recognition,2025,0.00011638779818112528,1
W4409606464,Research on Wearable Devices for Pedestrian Navigation Based on the Informer Model Zero-Velocity Update Architecture,2025,0.00011638779818112528,1
W4391906156,An LSTM-SA model for SOC estimation of lithium-ion batteries under various temperatures and aging levels,2024,0.00011638779818112528,1
W4281741710,A Comprehensive Survey on Various Fully Automatic Machine Translation Evaluation Metrics,2022,0.00011638779818112528,1
W4213219213,DarknetSec: A novel self-attentive deep learning method for darknet traffic classification and application identification,2022,0.00011638779818112528,1
W4385256302,Fuzzy clustering analysis for the loan audit short texts,2023,0.00011638779818112528,1
W2728069591,Multilingual Hierarchical Attention Networks for Document Classification,2017,0.00011638779818112528,1
W3186833834,Text Guide: Improving the Quality of Long Text Classification by a Text Selection Method Based on Feature Importance,2021,0.00011638779818112528,1
W4391612940,Adaptive micro- and macro-knowledge incorporation for hierarchical text classification,2024,0.00011638779818112528,1
W4391224777,"TAXN: Translate Align Extract Normalize, a Multilingual Extraction Tool for Clinical Texts",2024,0.00011638779818112528,1
W2955750298,Character-level Supervision for Low-resource POS Tagging,2018,0.00011638779818112528,1
W4390939135,Survey on Multi-Task Learning in Smart Transportation,2024,0.00011638779818112528,1
W2803039862,End-to-End Neural Network Based Automated Speech Scoring,2018,0.00011638779818112528,1
W4401164045,A Novel Technique for Extracting Entity Relations,2024,0.00011638779818112528,1
W4392976240,LCDFormer: Long-term correlations dual-graph transformer for traffic forecasting,2024,0.00011638779818112528,1
W4313151162,A Review of Neural Networks for Anomaly Detection,2022,0.00011638779818112528,1
W4221153174,Learning physics-constrained subgrid-scale closures in the small-data regime for stable and accurate LES,2022,0.00011638779818112528,1
W4399864464,MHGNN: Multi-view fusion based Heterogeneous Graph Neural Network,2024,0.00011638779818112528,1
W4210334299,Learning multi-label label-specific features via global and local label correlations,2022,0.00011638779818112528,1
W3212722208,Self-Supervised Curriculum Learning for Spelling Error Correction,2021,0.00011638779818112528,1
W4391994338,"Evaluating Time-Series Prediction of Temperature, Relative Humidity, and CO2 in the Greenhouse with Transformer-Based and RNN-Based Models",2024,0.00011638779818112528,1
W4406080987,A systematic review for transformer-based long-term series forecasting,2025,0.00011638779818112528,1
W3132366366,Fusion Models for Improved Image Captioning,2021,0.00011638779818112528,1
W4386021093,Transformers are Short-Text Classifiers,2023,0.00011638779818112528,1
W4387967494,NOA-LSTM: An efficient LSTM cell architecture for time series forecasting,2023,0.00011638779818112528,1
W4287888115,Maximum Bayes Smatch Ensemble Distillation for AMR Parsing,2022,0.00011638779818112528,1
W3171088343,Probing Word Translations in the Transformer and Trading Decoder for Encoder Layers,2021,0.00011638779818112528,1
W4406681264,Multilingual pretrained based multi-feature fusion model for English text classification,2025,0.00011638779818112528,1
W4407719259,A location-centric transformer framework for multi-location short-term wind speed forecasting,2025,0.00011638779818112528,1
W4400602210,Confined attention mechanism enabled Recurrent Neural Network framework to improve traffic flow prediction,2024,0.00011638779818112528,1
W4377211416,Tackling Ambiguity with Images: Improved Multimodal Machine Translation and Contrastive Evaluation,2023,0.00011638779818112528,1
W4410056584,Improving machine translation accuracy for underrepresented languages in linguistic research using transformer models,2025,0.00011638779818112528,1
W4400678841,Context-Aware Machine Translation with Source Coreference Explanation,2024,0.00011638779818112528,1
W4389497068,"Explainable, interpretable, and trustworthy AI for an intelligent digital twin: A case study on remaining useful life",2023,0.00011638779818112528,1
W4407574881,Improving Low-Resource Kazakh-English and Turkish-English Neural Machine Translation Using Transfer Learning and Part of Speech Tags,2025,0.00011638779818112528,1
W4296191071,Train wheel degradation generation and prediction based on the time series generation adversarial network,2022,0.00011638779818112528,1
W3003693721,A Hierarchical Clustering Approach to Fuzzy Semantic Representation of Rare Words in Neural Machine Translation,2020,0.00011638779818112528,1
W4410119725,Knowledge-guided Adaptive Spatial-Temporal Graph Contrastive Learning Framework: Regional Crop Diseases Prediction based on Electronic Medical Records,2025,0.00011638779818112528,1
W4220712276,Attention-based Conv-LSTM and Bi-LSTM networks for large-scale traffic speed prediction,2022,0.00011638779818112528,1
W4386474260,A novel EMD and causal convolutional network integrated with Transformer for ultra short-term wind power forecasting,2023,0.00011638779818112528,1
W4311165734,Boosting Neural Networks to Decompile Optimized Binaries,2022,0.00011638779818112528,1
W4380742759,Anomaly detection for multivariate times series through the multi-scale convolutional recurrent variational autoencoder,2023,0.00011638779818112528,1
W4399975443,Graph transformer embedded deep learning for short-term passenger flow prediction in urban rail transit systems: A multi-gate mixture-of-experts model,2024,0.00011638779818112528,1
W4407922782,STAT-LSTM: A multivariate spatiotemporal feature aggregation model for SPEI-based drought prediction,2025,0.00011638779818112528,1
W4402469109,A Critical Review of RNN and LSTM Variants in Hydrological Time Series Predictions,2024,0.00011638779818112528,1
W4410540086,Multi-label feature selection via exploring reliable instance similarities,2025,0.00011638779818112528,1
W4387846859,Reasoning beyond Triples: Recent Advances in Knowledge Graph Embeddings,2023,0.00011638779818112528,1
W4410486486,DocNet: Semantic Structure in Inductive Bias Detection Models,2025,0.00011638779818112528,1
W4384926261,Harnessing the power of AI: Advanced deep learning models optimization for accurate SARS-CoV-2 forecasting,2023,0.00011638779818112528,1
W4407242470,Automatic Evaluation of English Translation Based on Multi-granularity Interaction Fusion,2025,0.00011638779818112528,1
W4399687297,Unlocking the language barrier: A Journey through Arabic machine translation,2024,0.00011638779818112528,1
W4406144302,Anomaly detection in virtual machine logs against irrelevant attribute interference,2025,0.00011638779818112528,1
W4386986621,Integrated Multi-Head Self-Attention Transformer model for electricity demand prediction incorporating local climate variables,2023,0.00011638779818112528,1
W4397035966,Natural Language Processing,2023,0.00011638779818112528,1
W2945927415,AMR Parsing as Sequence-to-Graph Transduction,2019,0.00011638779818112528,1
W4382202724,Continual Graph Convolutional Network for Text Classification,2023,0.00011638779818112528,1
W4382202983,Label-Specific Feature Augmentation for Long-Tailed Multi-Label Text Classification,2023,0.00011638779818112528,1
W3174554374,Towards Fully Automated Manga Translation,2021,0.00011638779818112528,1
W4392432892,Achieving robustness in hybrid models: A physics-informed regularization approach for spatiotemporal parameter estimation in PDEs,2024,0.00011638779818112528,1
W4392523455,Application of Quantum Recurrent Neural Network in Low-Resource Language Text Classification,2024,0.00011638779818112528,1
W4318014921,ProtInteract: A deep learning framework for predicting protein–protein interactions,2023,0.00011638779818112528,1
W4390037644,Unsupervised multilingual machine translation with pretrained cross-lingual encoders,2023,0.00011638779818112528,1
W4395071168,Transformer encoder based self-supervised learning for HVAC fault detection with unlabeled data,2024,0.00011638779818112528,1
W4361981113,A Survey on Data-Driven Runoff Forecasting Models Based on Neural Networks,2023,0.00011638779818112528,1
W4394765698,Interlimb and Intralimb Synergy Modeling for Lower Limb Assistive Devices,2024,0.00011638779818112528,1
W4409603142,Beqi: Revitalize the Senegalese Wolof Language with a Robust Spelling Corrector,2025,0.00011638779818112528,1
W4392123654,Diffusion models in text generation: a survey,2024,0.00011638779818112528,1
W3157764526,Investigating the Performance of Fine-tuned Text Classification Models Based-on Bert,2020,0.00011638779818112528,1
W4389519005,Improving Seq2Seq Grammatical Error Correction via Decoding Interventions,2023,0.00011638779818112528,1
W4318476430,HFCM-LSTM: A novel hybrid framework for state-of-health estimation of lithium-ion battery,2023,0.00011638779818112528,1
W4221155853,Neural Grapheme-To-Phoneme Conversion with Pre-Trained Grapheme Models,2022,0.00011638779818112528,1
W4389783325,From Turing to Transformers: A Comprehensive Review and Tutorial on the Evolution and Applications of Generative Transformer Models,2023,0.00011638779818112528,1
W4296188488,Combining knowledge graph into metro passenger flow prediction: A split-attention relational graph convolutional network,2022,0.00011638779818112528,1
W4408596469,Log-Cumulative feature alignment for enhanced Prognosis of Aero-Engine remaining Useful life,2025,0.00011638779818112528,1
W4392714183,Explainability and Interpretability in Electric Load Forecasting Using Machine Learning Techniques – A Review,2024,0.00011638779818112528,1
W4362466625,Synthetized Multilanguage OCR Using CRNN and SVTR Models for Realtime Collaborative Tools,2023,0.00011638779818112528,1
W4316039505,Robust recurrent neural networks for time series forecasting,2023,0.00011638779818112528,1
W3217345529,A transformer-based model for default prediction in mid-cap corporate markets,2022,0.00011638779818112528,1
W4394060534,Advancing climate-resilient flood mitigation: Utilizing transformer-LSTM for water level forecasting at pumping stations,2024,0.00011638779818112528,1
W4407272113,Combining informed data-driven anomaly detection with knowledge graphs for root cause analysis in predictive maintenance,2025,0.00011638779818112528,1
W4403016694,ProTformer: Transformer-based model for superior prediction of protein content in lablab bean (Lablab purpureus L.) using Near-Infrared Reflectance spectroscopy,2024,0.00011638779818112528,1
W4407020552,"ScaloAdaptAlert, a novel framework for supervised anomaly detection in industrial acoustic data, integrating power scalograms, adaptive filter banks, and convolutional neural networks — A case study",2025,0.00011638779818112528,1
W4396917044,Novel deep-learning method based on LSA-Transformer for fault detection and its implementation in penicillin fermentation process,2024,0.00011638779818112528,1
W4385572192,Text Style Transfer Back-Translation,2023,0.00011638779818112528,1
W4360976562,Text classification using embeddings: a survey,2023,0.00011638779818112528,1
W4392137397,Unsupervised feature selection using chronological fitting with Shapley Additive explanation (SHAP) for industrial time-series anomaly detection,2024,0.00011638779818112528,1
W4403296460,Translating classical Arabic verse: human translation vs. AI large language models (Gemini and ChatGPT),2024,0.00011638779818112528,1
W4392883897,LSTTN: A Long-Short Term Transformer-based spatiotemporal neural network for traffic flow forecasting,2024,0.00011638779818112528,1
W4285272557,∞-former: Infinite Memory Transformer-former: Infinite Memory Transformer,2022,0.00011638779818112528,1
W3153961130,Attention-Based LSTM for Non-Contact Sleep Stage Classification Using IR-UWB Radar,2021,0.00011638779818112528,1
W4396888881,Contrastive BiLSTM-enabled Health Representation Learning for Remaining Useful Life Prediction,2024,0.00011638779818112528,1
W4406618530,A Multi-Model Fusion Network for Enhanced Blind Well Lithology Prediction,2025,0.00011638779818112528,1
W4379053920,Sensing prior constraints in deep neural networks for solving exploration geophysical problems,2023,0.00011638779818112528,1
W4386094835,Graph Representation Learning,2023,0.00011638779818112528,1
W4407894718,Novel model for medium to long term photovoltaic power prediction using interactive feature trend transformer,2025,0.00011638779818112528,1
W4406015697,Personalized tourism recommendation model based on temporal multilayer sequential neural network,2025,0.00011638779818112528,1
W4387875671,Design of a Modified Transformer Architecture Based on Relative Position Coding,2023,0.00011638779818112528,1
W4409245690,Advances in meta-learning and zero-shot learning for multi-label classification: A review,2025,0.00011638779818112528,1
W4409530322,From News to Trends: A Financial Time Series Forecasting Framework with LLM-Driven News Sentiment Analysis and Selective State Spaces,2025,0.00011638779818112528,1
W4406911809,Overcoming language barriers via machine translation with sparse Mixture-of-Experts fusion of large language models,2025,0.00011638779818112528,1
W4281621698,An intelligent approach for Arabic handwritten letter recognition using convolutional neural network,2022,0.00011638779818112528,1
W4406539492,A Hybrid CNN-Transformer Surrogate Model for the Multi-Objective Robust Optimization of Geological Carbon Sequestration,2025,0.00011638779818112528,1
W4410056673,"Evaluating Free Legal Translation Tools between Arabic and English: A Comparative Study of Google Translate, ChatGPT, and Gemini",2025,0.00011638779818112528,1
W4281929036,GTAD: Graph and Temporal Neural Network for Multivariate Time Series Anomaly Detection,2022,0.00011638779818112528,1
W2962716258,Neural optimizer search with reinforcement learning,2017,0.00011638779818112528,1
W4388036918,A multi-state fusion informer integrating transfer learning for metal tube bending early wrinkling prediction,2023,0.00011638779818112528,1
W4406209594,Intelligent identification of hydropower engineering safety hazards: research on text classification method based on deep learning,2025,0.00011638779818112528,1
W2952443824,Paraphrases as Foreign Languages in Multilingual Neural Machine Translation,2019,0.00011638779818112528,1
W4385571101,Open-ended Long Text Generation via Masked Language Modeling,2023,0.00011638779818112528,1
W4407190631,Multi-Subgraph Fusion: An Innovative Approach for Block Matrix Graph Convolutional Networks,2025,0.00011638779818112528,1
W3142584950,A large English–Thai parallel corpus from the web and machine-generated text,2021,0.00011638779818112528,1
W3128976925,Multimodal approach to analysing big social and news media data,2021,0.00011638779818112528,1
W4311750276,Domain generalization via adversarial out-domain augmentation for remaining useful life prediction of bearings under unseen conditions,2022,0.00011638779818112528,1
W4385626821,Twitter Bot Detection Using Neural Networks and Linguistic Embeddings,2023,0.00011638779818112528,1
W2804243520,Thermal load forecasting in district heating networks using deep learning and advanced feature selection methods,2018,0.00011638779818112528,1
W4387987111,TreeCN: Time Series Prediction With the Tree Convolutional Network for Traffic Prediction,2023,0.00011638779818112528,1
W3217689614,Structural Rotor Fault Diagnosis Using Attention-Based Sensor Fusion and Transformers,2021,0.00011638779818112528,1
W4381463374,A Neural Attention-Based Encoder-Decoder Approach for English to Bangla Translation,2023,0.00011638779818112528,1
W4380152257,A benchmark dataset and evaluation methodology for Chinese zero pronoun translation,2023,0.00011638779818112528,1
W3153368012,When FastText Pays Attention: Efficient Estimation of Word Representations using Constrained Positional Weighting,2022,0.00011638779818112528,1
W3006801027,Fixed Encoder Self-Attention Patterns in Transformer-Based Machine Translation,2020,0.00011638779818112528,1
W3187058997,BTS: Back TranScription for Speech-to-Text Post-Processor using Text-to-Speech-to-Text,2021,0.00011638779818112528,1
W4410288220,Triplet-modality group-guided incremental distillation with regularized group semantic consistency for multi-modal neural machine translation,2025,0.00011638779818112528,1
W2945534329,Effective Cross-lingual Transfer of Neural Machine Translation Models without Shared Vocabularies,2019,0.00011638779818112528,1
W4293259034,A novel adversarial domain adaptation transfer learning method for tool wear state prediction,2022,0.00011638779818112528,1
W2893384461,Research on the LSTM Mongolian and Chinese machine translation based on morpheme encoding,2018,0.00011638779818112528,1
W4392452799,An encoder–decoder architecture with Fourier attention for chaotic time series multi-step prediction,2024,0.00011638779818112528,1
W4406848965,Enhancing Transformer-based models for long sequence time series forecasting via structured matrix,2025,0.00011638779818112528,1
W4386566338,Language-Family Adapters for Low-Resource Multilingual Neural Machine Translation,2023,0.00011638779818112528,1
W4408545849,Error Analysis and Instructional Strategy Adjustment in a Corpus of English Language Learners,2025,0.00011638779818112528,1
W3045571807,Robust Prediction of Punctuation and Truecasing for Medical ASR,2020,0.00011638779818112528,1
W2905288168,Learning to Generate Corrective Patches using Neural Machine Translation,2018,0.00011638779818112528,1
W3172643943,Choose a Transformer: Fourier or Galerkin,2021,0.00011638779818112528,1
W3212440929,Geo-BERT Pre-training Model for Query Rewriting in POI Search,2021,0.00011638779818112528,1
W4385572877,Neural Machine Translation with Contrastive Translation Memories,2022,0.00011638779818112528,1
W4408854639,From innovativeness to insecurity: unveiling the facets of translation technology use behavior among EFL learners using TRI 2.0,2025,0.00011638779818112528,1
W4375857395,"Neural machine translation in EFL classrooms: learners’ vocabulary improvement, immediate vocabulary retention and delayed vocabulary retention",2023,0.00011638779818112528,1
W3102427165,Translating math formula images to LaTeX sequences using deep neural networks with sequence-level training,2020,0.00011638779818112528,1
W4375858432,Hybrid deep neural network with dimension attention for state-of-health estimation of Lithium-ion Batteries,2023,0.00011638779818112528,1
W2998259434,Enhancing Pointer Network for Sentence Ordering with Pairwise Ordering Predictions,2020,0.00011638779818112528,1
W3124426233,A data aggregation based approach to exploit dynamic spatio-temporal correlations for citywide crowd flows prediction in fog computing,2021,0.00011638779818112528,1
W4285296929,Pre-Trained Multilingual Sequence-to-Sequence Models: A Hope for Low-Resource Language Translation?,2022,0.00011638779818112528,1
W4289866548,Anomaly Detection in Time Series with Robust Variational Quasi-Recurrent Autoencoders,2022,0.00011638779818112528,1
W4362589932,LenM: Improving Low-Resource Neural Machine Translation Using Target Length Modeling,2023,0.00011638779818112528,1
W4410215172,An Improved Deep Learning Model for Word Embeddings Based Clustering for Large Text Datasets,2025,0.00011638779818112528,1
W4408470385,Hierarchical Text Classification: Fine-tuned GPT-2 vs BERT-BiLSTM,2025,0.00011638779818112528,1
W4303644832,Egg Freshness Prediction Model Using Real-Time Cold Chain Storage Condition Based on Transfer Learning,2022,0.00011638779818112528,1
W4400441570,Multi-domain encoder–decoder neural networks for latent data assimilation in dynamical systems,2024,0.00011638779818112528,1
W4362563550,Generating Natural Language From Logic Expressions With Structural Representation,2023,0.00011638779818112528,1
W3160789530,Neural Inverse Text Normalization,2021,0.00011638779818112528,1
W4406946743,"A Transformer-Based Model for Network Intrusion Detection: Architecture, Classification Heads, and Transformer Blocks",2025,0.00011638779818112528,1
W4387164353,TGCN-Bert Emoji Prediction in Information Systems Using TCN and GCN Fusing Features Based on BERT,2023,0.00011638779818112528,1
W4297973310,An LSTM-Autoencoder Architecture for Anomaly Detection Applied on Compressors Audio Data,2022,0.00011638779818112528,1
W4229744135,Proceedings of the First Workshop on Subword and Character Level Models in NLP,2017,0.00011638779818112528,1
W4205729691,A Multiagent Deep Reinforcement Learning Based Approach for the Optimization of Transformer Life Using Coordinated Electric Vehicles,2022,0.00011638779818112528,1
W4388459526,Medical image analysis using deep learning algorithms,2023,0.00011638779818112528,1
W3170034074,Macro-Average: Rare Types Are Important Too,2021,0.00011638779818112528,1
W4378229377,Landslide Susceptibility Mapping Based on Deep Learning Algorithms Using Information Value Analysis Optimization,2023,0.00011638779818112528,1
W4223944214,Threat intelligence ATT&amp;CK extraction based on the attention transformer hierarchical recurrent neural network,2022,0.00011638779818112528,1
W4396978893,Dynamic spatial aware graph transformer for spatiotemporal traffic flow forecasting,2024,0.00011638779818112528,1
W4309835665,A novel transformer-based multi-variable multi-step prediction method for chemical process fault prognosis,2022,0.00011638779818112528,1
W4292664320,High Speed Simulation and Freeform Optimization of Nanophotonic Devices with Physics-Augmented Deep Learning,2022,0.00011638779818112528,1
W3196227100,Feature selection for label distribution learning via feature similarity and label correlation,2021,0.00011638779818112528,1
W3131017962,The automated prediction of solar flares from SDO images using deep learning,2021,0.00011638779818112528,1
W4392180639,MAgNET: A graph U-Net architecture for mesh-based simulations,2024,0.00011638779818112528,1
W3134371412,GIKT: A Graph-Based Interaction Model for Knowledge Tracing,2021,0.00011638779818112528,1
W4385571296,Bidirectional Transformer Reranker for Grammatical Error Correction,2023,0.00011638779818112528,1
W3213650470,A hybrid partitioned deep learning methodology for moving interface and fluid–structure interaction,2021,0.00011638779818112528,1
W4381326995,LightCTS: A Lightweight Framework for Correlated Time Series Forecasting,2023,0.00011638779818112528,1
W4319996212,Energformer: A New Transformer Model for Energy Disaggregation,2023,0.00011638779818112528,1
W4401551179,Sensitive Analysis of Natural Language Processing Using for MOORA Method,2024,0.00011638779818112528,1
W4409657370,<scp>UniDEC</scp> : Unified Dual Encoder and Classifier Training for Extreme Multi-Label Classification,2025,0.00011638779818112528,1
W3142358935,An attention‐based category‐aware GRU model for the next POI recommendation,2021,0.00011638779818112528,1
W4408484065,Translator Chatbot in Cloud Environment Using Amazon Translate and Amazon Lex,2025,0.00011638779818112528,1
W4375928748,Nonlinear Spiking Neural Systems With Autapses for Predicting Chaotic Time Series,2023,0.00011638779818112528,1
W2961117861,OmniNet: A unified architecture for multi-modal multi-task learning,2019,0.00011638779818112528,1
W4385570074,ChatBack: Investigating Methods of Providing Grammatical Error Feedback in a GUI-based Language Learning Chatbot,2023,0.00011638779818112528,1
W4390841728,DAO-LGBM: dual annealing optimization with light gradient boosting machine for advocates prediction in online customer engagement,2024,0.00011638779818112528,1
W4290948450,Causal Attention for Interpretable and Generalizable Graph Classification,2022,0.00011638779818112528,1
W4396779890,Exploring Sentence-level Revision Capabilities of LLMs in English for Academic Purposes Writing Assistance,2024,0.00011638779818112528,1
W4409831893,Spanish to Mexican Sign Language glosses corpus for natural language processing tasks,2025,0.00011638779818112528,1
W3203385474,The Low-Resource Double Bind: An Empirical Study of Pruning for Low-Resource Machine Translation,2021,0.00011638779818112528,1
W4407870846,Routeformer:Transformer utilizing routing mechanism for traffic flow forecasting,2025,0.00011638779818112528,1
W4389520033,"Efficient Long-Range Transformers: You Need to Attend More, but Not Necessarily at Every Layer",2023,0.00011638779818112528,1
W4403577901,DIFN: A Dual Intention-aware Network for Repurchase Recommendation with Hierarchical Spatio-temporal Fusion,2024,0.00011638779818112528,1
W4396694481,A novel hybrid model based on Empirical Mode Decomposition and Echo State Network for wind power forecasting,2024,0.00011638779818112528,1
W4407591251,Incorporating bilingual translation templates into neural machine translation,2025,0.00011638779818112528,1
W3109995084,milliEgo,2020,0.00011638779818112528,1
W4226209484,Learning to Solve 3-D Bin Packing Problem via Deep Reinforcement Learning and Constraint Programming,2021,0.00011638779818112528,1
W3186283138,English Grammar Error Detection Using Recurrent Neural Networks,2021,0.00011638779818112528,1
W4383340789,Self-attention Mechanism at the Token Level: Gradient Analysis and Algorithm Optimization,2023,0.00011638779818112528,1
W4410544883,Addressing Syntactic Divergence in Low-Resource Neural Machine Translation via Language Independent Word Reordering,2025,0.00011638779818112528,1
W4408384615,Improving Neural Machine Translation Through Code‐Mixed Data Augmentation,2025,0.00011638779818112528,1
W3106786448,Attention-gating for improved radio galaxy classification,2020,0.00011638779818112528,1
W4250928698,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations,2019,0.00011638779818112528,1
W4399556159,TriChronoNet: Advancing electricity price prediction with Multi-module fusion,2024,0.00011638779818112528,1
W4401463408,The Use of Attention-Enhanced CNN-LSTM Models for Multi-Indicator and Time-Series Predictions of Surface Water Quality,2024,0.00011638779818112528,1
W4365597197,Angler: Helping Machine Translation Practitioners Prioritize Model Improvements,2023,0.00011638779818112528,1
W4389503368,ICFormer: A Deep Learning model for informed lithium-ion battery diagnosis and early knee detection,2023,0.00011638779818112528,1
W3168169499,Context-aware Self-Attention Networks for Natural Language Processing,2021,0.00011638779818112528,1
W3213934211,How Suitable Are Subword Segmentation Strategies for Translating Non-Concatenative Morphology?,2021,0.00011638779818112528,1
W3171460770,Dynamic Language Models for Continuously Evolving Content,2021,0.00011638779818112528,1
W3173069567,Deep learning approach for Translating Arabic Holy Quran into Italian language,2021,0.00011638779818112528,1
W2987395887,Multilingual Whispers: Generating Paraphrases with Translation,2019,0.00011638779818112528,1
W4321615273,Time-series quantum reservoir computing with weak and projective measurements,2023,0.00011638779818112528,1
W4388242026,Explainable Spatio-Temporal Graph Neural Networks for multi-site photovoltaic energy production,2023,0.00011638779818112528,1
W4392163668,Neural machine translation of clinical text: an empirical investigation into multilingual pre-trained language models and transfer-learning,2024,0.00011638779818112528,1
W4385287316,A novel hybrid deep learning model with ARIMA Conv-LSTM networks and shuffle attention layer for short-term traffic flow prediction,2023,0.00011638779818112528,1
W3088321919,"Tasks, stability, architecture, and compute: Training more effective learned optimizers, and using them to train themselves.",2020,0.00011638779818112528,1
W4386566814,Summarize and Generate to Back-translate: Unsupervised Translation of Programming Languages,2023,0.00011638779818112528,1
W3159560594,Designing a Uniform Meaning Representation for Natural Language Processing,2021,0.00011638779818112528,1
W2936497627,Language Models with Transformers,2019,0.00011638779818112528,1
W4285262293,Water Quality Prediction for Smart Aquaculture Using Hybrid Deep Learning Models,2022,0.00011638779818112528,1
W4224281298,ATP: AMRize Then Parse! Enhancing AMR Parsing with PseudoAMRs,2022,0.00011638779818112528,1
W4406798421,Data Augmentation Strategies for Improved PM2.5 Forecasting Using Transformer Architectures,2025,0.00011638779818112528,1
W4400723670,A novel approach to forecast water table rise in arid regions using stacked ensemble machine learning and deep artificial intelligence models,2024,0.00011638779818112528,1
W4392094097,Transformer based Kalman Filter with EM algorithm for time series prediction and anomaly detection of complex systems,2024,0.00011638779818112528,1
W4388798200,Improved deep bidirectional recurrent neural network for learning the cross-sensitivity rules of gas sensor array,2023,0.00011638779818112528,1
W4384200848,Investigating Unsupervised Neural Machine Translation for Low-resource Language Pair English-Mizo via Lexically Enhanced Pre-trained Language Models,2023,0.00011638779818112528,1
W2902363804,Stable Forecasting of Environmental Time Series via Long Short Term Memory Recurrent Neural Network,2018,0.00011638779818112528,1
W3156039010,MedPath: Augmenting Health Risk Prediction via Medical Knowledge Paths,2021,0.00011638779818112528,1
W4290927906,CAT: Beyond Efficient Transformer for Content-Aware Anomaly Detection in Event Sequences,2022,0.00011638779818112528,1
W4385565515,Sparse Binary Transformers for Multivariate Time Series Modeling,2023,0.00011638779818112528,1
W3026538704,Applying the Transformer to Character-level Transduction,2020,0.00011638779818112528,1
W3087462960,Inter-hours rolling scheduling of behind-the-meter storage operating systems using electricity price forecasting based on deep convolutional neural network,2020,0.00011638779818112528,1
W3114268635,Reservoir Transformers,2021,0.00011638779818112528,1
W4406049444,Physics-informed radial basis function neural network for efficiently modeling oil–water two-phase Darcy flow,2025,0.00011638779818112528,1
W4283399618,Short-term multi-hour ahead country-wide wind power prediction for Germany using gated recurrent unit deep learning,2022,0.00011638779818112528,1
W3150584131,Multigraph Transformer for Free-Hand Sketch Recognition,2021,0.00011638779818112528,1
W3197963420,Building interpretable models for business process prediction using shared and specialised attention mechanisms,2022,0.00011638779818112528,1
W3095962368,Detecting Hallucinated Content in Conditional Neural Sequence Generation,2020,0.00011638779818112528,1
W3207024370,GNN-LM: Language Modeling based on Global Contexts via GNN,2021,0.00011638779818112528,1
W4388976461,Forecasting water quality variable using deep learning and weighted averaging ensemble models,2023,0.00011638779818112528,1
W2908623803,Causal Discovery with Attention-Based Convolutional Neural Networks,2019,0.00011638779818112528,1
W4318588669,Data augmentation using Heuristic Masked Language Modeling,2023,0.00011638779818112528,1
W4409999318,BiG: A Bidirectional Group-Wise Contrastive Learning Method for Multi-Label Text Classification,2025,0.00011638779818112528,1
W3121356850,Graph Deep Learning: State of the Art and Challenges,2021,0.00011638779818112528,1
W4409972024,Missing Traffic Data Imputation based on Tensor Completion and Graph Network Fusion,2025,0.00011638779818112528,1
W3095093830,Deep Learning–Based Segmentation and Quantification in Experimental Kidney Histopathology,2020,0.00011638779818112528,1
W4387469767,Lithium-ion battery state of health estimation using a hybrid model based on a convolutional neural network and bidirectional gated recurrent unit,2023,0.00011638779818112528,1
W4410076829,A Novel Approach for Advanced Persistent Threats Detection via Graph Transformer,2025,0.00011638779818112528,1
W4205347394,Augmentation and heterogeneous graph neural network for AAAI2021-COVID-19 fake news detection,2022,0.00011638779818112528,1
W4385569983,Augmenters at SemEval-2023 Task 1: Enhancing CLIP in Handling Compositionality and Ambiguity for Zero-Shot Visual WSD through Prompt Augmentation and Text-To-Image Diffusion,2023,0.00011638779818112528,1
W2922268266,Novel Deep Learning Model with CNN and Bi-Directional LSTM for Improved Stock Market Index Prediction,2019,0.00011638779818112528,1
W4390876416,Knowledge Graph Enhanced Transformers for Diagnosis Generation of Chinese Medicine,2024,0.00011638779818112528,1
W3091991378,Efficient Wait-k Models for Simultaneous Machine Translation,2020,0.00011638779818112528,1
W3005377970,Beyond Expectation: Deep Joint Mean and Quantile Regression for Spatiotemporal Problems,2020,0.00011638779818112528,1
W4289933203,Online public opinion prediction based on a novel seasonal grey decomposition and ensemble model,2022,0.00011638779818112528,1
W4206626673,Multivariate Correlation-aware Spatio-temporal Graph Convolutional Networks for Multi-scale Traffic Prediction,2022,0.00011638779818112528,1
W4313887285,A Stochastic Recurrent Encoder Decoder Network for Multistep Probabilistic Wind Power Predictions,2023,0.00011638779818112528,1
W4388584848,Rolling bearing intelligent fault diagnosis towards variable speed and imbalanced samples using multiscale dynamic supervised contrast learning,2023,0.00011638779818112528,1
W3080670519,TAdaNet: Task-Adaptive Network for Graph-Enriched Meta-Learning,2020,0.00011638779818112528,1
W4365420380,A Lightweight Transformer-Based Approach of Specific Emitter Identification for the Automatic Identification System,2023,0.00011638779818112528,1
W4392671492,A regularized constrained two-stream convolution augmented Transformer for aircraft engine remaining useful life prediction,2024,0.00011638779818112528,1
W4391540437,On the Value of Head Labels in Multi-Label Text Classification,2024,0.00011638779818112528,1
W4378979493,Dual-interactive fusion for code-mixed deep representation learning in tag recommendation,2023,0.00011638779818112528,1
W4406902818,Adaptive transformer-based multi-task learning framework for synchronous prediction of substation flooding and outage risks,2025,0.00011638779818112528,1
W3170740203,Sentence Concatenation Approach to Data Augmentation for Neural Machine Translation,2021,0.00011638779818112528,1
W4386322034,ES-dRNN: A Hybrid Exponential Smoothing and Dilated Recurrent Neural Network Model for Short-Term Load Forecasting,2023,0.00011638779818112528,1
W4407031014,LLM-Augmented Linear Transformer–CNN for Enhanced Stock Price Prediction,2025,0.00011638779818112528,1
W4361025967,BTAD: A binary transformer deep neural network model for anomaly detection in multivariate time series data,2023,0.00011638779818112528,1
W4316038338,Fault diagnosis of wind turbine based on multi-signal CNN-GRU model,2023,0.00011638779818112528,1
W4392698767,Sparsity in transformers: A systematic literature review,2024,0.00011638779818112528,1
W4406047825,Few‐label aerial target intention recognition based on self‐supervised contrastive learning,2025,0.00011638779818112528,1
W4366823268,What’s the next word in large language models?,2023,0.00011638779818112528,1
W4386947607,A feature decomposition-based deep transfer learning framework for concrete dam deformation prediction with observational insufficiency,2023,0.00011638779818112528,1
W3138501833,Fault detection in Tennessee Eastman process with temporal deep learning models,2021,0.00011638779818112528,1
W4383955240,Deep Learning Framework for Lithium-ion Battery State of Charge Estimation: Recent Advances and Future Perspectives,2023,0.00011638779818112528,1
W4321490471,Design and Proofreading of the English-Chinese Computer-Aided Translation System by the Neural Network,2023,0.00011638779818112528,1
W4391589817,Unmanned Aerial Vehicles anomaly detection model based on sensor information fusion and hybrid multimodal neural network,2024,0.00011638779818112528,1
W4392345811,Ensemble of temporal Transformers for financial time series,2024,0.00011638779818112528,1
W4394018559,A task-oriented deep learning framework based on target-related transformer network for industrial quality prediction applications,2024,0.00011638779818112528,1
W4243882989,Proceedings of The Third Workshop on Representation Learning for NLP,2018,0.00011638779818112528,1
W4409917064,Prediction of stress-strain behavior of rock materials under biaxial compression using a deep learning approach,2025,0.00011638779818112528,1
W4406237835,Rethinking the message passing for graph-level classification tasks in a category-based view,2025,0.00011638779818112528,1
W4213154819,"Accurate workload prediction for edge data centers: Savitzky-Golay filter, CNN and BiLSTM with attention mechanism",2022,0.00011638779818112528,1
W2805713564,Heart Sound Segmentation—An Event Detection Approach Using Deep Recurrent Neural Networks,2018,0.00011638779818112528,1
W4390671307,"Physics-Guided, Physics-Informed, and Physics-Encoded Neural Networks and Operators in Scientific Computing: Fluid and Solid Mechanics",2024,0.00011638779818112528,1
W3123221884,An Attention Free Transformer,2021,0.00011638779818112528,1
W4408754018,Evaluating Large Language Models in Translation: A Theoretical and Practical Analysis Based on Skopos Theory,2025,0.00011638779818112528,1
W4410033944,Multiscale session-enhanced long time series modeling for power transformer oil temperature prediction,2025,0.00011638779818112528,1
W3144827309,ODE Transformer: An Ordinary Differential Equation-Inspired Model for Neural Machine Translation,2021,0.00011638779818112528,1
W3034296505,A Mixture of h - 1 Heads is Better than h Heads,2020,0.00011638779818112528,1
W2968370607,Robust Attentional Aggregation of Deep Feature Sets for Multi-view 3D Reconstruction,2019,0.00011638779818112528,1
W4388841071,Refining one-class representation: A unified transformer for unsupervised time-series anomaly detection,2023,0.00011638779818112528,1
W4312056220,Fast training of a transformer for global multi-horizon time series forecasting on tensor processing units,2022,0.00011638779818112528,1
W4393152681,Improved Graph Contrastive Learning for Short Text Classification,2024,0.00011638779818112528,1
W4226031225,Electric Vehicle Velocity and Energy Consumption Predictions Using Transformer and Markov-Chain Monte Carlo,2022,0.00011638779818112528,1
W3177223224,Putting words into the system’s mouth: A targeted attack on neural machine translation using monolingual data poisoning,2021,0.00011638779818112528,1
W3196530826,Recurrent neural networks for atmospheric noise removal from InSAR time series with missing values,2021,0.00011638779818112528,1
W4381618831,A deep learning based health indicator construction and fault prognosis with uncertainty quantification for rolling bearings,2023,0.00011638779818112528,1
W3155116954,Transformer-based Machine Translation for Low-resourced Languages embedded with Language Identification,2021,0.00011638779818112528,1
W4205270295,Dynamic Prototype Network based on Sample Adaptation for Few-Shot Malware Detection,2022,0.00011638779818112528,1
W3172722713,An entity linking model based on candidate features,2021,0.00011638779818112528,1
W2963030892,LCANet: End-to-End Lipreading with Cascaded Attention-CTC,2018,0.00011638779818112528,1
W4408058742,Using tide for rainfall runoff simulation with feature projection and reversible instance normalization,2025,0.00011638779818112528,1
W2970469088,Translate and Label! An Encoder-Decoder Approach for Cross-lingual Semantic Role Labeling,2019,0.00011638779818112528,1
W4401626610,"Recurrent Neural Networks: A Comprehensive Review of Architectures, Variants, and Applications",2024,0.00011638779818112528,1
W4409364692,Text augmentation method with adjustable manipulation intensity based on in-context learning,2025,0.00011638779818112528,1
W3047331772,"Foundations of Population-based SHM, Part II: Heterogeneous populations – Graphs, networks, and communities",2020,0.00011638779818112528,1
W3176997878,BERTTune: Fine-Tuning Neural Machine Translation with BERTScore,2021,0.00011638779818112528,1
W4396518138,Anomaly Detection for Asynchronous Multivariate Time Series of Nuclear Power Plants Using a Temporal-Spatial Transformer,2024,0.00011638779818112528,1
W2944992190,Wireless Network Intrusion Detection Based on Improved Convolutional Neural Network,2019,0.00011638779818112528,1
W3175710487,H-Transformer-1D: Fast One-Dimensional Hierarchical Attention for Sequences,2021,0.00011638779818112528,1
W4407666369,Text Classification Method Based on Graph Neural Networks,2025,0.00011638779818112528,1
W4308500886,Handwritten computer science words vocabulary recognition using concatenated convolutional neural networks,2022,0.00011638779818112528,1
W4390704115,A deep learning-based hybrid approach for multi-time-ahead streamflow prediction in an arid region of Northwest China,2024,0.00011638779818112528,1
W4391642338,Argo data anomaly detection based on transformer and Fourier transform,2024,0.00011638779818112528,1
W4407410754,Applying cultural-historical activity theory to understand Korean tourists’ experiences with language translation applications,2025,0.00011638779818112528,1
W3112317145,SongMASS: Automatic Song Writing with Pre-training and Alignment Constraint,2021,0.00011638779818112528,1
W4385808309,Learning the Language of NMR: Structure Elucidation from NMR spectra using Transformer Models,2023,0.00011638779818112528,1
W4409680692,Cross-Dataset Analysis of Language Models for Generalised Multi-label Review Note Distribution in Animated Productions,2025,0.00011638779818112528,1
W3175260681,Language Tags Matter for Zero-Shot Neural Machine Translation,2021,0.00011638779818112528,1
W4399883732,Addressing the data gap: building a parallel corpus for Kashmiri language,2024,0.00011638779818112528,1
W3164487383,Spatial-Temporal Conv-Sequence Learning With Accident Encoding for Traffic Flow Prediction,2022,0.00011638779818112528,1
W4311421441,Bearing remaining useful life prediction using self-adaptive graph convolutional networks with self-attention mechanism,2022,0.00011638779818112528,1
W2884159461,A Survey of the Usages of Deep Learning in Natural Language Processing,2018,0.00011638779818112528,1
W4399469388,Efficiently localizing system anomalies for cloud infrastructures: a novel Dynamic Graph Transformer based Parallel Framework,2024,0.00011638779818112528,1
W3047397334,A Survey of Orthographic Information in Machine Translation,2021,0.00011638779818112528,1
W4409990846,Rethinking Transformers for Efficiency and Scalability,2025,0.00011638779818112528,1
W4394824429,Deep learning-based spatial-temporal graph neural networks for price movement classification in crude oil and precious metal markets,2024,0.00011638779818112528,1
W4368359023,A Multichannel Convolutional Decoding Network for Graph Classification,2023,0.00011638779818112528,1
W4392715732,Multilingual Neural Machine Translation for Indic to Indic Languages,2024,0.00011638779818112528,1
W4385756443,MG-GCN: Multi-Granularity Graph Convolutional Neural Network for Multi-Label Classification in Multi-Label Information System,2023,0.00011638779818112528,1
W4407666365,Research progress on Chinese and English text error correction,2025,0.00011638779818112528,1
W4392828127,Quality Prediction Modeling for Industrial Processes Using Multiscale Attention-Based Convolutional Neural Network,2024,0.00011638779818112528,1
W4397024830,"Implications of using AI in Translation Studies: Trends, Challenges, and Future Direction",2024,0.00011638779818112528,1
W4399154202,Graph Kernel Neural Networks,2024,0.00011638779818112528,1
W4404633977,"Opportunities and Challenges in Transformer Neural Networks for Battery State Estimation: Charge, Health, Lifetime, and Safety",2024,0.00011638779818112528,1
W4382202529,SoftCorrect: Error Correction with Soft Detection for Automatic Speech Recognition,2023,0.00011638779818112528,1
W2908503141,MuVAN: A Multi-view Attention Network for Multivariate Temporal Data,2018,0.00011638779818112528,1
W4392271377,Natural Language Processing Methods for Symbolic Music Generation and Information Retrieval: A Survey,2025,0.00011638779818112528,1
W4323923311,A novel XGBoost-based featurization approach to forecast renewable energy consumption with deep learning models,2023,0.00011638779818112528,1
W4385573925,Multilingual Sentence Transformer as A Multilingual Word Aligner,2022,0.00011638779818112528,1
W4362733507,Graph Neural Networks and Open-Government Data to Forecast Traffic Flow,2023,0.00011638779818112528,1
W4394687230,Multi-scale feature enhanced spatio-temporal learning for traffic flow forecasting,2024,0.00011638779818112528,1
W4311765452,A novel convolutional informer network for deterministic and probabilistic state-of-charge estimation of lithium-ion batteries,2022,0.00011638779818112528,1
W4396878152,TKAN: Temporal Kolmogorov-Arnold Networks,2024,0.00011638779818112528,1
W4410253015,Deep Learning Techniques for Machine Translation: A Survey,2025,0.00011638779818112528,1
W2996331899,Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting,2019,0.00011638779818112528,1
W4406019758,Prediction of Electricity Consumption in Residential Areas using Temporal Fusion Transformer and Convolutional Neural Network,2025,0.00011638779818112528,1
W4293833044,A CNN-Bi_LSTM parallel network approach for train travel time prediction,2022,0.00011638779818112528,1
W4393033598,Predicting ICU Interventions: A Transparent Decision Support Model Based on Multivariate Time Series Graph Convolutional Neural Network,2024,0.00011638779818112528,1
W4391653525,Modelling monthly rainfall of India through transformer-based deep learning architecture,2024,0.00011638779818112528,1
W4306811603,Deep transfer learning based on Bi-LSTM and attention for remaining useful life prediction of rolling bearing,2022,0.00011638779818112528,1
W4385261005,Applying QNLP to Sentiment Analysis in Finance,2023,0.00011638779818112528,1
W3166016508,Graph Neural Networks for Natural Language Processing: A Survey,2021,0.00011638779818112528,1
W4406893043,Application of Transformer Models for Advanced Process Optimization and Process Mining,2025,0.00011638779818112528,1
W3207645655,Beyond Distillation: Task-level Mixture-of-Experts for Efficient Inference,2021,0.00011638779818112528,1
W4396758709,UniTime: A Language-Empowered Unified Model for Cross-Domain Time Series Forecasting,2024,0.00011638779818112528,1
W4408372743,Research on multi-label short text categorization method for online education under deep learning,2025,0.00011638779818112528,1
W4362670671,Classification of Research Papers on Radio Frequency Electromagnetic Field (RF-EMF) Using Graph Neural Networks (GNN),2023,0.00011638779818112528,1
W4407923384,A multi-factor clustering integration paradigm for wind speed point-interval prediction based on feature selection and optimized inverted transformer,2025,0.00011638779818112528,1
W2952975409,Neural Architecture Optimization,2018,0.00011638779818112528,1
W4391486486,STFormer: A dual-stage transformer model utilizing spatio-temporal graph embedding for multivariate time series forecasting,2024,0.00011638779818112528,1
W2606554264,Bayesian Recurrent Neural Networks,2017,0.00011638779818112528,1
W4391553729,Contrastive feature-based learning-guided elevated deep reinforcement learning: Developing an imbalanced fault quantitative diagnosis under variable working conditions,2024,0.00011638779818112528,1
W4285193872,Mukayese: Turkish NLP Strikes Back,2022,0.00011638779818112528,1
W4391407085,Neural Architecture Search for Anomaly Detection in Time-Series Data of Smart Buildings: A Reinforcement Learning Approach for Optimal Autoencoder Design,2024,0.00011638779818112528,1
W4364382428,SwiftR: Cross-platform ransomware fingerprinting using hierarchical neural networks on hybrid features,2023,0.00011638779818112528,1
W2964053550,Tensorized Self-Attention: Efficiently Modeling Pairwise and Global Dependencies Together,2019,0.00011638779818112528,1
W4396762170,Fairness Testing of Machine Translation Systems,2024,0.00011638779818112528,1
W2805041018,Unsupervised Text Style Transfer using Language Models as Discriminators,2018,0.00011638779818112528,1
W4382203122,Time Series Anomaly Detection Using Transformer-Based GAN With Two-Step Masking,2023,0.00011638779818112528,1
W4405185121,Contrastive multi-graph learning with neighbor hierarchical sifting for semi-supervised text classification,2024,0.00011638779818112528,1
W2804025582,Wave2Vec: Deep representation learning for clinical temporal data,2018,0.00011638779818112528,1
W2948975009,Real or Fake? Learning to Discriminate Machine from Human Generated Text.,2019,0.00011638779818112528,1
W4307725013,Parallel Deep Learning with a hybrid BP-PSO framework for feature extraction and malware classification,2022,0.00011638779818112528,1
W2898410387,Evaluating prose style transfer with the Bible,2018,0.00011638779818112528,1
W4285275791,Multitask Hypergraph Convolutional Networks: A Heterogeneous Traffic Prediction Framework,2022,0.00011638779818112528,1
W3046263488,The importance of short lag-time in the runoff forecasting model based on long short-term memory,2020,0.00011638779818112528,1
W4385805582,Continual Deep Learning for Time Series Modeling,2023,0.00011638779818112528,1
W4283771810,FedHGCDroid: An Adaptive Multi-Dimensional Federated Learning for Privacy-Preserving Android Malware Classification,2022,0.00011638779818112528,1
W4210907736,Multi-level text document similarity estimation and its application for plagiarism detection,2022,0.00011638779818112528,1
W4409772377,Transformers to the rescue: alleviating data scarcity in arabic grammatical error correction with pre-trained models,2025,0.00011638779818112528,1
W4319924564,MDFULog: Multi-Feature Deep Fusion of Unstable Log Anomaly Detection Model,2023,0.00011638779818112528,1
W4385574170,EdgeFormer: A Parameter-Efficient Transformer for On-Device Seq2seq Generation,2022,0.00011638779818112528,1
W4379799065,A review on big data based on deep neural network approaches,2023,0.00011638779818112528,1
W3116929749,Part-of-speech tagging of building codes empowered by deep learning and transformational rules,2020,0.00011638779818112528,1
W4401889742,"Recurrent Neural Networks: A Comprehensive Review of Architectures, Variants, and Applications",2024,0.00011638779818112528,1
W3193741318,A Deep Learning Approach for Flight Delay Prediction Through Time-Evolving Graphs,2021,0.00011638779818112528,1
W4395468431,A Joint Time-Frequency Domain Transformer for multivariate time series forecasting,2024,0.00011638779818112528,1
W4408067834,Language Intelligence in Law: NLP Solutions for Legal Excellence,2025,0.00011638779818112528,1
W3113920925,mmFall: Fall Detection Using 4-D mmWave Radar and a Hybrid Variational RNN AutoEncoder,2020,0.00011638779818112528,1
W4285110390,Controlling Translation Formality Using Pre-trained Multilingual Language Models,2022,0.00011638779818112528,1
W4313427720,Malware Detection Using Deep Learning and Correlation-Based Feature Selection,2023,0.00011638779818112528,1
W4385069426,STN-GCN: Spatial and Temporal Normalization Graph Convolutional Neural Networks for Traffic Flow Forecasting,2023,0.00011638779818112528,1
W3166943438,Can You Traducir This? Machine Translation for Code-Switched Input,2021,0.00011638779818112528,1
W4391344861,A lightweight multi-layer perceptron for efficient multivariate time series forecasting,2024,0.00011638779818112528,1
W4313177352,Transformers discover an elementary calculation system exploiting local attention and grid-like problem representation,2022,0.00011638779818112528,1
W3118419305,A novel one-stage framework for visual pulse rate estimation using deep neural networks,2021,0.00011638779818112528,1
W4406189876,LogSD: log anomaly detection via topic words awareness semantic augmentation and category-guided Mixup data augmentation,2025,0.00011638779818112528,1
W4385570660,BigVideo: A Large-scale Video Subtitle Translation Dataset for Multimodal Machine Translation,2023,0.00011638779818112528,1
W4409694971,Hierarchical contrastive learning for multi-label text classification,2025,0.00011638779818112528,1
W4392921739,A Novel Transformer-Based Anomaly Detection Approach for ECG Monitoring Healthcare System,2024,0.00011638779818112528,1
W3200520312,SHAPE: Shifted Absolute Position Embedding for Transformers,2021,0.00011638779818112528,1
W3012798438,Dynamic Sampling and Selective Masking for Communication-Efficient Federated Learning,2021,0.00011638779818112528,1
W3110908468,Fact-Enhanced Synthetic News Generation,2021,0.00011638779818112528,1
W3111375540,ReTransformer,2020,0.00011638779818112528,1
W4404474646,"Decoder-Only Transformers: The Brains Behind Generative AI, Large Language Models and Large Multimodal Models",2024,0.00011638779818112528,1
W4408538777,A hybrid re-fusion model for text classification,2025,0.00011638779818112528,1
W3184465100,A novel temporal convolutional network via enhancing feature extraction for the chiller fault diagnosis,2021,0.00011638779818112528,1
W4367310799,DESCINet: A hierarchical deep convolutional neural network with skip connection for long time series forecasting,2023,0.00011638779818112528,1
W4408971054,Medical Text Classification with Data Augmentation Based on Baichuan2,2025,0.00011638779818112528,1
W4408362397,The Application of Intelligent Translation System Based on Machine Translation in English Education Curriculum Reforms,2025,0.00011638779818112528,1
W2963622218,HeteroMed,2018,0.00011638779818112528,1
W4406305410,Hierarchical graph-based integration network for propaganda detection in textual news articles on social media,2025,0.00011638779818112528,1
W4396496351,An Evaluation of ChatGPT's Translation Accuracy Using BLEU Score,2024,0.00011638779818112528,1
W4409890951,Disfluency processing for cascaded speech translation involving English and Indian languages,2025,0.00011638779818112528,1
W4387566946,State of health estimation of lithium-ion batteries based on Mixers-bidirectional temporal convolutional neural network,2023,0.00011638779818112528,1
W3199222954,Rapid ultracapacitor life prediction with a convolutional neural network,2021,0.00011638779818112528,1
W2910795780,Graph Convolutional Network with Sequential Attention for Goal-Oriented Dialogue Systems,2019,0.00011638779818112528,1
W2884096449,Language Informed Modeling of Code-Switched Text,2018,0.00011638779818112528,1
W4393145324,"A Hybrid Method of Self-Supervised Graph Embedding, Siamese Networks, and Transformers for Sentiment Analysis in Persian Language",2024,0.00011638779818112528,1
W2950527268,Learning Differentially Private Recurrent Language Models,2017,0.00011638779818112528,1
W4205438547,A Comparison of TCN and LSTM Models in Detecting Anomalies in Time Series Data,2021,0.00011638779818112528,1
W4385895548,Adaptive filters in Graph Convolutional Neural Networks,2023,0.00011638779818112528,1
W2901739041,Mixed-Precision Training for NLP and Speech Recognition with OpenSeq2Seq,2018,0.00011638779818112528,1
W3088304121,The Challenges of Using Neural Machine Translation for Literature,2019,0.00011638779818112528,1
W4403682256,An efficient class-dependent learning label approach using feature selection to improve multi-label classification algorithms,2024,0.00011638779818112528,1
W3082184637,Cooperative Deep Dynamic Feature Extraction and Variable Time-Delay Estimation for Industrial Quality Prediction,2020,0.00011638779818112528,1
W3184237885,Energy consumption prediction of appliances using machine learning and multi-objective binary grey wolf optimization for feature selection,2021,0.00011638779818112528,1
W4379106999,MrCAN: Multi-relations aware convolutional attention network for multivariate time series forecasting,2023,0.00011638779818112528,1
W4225470987,Conditional Bilingual Mutual Information Based Adaptive Training for Neural Machine Translation,2022,0.00011638779818112528,1
W4406769409,Interval evaluation of temporal (in)stability for neural machine translation,2025,0.00011638779818112528,1
W4408667798,Symmetric KL-divergence by Stein’s Method,2025,0.00011638779818112528,1
W4399813745,A lightweight CNN-transformer model for learning traveling salesman problems,2024,0.00011638779818112528,1
W4390628459,A hybrid deep learning approach for remaining useful life prediction of lithium-ion batteries based on discharging fragments,2024,0.00011638779818112528,1
W4394779417,Deep learning and structural health monitoring: Temporal Fusion Transformers for anomaly detection in masonry towers,2024,0.00011638779818112528,1
W4390905466,WindTrans: Transformer-Based Wind Speed Forecasting Method for High-Speed Railway,2024,0.00011638779818112528,1
W4387182867,MCA-DTCN: A novel dual-task temporal convolutional network with multi-channel attention for first prediction time detection and remaining useful life prediction,2023,0.00011638779818112528,1
W4396498890,How good are different machine and deep learning models in forecasting the future price of metals? Full sample versus sub-sample,2024,0.00011638779818112528,1
W4390097263,EHR-HGCN: An Enhanced Hybrid Approach for Text Classification Using Heterogeneous Graph Convolutional Networks in Electronic Health Records,2023,0.00011638779818112528,1
W4361271286,Wavelet-Seq2Seq-LSTM with attention for time series forecasting of level of dams in hydroelectric power plants,2023,0.00011638779818112528,1
W4392106667,TCDformer: A transformer framework for non-stationary time series forecasting based on trend and change-point detection,2024,0.00011638779818112528,1
W4409799499,Prompt enhanced neural machine translation with POS tags,2025,0.00011638779818112528,1
W4387787572,Analysis of Language Model Role in Improving Machine Translation Accuracy for Extremely Low Resource Languages,2023,0.00011638779818112528,1
W4385572835,LVP-M3: Language-aware Visual Prompt for Multilingual Multimodal Machine Translation,2022,0.00011638779818112528,1
W4310145190,Automated Rule-Based Data Cleaning Using NLP,2022,0.00011638779818112528,1
W2945888757,Highly Effective,2019,0.00011638779818112528,1
W4283809531,Wasserstein Adversarial Transformer for Cloud Workload Prediction,2022,0.00011638779818112528,1
W4391490399,Deep signal separation for adaptive estimation of instantaneous phase from vibration signals,2024,0.00011638779818112528,1
W2901578516,Topical Co-Attention Networks for hashtag recommendation on microblogs,2018,0.00011638779818112528,1
W4407445115,A transformer-based semi-autoregressive framework for high-speed and accurate de novo peptide sequencing,2025,0.00011638779818112528,1
W4390841447,Multi-resolution partial differential equations preserved learning framework for spatiotemporal dynamics,2024,0.00011638779818112528,1
W3031420959,ADAHESSIAN: An Adaptive Second Order Optimizer for Machine Learning,2021,0.00011638779818112528,1
W4392460704,Mining construction accident reports via unsupervised NLP and Accimap for systemic risk analysis,2024,0.00011638779818112528,1
W4386402121,Artificial intelligence literacy for the language industry – with particular emphasis on recent large language models such as GPT-4,2023,0.00011638779818112528,1
W3006240412,Multi-label feature selection based on label distribution and feature complementarity,2020,0.00011638779818112528,1
W3205972749,Taming Sparsely Activated Transformer with Stochastic Experts,2021,0.00011638779818112528,1
W3187800134,A Structure Self-Aware Model for Discourse Parsing on Multi-Party Dialogues,2021,0.00011638779818112528,1
W4385568303,Transferable Graph Structure Learning for Graph-based Traffic Forecasting Across Cities,2023,0.00011638779818112528,1
W4406668349,MFFCNN: multi-scale fractional Fourier transform convolutional neural network for multivariate time series forecasting,2025,0.00011638779818112528,1
W2601322194,One-Shot Imitation Learning,2017,0.00011638779818112528,1
W4320921439,High ECG diagnosis rate using novel machine learning techniques with Distributed Arithmetic (DA) based gated recurrent units,2023,0.00011638779818112528,1
W3100715140,Consistency of a Recurrent Language Model With Respect to Incomplete Decoding,2020,0.00011638779818112528,1
W2964941017,Supervised and Unsupervised Neural Approaches to Text Readability,2021,0.00011638779818112528,1
W3014676873,"A Hybrid Deep Learning Model to Forecast Particulate Matter Concentration Levels in Seoul, South Korea",2020,0.00011638779818112528,1
W4410036785,Context-Aware Encoder with Adaptive Tuning for Neural Machine Translation,2025,0.00011638779818112528,1
W3005630930,BAT: Deep Learning Methods on Network Intrusion Detection Using NSL-KDD Dataset,2020,0.00011638779818112528,1
W4409919402,Memory-enhanced hierarchical and temporal semantic learning for multi-label patent classification,2025,0.00011638779818112528,1
W4406728187,Charge diagnostics and state estimation of Battery Energy Storage Systems through Transformer models,2025,0.00011638779818112528,1
W4382199756,Interpretation and explanation of convolutional neural network-based fault diagnosis model at the feature-level for building energy systems,2023,0.00011638779818112528,1
W4319811730,BiT-MAC: Mortality prediction by bidirectional time and multi-feature attention coupled network on multivariate irregular time series,2023,0.00011638779818112528,1
W4386263530,"Short-Term Traffic Prediction Using Deep Learning Long Short-Term Memory: Taxonomy, Applications, Challenges, and Future Trends",2023,0.00011638779818112528,1
W3185906304,Day-ahead electricity price prediction applying hybrid models of LSTM-based deep learning methods and feature selection algorithms under consideration of market coupling,2021,0.00011638779818112528,1
W4323519319,Transfer Learning With Spatial–Temporal Graph Convolutional Network for Traffic Prediction,2023,0.00011638779818112528,1
W4403284445,Enhancing road traffic flow in sustainable cities through transformer models: Advancements and challenges,2024,0.00011638779818112528,1
W4306402945,"Water Quality Prediction Based on LSTM and Attention Mechanism: A Case Study of the Burnett River, Australia",2022,0.00011638779818112528,1
W4285280911,Can Transformer be Too Compositional? Analysing Idiom Processing in Neural Machine Translation,2022,0.00011638779818112528,1
W3209973822,Graph neural network initialisation of quantum approximate optimisation,2022,0.00011638779818112528,1
W4407002324,Word embedding factor based multi-head attention,2025,0.00011638779818112528,1
W3201524630,A keyphrase-based approach for interpretable ICD-10 code classification of Spanish medical reports,2021,0.00011638779818112528,1
W3164401570,Geometric deep learning and equivariant neural networks,2023,0.00011638779818112528,1
W4280617006,Prediction of protein–protein interaction using graph neural networks,2022,0.00011638779818112528,1
W4402526753,Dictionary domain adaptation transformer for cross-machine fault diagnosis of rolling bearings,2024,0.00011638779818112528,1
W3026999846,Radar Emitter Classification With Attention-Based Multi-RNNs,2020,0.00011638779818112528,1
W4403826725,Recent Advances in Interactive Machine Translation with Large Language Models,2024,0.00011638779818112528,1
W4404486476,TTG-Text: A Graph-Based Text Representation Framework Enhanced by Typical Testors for Improved Classification,2024,0.00011638779818112528,1
W4385570052,Synthetic Pre-Training Tasks for Neural Machine Translation,2023,0.00011638779818112528,1
W3098124506,Demographic Inference and Representative Population Estimates from Multilingual Social Media Data,2019,0.00011638779818112528,1
W2978015420,Sparse Binary Compression: Towards Distributed Deep Learning with minimal Communication,2019,0.00011638779818112528,1
W3211994460,Beyond Grammatical Error Correction: Improving L1-influenced research writing in English using pre-trained encoder-decoder models,2021,0.00011638779818112528,1
W3099107321,The OpenNMT Neural Machine Translation Toolkit: 2020 Edition,2020,0.00011638779818112528,1
W4406015732,CoGraphNet for enhanced text classification using word-sentence heterogeneous graph representations and improved interpretability,2025,0.00011638779818112528,1
W4289825471,Short-Term Weather Forecasting Using Spatial Feature Attention Based LSTM Model,2022,0.00011638779818112528,1
W2601273560,RobustFill: neural program learning under noisy I/O,2017,0.00011638779818112528,1
W4226288657,NeuroLogic A*esque Decoding: Constrained Text Generation with Lookahead Heuristics,2022,0.00011638779818112528,1
W4397012280,A survey of context in neural machine translation and its evaluation,2024,0.00011638779818112528,1
W3205400264,Decentralized Structural-RNN for Robot Crowd Navigation with Deep Reinforcement Learning,2021,0.00011638779818112528,1
W4397293650,Probing the limit of hydrologic predictability with the Transformer network,2024,0.00011638779818112528,1
W4401115759,Prediction and analysis of sea surface temperature based on LSTM-transformer model,2024,0.00011638779818112528,1
W3216307239,Dynamical time series embeddings in recurrent neural networks,2021,0.00011638779818112528,1
W4393902231,A component diagnostic and prognostic framework for pump bearings based on deep learning with data augmentation,2024,0.00011638779818112528,1
W4319068974,An Efficient Federated Learning Framework for Machinery Fault Diagnosis With Improved Model Aggregation and Local Model Training,2023,0.00011638779818112528,1
W3033638351,Unsupervised Translation of Programming Languages,2020,0.00011638779818112528,1
W4401437587,State of health estimation for lithium-ion batteries based on incremental capacity analysis and Transformer modeling,2024,0.00011638779818112528,1
W4389010438,"FurChat: An Embodied Conversational Agent using LLMs, Combining Open and Closed-Domain Dialogue with Facial Expressions",2023,0.00011638779818112528,1
W2970418174,Automatically Learning Data Augmentation Policies for Dialogue Tasks,2019,0.00011638779818112528,1
W3047286661,Predicting Alzheimer's disease progression using deep recurrent neural networks,2020,0.00011638779818112528,1
W4323338301,A Data Augmentation Method for English-Vietnamese Neural Machine Translation,2023,0.00011638779818112528,1
W4313473147,A Combined Model Based on Recurrent Neural Networks and Graph Convolutional Networks for Financial Time Series Forecasting,2023,0.00011638779818112528,1
W4205802268,The Routledge Handbook of Translation and Methodology,2022,0.00011638779818112528,1
W4399009424,How Ready Are Generative Pre-trained Large Language Models for Explaining Bengali Grammatical Errors?,2024,0.00011638779818112528,1
W3133841585,An Attention-Based Multilayer GRU Model for Multistep-Ahead Short-Term Load Forecasting,2021,0.00011638779818112528,1
W4224299101,StableMoE: Stable Routing Strategy for Mixture of Experts,2022,0.00011638779818112528,1
W3042959233,Short-term energy use prediction of solar-assisted water heating system: Application case of combined attention-based LSTM and time-series decomposition,2020,0.00011638779818112528,1
W4409759066,DNN-Schedule: A Predictive Scheduler for Minimizing Interference of Co-located DNN Workload,2025,0.00011638779818112528,1
W3035263353,Verbal Multiword Expressions for Identification of Metaphor,2020,0.00011638779818112528,1
W4285682826,A systematic exploration of reservoir computing for forecasting complex spatiotemporal dynamics,2022,0.00011638779818112528,1
W4322760879,MA-GCN: A Memory Augmented Graph Convolutional Network for traffic prediction,2023,0.00011638779818112528,1
W3199890931,Improving Multilingual Translation by Representation and Gradient Regularization,2021,0.00011638779818112528,1
W4408987952,A Transformer-Based Robot Autonomous Exploration Method,2025,0.00011638779818112528,1
W3007216417,On Feature Normalization and Data Augmentation,2020,0.00011638779818112528,1
W2811992740,Review of State-of-the-Art in Deep Learning Artificial Intelligence,2018,0.00011638779818112528,1
W4382202798,Diffuser: Efficient Transformers with Multi-Hop Attention Diffusion for Long Sequences,2023,0.00011638779818112528,1
W3204896549,ATISS: Autoregressive Transformers for Indoor Scene Synthesis,2021,0.00011638779818112528,1
W4409051266,Generality-aware self-supervised transformer for multivariate time series anomaly detection,2025,0.00011638779818112528,1
W4295699310,Deep multi-view graph-based network for citywide ride-hailing demand prediction,2022,0.00011638779818112528,1
W3204920203,Causal Direction of Data Collection Matters: Implications of Causal and Anticausal Learning for NLP,2021,0.00011638779818112528,1
W4286906805,WeTS: A Benchmark for Translation Suggestion,2022,0.00011638779818112528,1
W4392173954,EEG Emotion Recognition Model Based on Attention and GAN,2024,0.00011638779818112528,1
W4380716409,Android Malware Detection Methods Based on Convolutional Neural Network: A Survey,2023,0.00011638779818112528,1
W4407684421,Character-Level Encoding based Neural Machine Translation for Hindi language,2025,0.00011638779818112528,1
W4409524670,ResDNViT: A hybrid architecture for Netflow-based attack detection using a residual dense network and Vision Transformer,2025,0.00011638779818112528,1
W3026592756,Towards More Diverse Input Representation for Neural Machine Translation,2020,0.00011638779818112528,1
W4406241919,A survey of multilingual large language models,2025,0.00011638779818112528,1
W3016661780,RootPainter: Deep Learning Segmentation of Biological Images with Corrective Annotation,2020,0.00011638779818112528,1
W4210450738,RUL Prediction of Wind Turbine Gearbox Bearings Based on Self-Calibration Temporal Convolutional Network,2022,0.00011638779818112528,1
W4406112800,A priori physical information to aid generalization capabilities of neural networks for hydraulic modeling,2025,0.00011638779818112528,1
W4408083944,LM-Hunter: An NLP-Powered Graph Method for Detecting Adversary Lateral Movements in APT Cyber-Attacks at Scale,2025,0.00011638779818112528,1
W4395447244,A Fuzzy C-Means Clustering-Based Hybrid Multivariate Time Series Prediction Framework With Feature Selection,2024,0.00011638779818112528,1
W4407390185,Traffic prediction by graph transformer embedded with subgraphs,2025,0.00011638779818112528,1
W4321465178,An unsupervised latent/output physics-informed convolutional-LSTM network for solving partial differential equations using peridynamic differential operator,2023,0.00011638779818112528,1
W4387705023,Neural Networks for Constitutive Modeling: From Universal Function Approximators to Advanced Models and the Integration of Physics,2023,0.00011638779818112528,1
W4312454513,A Survey of Deep Anomaly Detection for System Logs,2022,0.00011638779818112528,1
W4406521352,Transformer-Based Intelligent Prediction Model for Multimodal Multi-Objective Optimization,2025,0.00011638779818112528,1
W3200809940,Comparing Prophet and Deep Learning to ARIMA in Forecasting Wholesale Food Prices,2021,0.00011638779818112528,1
W4399264264,Power Customer Satisfaction Based on Power Big Data and NLP,2024,0.00011638779818112528,1
W3116425023,A ranking-based feature selection for multi-label classification with fuzzy relative discernibility,2020,0.00011638779818112528,1
W2938824541,Adapting Sequence to Sequence Models for Text Normalization in Social Media,2019,0.00011638779818112528,1
W4322501311,Development and Analysis of a CNN- and Transfer-Learning-Based Classification Model for Automated Dairy Cow Feeding Behavior Recognition from Accelerometer Data,2023,0.00011638779818112528,1
W4382318655,Federated Learning on Non-IID Graphs via Structural Knowledge Sharing,2023,0.00011638779818112528,1
W4380368768,Hierarchical graph-based text classification framework with contextual node embedding and BERT-based dynamic fusion,2023,0.00011638779818112528,1
W4406678260,Text Classification Using Graph Convolutional Networks: A Comprehensive Survey,2025,0.00011638779818112528,1
W4408536479,A new evaluation method: evaluation data and metrics for Chinese grammatical error correction,2025,0.00011638779818112528,1
W4390520556,Improving deep-learning methods for area-based traffic demand prediction via hierarchical reconciliation,2024,0.00011638779818112528,1
W4393235323,Neural Machine Translation with CARU-Embedding Layer and CARU-Gated Attention Layer,2024,0.00011638779818112528,1
W4408078410,A remaining useful life prediction method of rolling bearings by RSA-BAFT combined with Copula Entropy feature selection,2025,0.00011638779818112528,1
W3106208347,It’s not a Non-Issue: Negation as a Source of Error in Machine Translation,2020,0.00011638779818112528,1
W4317103791,Forecasting Short-Term Passenger Flow of Subway Stations Based on the Temporal Pattern Attention Mechanism and the Long Short-Term Memory Network,2023,0.00011638779818112528,1
W3202970975,Language Translation as a Socio-Technical System:Case-Studies of Mixed-Initiative Interactions,2021,0.00011638779818112528,1
W3130456109,A graph-based CNN-LSTM stock price prediction algorithm with leading indicators,2021,0.00011638779818112528,1
W4391597917,A Transformer based approach to electricity load forecasting,2024,0.00011638779818112528,1
W4387848755,DSformer: A Double Sampling Transformer for Multivariate Time Series Long-term Prediction,2023,0.00011638779818112528,1
W4385571897,Towards Accurate Translation via Semantically Appropriate Application of Lexical Constraints,2023,0.00011638779818112528,1
W4401380102,Automatic language ability assessment method based on natural language processing,2024,0.00011638779818112528,1
W4324157275,Improving Multilingual Neural Machine Translation System for Indic Languages,2023,0.00011638779818112528,1
W3188334090,(Un)solving Morphological Inflection: Lemma Overlap Artificially Inflates Models’ Performance,2022,0.00011638779818112528,1
W3168492867,Learnable Fourier Features for Multi-Dimensional Spatial Positional Encoding,2021,0.00011638779818112528,1
W3201047833,Spatial-Temporal Traffic Data Imputation via Graph Attention Convolutional Network,2021,0.00011638779818112528,1
W4385571550,Augmenting Large Language Model Translators via Translation Memories,2023,0.00011638779818112528,1
W4366815213,Recent advances in deep learning models: a systematic literature review,2023,0.00011638779818112528,1
W4224925597,Adversarial Mask Transformer for Sequential Learning,2022,0.00011638779818112528,1
W4213130097,A GAN-Based Short-Term Link Traffic Prediction Approach for Urban Road Networks Under a Parallel Learning Framework,2022,0.00011638779818112528,1
W4306408437,Differential attention net: Multi-directed differential attention based hybrid deep learning model for solar power forecasting,2022,0.00011638779818112528,1
W4364302133,Triple Alliance Prototype Orthotist Network for Long-Tailed Multi-Label Text Classification,2023,0.00011638779818112528,1
W4221017237,Low-resource Neural Machine Translation: Methods and Trends,2022,0.00011638779818112528,1
W4393153277,Feature Transportation Improves Graph Neural Networks,2024,0.00011638779818112528,1
W4362009348,Remaining Useful Life Prediction of Turbofan Engines Using CNN-LSTM-SAM Approach,2023,0.00011638779818112528,1
W4386064855,A long-term water quality prediction model for marine ranch based on time-graph convolutional neural network,2023,0.00011638779818112528,1
W4390610528,STGAFormer: Spatial–temporal Gated Attention Transformer based Graph Neural Network for traffic flow forecasting,2024,0.00011638779818112528,1
W4385767932,Diffusion Models for Non-autoregressive Text Generation: A Survey,2023,0.00011638779818112528,1
W3175663471,Crafting Adversarial Examples for Neural Machine Translation,2021,0.00011638779818112528,1
W3103915675,ChrEn: Cherokee-English Machine Translation for Endangered Language Revitalization,2020,0.00011638779818112528,1
W3207149528,Melons: Generating Melody With Long-Term Structure Using Transformers And Structure Graph,2022,0.00011638779818112528,1
W4406940594,Fine-Tuning Large Language Models Using Nlp and a Self-Organizing Map for Genre-Based Automated Writing Evaluation,2025,0.00011638779818112528,1
W4213355816,RicENN: Prediction of Rice Enhancers with Neural Network Based on DNA Sequences,2022,0.00011638779818112528,1
W4281674262,A Review on Deep Sequential Models for Forecasting Time Series Data,2022,0.00011638779818112528,1
W4366378735,A Fault Diagnosis Method for Rolling Bearing Based on 1D-ViT Model,2023,0.00011638779818112528,1
W4406083334,Design of IoT energy consumption forecasting model for residential buildings based on improved long short-term memory (LSTM),2025,0.00011638779818112528,1
W4385571208,Exploring Effectiveness of GPT-3 in Grammatical Error Correction: A Study on Performance and Controllability in Prompt-Based Methods,2023,0.00011638779818112528,1
W3196027777,Text Classification Using Neural Network Language Model (NNLM) and BERT: An Empirical Comparison,2021,0.00011638779818112528,1
W4407058560,TaintAttack: rapid attack investigation based on information flow tracking,2025,0.00011638779818112528,1
W4206119104,Region-attentive multimodal neural machine translation,2022,0.00011638779818112528,1
W4406331643,TTSNet: Transformer–Temporal Convolutional Network–Self-Attention with Feature Fusion for Prediction of Remaining Useful Life of Aircraft Engines,2025,0.00011638779818112528,1
W4409407626,GERA: A Corpus of Russian School Texts Annotated for Grammatical Error Correction,2025,0.00011638779818112528,1
W4213346784,Multi-channel fusion LSTM for medical event prediction using EHRs,2022,0.00011638779818112528,1
W4391543346,Spatiotemporal Fusion Transformer for large-scale traffic forecasting,2024,0.00011638779818112528,1
W4409125889,Negative Language Transfer Identification in the English Writing of Chinese and Farsi Native Speakers,2025,0.00011638779818112528,1
W4382934573,Exploring transformers for behavioural biometrics: A case study in gait recognition,2023,0.00011638779818112528,1
W4390534762,A Lightweight Group Transformer-Based Time Series Reduction Network for Edge Intelligence and Its Application in Industrial RUL Prediction,2024,0.00011638779818112528,1
W2997015083,Context based machine translation with recurrent neural network for English–Amharic translation,2021,0.00011638779818112528,1
W3154410208,Data Augmentation for Hypernymy Detection,2021,0.00011638779818112528,1
W4311557029,Eleven quick tips for data cleaning and feature engineering,2022,0.00011638779818112528,1
W4379387130,A contrastive learning-based framework for wind power forecast,2023,0.00011638779818112528,1
W3034651160,Multi-Label and Multilingual News Framing Analysis,2020,0.00011638779818112528,1
W4386124663,Exploring Natural Language Processing Methods for Interactive Behaviour Modelling,2023,0.00011638779818112528,1
W4389518727,Viewing Knowledge Transfer in Multilingual Machine Translation Through a Representational Lens,2023,0.00011638779818112528,1
W2951575317,A Hybrid Convolutional Variational Autoencoder for Text Generation,2017,0.00011638779818112528,1
W4400605513,A novel method for ship carbon emissions prediction under the influence of emergency events,2024,0.00011638779818112528,1
W4398193394,State-of-charge estimation of sodium-ion batteries: A fusion deep learning approach,2024,0.00011638779818112528,1
W3102662787,Weakly Supervised Medication Regimen Extraction from Medical Conversations,2020,0.00011638779818112528,1
W4396661345,Local spatial and temporal relation discovery model based on attention mechanism for traffic forecasting,2024,0.00011638779818112528,1
W2963368804,Deep Learning Under Privileged Information Using Heteroscedastic Dropout,2018,0.00011638779818112528,1
W4322732473,A transformer with layer-cross decoding for remaining useful life prediction,2023,0.00011638779818112528,1
W3113709932,Rethinking the Value of Transformer Components,2020,0.00011638779818112528,1
W3212259963,Smelting Gold and Silver for Improved Multilingual AMR-to-Text Generation,2021,0.00011638779818112528,1
W3138415243,Multi-disease prediction using LSTM recurrent neural networks,2021,0.00011638779818112528,1
W3172198372,LightSeq: A High Performance Inference Library for Transformers,2021,0.00011638779818112528,1
W4241461373,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop,2021,0.00011638779818112528,1
W3124842510,Automated Source Code Generation and Auto-Completion Using Deep Learning: Comparing and Discussing Current Language Model-Related Approaches,2021,0.00011638779818112528,1
W4384701513,Fast simulation and prediction of urban pluvial floods using a deep convolutional neural network model,2023,0.00011638779818112528,1
W4225759408,"Representing Context in FrameNet: A Multidimensional, Multimodal Approach",2022,0.00011638779818112528,1
W4211067021,A Digital Twin of a Water Distribution System by Using Graph Convolutional Networks for Pump Speed-Based State Estimation,2022,0.00011638779818112528,1
W4316664875,Robust framework based on hybrid deep learning approach for short term load forecasting of building electricity demand,2023,0.00011638779818112528,1
W3200891745,The challenges of modern computing and new opportunities for optics,2021,0.00011638779818112528,1
W4406322062,Time-series Forecasting in Industrial Environments: A Performance Study and a Novel Late Fusion Framework,2025,0.00011638779818112528,1
W4392903654,Enhancing End-to-End Conversational Speech Translation Through Target Language Context Utilization,2024,0.00011638779818112528,1
W4389060462,RUL prediction of rolling bearings across working conditions based on multi-scale convolutional parallel memory domain adaptation network,2023,0.00011638779818112528,1
W4313368113,Multi-step ahead voltage prediction and voltage fault diagnosis based on gated recurrent unit neural network and incremental training,2022,0.00011638779818112528,1
W4407320464,Assimilation of the chronology of mineral system components in prospectivity analysis procedure for mineral exploration targeting: Adaptation of recurrent neural networks,2025,0.00011638779818112528,1
W4284892020,Recognizing Medical Search Query Intent by Few-shot Learning,2022,0.00011638779818112528,1
W3175963743,SemFace: Pre-training Encoder and Decoder with a Semantic Interface for Neural Machine Translation,2021,0.00011638779818112528,1
W4408817468,A customized dual-transformer framework for remaining useful life prediction of mechanical systems with degraded state,2025,0.00011638779818112528,1
W4367676272,Translating Akkadian to English with neural machine translation,2023,0.00011638779818112528,1
W4322588511,Expanding the prediction capacity in long sequence time-series forecasting,2023,0.00011638779818112528,1
W4285135404,Bag-of-Words vs. Graph vs. Sequence in Text Classification: Questioning the Necessity of Text-Graphs and the Surprising Strength of a Wide MLP,2022,0.00011638779818112528,1
W4399527010,A Deep Learning-Based Approach for Part of Speech (PoS) Tagging in the Pashto Language,2024,0.00011638779818112528,1
W4407032389,FE-PIRBN:Feature-Enhanced physics-informed radial basis neural networks for solving high-frequency electromagnetic scattering problems,2025,0.00011638779818112528,1
W4379209990,VDGCNeT: A novel network-wide Virtual Dynamic Graph Convolution Neural network and Transformer-based traffic prediction model,2023,0.00011638779818112528,1
W4406919111,Artificial intelligence methods applied to longitudinal data from electronic health records for prediction of cancer: a scoping review,2025,0.00011638779818112528,1
W2995082892,Recurrent Neural Networks (RNNs): A gentle Introduction and Overview,2019,0.00011638779818112528,1
W4385076171,API-MalDetect: Automated malware detection framework for windows based on API calls and deep learning techniques,2023,0.00011638779818112528,1
W4376645491,MultiGED-2023 shared task at NLP4CALL: Multilingual Grammatical Error Detection,2023,0.00011638779818112528,1
W4390919300,Unsupervised Deep Anomaly Detection for Industrial Multivariate Time Series Data,2024,0.00011638779818112528,1
W4365513119,Automatic Parsing and Utilization of System Log Features in Log Analysis: A Survey,2023,0.00011638779818112528,1
W4389388534,An Advanced Real-Time Job Recommendation System and Resume Analyser,2023,0.00011638779818112528,1
W2886440583,Neural Machine Translation Techniques for Named Entity Transliteration,2018,0.00011638779818112528,1
W4319297852,XTM: A Novel Transformer and LSTM-Based Model for Detection and Localization of Formally Verified FDI Attack in Smart Grid,2023,0.00011638779818112528,1
W4322615356,A method for assisting the accident consequence prediction and cause investigation in petrochemical industries based on natural language processing technology,2023,0.00011638779818112528,1
W4285187956,Aircraft Engines Remaining Useful Life Prediction Based on A Hybrid Model of Autoencoder and Deep Belief Network,2022,0.00011638779818112528,1
W4386576838,Multilingual Representation Distillation with Contrastive Learning,2023,0.00011638779818112528,1
W4400749119,"Revolutionising Translation Technology: A Comparative Study of Variant Transformer Models - BERT, GPT, and T5",2024,0.00011638779818112528,1
W4393032946,Graph Receptive Transformer Encoder for Text Classification,2024,0.00011638779818112528,1
W4387340756,Cardiovascular disease identification using a hybrid CNN-LSTM model with explainable AI,2023,0.00011638779818112528,1
W4407290098,Research on morphological knowledge-guided low-resource agglutinative languages-Chinese translation,2025,0.00011638779818112528,1
W4381548641,An improved GNN using dynamic graph embedding mechanism: A novel end-to-end framework for rolling bearing fault diagnosis under variable working conditions,2023,0.00011638779818112528,1
W3017887871,Incorporating Sememes into Chinese Definition Modeling,2020,0.00011638779818112528,1
W3126720815,Machine Learning with Neural Networks,2021,0.00011638779818112528,1
W4382317864,AMOM: Adaptive Masking over Masking for Conditional Masked Language Model,2023,0.00011638779818112528,1
W4318594329,Spatiotemporal correlation modelling for machine learning-based traffic state predictions: state-of-the-art and beyond,2023,0.00011638779818112528,1
W4401198529,MGSFformer: A Multi-Granularity Spatiotemporal Fusion Transformer for Air Quality Prediction,2024,0.00011638779818112528,1
W4408482320,Combining transformer and 3DCNN models to achieve co-design of structures and sequences of antibodies in a diffusional manner,2025,0.00011638779818112528,1
W4406256786,Optimizing Stock Predictions With Bi-Directional LSTM and Levy Flight Fuzzy Social Spider Optimization (LFFSSO),2025,0.00011638779818112528,1
W4391849633,Fading memory as inductive bias in residual recurrent networks,2024,0.00011638779818112528,1
W4406846597,Forecasting chaotic time series: Comparative performance of LSTM-based and Transformer-based neural network,2025,0.00011638779818112528,1
W4407414419,An Evaluation of Physics-Informed Learning With General Neural Operator Transformers,2025,0.00011638779818112528,1
W3209873929,Hierarchical Transformers Are More Efficient Language Models,2022,0.00011638779818112528,1
W4312201182,ST-3DGMR: Spatio-temporal 3D grouped multiscale ResNet network for region-based urban traffic flow prediction,2022,0.00011638779818112528,1
W4391225283,Automation and Orchestration of Zero Trust Architecture: Potential Solutions and Challenges,2024,0.00011638779818112528,1
W4378697395,STAGED: A Spatial-Temporal Aware Graph Encoder–Decoder for Fault Diagnosis in Industrial Processes,2023,0.00011638779818112528,1
W4394853400,AI-powered COVID-19 forecasting: a comprehensive comparison of advanced deep learning methods,2024,0.00011638779818112528,1
W4319777762,"A Systematic Literature Review on Multimodal Machine Learning: Applications, Challenges, Gaps and Future Directions",2023,0.00011638779818112528,1
W2945767825,Are Sixteen Heads Really Better than One,2019,0.00011638779818112528,1
W3134482564,Very short-term forecasting of wind power generation using hybrid deep learning model,2021,0.00011638779818112528,1
W4408525846,An empirical investigation of the neural base approaches based on the sentence length using low-resource language: English-to-Nyishi,2025,0.00011638779818112528,1
W4391850361,UCFN Net: Ulcerative colitis evaluation based on fine-grained lesion learner and noise suppression gating,2024,0.00011638779818112528,1
W3186647146,Ensemble of recurrent neural networks with long short-term memory cells for high-rate structural health monitoring,2021,0.00011638779818112528,1
W4323664841,ODformer: Spatial–temporal transformers for long sequence Origin–Destination matrix forecasting against cross application scenario,2023,0.00011638779818112528,1
W3086834600,Towards efficient unconstrained handwriting recognition using Dilated Temporal Convolution Network,2020,0.00011638779818112528,1
W4366714851,A cyber-physical robotic mobile fulfillment system in smart manufacturing: The simulation aspect,2023,0.00011638779818112528,1
W2975933472,Neighbors helping the poor: improving low-resource machine translation using related languages,2019,0.00011638779818112528,1
