id,title,year,pagerank,cluster
W1525961042,Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks,2015,0.03190802099604721,2
W580074167,Large-scale Simple Question Answering with Memory Networks,2015,0.02651014506103851,2
W2126209950,The Goldilocks Principle: Reading Children's Books with Explicit Memory Representations,2015,0.023864024429746337,2
W2950726992,Skip-Thought Vectors,2015,0.017973185670530543,2
W2963341956,,2019,0.016694701527800018,2
W1840435438,A large annotated corpus for learning natural language inference,2015,0.015308167768943602,2
W2896457183,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,2018,0.013619254508968608,2
W1566289585,Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books,2015,0.013426962314104264,2
W2962809918,A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task,2016,0.012961543736987205,2
W2963595025,Text Understanding with the Attention Sum Reader Network,2016,0.01123054574493649,2
W2963748441,"SQuAD: 100,000+ Questions for Machine Comprehension of Text",2016,0.010837752349423416,2
W1486649854,Skip-thought vectors,2015,0.0097651660721303,2
W2965373594,RoBERTa: A Robustly Optimized BERT Pretraining Approach,2019,0.008355851039639128,2
W1793121960,End-to-end memory networks,2015,0.00729067801863337,2
W2963440143,Recursive Neural Networks Can Learn Logical Semantics,2015,0.007188221242451171,2
W2963918774,Supervised Learning of Universal Sentence Representations from Natural Language Inference Data,2017,0.00714350927530426,2
W1951216520,Visualizing and Understanding Recurrent Networks,2015,0.007061927550441363,2
W2963846996,A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference,2018,0.006808168581682731,2
W2963542836,Learning Natural Language Inference with LSTM,2016,0.00628100177002542,2
W2551396370,Bidirectional Attention Flow for Machine Comprehension,2016,0.00598031498299408,2
W2963012544,Character-level Convolutional Networks for Text Classification,2015,0.005867161506093629,2
W2413794162,A Decomposable Attention Model for Natural Language Inference,2016,0.005602210821522339,2
W2308720496,A Fast Unified Model for Parsing and Sentence Understanding,2016,0.005161614020333058,2
W2133458109,"SemEval-2015 Task 2: Semantic Textual Similarity, English, Spanish and Pilot on Interpretability",2015,0.005078528371156385,2
W2427527485,"SQuAD: 100,000+ Questions for Machine Comprehension of Text",2016,0.004866407211754785,2
W2963026768,Universal Language Model Fine-tuning for Text Classification,2018,0.004776110242307743,2
W2963310665,GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding,2018,0.004313303779676148,2
W2170973209,Semi-supervised Sequence Learning,2015,0.004287108917253123,2
W4292779060,Language Models are Few-Shot Learners,2020,0.004204147972051648,2
W2911489562,BioBERT: a pre-trained biomedical language representation model for biomedical text mining,2019,0.00401019361698117,2
W2970597249,XLNet: Generalized Autoregressive Pretraining for Language Understanding,2019,0.003987008028725431,2
W2963756346,Learned in translation: contextualized word vectors,2017,0.003964326572396198,2
W2516930406,Machine Comprehension Using Match-LSTM and Answer Pointer,2016,0.003854132558988789,2
W2963339397,TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension,2017,0.003798147326060805,2
W2963804993,Learning Distributed Representations of Sentences from Unlabelled Data,2016,0.0036863192430058073,2
W2549835527,Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies,2016,0.00363223602259865,2
W2951534261,MS MARCO: A Human Generated MAchine Reading COmprehension Dataset,2016,0.003622080390029244,2
W3104033643,SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation,2017,0.0035904132677954336,2
W4288089799,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer,2019,0.0035636212970453197,2
W2259472270,Exploring the Limits of Language Modeling,2016,0.0035254473524040054,2
W2970641574,Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks,2019,0.0034112359036929975,2
W2923014074,GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding,2018,0.0033795208504474785,2
W2963969878,Adversarial Examples for Evaluating Reading Comprehension Systems,2017,0.0032312720946471307,2
W2787560479,Deep contextualized word representations,2018,0.003179371336098791,2
W2411480514,A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task,2016,0.0031706423657357017,2
W2608787653,Enhanced LSTM for Natural Language Inference,2017,0.0031683712664817136,2
W2963499246,Towards Universal Paraphrastic Sentence Embeddings,2016,0.002877704437433694,2
W2964159778,Visualizing and Understanding Neural Models in NLP,2016,0.002772407524306556,2
W2211192759,ABCNN: Attention-Based Convolutional Neural Network for Modeling Sentence Pairs,2016,0.002751461004973181,2
W2963073938,Recurrent Neural Network Grammars,2016,0.0027321991974325706,2
W2118463056,Reasoning about Entailment with Neural Attention,2015,0.0026718022862256543,2
W2962985038,Reading Wikipedia to Answer Open-Domain Questions,2017,0.0025519974630362646,2
W2962718483,Simple and Effective Multi-Paragraph Reading Comprehension,2018,0.002508885892982801,2
W2978670439,Neural Network Acceptability Judgments,2019,0.0024342104304312068,2
W2740747242,Gated Self-Matching Networks for Reading Comprehension and Question Answering,2017,0.002349480221275449,2
W2979826702,Transformers: State-of-the-Art Natural Language Processing,2020,0.002171264023776881,2
W2963323070,Know What You Don’t Know: Unanswerable Questions for SQuAD,2018,0.002168172963944306,2
W2521709538,ReasoNet,2017,0.0021500085042540714,2
W2963159690,SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference,2018,0.002149297230917883,2
W2557764419,NewsQA: A Machine Comprehension Dataset,2017,0.0021390719120025115,2
W2996428491,ALBERT: A Lite BERT for Self-supervised Learning of Language Representations,2019,0.002069911856142427,2
W2888329843,Dissecting Contextual Word Embeddings: Architecture and Representation,2018,0.0020583163357392746,2
W2552027021,Dynamic Coattention Networks For Question Answering,2016,0.00197149039645196,2
W2978017171,"DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter",2019,0.0019672565468172917,2
W2952191002,Long Short-Term Memory-Networks for Machine Reading,2016,0.0019659019345111776,2
W2609826708,SearchQA: A New Q&A Dataset Augmented with Context from a Search Engine,2017,0.0018576146355818487,2
W2962736243,Annotation Artifacts in Natural Language Inference Data,2018,0.0018479678209931225,2
W2912924812,Natural Questions: A Benchmark for Question Answering Research,2019,0.0018391291267131115,2
W2173361515,LSTM-based Deep Learning Models for Non-factoid Answer Selection,2015,0.001837219524698469,2
W3104486441,Attention-over-Attention Neural Networks for Reading Comprehension,2017,0.0018329772174721388,2
W2963691697,AllenNLP: A Deep Semantic Natural Language Processing Platform,2018,0.0018304423692198214,2
W2101848544,Compositional Vector Space Models for Knowledge Base Completion,2015,0.0018165064347332408,2
W2963716420,Publicly Available Clinical,2019,0.0018131295651146282,2
W4302343710,Learned in Translation: Contextualized Word Vectors,2017,0.0017590542848160647,2
W2510759893,WikiReading: A Novel Large-scale Language Understanding Task over Wikipedia,2016,0.0017438098573896122,2
W2606964149,RACE: Large-scale ReAding Comprehension Dataset From Examinations,2017,0.001707891962416827,2
W2415204069,Learning Natural Language Inference using Bidirectional LSTM model and Inner-Attention,2016,0.001691369434245851,2
W2980282514,HuggingFace's Transformers: State-of-the-art Natural Language Processing,2019,0.0016883880548727757,2
W2250635077,Representing Text for Joint Embedding of Text and Knowledge Bases,2015,0.00165374341319283,2
W2548872772,End-to-End Answer Chunk Extraction and Ranking for Reading Comprehension,2016,0.0016354919067323405,2
W2610858497,Discourse-Based Objectives for Fast Unsupervised Sentence Representation Learning,2017,0.0016348119770894368,2
W2951815760,Bidirectional Attention Flow for Machine Comprehension,2016,0.0016105035986737173,2
W2949433733,Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books,2015,0.0016010268834136445,2
W2970476646,Language Models as Knowledge Bases?,2019,0.0015654299425315417,2
W3122775348,Deep Sentence Embedding Using Long Short-Term Memory Networks: Analysis and Application to Information Retrieval,2016,0.0015600821506139794,2
W2563574619,Does String-Based Neural MT Learn Source Syntax?,2016,0.0015355308301745253,2
W2970771982,SciBERT: A Pretrained Language Model for Scientific Text,2019,0.001465923965898374,2
W2562979205,Understanding Neural Networks through Representation Erasure,2016,0.0014584327936166335,2
W2462305634,"SemEval-2016 Task 1: Semantic Textual Similarity, Monolingual and Cross-Lingual Evaluation",2016,0.001447484439823808,2
W2566011400,Multi-Perspective Context Matching for Machine Comprehension,2016,0.0014405505074804577,2
W3098057198,Multi-Granularity Hierarchical Attention Fusion Networks for Reading Comprehension and Question Answering,2018,0.0014394685398309254,2
W2962808855,Reinforced Mnemonic Reader for Machine Reading Comprehension,2018,0.0013875135230536106,2
W2292919134,Representation of Linguistic Form and Function in Recurrent Neural Networks,2017,0.0013857574881456704,2
W2606347107,Learning to Generate Reviews and Discovering Sentiment,2017,0.001361920167391561,2
W2415755012,Gated-Attention Readers for Text Comprehension,2016,0.001347311324823674,2
W2888922637,Targeted Syntactic Evaluation of Language Models,2018,0.0013419167894256313,2
W2963015836,The LAMBADA dataset: Word prediction requiring a broad discourse context,2016,0.001339224497740494,2
W2805206884,A Simple Method for Commonsense Reasoning,2018,0.001323524168641651,2
W3099700870,Dense Passage Retrieval for Open-Domain Question Answering,2020,0.0013192825745085763,2
W2990704537,SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems,2019,0.0013004256824330697,2
W2466175319,A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense Stories,2016,0.0012942696657222306,2
W2515741950,Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks,2016,0.0012910594037213892,2
W2963096510,Hierarchical Neural Story Generation,2018,0.0012828185313320086,2
W2889787757,"HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering",2018,0.0012187781279609303,2
W2528904340,Embracing data abundance: BookTest Dataset for Reading Comprehension,2016,0.001207917627421726,2
W2784121710,Fine-tuned Language Models for Text Classification.,2018,0.0011981138872766094,2
W2605717780,What do Neural Machine Translation Models Learn about Morphology?,2017,0.0011918517735016328,2
W2946417913,BERT Rediscovers the Classical NLP Pipeline,2019,0.0011843802586619654,2
W2963448850,Key-Value Memory Networks for Directly Reading Documents,2016,0.0011745886121273556,2
W2963961878,FEVER: a Large-scale Dataset for Fact Extraction and VERification,2018,0.0011631973821775127,2
W2963973721,Neural Semantic Encoders,2017,0.001162622652530128,2
W2962843521,Hypothesis Only Baselines in Natural Language Inference,2018,0.001137491880794682,2
W3016169217,Neural Tree Indexers for Text Understanding,2016,0.0011309184075742262,2
W2964204621,What you can cram into a single $&amp;!#* vector: Probing sentence embeddings for linguistic properties,2018,0.0011259040641391545,2
W2793978524,AllenNLP: A Deep Semantic Natural Language Processing Platform,2018,0.0011198441777884938,2
W2963344337,Gated-Attention Readers for Text Comprehension,2017,0.0011094290315520588,2
W2925863688,Publicly Available Clinical BERT Embeddings,2019,0.0010696571017148584,2
W4313908941,SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Cross-lingual Focused Evaluation,2017,0.0010572233391765286,2
W2576562514,Reading and Thinking: Re-read LSTM Unit for Textual Entailment Recognition,2016,0.0010530878963874318,2
W2938830017,ERNIE: Enhanced Representation through Knowledge Integration,2019,0.0010452048956791195,2
W2909544278,Passage Re-ranking with BERT,2019,0.0010392721663957307,2
W3011411500,SpanBERT: Improving Pre-training by Representing and Predicting Spans,2020,0.0010210314147546086,2
W2950339735,COMET: Commonsense Transformers for Automatic Knowledge Graph Construction,2019,0.0010102566480278846,2
W2605035112,Unsupervised Learning of Sentence Embeddings Using Compositional n-Gram Features,2018,0.0009856253449843473,2
W2953356739,ERNIE: Enhanced Language Representation with Informative Entities,2019,0.0009852550518380406,2
W3106224367,ScispaCy: Fast and Robust Models for Biomedical Natural Language Processing,2019,0.0009842597566297915,2
W2963854351,Multi-Task Deep Neural Networks for Natural Language Understanding,2019,0.0009801007419855629,2
W2950501607,RACE: Large-scale ReAding Comprehension Dataset From Examinations,2017,0.0009708022999290292,2
W2962690139,Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples,2018,0.0009645681039065874,2
W2495998536,Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain Factoid Question Answering,2016,0.0009638776246437604,2
W2626154462,Making Neural QA as Simple as Possible but not Simpler,2017,0.0009403315148852042,2
W2943552823,SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems,2019,0.0009185636329077667,2
W2962881743,Zero-Shot Relation Extraction via Reading Comprehension,2017,0.0009060282602958388,2
W3046375318,Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing,2021,0.0009047058108139866,2
W3156636935,SimCSE: Simple Contrastive Learning of Sentence Embeddings,2021,0.0008985453584073984,2
W2963491027,The RepEval 2017 Shared Task: Multi-Genre Natural Language Inference with Sentence Representations,2017,0.0008946304921317029,2
W2963899155,Revisiting Recurrent Networks for Paraphrastic Sentence Embeddings,2017,0.0008940218803421375,2
W3185341429,"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing",2022,0.0008928608451730399,2
W2898700502,Sentence Encoders on STILTs: Supplementary Training on Intermediate Labeled-data Tasks,2018,0.000883855158180368,2
W2798665661,Breaking NLI Systems with Sentences that Require Simple Lexical Inferences,2018,0.0008812391600907152,2
W2756386045,Natural Language Inference over Interaction Space,2017,0.0008793581751888785,2
W3027879771,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks,2020,0.0008778810803301313,2
W2951434086,Latent Retrieval for Weakly Supervised Open Domain Question Answering,2019,0.0008744646902756387,2
W2963101081,ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning,2019,0.0008739101586949925,2
W3153427360,Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference,2021,0.0008707301382999563,2
W3098824823,Transformers: State-of-the-Art Natural Language Processing,2020,0.0008603191362568552,2
W2794557536,Universal Sentence Encoder,2018,0.0008512659168437205,2
W2523467643,Enhancing and Combining Sequential and Tree LSTM for Natural Language Inference.,2016,0.0008510709813142501,2
W4299838440,Regularizing and Optimizing LSTM Language Models,2017,0.000844987183109584,2
W2806120502,Neural Network Acceptability Judgments,2018,0.0008421491275540532,2
W2951286828,Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference,2019,0.0008401458336773225,2
W2972324944,What Does BERT Look at? An Analysis of BERT’s Attention,2019,0.0008358064443731458,2
W3030163527,Language Models are Few-Shot Learners,2020,0.0008351200094140391,2
W2963866616,Constructing Datasets for Multi-hop Reading Comprehension Across Documents,2018,0.0008164738477083396,2
W2964303116,Linguistic Knowledge and Transferability of Contextual Representations,2019,0.0008100281487095824,2
W3034238904,Don’t Stop Pretraining: Adapt Language Models to Domains and Tasks,2020,0.0008091538627354653,2
W3044438666,How Can We Know What Language Models Know?,2020,0.0008063743957320715,2
W2964223283,CoQA: A Conversational Question Answering Challenge,2019,0.0008049036940565347,2
W2910243263,Assessing BERT's Syntactic Abilities.,2019,0.0007968645837861998,2
W2963019137,Natural Language Comprehension with the EpiReader,2016,0.0007864482251206149,2
W2799124508,What you can cram into a single \$&!#* vector: Probing sentence embeddings for linguistic properties,2018,0.0007848011585950423,2
W2914526845,Multi-Task Deep Neural Networks for Natural Language Understanding,2019,0.000773598140386538,2
W3174770825,Prefix-Tuning: Optimizing Continuous Prompts for Generation,2021,0.0007624181573419525,2
W2981852735,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer,2019,0.0007532676786815813,2
W2963053846,A Deep Architecture for Semantic Matching with Multiple Positional Sentence Representations,2015,0.0007527945000923731,2
W2890894339,Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering,2018,0.0007455425842237164,2
W2963963993,The NarrativeQA Reading Comprehension Challenge,2018,0.0007443222489534956,2
W2788496822,SciTaiL: A Textual Entailment Dataset from Science Question Answering,2018,0.000741670672141215,2
W2950813464,XLNet: Generalized Autoregressive Pretraining for Language Understanding,2019,0.0007416283437826354,2
W2964150944,The Effect of Different Writing Tasks on Linguistic Style: A Case Study of the ROC Story Cloze Task,2017,0.0007407526967635702,2
W2587528408,Question Answering through Transfer Learning from Large Fine-grained Supervision Data,2017,0.0007395762097184748,2
W2964142373,Explainable Prediction of Medical Codes from Clinical Text,2018,0.0007358994878495573,2
W3118485687,A Primer in BERTology: What We Know About How BERT Works,2020,0.0007312979810738682,2
W4205991051,The Power of Scale for Parameter-Efficient Prompt Tuning,2021,0.0007300072492218865,2
W2963923670,A comparison of word embeddings for the biomedical natural language processing,2018,0.0007249444846925208,2
W3173777717,Making Pre-trained Language Models Better Few-shot Learners,2021,0.0007235178287460899,2
W2607219512,Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks,2018,0.000711241733564807,2
W2962718684,Generating Natural Language Adversarial Examples,2018,0.0007048987305244409,2
W2948947170,What Does BERT Learn about the Structure of Language?,2019,0.0006987681575662179,2
W2798858969,QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension,2018,0.0006965728097772688,2
W2888302696,QuAC: Question Answering in Context,2018,0.0006936905333212205,2
W2963769536,Stochastic Answer Networks for Machine Reading Comprehension,2018,0.0006935168877113497,2
W3098267758,AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts,2020,0.0006901581618656629,2
W2546950329,Neural Symbolic Machines: Learning Semantic Parsers on Freebase with Weak Supervision,2017,0.0006890754973504368,2
W2888120268,Lessons from Natural Language Inference in the Clinical Domain,2018,0.0006888294138229788,2
W3105966348,TinyBERT: Distilling BERT for Natural Language Understanding,2020,0.0006841111556743884,2
W2963126845,Adversarial Example Generation with Syntactically Controlled Paraphrase Networks,2018,0.0006816337674672112,2
W2946359678,,2019,0.0006781051384081108,2
W3007672467,REALM: Retrieval-Augmented Language Model Pre-Training,2020,0.0006763752752233581,2
W2963995027,,2019,0.0006673619190397485,2
W2799007037,Semantically Equivalent Adversarial Rules for Debugging NLP models,2018,0.000659844282363563,2
W2962753370,SpanBERT: Improving Pre-training by Representing and Predicting Spans,2019,0.0006557756083137407,2
W2971258845,Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets,2019,0.0006541505327216387,2
W2924902521,Distilling Task-Specific Knowledge from BERT into Simple Neural Networks,2019,0.0006526083411543018,2
W2962911926,The Importance of Being Recurrent for Modeling Hierarchical Structure,2018,0.0006419370585678233,2
W2964120615,The Web as a Knowledge-Base for Answering Complex Questions,2018,0.0006397487304420251,2
W2804897457,Looking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences,2018,0.0006328112689931317,2
W2963651521,Deep RNNs Encode Soft Hierarchical Syntax,2018,0.0006301572677682505,2
W2612431505,TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension,2017,0.0006300229285930706,2
W3102659883,How Much Knowledge Can You Pack Into the Parameters of a Language Model?,2020,0.0006273235198412552,2
W2963363070,Learning to Skim Text,2017,0.0006242764734135043,2
W2963025830,Assessing Composition in Sentence Vector Representations.,2018,0.0006227085653684116,2
W2945290257,A Surprisingly Robust Trick for the Winograd Schema Challenge,2019,0.0006204826491988759,2
W2970986510,Knowledge Enhanced Contextual Word Representations,2019,0.0006122204016398907,2
W2790235966,SentEval: An Evaluation Toolkit for Universal Sentence Representations,2018,0.0006096334251534176,2
W2951105272,Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs,2019,0.0006036301490560152,2
W2937845937,ClinicalBERT: Modeling Clinical Notes and Predicting Hospital Readmission,2019,0.0005989133300655195,2
W2734823783,Quasar: Datasets for Question Answering by Search and Reading,2017,0.0005970989283388762,2
W2919420119,,2019,0.000592097950378453,2
W2937297214,Improving Multi-Task Deep Neural Networks via Knowledge Distillation for Natural Language Understanding,2019,0.0005888589804766125,2
W2739505524,Pay Attention to the Ending:Strong Neural Baselines for the ROC Story Cloze Task,2017,0.0005812723256735484,2
W2962961857,What do RNN Language Models Learn about Filler–Gap Dependencies?,2018,0.0005783231382268312,2
W2934842096,,2019,0.0005654758599581035,2
W2609368435,Deep Text Classification Can be Fooled,2018,0.0005624492840289165,2
W2955041501,SemEval-2019 Task 4: Hyperpartisan News Detection,2019,0.0005538912566450193,2
W2752194699,LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks,2017,0.0005525099671891204,2
W2912817604,End-to-End Open-Domain Question Answering with,2019,0.0005490419577213111,2
W2469060249,Pairwise Word Interaction Modeling with Deep Neural Networks for Semantic Similarity Measurement,2016,0.0005451714096287407,2
W2906152891,Analysis Methods in Neural Language Processing: A Survey,2019,0.0005376997144826883,2
W4384071683,Large language models encode clinical knowledge,2023,0.000536574360342386,2
W2593833795,Bilateral Multi-Perspective Matching for Natural Language Sentences,2017,0.0005337404676758485,2
W2988217457,"How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings",2019,0.0005322081761006736,2
W2798727047,"LSTMs Can Learn Syntax-Sensitive Dependencies Well, But Modeling Structure Makes Them Better",2018,0.0005318396495027996,2
W2738015883,Adversarial Examples for Evaluating Reading Comprehension Systems,2017,0.0005307838100421608,2
W2280395961,Sentence Similarity Learning by Lexical Decomposition and Composition,2016,0.0005262023050651385,2
W2982756474,Universal Adversarial Triggers for Attacking and Analyzing NLP,2019,0.0005262008478253175,2
W2772121968,Medical subdomain classification of clinical notes using a machine learning-based natural language processing approach,2017,0.0005257646107284964,2
W3004346089,What BERT Is Not: Lessons from a New Suite of Psycholinguistic Diagnostics for Language Models,2020,0.0005201537697406562,2
W2963925965,Dynamic Entity Representations in Neural Language Models,2017,0.000517708163509316,2
W3168867926,LoRA: Low-Rank Adaptation of Large Language Models,2021,0.0005158680345521871,2
W4205807230,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,2021,0.0005071219058997008,2
W3172642864,It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners,2021,0.0005055437530399832,2
W3105816068,On the Sentence Embeddings from Pre-trained Language Models,2020,0.0005014033401033175,2
W2809324505,The Natural Language Decathlon: Multitask Learning as Question Answering,2018,0.0004931198177749376,2
W2964165804,SentEval: An Evaluation Toolkit for Universal Sentence Representations,2018,0.0004930526995449535,2
W2891177506,Universal Sentence Encoder for English,2018,0.0004927559595126925,2
W2972167903,KG-BERT: BERT for Knowledge Graph Completion,2019,0.00048767974817746354,2
W2946794439,"Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned",2019,0.0004816234695678364,2
W2898695519,CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge,2018,0.0004815523933756179,2
W3034850762,Adversarial NLI: A New Benchmark for Natural Language Understanding,2020,0.00048140540155534986,2
W2963488798,Neural Domain Adaptation for Biomedical Question Answering,2017,0.00047964813149868634,2
W2605089588,Neural Network-based Question Answering over Knowledge Graphs on Word and Character Level,2017,0.00047575085618560846,2
W2973049837,CTRL: A Conditional Transformer Language Model for Controllable Generation,2019,0.00047319423396548975,2
W2962998327,Neural Tree Indexers for Text Understanding,2017,0.0004727241145198876,2
W2788448041,R 3 : Reinforced Ranker-Reader for Open-Domain Question Answering.,2018,0.0004716438755816103,2
W2953369973,What do you learn from context? Probing for sentence structure in contextualized word representations,2019,0.0004650002179260869,2
W3111372685,oLMpics-On What Language Model Pre-training Captures,2020,0.0004618766404993883,2
W2476140796,A Neural Knowledge Language Model,2016,0.0004614528608600458,2
W2572185161,Task-Oriented Intrinsic Evaluation of Semantic Textual Similarity,2016,0.0004600587295508352,2
W2947813521,Defending Against Neural Fake News,2019,0.00045834059957770444,2
W2554915555,What Do Recurrent Neural Network Grammars Learn About Syntax?,2017,0.00045786509024245094,2
W2948629866,KERMIT: Generative Insertion-Based Modeling for Sequences,2019,0.0004564360587687143,2
W2460937040,Adversarial examples in the physical world,2016,0.00044692129057464824,2
W2946609015,HellaSwag: Can a Machine Really Finish Your Sentence?,2019,0.0004468385179055104,2
W2962833140,Explain Yourself! Leveraging Language Models for Commonsense Reasoning,2019,0.00044660483051627925,2
W2963861211,Simple Question Answering by Attentive Convolutional Neural Network,2016,0.0004464067072393905,2
W3151929433,KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation,2021,0.0004462625361024747,2
W2975059944,ALBERT: A Lite BERT for Self-supervised Learning of Language Representations,2019,0.0004444229198400694,2
W3088335873,A,2019,0.000443117218440083,2
W2769934148,DuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications,2017,0.0004391668167826681,2
W2951025380,Attention is not Explanation,2019,0.0004339517609113769,2
W3099950029,LEGAL-BERT: The Muppets straight out of Law School,2020,0.0004318625478128488,2
W2963545917,Contextual Augmentation: Data Augmentation by Words with Paradigmatic Relations,2018,0.00042980663405861954,2
W2963951265,"Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context",2018,0.0004273354616139615,2
W2962816513,Pathologies of Neural Models Make Interpretations Difficult,2018,0.0004263749959636494,2
W2970062726,Social IQa: Commonsense Reasoning about Social Interactions,2019,0.0004255794847996469,2
W3122890974,DEBERTA: DECODING-ENHANCED BERT WITH DISENTANGLED ATTENTION,2021,0.0004252592268580735,2
W2951976932,Tracking the World State with Recurrent Entity Networks,2016,0.0004238097475714316,2
W2970482702,PubMedQA: A Dataset for Biomedical Research Question Answering,2019,0.000421279495190115,2
W2766371743,DCN+: Mixed Objective and Deep Residual Coattention for Question Answering,2017,0.00041966382652522556,2
W3156789018,Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering,2021,0.00041677691184712677,2
W2963829073,Knowledgeable Reader: Enhancing Cloze-Style Reading Comprehension with External Commonsense Knowledge,2018,0.0004160554926392752,2
W2898662126,ReCoRD: Bridging the Gap between Human and Machine Commonsense Reading Comprehension,2018,0.0004105851777750813,2
W3210120707,Pre-Training With Whole Word Masking for Chinese BERT,2021,0.0004103129659197538,2
W2539671052,Learning to Match using Local and Distributed Representations of Text for Web Search,2017,0.000408873678115969,2
W2889468083,Collecting Diverse Natural Language Inference Problems for Sentence Representation Evaluation,2018,0.0004066448463886682,2
W2980708516,How to Fine-Tune BERT for Text Classification?,2019,0.00040479952739274705,2
W2946659172,,2019,0.00040133864835664577,2
W2786464815,An efficient framework for learning sentence representations,2018,0.0003984027425781935,2
W2963502184,Siamese CBOW: Optimizing Word Embeddings for Sentence Representations,2016,0.00039736104008476395,2
W2998385486,K-BERT: Enabling Language Representation with Knowledge Graph,2020,0.000395983812963197,2
W2761988601,DisSent: Sentence Representation Learning from Explicit Discourse Relations,2017,0.00039536189996580966,2
W2970161131,Commonsense Knowledge Mining from Pretrained Models,2019,0.0003940694630279159,2
W2970454332,Patient Knowledge Distillation for BERT Model Compression,2019,0.00039300839048989885,2
W3210923133,The neural architecture of language: Integrative modeling converges on predictive processing,2021,0.00039208899801740176,2
W3099655892,UNIFIEDQA: Crossing Format Boundaries with a Single QA System,2020,0.00039125630663437694,2
W2785611959,T-Rex : A Large Scale Alignment of Natural Language with Knowledge Base Triples,2017,0.00038868586631975464,2
W3031914912,Emergent linguistic structure in artificial neural networks trained by self-supervision,2020,0.0003862626844847407,2
W2799054028,GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding,2018,0.00038486279176084247,2
W2937036051,Document Expansion by Query Prediction,2019,0.00038441789207843154,2
W2962832505,Regularizing and Optimizing LSTM Language Models,2017,0.0003829947497800165,2
W2970352191,To Tune or Not to Tune? Adapting Pretrained Representations to Diverse Tasks,2019,0.00037808741506822175,2
W2964222268,Under the Hood: Using Diagnostic Classifiers to Investigate and Improve how Language Models Track Agreement Information,2018,0.00037727910797593863,2
W2996287690,The Curious Case of Neural Text Degeneration,2020,0.00037517338984493527,2
W4297253404,BioGPT: generative pre-trained transformer for biomedical text generation and mining,2022,0.00037477075419968195,2
W2944400536,"BioWordVec, improving biomedical word embeddings with subword information and MeSH",2019,0.00037180982612141674,2
W2962891712,Ultra-Fine Entity Typing,2018,0.00037152187741770255,2
W2997200074,ERNIE 2.0: A Continual Pre-Training Framework for Language Understanding,2020,0.00037033227133054486,2
W2998617917,PIQA: Reasoning about Physical Commonsense in Natural Language,2020,0.0003689692475737617,2
W2508865106,Siamese Recurrent Architectures for Learning Sentence Similarity,2016,0.0003684382258260484,2
W2970862333,Designing and Interpreting Probes with Control Tasks,2019,0.00036395019116878033,2
W2908230750,Knowledge Graph Embedding Based Question Answering,2019,0.0003630084294532974,2
W2949128310,Generating Natural Language Adversarial Examples through Probability Weighted Word Saliency,2019,0.0003618890610111701,2
W2998184481,Do Not Have Enough Data? Deep Learning to the Rescue!,2020,0.0003611092727311949,2
W2912351236,An Analysis of Encoder Representations in Transformer-Based Machine Translation,2018,0.000359675653595359,2
W2753329127,R$^3$: Reinforced Reader-Ranker for Open-Domain Question Answering,2017,0.000359559282666826,2
W2951048068,Barack’s Wife Hillary: Using Knowledge Graphs for Fact-Aware Language Modeling,2019,0.00035558193526817746,2
W2918996109,Structural Supervision Improves Learning of Non-Local Grammatical Dependencies,2019,0.00035518845905243353,2
W3035503910,ERASER: A Benchmark to Evaluate Rationalized NLP Models,2020,0.00035502768165283834,2
W2798416089,Neural Natural Language Inference Models Enhanced with External Knowledge,2018,0.00035465046439125877,2
W2986266667,Do NLP Models Know Numbers? Probing Numeracy in Embeddings,2019,0.0003536031886698022,2
W3176380929,Pre-training is a Hot Topic: Contextualized Document Embeddings Improve Topic Coherence,2021,0.0003527409322130297,2
W2611029872,Efficient Natural Language Response Suggestion for Smart Reply,2017,0.00035202925620244816,2
W2739749670,MEMEN: Multi-layer Embedding with Memory Networks for Machine Comprehension,2017,0.00035198999363993426,2
W2606089314,Neural Network Methods for Natural Language Processing,2017,0.0003511586141691423,2
W3034723486,"Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data",2020,0.00035044883588055043,2
W2769395616,Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering,2017,0.0003472176705686265,2
W2951125449,Condensed Memory Networks for Clinical Diagnostic Inferencing,2017,0.0003456435464117536,2
W2990928880,Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering,2019,0.0003447854340456758,2
W2951528484,A Compare-Aggregate Model for Matching Text Sequences,2016,0.00034403678568186325,2
W2890961898,Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text,2018,0.0003434527436676512,2
W2995638926,Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering,2020,0.00034326193836713804,2
W2962854673,Neural Legal Judgment Prediction in English,2019,0.00033834046744305135,2
W2771275742,Inference is Everything: Recasting Semantic Resources into a Unified Evaluation Framework,2017,0.00033786809108185073,2
W3099236585,Distributional Semantics and Linguistic Theory,2019,0.0003364700729691469,2
W2963738886,CFO: Conditional Focused Neural Question Answering with Large-scale Knowledge Bases,2016,0.00033625643623321996,2
W2952984539,Probing Neural Network Comprehension of Natural Language Arguments,2019,0.0003359550878767546,2
W3205068155,Multitask Prompted Training Enables Zero-Shot Task Generalization,2021,0.000335405615321215,2
W4210984920,Neural Network Methods for Natural Language Processing,2017,0.00033322272196641774,2
W2612228435,Search-based Neural Structured Learning for Sequential Question Answering,2017,0.0003318696748842629,2
W2996851481,Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment,2020,0.00033039301433163127,2
W2964301649,Audio Adversarial Examples: Targeted Attacks on Speech-to-Text,2018,0.0003297243201657303,2
W4283819412,BERTMap: A BERT-Based Ontology Alignment System,2022,0.00032745003075884503,2
W2755637027,Variational Reasoning for Question Answering With Knowledge Graph,2018,0.0003266211873239379,2
W2892280852,Commonsense for Generative Multi-Hop Question Answering Tasks,2018,0.00032479253793819596,2
W2945127593,Deeper Text Understanding for IR with Contextual Neural Language Modeling,2019,0.0003242106893734255,2
W2970200208,"Benchmarking Zero-shot Text Classification: Datasets, Evaluation and Entailment Approach",2019,0.0003233275906114709,2
W3035507081,Beyond Accuracy: Behavioral Testing of NLP Models with CheckList,2020,0.000322576712223751,2
W2962727366,How Much Reading Does Reading Comprehension Require? A Critical Investigation of Popular Benchmarks,2018,0.00032255161515278344,2
W2805003518,Incorporating Context into Language Encoding Models for fMRI,2018,0.0003220217917307234,2
W2911681509,Learning and Evaluating General Linguistic Intelligence,2019,0.00032104278925006163,2
W2963149412,Learning Semantic Textual Similarity from Conversations,2018,0.0003207369868326534,2
W2915589364,The State of Sparsity in Deep Neural Networks,2019,0.0003194226123300477,2
W2962685628,Shortcut-Stacked Sentence Encoders for Multi-Domain Inference,2017,0.00031902000961442676,2
W2970168256,A Discrete Hard EM Approach for Weakly Supervised Question Answering,2019,0.00031397243775920436,2
W3008374555,MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers,2020,0.00031346305369335515,2
W2983995706,KagNet: Knowledge-Aware Graph Networks for Commonsense Reasoning,2019,0.0003134452271198472,2
W3034457371,MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices,2020,0.000312777862988888,2
W3118781290,The Pile: An 800GB Dataset of Diverse Text for Language Modeling,2021,0.0003127546524325984,2
W3166846774,Learning How to Ask: Querying LMs with Mixtures of Soft Prompts,2021,0.00030939161680427243,2
W2765742249,Drug–drug interaction extraction via hierarchical RNNs on sequence and shortest dependency paths,2017,0.0003072951823642784,2
W2972498556,Analyzing the Structure of Attention in a Transformer Language Model,2019,0.0003064932401756701,2
W4382246105,Recent Advances in Natural Language Processing via Large Pre-trained Language Models: A Survey,2023,0.0003054773061053662,2
W2973154008,Open Sesame: Getting inside BERT’s Linguistic Knowledge,2019,0.0003054088420076819,2
W2963120843,Performance Impact Caused by Hidden Bias of Training Data for Recognizing Textual Entailment,2018,0.00030500495496894105,2
W4220949944,Shared computational principles for language processing in humans and deep language models,2022,0.0003025713422235505,2
W3175362188,ConSERT: A Contrastive Framework for Self-Supervised Sentence Representation Transfer,2021,0.00030236131164383467,2
W2607892599,A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference,2017,0.00030158865300479784,2
W3100107515,Document Ranking with a Pretrained Sequence-to-Sequence Model,2020,0.0003010476916176188,2
W3155457426,Cross-lingual Contextualized Topic Models with Zero-shot Learning,2021,0.0002982392204441968,2
W2905266130,Conditional BERT Contextual Augmentation,2019,0.0002973133177816604,2
W2511929605,Inner Attention based Recurrent Neural Networks for Answer Selection,2016,0.000296859851771316,2
W2970283086,Show Your Work: Improved Reporting of Experimental Results,2019,0.00029557638988542226,2
W2952826391,Zero-Shot Entity Linking by Reading Entity Descriptions,2019,0.00029556032287053694,2
W2749581528,Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates,2017,0.0002934969786491135,2
W2950768109,Is Attention Interpretable?,2019,0.00029174489758691937,2
W3035140194,TaPas: Weakly Supervised Table Parsing via Pre-training,2020,0.00029076589815820136,2
W2604368306,Reading Wikipedia to Answer Open-Domain Questions,2017,0.0002902926357975494,2
W2921890305,Neural language models as psycholinguistic subjects: Representations of syntactic state,2019,0.0002891646402557465,2
W2739716023,An End-to-End Model for Question Answering over Knowledge Base with Cross-Attention Combining Global Knowledge,2017,0.0002883265336322983,2
W3177265267,Q8BERT: Quantized 8Bit BERT,2019,0.000286767697794494,2
W3173783447,DeCLUTR: Deep Contrastive Learning for Unsupervised Textual Representations,2021,0.000286153945944772,2
W2979949198,exBERT: A Visual Analysis Tool to Explore Learned Representations in Transformers Models,2019,0.0002848914514489701,2
W2550837020,Words or Characters? Fine-grained Gating for Reading Comprehension,2016,0.00028421943085469464,2
W3105935311,Wikipedia2Vec: An Efficient Toolkit for Learning and Visualizing the Embeddings of Words and Entities from Wikipedia,2020,0.0002799095700828732,2
W3034862985,Improving Multi-hop Question Answering over Knowledge Graphs using Knowledge Base Embeddings,2020,0.0002798233973915935,2
W3160137267,Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction,2021,0.00027883645695084633,2
W4385567149,Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?,2022,0.000278830264408839,2
W2963957489,DuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications,2018,0.0002786621036562435,2
W3174784402,WARP: Word-level Adversarial ReProgramming,2021,0.0002771956917252713,2
W2989312920,Knowledge Guided Text Retrieval and Reading for Open Domain Question Answering,2019,0.00027679948312117305,2
W2757276219,Deep Neural Solver for Math Word Problems,2017,0.0002751594605040497,2
W2938224028,Understanding the Behaviors of BERT in Ranking,2019,0.00027460785528092584,2
W2892163801,UKP-Athene: Multi-Sentence Textual Entailment for Claim Verification,2018,0.00027436778695675375,2
W3154229486,Whitening Sentence Representations for Better Semantics and Faster Retrieval,2021,0.0002740341126200832,2
W3099215402,TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification,2020,0.00027369483192499287,2
W2963719234,Natural Language Inference over Interaction Space,2017,0.0002735974495435849,2
W4213191780,Overview and Discussion of the Competition on Legal Information Extraction/Entailment (COLIEE) 2021,2022,0.00027313678072040987,2
W2964060837,The Fact Extraction and VERification (FEVER) Shared Task,2018,0.0002730539621086111,2
W2963859254,TextBugger: Generating Adversarial Text Against Real-world Applications,2019,0.0002722192272678198,2
W4309811444,PTR: Prompt Tuning with Rules for Text Classification,2022,0.00027119954461536053,2
W2962940365,Interpretable Charge Predictions for Criminal Cases: Learning to Generate Court Views from Fact Descriptions,2018,0.00027064779392601363,2
W3103536442,Syntactic Structure from Deep Learning,2020,0.00027047625464026,2
W2971155257,PullNet: Open Domain Question Answering with Iterative Retrieval on Knowledge Bases and Text,2019,0.0002697882900042223,2
W2950681488,ELI5: Long Form Question Answering,2019,0.0002677038418709147,2
W3034995113,"Negated and Misprimed Probes for Pretrained Language Models: Birds Can Talk, But Cannot Fly",2020,0.0002662692587908741,2
W2996728628,BLiMP: The Benchmark of Linguistic Minimal Pairs for English,2020,0.00026608444502467,2
W3130880317,Evolution of Semantic Similarity—A Survey,2021,0.0002660525530111337,2
W3155001903,Structure-Augmented Text Representation Learning for Efficient Knowledge Graph Completion,2021,0.000265531556090001,2
W2963938442,Semi-Supervised QA with Generative Domain-Adaptive Nets,2017,0.00026396631632667094,2
W2998230451,Semantics-Aware BERT for Language Understanding,2020,0.000261537449380973,2
W2950336186,GEAR: Graph-based Evidence Aggregating and Reasoning for Fact Verification,2019,0.0002609385630897698,2
W2789244308,Comparing deep learning and concept extraction based methods for patient phenotyping from clinical narratives,2018,0.00026013785157178,2
W2963662654,Question Answering by Reasoning Across Documents with Graph Convolutional Networks,2019,0.000260106140157054,2
W3121904249,Measuring Massive Multitask Language Understanding,2021,0.000259652618853934,2
W2998557616,Inducing Relational Knowledge from BERT,2020,0.00025937910795150175,2
W4321452549,Single-cell biological network inference using a heterogeneous graph transformer,2023,0.0002580151113132835,2
W2786472750,Complex Sequential Question Answering: Towards Learning to Converse Over Linked Question Answer Pairs with a Knowledge Graph,2018,0.0002579517174555827,2
W2963682631,Character-Level Question Answering with Attention,2016,0.00025651811763062075,2
W2769099080,Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning,2017,0.0002563948762563084,2
W3160596727,Med7: A transferable clinical natural language processing model for electronic health records,2021,0.00025597875866129077,2
W3035204084,SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization,2020,0.0002550801890814413,2
W3100452049,Pretrained Language Models for Biomedical and Clinical Tasks: Understanding and Extending the State-of-the-Art,2020,0.0002544586197642145,2
W2994915912,Pretrained Encyclopedia: Weakly Supervised Knowledge-Pretrained Language Model,2019,0.0002527063420260829,2
W2971105107,Multi-passage BERT: A Globally Normalized BERT Model for Open-domain Question Answering,2019,0.0002516241422274871,2
W2956105246,,2019,0.0002515297504819819,2
W2963900105,Attention-Based Convolutional Neural Network for Machine Comprehension,2016,0.0002514888919266437,2
W3100355250,RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models,2020,0.00025046257824427073,2
W2889729765,Ranking Paragraphs for Improving Answer Recall in Open-Domain Question Answering,2018,0.00024793707506609857,2
W3164540570,Self-Alignment Pretraining for Biomedical Entity Representations,2021,0.00024764608401285366,2
W2741075451,Leveraging Knowledge Bases in LSTMs for Improving Machine Reading,2017,0.0002461458452028117,2
W2988421999,MRQA 2019 Shared Task: Evaluating Generalization in Reading Comprehension,2019,0.00024562618343375477,2
W3169283738,KILT: a Benchmark for Knowledge Intensive Language Tasks,2021,0.0002451293619204393,2
W4391876619,Lost in the Middle: How Language Models Use Long Contexts,2024,0.00024379416439030226,2
W2996848635,QASC: A Dataset for Question Answering via Sentence Composition,2020,0.0002437257026599034,2
W2799081691,Denoising Distantly Supervised Open-Domain Question Answering,2018,0.00024308261866171478,2
W3153675281,AdapterFusion: Non-Destructive Task Composition for Transfer Learning,2021,0.00024298326481522346,2
W2806055002,SemEval-2018 Task 11: Machine Comprehension Using Commonsense Knowledge,2018,0.00024285062048650134,2
W2964082993,Semantic Sentence Matching with Densely-Connected Recurrent and Co-Attentive Information,2019,0.0002402142838417635,2
W3011574394,Pre-trained models for natural language processing: A survey,2020,0.00023972598527484632,2
W2963159735,Efficient and Robust Question Answering from Minimal Context over Documents,2018,0.00023927044296562114,2
W2950784811,A Multiscale Visualization of Attention in the Transformer Model,2019,0.00023872359381395635,2
W3016473712,MPNet: Masked and Permuted Pre-training for Language Understanding,2020,0.0002386383202693968,2
W2768377508,Hierarchical attention networks for information extraction from cancer pathology reports,2017,0.00023843498159513933,2
W3156470785,Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity,2022,0.00023824838592306958,2
W3115295967,CLEAR: Contrastive Learning for Sentence Representation,2020,0.00023816655183268688,2
W3166986030,Factual Probing Is [MASK]: Learning vs. Learning to Recall,2021,0.0002381098346312458,2
W3104748221,Scalable Zero-shot Entity Linking with Dense Entity Retrieval,2020,0.00023787633444137963,2
W3105994699,Measuring the Similarity of Sentential Arguments in Dialogue,2016,0.00023762701618349982,2
W4221153690,LinkBERT: Pretraining Language Models with Document Links,2022,0.00023724076649729985,2
W2970780738,Cosmos QA: Machine Reading Comprehension with Contextual Commonsense Reasoning,2019,0.00023709206667453978,2
W2891304738,Interpretation of Natural Language Rules in Conversational Machine Reading,2018,0.00023688526622638682,2
W3013571468,ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators,2020,0.00023649722638802354,2
W3104423855,BAE: BERT-based Adversarial Examples for Text Classification,2020,0.00023610324519846002,2
W3158665049,Multi-domain clinical natural language processing with MedCAT: The Medical Concept Annotation Toolkit,2021,0.0002357305051734006,2
W4390692489,Unifying Large Language Models and Knowledge Graphs: A Roadmap,2024,0.00023512835135880758,2
W2806168354,Automatic Detection of Incoherent Speech for Diagnosing Schizophrenia,2018,0.00023319541915060334,2
W3033187248,DeBERTa: Decoding-enhanced BERT with Disentangled Attention,2020,0.00023316423436434353,2
W2889577585,Few-Shot and Zero-Shot Multi-Label Learning for Structured Label Spaces,2018,0.000233117113526203,2
W3104415840,LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention,2020,0.00023303983694256323,2
W2971209824,Cross-Domain Modeling of Sentence-Level Evidence for Document Retrieval,2019,0.000232930181836621,2
W2885396331,Interpreting Recurrent and Attention-Based Neural Models: a Case Study on Natural Language Inference,2018,0.00023282833577657012,2
W2993873509,Deep learning in clinical natural language processing: a methodical review,2019,0.00023200519244643902,2
W2909970382,Grammatical Analysis of Pretrained Sentence Encoders with Acceptability Judgments.,2019,0.00023015283952253183,2
W2963993699,Plan-and-Write: Towards Better Automatic Storytelling,2019,0.00022979923586989592,2
W2782630856,Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs,2018,0.00022950035708618733,2
W2953163841,Compositional Questions Do Not Necessitate Multi-hop Reasoning,2019,0.00022948384337978872,2
W3101449015,BERT-ATTACK: Adversarial Attack Against BERT Using BERT,2020,0.00022917094887485939,2
W2952862139,"HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering",2018,0.00022875866594022684,2
W2952087461,Classification and Clustering of Arguments with Contextualized Word Embeddings,2019,0.00022776869628328883,2
W2949428332,Multi-step Retriever-Reader Interaction for Scalable Open-domain Question Answering,2019,0.00022746225661028613,2
W2888296173,CoQA: A Conversational Question Answering Challenge,2018,0.00022713095540320702,2
W2952113915,Bilateral Multi-Perspective Matching for Natural Language Sentences,2017,0.00022702966027760688,2
W3168875417,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,0.00022600934123150664,2
W2625541525,S-Net: From Answer Extraction to Answer Generation for Machine Reading Comprehension,2017,0.00022565992331112308,2
W3034917890,Towards Faithfully Interpretable NLP Systems: How Should We Define and Evaluate Faithfulness?,2020,0.00022526446104456033,2
W3104186312,BERTweet: A pre-trained language model for English Tweets,2020,0.00022376792531721975,2
W2963001247,Learning Paraphrastic Sentence Embeddings from Back-Translated Bitext,2017,0.00022291371191552307,2
W3162922479,What Disease Does This Patient Have? A Large-Scale Open Domain Question Answering Dataset from Medical Exams,2021,0.0002222536419830483,2
W3176828726,BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models,2022,0.00022176883814402565,2
W2998374885,Graph-Based Reasoning over Heterogeneous External Knowledge for Commonsense Question Answering,2020,0.00022024764433132893,2
W3129831491,ZeRO: Memory optimizations Toward Training Trillion Parameter Models,2020,0.00021996777713692038,2
W3172335055,QA-GNN: Reasoning with Language Models and Knowledge Graphs for Question Answering,2021,0.00021991239476224178,2
W4389520455,Text Classification via Large Language Models,2023,0.00021942908533913185,2
W4385573087,Large language models are few-shot clinical information extractors,2022,0.0002193876755863054,2
W3102725307,Revisiting Pre-Trained Models for Chinese Natural Language Processing,2020,0.00021872988699184038,2
W3106031450,A Span-Extraction Dataset for Chinese Machine Reading Comprehension,2019,0.00021816854741455927,2
W3092557781,Overview of the Transformer-based Models for NLP Tasks,2020,0.00021773197781202637,2
W3035153870,SenseBERT: Driving Some Sense into BERT,2020,0.00021726047845456082,2
W2998183051,Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT,2020,0.0002167524598882585,2
W4246183800,TSDAE: Using Transformer-based Sequential Denoising Auto-Encoderfor Unsupervised Sentence Embedding Learning,2021,0.00021654197410044503,2
W2970139579,Revealing the Importance of Semantic Retrieval for Machine Reading at Scale,2019,0.00021631255287168536,2
W2891691791,Multi-Source Domain Adaptation with Mixture of Experts,2018,0.0002162495972940192,2
W2951515642,A2N: Attending to Neighbors for Knowledge Graph Inference,2019,0.00021598161833835954,2
W2889272240,MedSTS: a resource for clinical semantic textual similarity,2018,0.00021595021884147363,2
W3177323791,Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning,2021,0.00021581699231323608,2
W4312220150,A large language model for electronic health records,2022,0.00021529298976693338,2
W2949134692,Multi-hop Reading Comprehension through Question Decomposition and Rescoring,2019,0.00021479005695215813,2
W3090325631,LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention,2020,0.0002124763218886791,2
W3152698349,Masked Language Modeling and the Distributional Hypothesis: Order Word Matters Pre-training for Little,2021,0.00021224447346765088,2
W3111412136,Text mining approaches for dealing with the rapidly expanding literature on COVID-19,2020,0.00021154625245092096,2
W2962941914,Finding syntax in human encephalography with beam search,2018,0.00021040571440850486,2
W2994934025,Learning The Difference That Makes A Difference With Counterfactually-Augmented Data,2020,0.0002101086908350925,2
W3042631625,SBERT-WK: A Sentence Embedding Method by Dissecting BERT-Based Word Models,2020,0.00020885720451400034,2
W2891308403,Transforming Question Answering Datasets Into Natural Language Inference Datasets,2018,0.00020853609999466616,2
W2962817854,Numeracy for Language Models: Evaluating and Improving their Ability to Predict Numbers,2018,0.00020799915340468059,2
W2791941932,Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples,2018,0.0002075547474496301,2
W3014521650,A Knowledge-Enhanced Pretraining Model for Commonsense Story Generation,2020,0.00020712504765351436,2
W3105604018,"TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP",2020,0.00020606509354438246,2
W2770626128,Pushing the Limits of Paraphrastic Sentence Embeddings with Millions of Machine Translations,2017,0.00020531475490387453,2
W2798459010,Stochastic Answer Networks for Natural Language Inference,2018,0.0002046299010094365,2
W3088418428,Placing language in an integrated understanding system: Next steps toward human-level performance in neural language models,2020,0.00020458312490595368,2
W2911435132,Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference,2019,0.0002043214341355101,2
W2963453233,BAM! Born-Again Multi-Task Networks for Natural Language Understanding,2019,0.00020393190611867943,2
W4298110867,<scp>FinBERT</scp>: A Large Language Model for Extracting Information from Financial Text*,2022,0.0002038615575007296,2
W2888236192,End-to-End Neural Entity Linking,2018,0.0002036703858508625,2
W2966892770,"StructBERT: Incorporating Language Structures into Pre-training for Deep
  Language Understanding",2019,0.00020350524539230292,2
W4389523957,Is ChatGPT a General-Purpose Natural Language Processing Task Solver?,2023,0.0002033131755964627,2
W2912904516,DREAM: A Challenge Data Set and Models for Dialogue-Based Reading Comprehension,2019,0.00020262254982024566,2
W2929581986,Analyzing and interpreting neural networks for NLP: A report on the first BlackboxNLP workshop,2019,0.00020210865490812263,2
W2803267010,Neural Text Generation in Stories Using Entity Representations as Context,2018,0.00020175483334244242,2
W3035367371,Weight Poisoning Attacks on Pretrained Models,2020,0.00020168657312622735,2
W2962922117,Cognitive Graph for Multi-Hop Reading Comprehension at Scale,2019,0.00020060803075289284,2
W2963983586,Tracking State Changes in Procedural Text: a Challenge Dataset and Models for Process Paragraph Comprehension,2018,0.00020008990874746847,2
W2911462778,Evaluation and accurate diagnoses of pediatric diseases using artificial intelligence,2019,0.00019936807060407853,2
W2948771346,Visualizing and Measuring the Geometry of BERT,2019,0.0001991857981591073,2
W4287891464,Learning To Retrieve Prompts for In-Context Learning,2022,0.0001987871281624773,2
W3184324824,Detecting formal thought disorder by deep contextualized word representations,2021,0.0001983117423389383,2
W3211686893,DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing,2021,0.00019830696965134957,2
W3154065069,"COVID-19 information retrieval with deep-learning based semantic search, question answering, and abstractive summarization",2021,0.00019741917321211701,2
W4285294723,GLM: General Language Model Pretraining with Autoregressive Blank Infilling,2022,0.00019723485016243808,2
W3162462834,Evaluation of BERT and ALBERT Sentence Embedding Performance on Downstream NLP Tasks,2021,0.00019716715859553933,2
W3176047188,Self-Guided Contrastive Learning for BERT Sentence Representations,2021,0.0001967920903212839,2
W2996035354,ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators,2020,0.0001965789804154118,2
W3034287667,Automatic Detection of Generated Text is Easiest when Humans are Fooled,2020,0.00019649816600797234,2
W4386576685,MTEB: Massive Text Embedding Benchmark,2023,0.0001962371862874097,2
W2941666437,Probing What Different NLP Tasks Teach Machines about Function Word Comprehension,2019,0.00019571819670614722,2
W2799051010,Learning Thematic Similarity Metric from Article Sections Using Triplet Networks,2018,0.00019544370077492242,2
W2915240437,SemEval-2017 Task 3: Community Question Answering,2017,0.00019526018124761907,2
W2927746189,An Embarrassingly Simple Approach for Transfer Learning from Pretrained Language Models,2019,0.0001948957480249453,2
W3035102548,Interpreting Pretrained Contextualized Representations via Reductions to Static Embeddings,2020,0.00019388951214224475,2
W4206693003,A hybrid approach of Weighted Fine-Tuned BERT extraction with deep Siamese Bi – LSTM model for semantic text similarity identification,2022,0.00019354403371514475,2
W3202586005,Generalization in NLI: Ways (Not) To Go Beyond Simple Heuristics,2021,0.00019274990646915807,2
W2952831501,Putting Words in Context: LSTM Language Models and Lexical Ambiguity,2019,0.00019261018262980352,2
W3196731672,Cross-Task Generalization via Natural Language Crowdsourcing Instructions,2022,0.00019258984796021567,2
W2963041663,Open-World Knowledge Graph Completion,2018,0.00019242713500138665,2
W2515385951,Pruning Filters for Efficient ConvNets,2016,0.00019219668142117662,2
W2791751435,Do latent tree learning models identify meaningful structure in sentences?,2018,0.00019209520888993428,2
W3035030897,FastBERT: a Self-distilling BERT with Adaptive Inference Time,2020,0.00019164027124057593,2
W3181361218,Neural Natural Language Processing for unstructured data in electronic health records: A review,2022,0.00019147823537734402,2
W3034808961,Reasoning Over Semantic-Level Graph for Fact Checking,2020,0.0001914328625390414,2
W2741263286,Coarse-to-Fine Question Answering for Long Documents,2017,0.0001910385597339811,2
W2955753753,UCL Machine Reading Group: Four Factor Framework For Fact Finding (HexaF),2018,0.0001909627526762473,2
W2971869958,Language Models as Knowledge Bases,2019,0.0001908852021795112,2
W3034229721,Biomedical Entity Representations with Synonym Marginalization,2020,0.00019083478167148532,2
W2995289474,Poly-encoders: Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring,2020,0.00019074421007760114,2
W3106109117,Text Classification Using Label Names Only: A Language Model Self-Training Approach,2020,0.00019042844235471948,2
W3105055324,Hierarchical Graph Network for Multi-hop Question Answering,2020,0.00019035420855020266,2
W2971044268,Investigating BERT’s Knowledge of Language: Five Analysis Methods with NPIs,2019,0.00019008480804279783,2
W3034775979,Masked Language Model Scoring,2020,0.00018984542814904566,2
W3104499181,Unsupervised Commonsense Question Answering with Self-Talk,2020,0.00018933739272128448,2
W3038012435,Compressing BERT: Studying the Effects of Weight Pruning on Transfer Learning,2020,0.00018871627246351932,2
W2969574947,Poly-encoders: Transformer Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring,2019,0.00018861659170055976,2
W2975381464,Reducing Transformer Depth on Demand with Structured Dropout,2019,0.00018814114556998292,2
W2923890923,Simple Applications of BERT for Ad Hoc Document Retrieval,2019,0.00018774191097567833,2
W2964031179,Examining CNN Representations With Respect to Dataset Bias,2018,0.00018740626955772845,2
W4385570872,SemEval-2023 Task 6: LegalEval - Understanding Legal Texts,2023,0.00018708928483080435,2
W3035668167,How Does NLP Benefit Legal System: A Summary of Legal Artificial Intelligence,2020,0.00018671076066854313,2
W3104059174,BioSentVec: creating sentence embeddings for biomedical texts,2019,0.0001866747199413677,2
W2963374347,Visual interpretability for deep learning: a survey,2018,0.0001866143659520292,2
W3032553678,Neural entity linking: A survey of models based on deep learning,2022,0.00018642487158260546,2
W3035038672,DeeBERT: Dynamic Early Exiting for Accelerating BERT Inference,2020,0.00018588602044511336,2
W3177382889,Lawformer: A pre-trained language model for Chinese legal long documents,2021,0.00018548771201163747,2
W3217305727,ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction,2022,0.00018536822442880642,2
W2932893307,,2019,0.00018533778516942141,2
W2970155250,Rethinking Cooperative Rationalization: Introspective Extraction and Complement Control,2019,0.00018528658443405126,2
W3035428952,Injecting Numerical Reasoning Skills into Language Models,2020,0.00018478515033236876,2
W4205857304,Surface Form Competition: Why the Highest Probability Answer Isn’t Always Right,2021,0.00018455443874261236,2
W3039017601,Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering,2020,0.00018440842797868255,2
W4391292768,Improving large language models for clinical named entity recognition via prompt engineering,2024,0.00018427229321342107,2
W2889002152,Story Ending Generation with Incremental Encoding and Commonsense Knowledge,2019,0.00018412675161867453,2
W2970442950,Are We Modeling the Task or the Annotator? An Investigation of Annotator Bias in Natural Language Understanding Datasets,2019,0.00018398185856249093,2
W2891488835,Understanding Convolutional Neural Networks for Text Classification,2018,0.000183732590921066,2
W3119438769,Prefix-Tuning: Optimizing Continuous Prompts for Generation,2021,0.00018365896822316937,2
W4289638300,A hierarchy of linguistic predictions during natural language comprehension,2022,0.00018350251315645425,2
W2914924671,Language Modeling Teaches You More than Translation Does: Lessons Learned Through Auxiliary Syntactic Task Analysis,2018,0.0001830140150895386,2
W2970379526,Towards Debiasing Fact Verification Models,2019,0.0001829194317622023,2
W3174828871,A Survey of Data Augmentation Approaches for NLP,2021,0.000182451721095156,2
W2964151654,Neural Models for Reasoning over Multiple Mentions Using Coreference,2018,0.00018185614439965542,2
W3131870090,COCO-LM: Correcting and Contrasting Text Sequences for Language Model Pretraining,2021,0.00018035576041837203,2
W2811010710,On Adversarial Examples for Character-Level Neural Machine Translation,2018,0.0001802900008878259,2
W3034408878,Pretrained Transformers Improve Out-of-Distribution Robustness,2020,0.0001800579710678139,2
W2822830299,Modeling Multi-turn Conversation with Deep Utterance Aggregation,2018,0.00017962237972265184,2
W4385572634,Self-Instruct: Aligning Language Models with Self-Generated Instructions,2023,0.0001791214334614773,2
W3137305332,Semantic Models for the First-Stage Retrieval: A Comprehensive Review,2022,0.00017900829966178045,2
W2964242047,Probing Biomedical Embeddings from Language Models,2019,0.0001782400786794728,2
W2946595845,Proppy: Organizing the news based on their propagandistic content,2019,0.00017823318600167302,2
W3177765786,Deduplicating Training Data Makes Language Models Better,2022,0.00017797338489086736,2
W2950729111,Real-Time Open-Domain Question Answering with Dense-Sparse Phrase Index,2019,0.0001776162279534438,2
W2939507640,DocBERT: BERT for Document Classification,2019,0.00017744817115491617,2
W2963028402,Training Classifiers with Natural Language Explanations,2018,0.00017741009110887782,2
W3035324702,SPECTER: Document-level Representation Learning using Citation-informed Transformers,2020,0.000177267204431012,2
W3007685714,FreeLB: Enhanced Adversarial Training for Natural Language Understanding,2019,0.0001761462393130111,2
W2966610483,Representation Degeneration Problem in Training Natural Language Generation Models,2019,0.00017608054980276504,2
W3101295217,We Can Detect Your Bias: Predicting the Political Ideology of News Articles,2020,0.00017607060079801611,2
W2952750383,DisSent: Learning Sentence Representations from Explicit Discourse Relations,2019,0.00017579274545916063,2
W3194782062,Sentence-T5: Scalable Sentence Encoders from Pre-trained Text-to-Text Models,2022,0.00017570464024372742,2
W2963804400,Integrating Semantic Knowledge to Tackle Zero-shot Text Classification,2019,0.00017516804589189016,2
W2807333695,SemEval-2018 Task 3: Irony Detection in English Tweets,2018,0.00017508775903974792,2
W4296557505,QA Dataset Explosion: A Taxonomy of NLP Resources for Question Answering and Reading Comprehension,2022,0.00017481187955752916,2
W2760327630,Interactive Visualization and Manipulation of Attention-based Neural Machine Translation,2017,0.00017480118493781347,2
W2950819771,Collecting Diverse Natural Language Inference Problems for Sentence Representation Evaluation,2018,0.00017443539780370729,2
W2963928014,DuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension,2018,0.00017416563553778277,2
W3100652389,An Unsupervised Sentence Embedding Method by Mutual Information Maximization,2020,0.0001740873107271242,2
W4385573170,PromptBERT: Improving BERT Sentence Embeddings with Prompts,2022,0.00017408505130883496,2
W2964059756,Question Answering on Knowledge Bases and Text using Universal Schema and Memory Networks,2017,0.00017404171933468123,2
W3155807546,Retrieval Augmentation Reduces Hallucination in Conversation,2021,0.00017397958379557495,2
W2889234142,One-Shot Relational Learning for Knowledge Graphs,2018,0.00017394875897513152,2
W2963082277,Contextualized Word Representations for Reading Comprehension,2018,0.0001738172988370911,2
W2982596739,Multi-Stage Document Ranking with BERT,2019,0.0001733761248759181,2
W3005441132,K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters,2020,0.0001733414866001457,2
W2764024122,Interpretable Convolutional Neural Networks,2018,0.00017332312701896337,2
W2927032858,A clinical text classification paradigm using weak supervision and deep representation,2019,0.00017317736573162082,2
W3099384026,Expansion via Prediction of Importance with Contextualization,2020,0.00017315283715160692,2
W2995335514,Zero-shot Text Classification With Generative Language Models,2019,0.00017292164197766185,2
W2962998183,Recognizing Implicit Discourse Relations via Repeated Reading: Neural Networks with Multi-Level Attention,2016,0.00017283971147810835,2
W2940009958,Adversarial Attacks on Deep Learning Models in Natural Language Processing: A Survey,2019,0.0001728042590636281,2
W4392669753,"A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity",2023,0.0001727307094016947,2
W3035305735,Information-Theoretic Probing for Linguistic Structure,2020,0.0001719762968997318,2
W2996657743,TabFact: A Large-scale Dataset for Table-based Fact Verification,2020,0.00017185467574645666,2
W4285190530,TimeLMs: Diachronic Language Models from Twitter,2022,0.0001718449475013128,2
W3099793224,AdapterHub: A Framework for Adapting Transformers,2020,0.00017172294036809095,2
W2962910668,Large-Scale Multi-Label Text Classification on EU Legislation,2019,0.00017166095979891655,2
W2910453440,A Survey of Zero-Shot Learning,2019,0.00017158851305857005,2
W2977745385,Improving Question Answering by Commonsense-Based Pre-training,2019,0.00017114252342347012,2
W2922293812,On Evaluation of Adversarial Perturbations for Sequence-to-Sequence Models,2019,0.00017027957467112106,2
W2964152081,"Chains of Reasoning over Entities, Relations, and Text using Recurrent Neural Networks",2017,0.0001700951672929565,2
W3175102705,COLIEE 2020: Methods for Legal Document Retrieval and Entailment,2021,0.00017003634797681808,2
W2951561177,Enhancing Pre-Trained Language Representations with Rich Knowledge for Machine Reading Comprehension,2019,0.00016925986492917854,2
W2726375170,Recurrent neural networks for classifying relations in clinical notes,2017,0.00016925367538973127,2
W2963429207,Modeling Naive Psychology of Characters in Simple Commonsense Stories,2018,0.0001686149675447978,2
W3100292568,AmbigQA: Answering Ambiguous Open-domain Questions,2020,0.00016816960426446892,2
W2965570621,Pre-training of Graph Augmented Transformers for Medication Recommendation,2019,0.00016800105116427793,2
W2998579922,DCMN+: Dual Co-Matching Network for Multi-Choice Reading Comprehension,2020,0.00016789469136457957,2
W3152956381,The Power of Scale for Parameter-Efficient Prompt Tuning,2021,0.00016742730654437413,2
W4322766928,Evidence of a predictive coding hierarchy in the human brain listening to speech,2023,0.00016664481286831923,2
W4381930847,ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model Meta-AI (LLaMA) Using Medical Domain Knowledge,2023,0.00016662818185603397,2
W3166204619,"BioM-Transformers: Building Large Biomedical Language Models with BERT, ALBERT and ELECTRA",2021,0.00016653085249509168,2
W3007759824,UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training,2020,0.00016632323450936363,2
W4226142803,SimKGC: Simple Contrastive Knowledge Graph Completion with Pre-trained Language Models,2022,0.000165749461533,2
W2787752464,Model compression via distillation and quantization,2018,0.00016549576447415858,2
W2997090102,TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer Sentence Selection,2020,0.0001654065123672226,2
W4392359953,Can large language models reason about medical questions?,2024,0.0001653718660393396,2
W3035267217,How Can We Accelerate Progress Towards Human-like Linguistic Generalization?,2020,0.00016526341905706291,2
W3035101152,FinBERT: A Pre-trained Financial Language Representation Model for Financial Text Mining,2020,0.00016523856445712991,2
W3174464510,(Comet-) Atomic 2020: On Symbolic and Neural Commonsense Knowledge Graphs,2021,0.00016516775260529284,2
W3088059392,,2019,0.0001651473422384863,2
W2952484617,Multi-Hop Paragraph Retrieval for Open-Domain Question Answering,2019,0.00016491735478323284,2
W2964025273,Learning Generic Sentence Representations Using Convolutional Neural Networks,2017,0.00016474905281559495,2
W2982096936,Context-Aware Sentence/Passage Term Importance Estimation For First Stage Retrieval,2019,0.00016411329008049155,2
W3104939451,Calibration of Pre-trained Transformers,2020,0.0001639352530223693,2
W4389520749,SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models,2023,0.0001634142476665752,2
W2998277219,Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples,2020,0.00016305163457616976,2
W3154280800,SPLADE: Sparse Lexical and Expansion Model for First Stage Ranking,2021,0.0001630332677838651,2
W2947415936,Combating Adversarial Misspellings with Robust Word Recognition,2019,0.00016291336492639126,2
W2517782820,Improved Representation Learning for Question Answer Matching,2016,0.00016259862601300068,2
W3122838366,Semantic Re-tuning with Contrastive Tension,2021,0.00016137100703750407,2
W3035134435,Low-Dimensional Hyperbolic Knowledge Graph Embeddings,2020,0.00016109188822274585,2
W2963059228,On the Practical Computational Power of Finite Precision RNNs for Language Recognition,2018,0.00016101964447214304,2
W3034156543,Patent classification by fine-tuning BERT language model,2020,0.00016072208431171654,2
W3102187933,CommonGen: A Constrained Text Generation Challenge for Generative Commonsense Reasoning,2020,0.00016063192306116125,2
W3198599617,Do Prompt-Based Models Really Understand the Meaning of Their Prompts?,2022,0.00015998695488496755,2
W4385573966,TweetNLP: Cutting-Edge Natural Language Processing for Social Media,2022,0.00015977570603699774,2
W2947012833,Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain),2019,0.00015974328998688244,2
W2963897632,Strong Baselines for Simple Question Answering over Knowledge Graphs with and without Neural Networks,2018,0.00015937240138257712,2
W2806081754,DRCD: a Chinese Machine Reading Comprehension Dataset,2018,0.00015921314311042432,2
W2889646190,Exploring Graph-structured Passage Representation for Multi-hop Reading Comprehension with Graph Neural Networks,2018,0.00015870790087749804,2
W2970078867,Certified Robustness to Adversarial Word Substitutions,2019,0.00015856657771877702,2
W4385571232,Can Large Language Models Be an Alternative to Human Evaluations?,2023,0.00015843693838317824,2
W2983962589,Do Massively Pretrained Language Models Make Better Storytellers?,2019,0.00015814095925613465,2
W2963430447,Unsupervised Question Answering by Cloze Translation,2019,0.0001573265850200183,2
W3100283070,E-BERT: Efficient-Yet-Effective Entity Embeddings for BERT,2020,0.0001572559096732617,2
W3013605954,Clinical Text Data in Machine Learning: Systematic Review,2020,0.00015605371110086403,2
W3017003177,Adversarial Training for Large Neural Language Models,2020,0.00015601786568543257,2
W2963190210,Integrating Stance Detection and Fact Checking in a Unified Corpus,2018,0.00015489906493168512,2
W3117339789,Multi-Task Learning for Knowledge Graph Completion with Pre-trained Language Models,2020,0.00015481379573096377,2
W3114326827,Automatic Detection of Machine Generated Text: A Critical Survey,2020,0.0001547779845344186,2
W3097986428,Scalable Multi-Hop Relational Reasoning for Knowledge-Aware Question Answering,2020,0.00015454363345087507,2
W4284664419,From Distillation to Hard Negative Sampling,2022,0.00015435903171026442,2
W2953150860,ABCNN: Attention-Based Convolutional Neural Network for Modeling Sentence Pairs,2015,0.0001539176854050667,2
W3034510440,A Systematic Assessment of Syntactic Generalization in Neural Language Models,2020,0.000153535053922941,2
W3034255912,Intermediate-Task Transfer Learning with Pretrained Language Models: When and Why Does It Work?,2020,0.0001532386227289725,2
W3035352537,Syntactic Data Augmentation Increases Robustness to Inference Heuristics,2020,0.00015308207267326096,2
W2970745243,Quoref: A Reading Comprehension Dataset with Questions Requiring Coreferential Reasoning,2019,0.00015268341169054543,2
W2949202705,A Multiscale Visualization of Attention in the Transformer Model,2019,0.0001521727762430319,2
W3172806051,Augmented SBERT: Data Augmentation Method for Improving Bi-Encoders for Pairwise Sentence Scoring Tasks,2021,0.00015213297689349104,2
W3201174429,TruthfulQA: Measuring How Models Mimic Human Falsehoods,2022,0.00015208901047853644,2
W3210129272,OpenPrompt: An Open-source Framework for Prompt-learning,2022,0.00015197835881982134,2
W3130740619,Overview of the TREC 2019 deep learning track,2020,0.0001514122043372386,2
W2954141754,Team Bertha von Suttner at SemEval-2019 Task 4: Hyperpartisan News Detection using ELMo Sentence Representation Convolutional Network,2019,0.00015110349015079574,2
W3016828850,B<scp>reak</scp> It Down: A Question Understanding Benchmark,2020,0.0001510530366315041,2
W3164972323,True Few-Shot Learning with Language Models,2021,0.0001506534368698054,2
W2888213795,A Skeleton-Based Model for Promoting Coherence Among Sentences in Narrative Story Generation,2018,0.00014973822036175348,2
W3091432621,Autoregressive Entity Retrieval,2020,0.00014887462604457722,2
W3021533447,How Context Affects Language Models' Factual Predictions,2020,0.0001487206553631649,2
W2964222271,Improving Machine Reading Comprehension with General Reading Strategies,2019,0.00014850115914008814,2
W2922523190,The emergence of number and syntax units in,2019,0.00014847346332162094,2
W2962863107,Towards Explainable NLP: A Generative Explanation Framework for Text Classification,2019,0.00014833883638978274,2
W3156450083,OCTIS: Comparing and Optimizing Topic models is Simple!,2021,0.00014831962515421182,2
W3173617765,Cutting Down on Prompts and Parameters: Simple Few-Shot Learning with Language Models,2022,0.00014806633489124668,2
W4285296644,A Contrastive Framework for Learning Sentence Representations from Pairwise and Triple-wise Perspective in Angular Space,2022,0.00014765426141842957,2
W4224313754,DiffCSE: Difference-based Contrastive Learning for Sentence Embeddings,2022,0.00014737241738878648,2
W3153451655,GPT3Mix: Leveraging Large-scale Language Models for Text Augmentation,2021,0.0001465848072933589,2
W3139958517,WhiteningBERT: An Easy Unsupervised Sentence Embedding Approach,2021,0.0001465425627403035,2
W2971277088,Unsupervised Domain Adaptation of Contextualized Embeddings for Sequence Labeling,2019,0.000146434178925914,2
W3102844651,Entities as Experts: Sparse Memory Access with Entity Supervision,2020,0.00014569943079222516,2
W2265289447,A Deep Architecture for Semantic Matching with Multiple Positional Sentence Representations,2016,0.00014497192111994194,2
W2963580443,Learning to Compose Task-Specific Tree Structures,2018,0.00014480581681895128,2
W2995643077,Abductive Commonsense Reasoning,2020,0.00014459989766873676,2
W3013843954,Generating Sentiment-Preserving Fake Online Reviews Using Neural Language Models and Their Human- and Machine-Based Detection,2020,0.000144515300078021,2
W2962979564,MCScript: A Novel Dataset for Assessing Machine Comprehension Using Script Knowledge,2018,0.0001441146128917826,2
W3153094109,Question and Answer Test-Train Overlap in Open-Domain Question Answering Datasets,2021,0.000143999327615051,2
W2910705748,"Definitions, methods, and applications in interpretable machine learning",2019,0.00014369666311835457,2
W2997522493,Clinical Concept Embeddings Learned from Massive Sources of Multimodal Medical Data,2019,0.00014335708328104828,2
W3188542058,Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification,2022,0.00014319559571825415,2
W2997429021,Iteratively Questioning and Answering for Interpretable Legal Judgment Prediction,2020,0.0001431172860106001,2
W2963895422,Improving Natural Language Inference Using External Knowledge in the Science Questions Domain,2019,0.0001428508631376406,2
W2971236147,“Going on a vacation” takes longer than “Going for a walk”: A Study of Temporal Commonsense Understanding,2019,0.00014273133534328648,2
W2942128719,Understanding Dataset Design Choices for Multi-hop Reasoning,2019,0.00014172011057388313,2
W2970648593,Linking artificial and human neural representations of language,2019,0.00014159751212653194,2
W3206435361,Automated fact‐checking: A survey,2021,0.00014158644487859414,2
W3021282678,"Sparse, Dense, and Attentional Representations for Text Retrieval",2020,0.00014124467663868462,2
W4385392860,SNCSE: Contrastive Learning for Unsupervised Sentence Embedding with Soft Negative Samples,2023,0.00014104692117324592,2
W3113763975,SemEval-2020 Task 11: Detection of Propaganda Techniques in News Articles,2020,0.00014056229189036726,2
W3015202090,Pre-training is a Hot Topic: Contextualized Document Embeddings Improve Topic Coherence,2020,0.00014043700965610427,2
W3005296017,Pre-training Tasks for Embedding-based Large-scale Retrieval,2020,0.00014023911198904684,2
W4393160302,Graph of Thoughts: Solving Elaborate Problems with Large Language Models,2024,0.00014006023583986452,2
W3034830866,Transformers as Soft Reasoners over Language,2020,0.00013982838295236312,2
W4226334043,ARL: An adaptive reinforcement learning framework for complex question answering over knowledge base,2022,0.00013957415763415638,2
W3096403953,CODER: Knowledge-infused cross-lingual medical term embedding for term normalization,2022,0.00013951904011314163,2
W2982424689,A survey of word embeddings for clinical text,2019,0.00013950406987357593,2
W2949849869,Synthetic QA Corpora Generation with Roundtrip Consistency,2019,0.00013928657751089148,2
W2996159613,Reducing Transformer Depth on Demand with Structured Dropout,2020,0.00013906307886572033,2
W4381487157,Beyond semantic distance: Automated scoring of divergent thinking greatly improves with large language models,2023,0.00013883556771492758,2
W3170403598,Are NLP Models really able to Solve Simple Math Word Problems?,2021,0.0001387667851282768,2
W2998733856,JEC-QA: A Legal-Domain Question Answering Dataset,2020,0.00013846798699172668,2
W3176443840,ILDC for CJPE: Indian Legal Documents Corpus for Court Judgment Prediction and Explanation,2021,0.00013835779481105877,2
W2911529999,Dual Co-Matching Network for Multi-choice Reading Comprehension,2019,0.00013833876307680953,2
W2984812384,EQUATE: A Benchmark Evaluation Framework for Quantitative Reasoning in Natural Language Inference,2019,0.00013831500064942267,2
W4385572845,Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks,2022,0.00013816784672789051,2
W3096580779,Automatically Identifying Words That Can Serve as Labels for Few-Shot Text Classification,2020,0.00013795747337536982,2
W3207166518,Symbolic Knowledge Distillation: from General Language Models to Commonsense Models,2022,0.00013781170961442996,2
W2998554035,Rare Words: A Major Problem for Contextualized Embeddings and How to Fix it by Attentive Mimicking,2020,0.0001378102285097846,2
W2963898730,Multi-Passage Machine Reading Comprehension with Cross-Passage Answer Verification,2018,0.00013753977694571816,2
W3015001695,Adversarial Attacks on Deep-learning Models in Natural Language Processing,2020,0.00013751882758496577,2
W3010293452,Data Augmentation using Pre-trained Transformer Models,2020,0.00013726820175255885,2
W3202712981,Measuring and Improving Consistency in Pretrained Language Models,2021,0.00013723725005254853,2
W2526174222,Image-embodied Knowledge Representation Learning,2017,0.00013702730805565427,2
W3176182290,Generation-Augmented Retrieval for Open-Domain Question Answering,2021,0.00013683978901412653,2
W3034374701,A Re-evaluation of Knowledge Graph Completion Methods,2020,0.00013620896574883197,2
W3035317050,Generating Fact Checking Explanations,2020,0.00013615357985975033,2
W3035064231,Learning to Faithfully Rationalize by Construction,2020,0.00013613521998175282,2
W2945232141,Submodular Optimization-based Diverse Paraphrasing and its Effectiveness in Data Augmentation,2019,0.0001357101478709563,2
W2963359213,Knowledge Graph Embedding With Iterative Guidance From Soft Rules,2018,0.00013561842628173273,2
W2998665041,SG-Net: Syntax-Guided Machine Reading Comprehension,2020,0.00013534571534084693,2
W2970023150,Answering Complex Open-domain Questions Through Iterative Query Generation,2019,0.00013481027383911918,2
W2148437670,Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),2023,0.00013437496592906472,2
W2983102021,KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation,2019,0.0001343142466336237,2
W3101082165,HybridQA: A Dataset of Multi-Hop Question Answering over Tabular and Textual Data,2020,0.00013365503888713995,2
W2997789497,Probing Natural Language Inference Models through Semantic Fragments,2020,0.00013360217798856133,2
W2991223644,Evaluating Commonsense in Pre-Trained Language Models,2020,0.00013334007285571944,2
W4385567216,Language Models of Code are Few-Shot Commonsense Learners,2022,0.00013328709469010813,2
W3022131108,Compositionality decomposed: how do neural networks generalise?,2019,0.0001331692387158391,2
W4379769651,Health system-scale language models are all-purpose prediction engines,2023,0.00013315665065058866,2
W3205949070,Towards a Unified View of Parameter-Efficient Transfer Learning,2021,0.00013260172048207964,2
W2963547127,Read + Verify: Machine Reading Comprehension with Unanswerable Questions,2019,0.00013247178264142525,2
W3099911888,OCNLI: Original Chinese Natural Language Inference,2020,0.00013227789381510703,2
W2952208026,The emergence of number and syntax units in LSTM language models,2019,0.0001322054315300764,2
W2951528897,"Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned",2019,0.0001321735172619938,2
W3001393026,Retrospective Reader for Machine Reading Comprehension,2021,0.0001319247940134114,2
W2890801081,DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep Learning,2018,0.000131368048268522,2
W4381587418,Opportunities and challenges for ChatGPT and large language models in biomedicine and health,2023,0.00013126268022558755,2
W2938205538,Data Augmentation for BERT Fine-Tuning in Open-Domain Question Answering,2019,0.00013107133843885918,2
W2996919866,Stepwise Reasoning for Multi-Relation Question Answering over Knowledge Graph with Weak Supervision,2020,0.00013104489426686694,2
W3154755316,Learning Passage Impacts for Inverted Indexes,2021,0.00013094831816878202,2
W2964072618,Variational Knowledge Graph Reasoning,2018,0.0001308493805191951,2
W3152515526,CrossFit: A Few-shot Learning Challenge for Cross-task Generalization in NLP,2021,0.00013081490691175965,2
W2964212550,ParaNMT-50M: Pushing the Limits of Paraphrastic Sentence Embeddings with Millions of Machine Translations,2018,0.0001306454756009299,2
W3119866685,Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity.,2021,0.00013064507034478805,2
W2987553933,Reasoning Over Paragraph Effects in Situations,2019,0.00013044657449306734,2
W3104578551,BioMegatron: Larger Biomedical Domain Language Model,2020,0.00013038300400234238,2
W3125238517,Answering Complex Open-Domain Questions with Multi-Hop Dense Retrieval,2020,0.00013034625190732558,2
W2970609357,Giving BERT a Calculator: Finding Operations and Arguments with Reading Comprehension,2019,0.00013029137431938575,2
W2962970011,Unit Dependency Graph and Its Application to Arithmetic Word Problem Solving,2017,0.0001296361310218512,2
W2950618399,Answering while Summarizing: Multi-task Learning for Multi-hop QA with Evidence Extraction,2019,0.00012943737482520965,2
W2988092105,The FEVER2.0 Shared Task,2019,0.00012917598617080703,2
W3186948566,BERT-based ensemble methods with data augmentation for legal textual entailment in COLIEE statute law task,2021,0.0001291329184316399,2
W2963001778,Semi-supervised Question Retrieval with Gated Convolutions,2016,0.00012900861325219675,2
W4385570594,"One Embedder, Any Task: Instruction-Finetuned Text Embeddings",2023,0.0001290048519346469,2
W3169948074,Contextualized Perturbation for Textual Adversarial Attack,2021,0.00012877903039677327,2
W3105451204,BERT with History Answer Embedding for Conversational Question Answering,2019,0.0001286820535835279,2
W3015883388,Dense Passage Retrieval for Open-Domain Question Answering,2020,0.00012865158946268377,2
W3016309009,Entities as Experts: Sparse Memory Access with Entity Supervision,2020,0.00012843255609706281,2
W3037252472,FinBERT: A Pretrained Language Model for Financial Communications,2020,0.00012840315152147437,2
W3152268000,Data augmentation in natural language processing: a novel text generation approach for long and short text classifiers,2022,0.0001282681749240919,2
W4388778348,In-Context Retrieval-Augmented Language Models,2023,0.00012813649249885324,2
W3104208618,Reevaluating Adversarial Examples in Natural Language,2020,0.00012809691368153333,2
W3172119680,COIL: Revisit Exact Lexical Match in Information Retrieval with Contextualized Inverted List,2021,0.0001279700899424411,2
W3186138538,Internet-Augmented Dialogue Generation,2022,0.00012767619022357562,2
W2891113091,emrQA: A Large Corpus for Question Answering on Electronic Medical Records,2018,0.00012766302508186188,2
W3205696278,Mind the Style of Text! Adversarial and Backdoor Attacks Based on Text Style Transfer,2021,0.00012756439252571347,2
W2963383094,Inoculation by Fine-Tuning: A Method for Analyzing Challenge Datasets,2019,0.0001274881389447967,2
W2913129712,"BERT has a Mouth, and It Must Speak: BERT as a Markov Random Field Language Model",2019,0.00012707700966585394,2
W2964027319,PreCo: A Large-scale Dataset in Preschool Vocabulary for Coreference Resolution,2018,0.00012658856872418105,2
W2808681756,Evaluation of sentence embeddings in downstream and linguistic probing tasks.,2018,0.00012657989280784096,2
W3092952717,Pretrained Transformers for Text Ranking: BERT and Beyond,2020,0.00012629018261468727,2
W3034588688,Contextualized Weak Supervision for Text Classification,2020,0.00012620830729701547,2
W3104163040,X-FACTR: Multilingual Factual Knowledge Retrieval from Pretrained Language Models,2020,0.00012618503643540126,2
W2786685006,Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning,2018,0.00012612572126328368,2
W3174368915,Learning from History: Modeling Temporal Knowledge Graphs with Sequential Copy-Generation Networks,2021,0.00012604477939349827,2
W2997759614,"Select, Answer and Explain: Interpretable Multi-Hop Reading Comprehension over Multiple Documents",2020,0.00012597443605521027,2
W3199958362,How Can We Know <i>When</i> Language Models Know? On the Calibration of Language Models for Question Answering,2021,0.00012593162320321738,2
W3034292689,The Right Tool for the Job: Matching Model and Instance Complexities,2020,0.00012583179409087297,2
W3198963017,Reframing Instructional Prompts to GPTk’s Language,2022,0.00012555336979098078,2
W4401857375,A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models,2024,0.00012551711545059045,2
W2991642412,Two Distinct Neural Timescales for Predictive Speech Processing,2019,0.000125072794498284,2
W4322766882,Parameter-efficient fine-tuning of large-scale pre-trained language models,2023,0.00012499917305201755,2
W2996857645,Fine-Grained Entity Typing for Domain Independent Entity Linking,2020,0.00012495711400140503,2
W3156128319,TransferNet: An Effective and Transparent Framework for Multi-hop Question Answering over Relation Graph,2021,0.00012489316765430686,2
W3090760060,Overview of CheckThat! 2020: Automatic Identification and Verification of Claims in Social Media,2020,0.0001247358466530639,2
W2963029083,Inferring Which Medical Treatments Work from Reports of Clinical Trials,2019,0.00012464632259640216,2
W3153389197,Natural Language Processing for Requirements Engineering,2021,0.00012458800338234493,2
W4385574293,WANLI: Worker and AI Collaboration for Natural Language Inference Dataset Creation,2022,0.00012402949116062137,2
W4206118214,Editing Factual Knowledge in Language Models,2021,0.00012402382735398633,2
W2963783335,Crowdsourcing Question-Answer Meaning Representations,2018,0.00012397465465727018,2
W3100436891,Unsupervised Question Decomposition for Question Answering,2020,0.00012396922967064573,2
W3108672584,Thinking ahead: spontaneous prediction in context as a keystone of language in humans and machines,2020,0.00012396854638647864,2
W3134642945,Measuring Mathematical Problem Solving With the MATH Dataset,2021,0.00012389411504229377,2
W3099624838,BERTs of a feather do not generalize together: Large variability in generalization across models with similar test set performance,2020,0.00012358883488200185,2
W3114916066,CoLAKE: Contextualized Language and Knowledge Embedding,2020,0.00012321709687253255,2
W3008736151,Hierarchical Transformers for Long Document Classification,2019,0.00012320286223878736,2
W2974875810,TinyBERT: Distilling BERT for Natural Language Understanding,2019,0.00012317990179998002,2
W3034707327,BERT-PLI: Modeling Paragraph-Level Interactions for Legal Case Retrieval,2020,0.0001227161946715161,2
W3020268419,Masking as an Efficient Alternative to Finetuning for Pretrained Language Models,2020,0.00012271201473917565,2
W4385574308,Semantic Segmentation of Legal Documents via Rhetorical Roles,2022,0.00012266829208071073,2
W4206178588,AdapterDrop: On the Efficiency of Adapters in Transformers,2021,0.00012266549661333636,2
W3132736064,Calibrate Before Use: Improving Few-Shot Performance of Language Models,2021,0.00012236060116847678,2
W3015233032,Poor Man's BERT: Smaller and Faster Transformer Models.,2020,0.0001221959268765506,2
W4206636317,Generating Datasets with Pretrained Language Models,2021,0.0001220490304562602,2
W2949694638,Improving Question Answering over Incomplete KBs with Knowledge-Aware Reader,2019,0.00012192422648853479,2
W2991361764,It Takes Nine to Smell a Rat: Neural Multi-Task Learning for Check-Worthiness Prediction,2019,0.00012182379821085203,2
W4389520103,Measuring and Narrowing the Compositionality Gap in Language Models,2023,0.00012150775257556521,2
W3002104146,Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference,2020,0.00012149883127178721,2
W2953647525,Team QCRI-MIT at SemEval-2019 Task 4: Propaganda Analysis Meets Hyperpartisan News Detection,2019,0.00012140140792781301,2
W3103291112,Generative Data Augmentation for Commonsense Reasoning,2020,0.0001211690459406534,2
W2911966030,Improving Question Answering with External Knowledge,2019,0.00012096497401842671,2
W3102554603,TextHide: Tackling Data Privacy in Language Understanding Tasks,2020,0.00012084167405765601,2
W2972987451,Testing the Generalization Power of Neural Network Models across NLI Benchmarks,2019,0.00012075719898531254,2
W2945067664,Human vs. Muppet: A Conservative Estimate of Human Performance on the GLUE Benchmark,2019,0.00012053070065861899,2
W3039556919,Language processing in brains and deep neural networks: computational convergence and its limits,2020,0.00012046187075533896,2
W3194309076,Adapting Language Models for Zero-shot Learning by Meta-tuning on Dataset and Prompt Collections,2021,0.00012046116519516985,2
W2997012196,Latent Relation Language Models,2020,0.00012040397216281988,2
W2996899616,Relational Graph Neural Network with Hierarchical Attention for Knowledge Graph Completion,2020,0.00011999820921185227,2
W3102999298,Birds have four legs?! NumerSense: Probing Numerical Commonsense Knowledge of Pre-Trained Language Models,2020,0.00011999720349019286,2
W2963083752,Interpretable Adversarial Perturbation in Input Embedding Space for Text,2018,0.00011999258499881415,2
W2971033911,Visualizing and Understanding the Effectiveness of BERT,2019,0.00011997259300682746,2
W3101891351,Authorship Attribution for Neural Text Generation,2020,0.00011989886427616222,2
W3134665270,Pretrained Transformers for Text Ranking: BERT and Beyond,2021,0.0001194621787263318,2
W2760753016,Inter-Weighted Alignment Network for Sentence Pair Modeling,2017,0.00011941174322133566,2
W2799079975,Data-Driven Methods for Solving Algebra Word Problems,2018,0.00011925163499644276,2
W2963121782,Can You Tell Me How to Get Past Sesame Street? Sentence-Level Pretraining Beyond Language Modeling,2019,0.00011911806383007726,2
W4312516176,"Causal Inference in Natural Language Processing: Estimation, Prediction, Interpretation and Beyond",2022,0.00011874448889086113,2
W2798698226,Evaluating neural network explanation methods using hybrid documents and morphosyntactic agreement,2018,0.0001184342921923688,2
W3017024317,A^3: Accelerating Attention Mechanisms in Neural Networks with Approximation,2020,0.0001184212271317425,2
W2970886003,Self-Assembling Modular Networks for Interpretable Multi-Hop Reasoning,2019,0.00011831411849511505,2
W3145630588,Complement Lexical Retrieval Model with Semantic Residual Embeddings,2021,0.00011813450680041938,2
W3024922541,SECNLP: A survey of embeddings in clinical natural language processing,2019,0.00011809446741208908,2
W2971016963,Quantity doesn’t buy quality syntax with neural language models,2019,0.00011809328871341436,2
W4226204319,Voxelwise Encoding Models Show That Cerebellar Language Representations Are Highly Conceptual,2021,0.00011798058965353232,2
W4385574286,Can language models learn from explanations in context?,2022,0.00011785304049583586,2
W4388725043,A study of generative large language model for medical research and healthcare,2023,0.00011764950326503598,2
W3023690688,WT5?! Training Text-to-Text Models to Explain their Predictions,2020,0.00011727302164406092,2
W3213730158,"Fast, Effective, and Self-Supervised: Transforming Masked Language Models into Universal Lexical and Sentence Encoders",2021,0.000116983712012847,2
W2939380783,Repurposing Entailment for Multi-Hop Question Answering Tasks,2019,0.00011698020851045584,2
W3165327186,Does BERT Pretrained on Clinical Notes Reveal Sensitive Data?,2021,0.0001168312978796335,2
W2913352150,A question-entailment approach to question answering,2019,0.00011650207702042583,2
W2970820321,The Bottom-up Evolution of Representations in the Transformer: A Study with Machine Translation and Language Modeling Objectives,2019,0.00011649664620535602,2
W2970102799,Improving Neural Story Generation by Targeted Common Sense Grounding,2019,0.00011642763804130512,2
W3099944244,Open-Retrieval Conversational Question Answering,2020,0.00011626432638429116,2
W3104982372,A Computational Approach to Understanding Empathy Expressed in Text-Based Mental Health Support,2020,0.00011606284222757599,2
W3192478068,A Robustly Optimized BERT Pre-training Approach with Post-training,2021,0.00011602016046179392,2
W3047185145,Aligning AI With Shared Human Values,2020,0.00011589556845557885,2
W2888491130,Adversarially Regularising Neural,2018,0.00011569197912741975,2
W4249573750,CERT: Contrastive Self-supervised Learning for Language Understanding,2020,0.00011564648236940524,2
W2966584111,Incorporating Structured Commonsense Knowledge in Story Completion,2019,0.00011562593558344152,2
W3169841173,Hurdles to Progress in Long-form Question Answering,2021,0.00011550945180772695,2
W2952902402,A Tensorized Transformer for Language Modeling,2019,0.0001154795201259599,2
W2970900584,NumNet: Machine Reading Comprehension with Numerical Reasoning,2019,0.00011545334605223376,2
W3171434230,Knowledge Graph Based Synthetic Corpus Generation for Knowledge-Enhanced Language Model Pre-training,2021,0.00011544521134836632,2
W3091973425,NoRBERT: Transfer Learning for Requirements Classification,2020,0.00011525422199402295,2
W2890560945,A State-transition Framework to Answer Complex Questions over Knowledge Base,2018,0.00011522550301145903,2
W2963838657,Learning to Rank Question-Answer Pairs Using Hierarchical Recurrent Encoder with Latent Topic Clustering,2018,0.00011521916490004723,2
W3037273551,The neural architecture of language: Integrative modeling converges on predictive processing,2020,0.0001151871939708074,2
W2774918944,Active Learning for Convolutional Neural Networks: A Core-Set Approach,2017,0.00011515797922782212,2
W4295857769,Pre-Trained Language Models and Their Applications,2022,0.00011505701266069012,2
W2997545008,Commonsense Knowledge Base Completion with Structural and Semantic Context,2020,0.00011500138379924842,2
W3129758539,Learning Knowledge Graph Embedding With Heterogeneous Relation Attention Networks,2021,0.00011486365743486313,2
W3204112174,LexGLUE: A Benchmark Dataset for Legal Language Understanding in English,2022,0.00011468301222711251,2
W3101950626,Semantic Structure and Interpretability of Word Embeddings,2018,0.00011461469803382409,2
W3100385063,Linguistic generalization and compositionality in modern artificial neural networks,2019,0.0001139262017553607,2
W2970742161,A Multi-Type Multi-Span Network for Reading Comprehension that Requires Discrete Reasoning,2019,0.00011373430395304239,2
W3207095490,PAQ: 65 Million Probably-Asked Questions and What You Can Do With Them,2021,0.00011367168055009013,2
W2995923603,StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding,2019,0.00011358749259613281,2
W4283172211,What Does it Mean for a Language Model to Preserve Privacy?,2022,0.00011350720090918803,2
W4205450747,Can Language Models be Biomedical Knowledge Bases?,2021,0.00011339339059286817,2
W3213241618,Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus,2021,0.00011338294402183438,2
W3095645723,Scaling Laws for Autoregressive Generative Modeling,2020,0.00011332532493589245,2
W2799187742,A Co-Matching Model for Multi-choice Reading Comprehension,2018,0.00011285850673741356,2
W3015609966,DynaBERT: Dynamic BERT with Adaptive Width and Depth,2020,0.00011271140242440498,2
W3156836409,Zero-shot Neural Passage Retrieval via Domain-targeted Synthetic Question Generation,2021,0.00011253591589271397,2
W4385573970,Large Dual Encoders Are Generalizable Retrievers,2022,0.00011251386546534349,2
W2907822478,Coarse-grain Fine-grain Coattention Network for Multi-evidence Question Answering,2019,0.00011218869533190522,2
W3206644354,Do travelers' reviews depend on the destination? An analysis in coastal and urban peer‐to‐peer lodgings,2021,0.00011207633454253589,2
W4245255589,Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP,2019,0.00011181149753922793,2
W3115037692,Question Rewriting for Conversational Question Answering,2021,0.00011179441655168467,2
W3159959439,<i>Did Aristotle Use a Laptop?</i>A Question Answering Benchmark with Implicit Reasoning Strategies,2021,0.00011174340846041595,2
W4391855109,"A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges",2024,0.00011166762998266723,2
W3083410900,Measuring Massive Multitask Language Understanding,2020,0.00011144499998180926,2
W2902516827,Clinical text classification with rule-based features and knowledge-guided convolutional neural networks,2019,0.00011133210494545155,2
W3033406728,DeCLUTR: Deep Contrastive Learning for Unsupervised Textual Representations,2020,0.00011099352341643026,2
W3202088367,FedNLP: Benchmarking Federated Learning Methods for Natural Language Processing Tasks,2022,0.00011097660572122978,2
W3175606037,UnNatural Language Inference,2021,0.00011078791472389786,2
W4205460703,Transformer Feed-Forward Layers Are Key-Value Memories,2021,0.00011072533735980389,2
W3174702398,Parameter-Efficient Transfer Learning with Diff Pruning,2021,0.00011062033471356495,2
W3156366114,Beyond I.I.D.: Three Levels of Generalization for Question Answering on Knowledge Bases,2021,0.0001101186114405813,2
W3110414860,CAiRE-COVID: A Question Answering and Query-focused Multi-Document Summarization System for COVID-19 Scholarly Information Management,2020,0.00010997298457259997,2
W3204619801,BadNL: Backdoor Attacks against NLP Models with Semantic-preserving Improvements,2021,0.00010968369998728068,2
W3102803571,Improving Neural Topic Models using Knowledge Distillation,2020,0.00010944609761261588,2
W3176640961,COVID-Fact: Fact Extraction and Verification of Real-World Claims on COVID-19 Pandemic,2021,0.00010912998915188272,2
W2889317091,Reasoning about Actions and State Changes by Injecting Commonsense Knowledge,2018,0.00010903853731574372,2
W2913222130,Generative Question Answering: Learning to Answer the Whole Question.,2018,0.00010899603705014442,2
W2970678056,Investigating Meta-Learning Algorithms for Low-Resource Natural Language Understanding Tasks,2019,0.00010898297945249701,2
W2962927633,The Gap of Semantic Parsing: A Survey on Automatic Math Word Problem Solvers,2019,0.00010878804259829637,2
W3176270593,Hidden Killer: Invisible Textual Backdoor Attacks with Syntactic Trigger,2021,0.00010868506732089297,2
W2963077723,DR-BiLSTM: Dependent Reading Bidirectional LSTM for Natural Language Inference,2018,0.00010856012015548851,2
W2789078277,Hierarchical Attention Flow for Multiple-Choice Reading Comprehension,2018,0.00010855536301163939,2
W4393161188,Interpretable Long-Form Legal Question Answering with Retrieval-Augmented Large Language Models,2024,0.00010847101101086327,2
W3209409148,MentalBERT: Publicly Available Pretrained Language Models for Mental Healthcare,2021,0.00010842166821513009,2
W3207553988,Generated Knowledge Prompting for Commonsense Reasoning,2022,0.00010809907744831817,2
W4385456320,Pre-trained Language Models in Biomedical Domain: A Systematic Survey,2023,0.00010795138526472169,2
W3163832451,The NLP Cookbook: Modern Recipes for Transformer Based Deep Learning Architectures,2021,0.00010788876251601061,2
W3036699898,Lack of selectivity for syntax relative to word meanings throughout the language network,2020,0.0001074034004073177,2
W3175962280,Word Embedding-Based Topic Similarity Measures,2021,0.00010734386752792483,2
W2997050424,ICD Coding from Clinical Text Using Multi-Filter Residual Convolutional Neural Network,2020,0.0001070128891974399,2
W3017344694,BERT for Evidence Retrieval and Claim Verification,2020,0.00010694613546046193,2
W3172427031,UmlsBERT: Clinical Domain Knowledge Augmentation of Contextual Embeddings Using the Unified Medical Language System Metathesaurus,2021,0.00010659057300220472,2
W2963102202,EARL: Joint Entity and Relation Linking for Question Answering over Knowledge Graphs,2018,0.00010648833918986637,2
W4206121183,Condenser: a Pre-training Architecture for Dense Retrieval,2021,0.00010627257519892854,2
W2997937415,SPARQA: Skeleton-Based Semantic Parsing for Complex Questions over Knowledge Bases,2020,0.00010606451634434091,2
W3048179169,Clinical concept extraction: A methodology review,2020,0.00010605451876557218,2
W4287111051,Time-Aware Language Models as Temporal Knowledge Bases,2022,0.00010600808332087119,2
W4388144297,LLMs4OL: Large Language Models for Ontology Learning,2023,0.00010594159770847047,2
W3174544005,MiniLMv2: Multi-Head Self-Attention Relation Distillation for Compressing Pretrained Transformers,2021,0.00010593700388802059,2
W3116847845,Improving Multi-hop Knowledge Base Question Answering by Learning Intermediate Supervision Signals,2021,0.00010569757648958797,2
W2950031296,Sentence-Level Evidence Embedding for Claim Verification with Hierarchical Attention Networks,2019,0.00010564415865076487,2
W2914855263,Strategies for Structuring Story Generation,2019,0.00010547700081720445,2
W2970103342,Applying BERT to Document Retrieval with Birch,2019,0.00010542416138167324,2
W2966491090,Trick Me If You Can: Human-in-the-Loop Generation of Adversarial Examples for Question Answering,2019,0.00010526190003211976,2
W2951674308,Adversarially Regularising Neural NLI Models to Integrate Logical Background Knowledge,2018,0.00010516500660075166,2
W3170180819,Get Your Vitamin C! Robust Fact Verification with Contrastive Evidence,2021,0.00010503774617371466,2
W2997514453,Artificial intelligence approaches using natural language processing to advance EHR-based clinical research,2019,0.00010492624455896304,2
W4385570088,Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models,2023,0.00010481318579475886,2
W3168921237,Self-training Improves Pre-training for Natural Language Understanding,2021,0.00010476920694007822,2
W3147509388,"The CLEF-2021 CheckThat! Lab on Detecting Check-Worthy Claims, Previously Fact-Checked Claims, and Fake News",2021,0.00010457652907858033,2
W4389523706,Large Language Models Can Self-Improve,2023,0.0001045450820457157,2
W3186492090,When does pretraining help?,2021,0.00010452232976892266,2
W3017374003,Compositionality Decomposed: How do Neural Networks Generalise?,2020,0.00010448921427081315,2
W3102561203,Building Legal Case Retrieval Systems with Lexical Matching and Summarization using A Pre-Trained Phrase Scoring Model,2019,0.00010447294155328677,2
W2963157366,Entity-Duet Neural Ranking: Understanding the Role of Knowledge Graph Semantics in Neural Information Retrieval,2018,0.00010411555163996354,2
W3034608141,Zero-shot Text Classification via Reinforced Self-training,2020,0.00010387245665479239,2
W2949845972,Robust Representation Learning of Biomedical Names,2019,0.00010385855356763095,2
W3159727696,SpAtten: Efficient Sparse Attention Architecture with Cascade Token and Head Pruning,2021,0.00010383442286018008,2
W2900069888,Extraction of Information Related to Adverse Drug Events from Electronic Health Record Notes: Design of an End-to-End Model Based on Deep Learning,2018,0.00010382055738355117,2
W3105817677,Efficient Document Re-Ranking for Transformers by Precomputing Term Representations,2020,0.0001037190572312565,2
W2952230306,FlowQA: Grasping Flow in History for Conversational Machine Comprehension,2018,0.00010364507327305164,2
W2968908603,"Align, Mask and Select: A Simple Method for Incorporating Commonsense Knowledge into Language Representation Models",2019,0.00010325545307794623,2
W3114537677,Universal Sentence Representation Learning with Conditional Masked Language Model,2021,0.00010291193625465475,2
W3103667349,Understanding tables with intermediate pre-training,2020,0.00010289018659091018,2
W3103754749,"When BERT Plays the Lottery, All Tickets Are Winning",2020,0.0001028845968949705,2
W4365511667,Fine-tuning large neural language models for biomedical natural language processing,2023,0.00010246325483212587,2
W4385430086,Emergent analogical reasoning in large language models,2023,0.00010243451146926632,2
W3205717164,SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer,2022,0.00010242675040265578,2
W2586597293,Neural Discourse Structure for Text Categorization,2017,0.00010239672299013708,2
W3132259035,Limitations of Transformers on Clinical Text Classification,2021,0.00010229109543283946,2
W3100452485,Learning from Task Descriptions,2020,0.00010228279332220274,2
W4224866872,The Moral Integrity Corpus: A Benchmark for Ethical Dialogue Systems,2022,0.0001020677490734147,2
W3163457243,Developing a BERT based triple classification model using knowledge graph embedding for question answering system,2021,0.00010183576664099441,2
W2984256198,Unlearn Dataset Bias in Natural Language Inference by Fitting the Residual,2019,0.00010174193343791523,2
W3152740956,Case-based Reasoning for Natural Language Queries over Knowledge Bases,2021,0.00010158859999011378,2
W3196790170,ESimCSE: Enhanced Sample Building Method for Contrastive Learning of Unsupervised Sentence Embedding,2021,0.00010150602483978932,2
W3064953855,PARADE: Passage Representation Aggregation forDocument Reranking,2023,0.0001014802480897711,2
W2973047874,Blackbox Meets Blackbox: Representational Similarity &amp; Stability Analysis of Neural Language Models and Brains,2019,0.00010127239073238353,2
W3113529090,Learning to Few-Shot Learn Across Diverse Natural Language Classification Tasks,2020,0.00010120172480563529,2
W3202546170,Sorting through the noise: Testing robustness of information processing in pre-trained language models,2021,0.00010092948458629796,2
W2932637973,Unsupervised Recurrent Neural Network Grammars,2019,0.00010023264778753863,2
W2971871542,NEZHA: Neural Contextualized Representation for Chinese Language Understanding,2019,0.0001002163108521239,2
W3103616906,Exploring Versatile Generative Language Model Via Parameter-Efficient Transfer Learning,2020,0.00010018624393996994,2
W2970449623,Achieving Verified Robustness to Symbol Substitutions via Interval Bound Propagation,2019,0.0001001524464231042,2
W2932592714,Probing Biomedical Embeddings from Language Models,2019,0.0001000266965414606,2
W3166508187,BioELECTRA:Pretrained Biomedical text Encoder using Discriminators,2021,9.999764091533927e-05,2
W3176750236,KG-BART: Knowledge Graph-Augmented BART for Generative Commonsense Reasoning,2021,9.985129359334579e-05,2
W3104216863,Structured Pruning of Large Language Models,2020,9.973263701230906e-05,2
W2967056613,Use of Natural Language Processing to Extract Clinical Cancer Phenotypes from Electronic Medical Records,2019,9.964662990870228e-05,2
W2619818172,Jointly learning sentence embeddings and syntax with unsupervised Tree-LSTMs,2019,9.958584346710197e-05,2
W3103368673,What Happens To BERT Embeddings During Fine-tuning?,2020,9.951349774973067e-05,2
W2984147501,Investigating Entity Knowledge in BERT with Simple Neural End-To-End Entity Linking,2019,9.939364117105333e-05,2
W2995628494,Neural Symbolic Reader: Scalable Integration of Distributed and Symbolic Representations for Reading Comprehension,2020,9.928686334916688e-05,2
W3101682885,HoVer: A Dataset for Many-Hop Fact Extraction And Claim Verification,2020,9.921762577379889e-05,2
W2951036431,Multi-task Learning with Sample Re-weighting for Machine Reading Comprehension,2019,9.916295862990828e-05,2
W2954447110,Team yeon-zi at SemEval-2019 Task 4: Hyperpartisan News Detection by De-noising Weakly-labeled Data,2019,9.911550608851155e-05,2
W3118999024,Retrieving and Reading: A Comprehensive Survey on Open-domain Question Answering,2021,9.899167349575896e-05,2
W2806198715,SemEval 2018 Task 2: Multilingual Emoji Prediction,2018,9.892627443706161e-05,2
W3023528699,AdapterFusion: Non-Destructive Task Composition for Transfer Learning,2020,9.877515129086467e-05,2
W3093150592,Drug repurposing for COVID-19 via knowledge graph completion,2021,9.874320989578467e-05,2
W2760057941,Multi-task Attention-based Neural Networks for Implicit Discourse Relationship Representation and Identification,2017,9.8696238823446e-05,2
W3190271517,"A Survey on Complex Knowledge Base Question Answering: Methods, Challenges and Solutions",2021,9.86234763822312e-05,2
W3100124407,Universal Natural Language Processing with Limited Annotations: Try Few-shot Textual Entailment as a Start,2020,9.85508500819017e-05,2
W2975185270,Mixout: Effective Regularization to Finetune Large-scale Pretrained Language Models,2019,9.850290183039224e-05,2
W2953044594,Explicit Utilization of General Knowledge in Machine Reading Comprehension,2019,9.837215375176791e-05,2
W2515860461,Metaphor as a Medium for Emotion: An Empirical Study,2016,9.82574316741818e-05,2
W3209749143,FacTeR-Check: Semi-automated fact-checking through semantic similarity and natural language inference,2022,9.82145463168109e-05,2
W2987669390,Towards Generalizable Neuro-Symbolic Systems for Commonsense Question Answering,2019,9.817800203462606e-05,2
W2988245244,A Richly Annotated Corpus for Different Tasks in Automated Fact-Checking,2019,9.813246737684216e-05,2
W2967690619,BERT-based Ranking for Biomedical Entity Normalization,2019,9.799178100489188e-05,2
W2982295985,Adversarial NLI: A New Benchmark for Natural Language Understanding,2019,9.796832220647725e-05,2
W2980649541,ClaimsKG: A Knowledge Graph of Fact-Checked Claims,2019,9.743108900106143e-05,2
W3099617520,SSMBA: Self-Supervised Manifold Based Data Augmentation for Improving Out-of-Domain Robustness,2020,9.729986302993558e-05,2
W3173561451,Biomedical and clinical English model packages for the Stanza Python NLP library,2021,9.711370419923757e-05,2
W3174169056,Out of Order: How important is the sequential order of words in a sentence in Natural Language Understanding tasks?,2021,9.708604428681673e-05,2
W3015777882,Deep Learning Based Text Classification: A Comprehensive Review,2020,9.672116866178077e-05,2
W4386187806,"GPT understands, too",2023,9.661652941932237e-05,2
W2953039212,Are Red Roses Red? Evaluating Consistency of Question-Answering Models,2019,9.640772476461639e-05,2
W2964302308,Subword-augmented Embedding for Cloze Reading Comprehension.,2018,9.6327819435565e-05,2
W2913946806,Parameter-Efficient Transfer Learning for NLP,2019,9.627077727545453e-05,2
W3035275890,INFOTABS: Inference on Tables as Semi-structured Data,2020,9.603915555520411e-05,2
W2984354699,Zero-shot Entity Linking with Dense Entity Retrieval.,2019,9.599514784185663e-05,2
W3194676777,WinoGrande,2021,9.591216278241023e-05,2
W3200253633,Not All Negatives are Equal: Label-Aware Contrastive Loss for Fine-grained Text Classification,2021,9.587199206988003e-05,2
W4226510082,Human Language Understanding &amp; Reasoning,2022,9.577263098000962e-05,2
W3135190223,CUAD: An Expert-Annotated NLP Dataset for Legal Contract Review,2021,9.567606323023855e-05,2
W2576754561,Self-Taught convolutional neural networks for short text clustering,2017,9.553127054661714e-05,2
W2610536450,Adversarial Connective-exploiting Networks for Implicit Discourse Relation Classification,2017,9.54310769779066e-05,2
W3098324846,A Simple and Effective Model for Answering Multi-span Questions,2020,9.536263315393752e-05,2
W2995446988,On Identifiability in Transformers,2020,9.523307118387268e-05,2
W2963505471,Team Fernando-Pessa at SemEval-2019 Task 4: Back to Basics in Hyperpartisan News Detection,2019,9.520119269269128e-05,2
W3105662186,Beat the AI: Investigating Adversarial Human Annotation for Reading Comprehension,2020,9.516114151729138e-05,2
W3198507920,FewshotQA: A simple framework for few-shot learning of question answering tasks using pre-trained text-to-text models,2021,9.516026492166653e-05,2
W3012590175,ASER: A Large-scale Eventuality Knowledge Graph,2020,9.513065928881152e-05,2
W3116459227,Few-Shot Text Generation with Pattern-Exploiting Training,2020,9.510451439300557e-05,2
W3101345273,Cold-start Active Learning through Self-supervised Language Modeling,2020,9.505452832963558e-05,2
W3212893438,Few-Shot Text Generation with Natural Language Instructions,2021,9.496649931012891e-05,2
W3005237274,Multiple features for clinical relation extraction: A machine learning approach,2020,9.474896092888937e-05,2
W3035628711,NILE : Natural Language Inference with Faithful Natural Language Explanations,2020,9.454256803210329e-05,2
W2951365061,DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs,2019,9.448899402944699e-05,2
W3105698638,ReQA: An Evaluation for End-to-End Answer Retrieval Models,2019,9.448331806338521e-05,2
W4385571011,Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes,2023,9.443135250861991e-05,2
W2963106052,Multi-Task Learning for Argumentation Mining in Low-Resource Settings,2018,9.440193375759671e-05,2
W2964181805,Joint Training of Candidate Extraction and Answer Selection for Reading Comprehension,2018,9.433184036126868e-05,2
W3212191244,Measuring Association Between Labels and Free-Text Rationales,2021,9.427494961620312e-05,2
W3034602344,Temporal Common Sense Acquisition with Minimal Supervision,2020,9.386889185470515e-05,2
W4360611202,A review and comparative study of cancer detection using machine learning: SBERT and SimCSE application,2023,9.367168118260768e-05,2
W2963967365,Phrase-Indexed Question Answering: A New Challenge for Scalable Document Comprehension,2018,9.366304274439144e-05,2
W2949858875,"Errudite: Scalable, Reproducible, and Testable Error Analysis",2019,9.358305918302454e-05,2
W3176108833,CLINE: Contrastive Learning with Semantic Negative Examples for Natural Language Understanding,2021,9.319754786793869e-05,2
W2804439688,Moon IME: Neural-based Chinese Pinyin Aided Input Method with Customizable Association,2018,9.316957913029358e-05,2
W3188983256,Unsupervised Corpus Aware Language Model Pre-training for Dense Passage Retrieval,2022,9.28625406115279e-05,2
W3035599593,Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition,2020,9.28408800041032e-05,2
W2953307569,BERT Rediscovers the Classical NLP Pipeline.,2019,9.277590447864724e-05,2
W3098467034,What Can We Learn from Collective Human Opinions on Natural Language Inference Data?,2020,9.240135883753317e-05,2
W2995998574,Mixout: Effective Regularization to Finetune Large-scale Pretrained Language Models,2019,9.217353561151002e-05,2
W4389520259,"HuatuoGPT, Towards Taming Language Model to Be a Doctor",2023,9.216583336603424e-05,2
W2995925258,You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings,2020,9.214857992376752e-05,2
W4385569771,Reasoning with Language Model Prompting: A Survey,2023,9.191876364881424e-05,2
W3146844750,"Language Models as Knowledge Bases: On Entity Representations, Storage Capacity, and Paraphrased Queries",2021,9.188224506109384e-05,2
W4385569882,Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework,2023,9.17231144586461e-05,2
W3024131638,Enabling Language Models to Fill in the Blanks,2020,9.165964962627626e-05,2
W4385573636,Impact of Pretraining Term Frequencies on Few-Shot Numerical Reasoning,2022,9.163376592591595e-05,2
W3154773080,GPT-2’s activations predict the degree of semantic comprehension in the human brain,2021,9.152150730195159e-05,2
W4385571411,Is GPT-3 a Good Data Annotator?,2023,9.150033214749727e-05,2
W2958089299,A Survey on Explainable Artificial Intelligence (XAI): Toward Medical XAI,2020,9.140381347748498e-05,2
W3138392969,Are NLP Models really able to Solve Simple Math Word Problems,2021,9.135311458348936e-05,2
W2949847757,"Retrieve, Read, Rerank: Towards End-to-End Multi-Document Reading Comprehension",2019,9.124485318362319e-05,2
W3015982254,Structured Pruning of a BERT-based Question Answering Model,2019,9.124079620331033e-05,2
W3214715529,AdapterDrop: On the Efficiency of Adapters in Transformers,2021,9.116835844398081e-05,2
W2988787701,Team DOMLIN: Exploiting Evidence Enhancement for the FEVER Shared Task,2019,9.114664236688429e-05,2
W4206648492,Active Learning by Acquiring Contrastive Examples,2021,9.099667513708958e-05,2
W2997710335,Compressing BERT: Studying the Effects of Weight Pruning on Transfer Learning,2020,9.098746797351786e-05,2
W2970863760,AllenNLP Interpret: A Framework for Explaining Predictions of NLP Models,2019,9.09853480082292e-05,2
W3045958725,MKQA: A Linguistically Diverse Benchmark for Multilingual Open Domain Question Answering,2021,9.078836477255319e-05,2
W4220967417,AMMU: A survey of transformer-based biomedical pretrained language models,2021,9.068197912798416e-05,2
W2963249435,AdvEntuRe: Adversarial Training for Textual Entailment with Knowledge-Guided Examples,2018,9.046286435840359e-05,2
W2981757109,Depth-Adaptive Transformer,2019,9.045693895466677e-05,2
W3113170987,Communicative Message Passing for Inductive Relation Reasoning,2021,9.042038672599127e-05,2
W2982054702,Learning to Discriminate Perturbations for Blocking Adversarial Attacks in Text Classification,2019,9.02564692667431e-05,2
W4391221150,Almanac — Retrieval-Augmented Language Models for Clinical Medicine,2024,9.019538672184004e-05,2
W4385573325,ZeroGen: Efficient Zero-shot Learning via Dataset Generation,2022,9.001888502933959e-05,2
W3157700644,Adaptive Semiparametric Language Models,2021,8.992960140228133e-05,2
W3034906811,Uncertain Natural Language Inference,2020,8.98367899017348e-05,2
W3124424060,Open Question Answering over Tables and Text,2021,8.981000765478828e-05,2
W4385572953,UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models,2022,8.976224128757785e-05,2
W3171654528,Dynabench: Rethinking Benchmarking in NLP,2021,8.972841976772357e-05,2
W3085177480,It's Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners,2020,8.958830152948112e-05,2
W3108936148,Answering Questions on COVID-19 in Real-Time,2020,8.954419447282277e-05,2
W3035317046,tBERT: Topic Models and BERT Joining Forces for Semantic Similarity Detection,2020,8.926190432494643e-05,2
W2890719433,Adversarial Over-Sensitivity and Over-Stability Strategies for Dialogue Models,2018,8.911939605710852e-05,2
W3201090304,Towards Zero-Label Language Learning,2021,8.900860685624603e-05,2
W3037458976,Contextual and Non-Contextual Word Embeddings: an in-depth Linguistic Investigation,2020,8.900663994111896e-05,2
W4256093969,IndoNLI: A Natural Language Inference Dataset for Indonesian,2021,8.895029688894626e-05,2
W2946809241,A Crowdsourced Corpus of Multiple Judgments and Disagreement on Anaphoric Interpretation,2019,8.894554502877111e-05,2
W3144194608,CausaLM: Causal Model Explanation Through Counterfactual Language Models,2021,8.892250965267919e-05,2
W3190730109,"An introduction to Deep Learning in Natural Language Processing: Models, techniques, and tools",2021,8.890733291529015e-05,2
W4385570481,"RARR: Researching and Revising What Language Models Say, Using Language Models",2023,8.883319482986167e-05,2
W2973123473,A Discrete Hard EM Approach for Weakly Supervised Question Answering,2019,8.842659280255323e-05,2
W4385571260,Teaching Small Language Models to Reason,2023,8.839887751832725e-05,2
W3174821868,End-to-End Training of Neural Retrievers for Open-Domain Question Answering,2021,8.83604342286254e-05,2
W2963997607,Variational Pretraining for Semi-supervised Text Classification,2019,8.818287092596159e-05,2
W3207429447,Large Language Models Can Be Strong Differentially Private Learners,2021,8.812820887211609e-05,2
W4385571219,Large Language Models Are Reasoning Teachers,2023,8.79248972441951e-05,2
W4205758343,Towards Improving Adversarial Training of NLP Models,2021,8.788100630499804e-05,2
W3034457116,LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning,2020,8.782887669329667e-05,2
W3035407756,Contextual Embeddings: When Are They Worth It?,2020,8.770021621124589e-05,2
W4385894687,Red Teaming Language Models with Language Models,2022,8.76121934467013e-05,2
W3157876196,Biomedical named entity recognition using BERT in the machine reading comprehension framework,2021,8.754762932940981e-05,2
W2985173696,EHR Coding with Multi-scale Feature Attention and Structured Knowledge Graph Propagation,2019,8.733938924261339e-05,2
W2998901379,Learning Cross-Context Entity Representations from Text,2020,8.726183676167566e-05,2
W3038046627,BadNL: Backdoor Attacks Against NLP Models,2020,8.717563198820635e-05,2
W3035441651,Selective Question Answering under Domain Shift,2020,8.704025682200773e-05,2
W2810519866,One-shot Learning for Question-Answering in Gaokao History Challenge,2018,8.69859949718416e-05,2
W3152858897,Toward Automated Factchecking,2021,8.697649571676869e-05,2
W3106092787,An Empirical Study on Large-Scale Multi-Label Text Classification Including Few and Zero-Shot Labels,2020,8.693431258077263e-05,2
W3170101424,Fine-tuning Encoders for Improved Monolingual and Zero-shot Polylingual Neural Topic Modeling,2021,8.692958767164509e-05,2
W2995359496,Deep Learning for Symbolic Mathematics,2019,8.691166932864177e-05,2
W3187018546,CPM: A large-scale generative Chinese Pre-trained language model,2021,8.686778596685823e-05,2
W3100985894,GOBO: Quantizing Attention-Based NLP Models for Low Latency and Energy Efficient Inference,2020,8.68610026926077e-05,2
W4389519585,Sources of Hallucination by Large Language Models on Inference Tasks,2023,8.68577032643981e-05,2
W3157374291,Entailment as Few-Shot Learner,2021,8.68216550815331e-05,2
W2512531235,Deep Fusion LSTMs for Text Semantic Matching,2016,8.64002941289144e-05,2
W3214637114,The Future is not One-dimensional: Complex Event Schema Induction by Graph Modeling for Event Prediction,2021,8.639641873757884e-05,2
W3034918576,TransOMCS: From Linguistic Graphs to Commonsense Knowledge,2020,8.636834340878466e-05,2
W2966176804,Still a Pain in the Neck: Evaluating Text Representations on Lexical Composition,2019,8.634733872095079e-05,2
W3195893957,Prompt-learning for Fine-grained Entity Typing,2022,8.632648388117212e-05,2
W4385570984,Unnatural Instructions: Tuning Language Models with (Almost) No Human Labor,2023,8.628040337492383e-05,2
W2983309655,Evaluating Question Answering Evaluation,2019,8.620436477786972e-05,2
W3108978252,A hierarchy of linguistic predictions during natural language comprehension,2020,8.604852519280263e-05,2
W2917049430,Transformer-Based Neural Network for Answer Selection in Question Answering,2019,8.599405480867275e-05,2
W2989033444,A Hybrid Neural Network Model for Commonsense Reasoning,2019,8.598630183353764e-05,2
W2948036864,Explain Yourself! Leveraging Language Models for Commonsense Reasoning,2019,8.595665369993976e-05,2
W3099180151,How Decoding Strategies Affect the Verifiability of Generated Text,2020,8.594366856176597e-05,2
W3105801792,COMETA: A Corpus for Medical Entity Linking in the Social Media,2020,8.58396309018227e-05,2
W4224315235,Topic Discovery via Latent Space Clustering of Pretrained Language Model Representations,2022,8.581177587866535e-05,2
W2991382858,How Can We Know What Language Models Know,2019,8.54601395530769e-05,2
W3098576111,TernaryBERT: Distillation-aware Ultra-low Bit BERT,2020,8.528570124020903e-05,2
W3099381148,Attentive History Selection for Conversational Question Answering,2019,8.514253277133518e-05,2
W4385566950,Named Entity Recognition in Indian court judgments,2022,8.509657053112718e-05,2
W3083500347,Accenture at CheckThat! 2020: If you say so: Post-hoc fact-checking of claims using transformer-based models,2020,8.484583351399845e-05,2
W3201915713,Data augmentation approaches in natural language processing: A survey,2022,8.479115333253163e-05,2
W3037063616,An Empirical Study of Multi-Task Learning on BERT for Biomedical Text Mining,2020,8.478679942783088e-05,2
W3174057701,"Polyjuice: Generating Counterfactuals for Explaining, Evaluating, and Improving Models",2021,8.478104166730052e-05,2
W3154903254,BERTese: Learning to Speak to BERT,2021,8.472279517668736e-05,2
W2955202831,Knowledge Base Question Answering With a Matching-Aggregation Model and Question-Specific Contextual Relations,2019,8.469633026140911e-05,2
W2892197424,Dialog-to-action: conversational question answering over a large-scale knowledge base,2018,8.458706509115711e-05,2
W4285172793,Sequence-to-Sequence Knowledge Graph Completion and Question Answering,2022,8.447424994333658e-05,2
W3101850416,Connecting the Dots: A Knowledgeable Path Generator for Commonsense Question Answering,2020,8.424252047003197e-05,2
W2518510348,Which argument is more convincing? Analyzing and predicting convincingness of Web arguments using bidirectional LSTM,2016,8.422792356682463e-05,2
W3203309275,Compressing Large-Scale Transformer-Based Models: A Case Study on BERT,2021,8.417710981190172e-05,2
W3192405822,Noisy Channel Language Model Prompting for Few-Shot Text Classification,2022,8.415632421147731e-05,2
W2950576363,Careful Selection of Knowledge to Solve Open Book Question Answering,2019,8.414922609491301e-05,2
W2970927596,Specializing Word Embeddings (for Parsing) by Information Bottleneck,2019,8.413923148054703e-05,2
W3034649382,Make Up Your Mind! Adversarial Generation of Inconsistent Natural Language Explanations,2020,8.410367334081127e-05,2
W2996251235,Neural Module Networks for Reasoning over Text,2019,8.408235762826111e-05,2
W3173520982,Overview of BioASQ 2020: The Eighth BioASQ Challenge on Large-Scale Biomedical Semantic Indexing and Question Answering,2020,8.40779966003688e-05,2
W3171953676,Human Sentence Processing: Recurrence or Attention?,2021,8.402822753414428e-05,2
W3098613713,Learning Which Features Matter: RoBERTa Acquires a Preference for Linguistic Generalizations (Eventually),2020,8.392667853055994e-05,2
W3139815689,"Feature-based detection of automated language models: tackling GPT-2, GPT-3 and Grover",2021,8.386194220341601e-05,2
W2808308446,Multiway Attention Networks for Modeling Sentence Pairs,2018,8.378823552889121e-05,2
W2970453125,Counterfactual Story Reasoning and Generation,2019,8.371857715741881e-05,2
W2947497897,Latent Retrieval for Weakly Supervised Open Domain Question Answering,2019,8.362073533424693e-05,2
W2998072062,Assessing the Benchmarking Capacity of Machine Reading Comprehension Datasets,2020,8.352837113361056e-05,2
W2974273066,Does BERT Make Any Sense? Interpretable Word Sense Disambiguation with Contextualized Embeddings,2019,8.344890374554698e-05,2
W2977162702,Attention Interpretability Across NLP Tasks.,2019,8.343182556242506e-05,2
W4327656064,An Empirical Survey of Data Augmentation for Limited Data Learning in NLP,2023,8.342495867673308e-05,2
W4385573057,Improving Passage Retrieval with Zero-Shot Question Generation,2022,8.338161580313581e-05,2
W2970960342,Neural Arabic Question Answering,2019,8.337212210993966e-05,2
W3187071356,Improved Text Classification via Contrastive Adversarial Training,2022,8.33339210417354e-05,2
W2948140294,Is Attention Interpretable,2019,8.328117002467429e-05,2
W3080429061,Medical Information Extraction in the Age of Deep Learning,2020,8.325377877130444e-05,2
W3098323839,GLUCOSE: GeneraLized and COntextualized Story Explanations,2020,8.321312182907503e-05,2
W4392935324,Dissociating language and thought in large language models,2024,8.316071410659788e-05,2
W2970764230,Movie Plot Analysis via Turning Point Identification,2019,8.315434380126221e-05,2
W2926937441,Ranking and Selecting Multi-Hop Knowledge Paths to Better Predict Human Needs,2019,8.313988065979253e-05,2
W2963947304,Learning short-text semantic similarity with word embeddings and external knowledge sources,2019,8.313620982889906e-05,2
W2798139452,Adversarial Example Generation with Syntactically Controlled Paraphrase Networks,2018,8.309159960191522e-05,2
W3196642073,Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners,2021,8.306477032893979e-05,2
W2964044490,Don’t Take the Premise for Granted: Mitigating Artifacts in Natural Language Inference,2019,8.302230189154925e-05,2
W3103873238,More Bang for Your Buck: Natural Perturbation for Robust Question Answering,2020,8.29647048082641e-05,2
W3035139434,End-to-End Bias Mitigation by Modelling Biases in Corpora,2020,8.296049734135723e-05,2
W3107969673,Modifying Memories in Transformer Models,2020,8.295499116829466e-05,2
W2949884065,ChID: A Large-scale Chinese IDiom Dataset for Cloze Test,2019,8.29107530082577e-05,2
W4297995647,Deep language algorithms predict semantic comprehension from brain activity,2022,8.288662950387335e-05,2
W3119145505,Medical concept normalization in French using multilingual terminologies and contextual embeddings,2021,8.285516686467639e-05,2
W3173813266,Explaining NLP Models via Minimal Contrastive Editing (MiCE),2021,8.28214845869195e-05,2
W3015770160,Explaining Question Answering Models through Text Generation,2020,8.280610308245177e-05,2
W3090721331,SparTerm: Learning Term-based Sparse Representation for Fast Text Retrieval,2020,8.259817450990441e-05,2
W3101007570,Training Question Answering Models From Synthetic Data,2020,8.254034493105134e-05,2
W2970530230,Evaluating adversarial attacks against multiple fact verification systems,2019,8.251452227028532e-05,2
W2947469743,On the Robustness of Self-Attentive Models,2019,8.249113323654332e-05,2
W2995636882,Differentiable Reasoning over a Virtual Knowledge Base,2020,8.243156851633648e-05,2
W3099403624,Self-Supervised Meta-Learning for Few-Shot Natural Language Classification Tasks,2020,8.23761627769949e-05,2
W4318983406,Building a knowledge graph to enable precision medicine,2023,8.235681642446923e-05,2
W3167292670,Relational Message Passing for Knowledge Graph Completion,2021,8.228796742755699e-05,2
W2977944219,On Identifiability in Transformers,2019,8.228673406812018e-05,2
W3017022649,Training with Quantization Noise for Extreme Model Compression,2020,8.227802228392915e-05,2
W2997738974,Few-Shot Knowledge Graph Completion,2020,8.227055774401463e-05,2
W4280604898,Machine Learning-Friendly Biomedical Datasets for Equivalence and Subsumption Ontology Matching,2022,8.2198573936774e-05,2
W3158631574,PanGu-$α$: Large-scale Autoregressive Pretrained Chinese Language Models with Auto-parallel Computation,2021,8.218163171431065e-05,2
W3203937348,The “Narratives” fMRI dataset for evaluating models of naturalistic language comprehension,2021,8.210568563701819e-05,2
W3162296828,KLUE: Korean Language Understanding Evaluation,2021,8.205579006369024e-05,2
W4390490761,Explainability for Large Language Models: A Survey,2024,8.203328493216036e-05,2
W2991265431,Do Attention Heads in BERT Track Syntactic Dependencies?,2019,8.196188997544367e-05,2
W3095992020,An Empirical Study on Robustness to Spurious Correlations using Pre-trained Language Models,2020,8.187168772409084e-05,2
W3014564055,Evaluating NLP Models via Contrast Sets,2020,8.186741398528924e-05,2
W3037979089,Enriching contextualized language model from knowledge graph for biomedical information extraction,2020,8.186457325541643e-05,2
W3119911952,A natural language processing approach for identifying temporal disease onset information from mental healthcare text,2021,8.185156160993825e-05,2
W4386361581,Detection of Fake Generated Scientific Abstracts,2023,8.179782689420831e-05,2
W2963958374,pair2vec: Compositional Word-Pair Embeddings for Cross-Sentence Inference,2019,8.177589895649224e-05,2
W3169937871,XOR QA: Cross-lingual Open-Retrieval Question Answering,2021,8.171625789173187e-05,2
W2971048662,Induction Networks for Few-Shot Text Classification,2019,8.16833750487086e-05,2
W2932376173,Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders,2019,8.164319200230893e-05,2
W2929198159,Bidirectional Attentive Memory Networks for Question Answering over Knowledge Bases,2019,8.153296007959314e-05,2
W3037404357,Scalable and explainable legal prediction,2020,8.148723950456653e-05,2
W2970648896,AMPERSAND: Argument Mining for PERSuAsive oNline Discussions,2019,8.147135886225067e-05,2
W3034998021,"Rˆ3: Reverse, Retrieve, and Rank for Sarcasm Generation with Commonsense Knowledge",2020,8.128924399853175e-05,2
W3011279327,Adv-BERT: BERT is not robust on misspellings! Generating nature adversarial samples on BERT,2020,8.124095997634451e-05,2
W3168090480,SciFive: a text-to-text transformer model for biomedical literature,2021,8.110798918602504e-05,2
W2963368301,QUAREL: A Dataset and Models for Answering Questions about Qualitative Relationships,2019,8.110762593843956e-05,2
W3034503989,Perturbed Masking: Parameter-free Probing for Analyzing and Interpreting BERT,2020,8.110026714549556e-05,2
W2970986790,"Overview of the MEDIQA 2019 Shared Task on Textual Inference, Question Entailment and Question Answering",2019,8.102921106705969e-05,2
W2969263964,Are We Safe Yet? The Limitations of Distributional Features for Fake News Detection.,2019,8.081722333548456e-05,2
W2961394393,Let's measure run time! Extending the IR replicability infrastructure to include performance aspects.,2019,8.081528563138899e-05,2
W2963096121,On Adversarial Removal of Hypothesis-only Bias in Natural Language Inference,2019,8.074459098039826e-05,2
W3100714086,MEGATRON-CNTRL: Controllable Story Generation with External Knowledge Using Large-Scale Language Models,2020,8.070776839162516e-05,2
W2969515962,Patient Knowledge Distillation for BERT Model Compression,2019,8.058308146621948e-05,2
W3119164154,Autoregressive Entity Retrieval,2020,8.052451055920387e-05,2
W3099836348,CoDEx: A Comprehensive Knowledge Graph Completion Benchmark,2020,8.04646698474144e-05,2
W3104738015,Early Exiting BERT for Efficient Document Ranking,2020,8.040043870265278e-05,2
W2950308662,Mining Discourse Markers for Unsupervised Sentence Representation Learning,2019,8.034161102901414e-05,2
W3008686018,How Much Knowledge Can You Pack Into the Parameters of a Language Model,2020,8.029608662459654e-05,2
W3022373106,Complementing Lexical Retrieval with Semantic Residual Embedding,2020,8.029200349154929e-05,2
W3199748991,Can Language Models Encode Perceptual Structure Without Grounding? A Case Study in Color,2021,8.026321739405183e-05,2
W4385381606,The shaky foundations of large language models and foundation models for electronic health records,2023,8.020045445068452e-05,2
W3102401511,Content Planning for Neural Story Generation with Aristotelian Rescoring,2020,8.015948616242125e-05,2
W3090656107,JAKET: Joint Pre-training of Knowledge Graph and Language Understanding,2022,8.004620708974757e-05,2
W3184402450,Domain-matched Pre-training Tasks for Dense Retrieval,2022,8.00261539856973e-05,2
W3038035611,exBERT: A Visual Analysis Tool to Explore Learned Representations in Transformer Models,2020,7.997122041428739e-05,2
W4214812012,A comparative evaluation and analysis of three generations of Distributional Semantic Models,2022,7.984649565385343e-05,2
W3017701505,Causal Mediation Analysis for Interpreting Neural NLP: The Case of Gender Bias,2020,7.982984512588453e-05,2
W2963515589,Multi-style Generative Reading Comprehension,2019,7.978628972376069e-05,2
W3133650345,Bidirectional Representation Learning From Transformers Using Multimodal Electronic Health Record Data to Predict Depression,2021,7.953739131946008e-05,2
W3105424285,Utility is in the Eye of the User: A Critique of NLP Leaderboards,2020,7.939605943017703e-05,2
W3101673779,Methods for Numeracy-Preserving Word Embeddings,2020,7.93831764986087e-05,2
W3034446185,MuTual: A Dataset for Multi-Turn Dialogue Reasoning,2020,7.91973023786334e-05,2
W3127622310,Better Fine-Tuning by Reducing Representational Collapse,2021,7.916752145050197e-05,2
W2952604841,Auditing Data Provenance in Text-Generation Models,2019,7.912163777871366e-05,2
W3152884768,Knowledge Neurons in Pretrained Transformers,2022,7.912046026468044e-05,2
W4284687473,Meta-Knowledge Transfer for Inductive Knowledge Graph Embedding,2022,7.908913084515482e-05,2
W3033188311,Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing,2020,7.89994537709791e-05,2
W4285261975,Do Pre-trained Models Benefit Knowledge Graph Completion? A Reliable Evaluation and a Reasonable Approach,2022,7.8998755901737e-05,2
W3030030185,Comparing BERT against traditional machine learning text classification,2020,7.899785630841484e-05,2
W3115772171,Automatically Identifying Words That Can Serve as Labels for Few-Shot Text Classification,2020,7.893004266673246e-05,2
W4379507314,Just Tell Me: Prompt Engineering in Business Process Management,2023,7.891410846143063e-05,2
W4388406741,Automating Intended Target Identification for Paraphasias in Discourse Using a Large Language Model,2023,7.891410846143063e-05,2
W2953365054,"Explore, Propose, and Assemble: An Interpretable Model for Multi-Hop Reading Comprehension",2019,7.879092011469014e-05,2
W4385571045,Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters,2023,7.868712335982256e-05,2
W3004654429,Interpretable & Time-Budget-Constrained Contextualization for Re-Ranking,2020,7.868013251913094e-05,2
W3173673636,Knowledgeable or Educated Guess? Revisiting Language Models as Knowledge Bases,2021,7.862948387875427e-05,2
W3134691471,Explainable automated coding of clinical notes using hierarchical label-wise attention networks and label embedding initialisation,2021,7.857397303487948e-05,2
W3100239257,Message Passing for Hyper-Relational Knowledge Graphs,2020,7.851870310263751e-05,2
W4205870266,Explaining Answers with Entailment Trees,2021,7.845409443992332e-05,2
W3100879603,Do Language Embeddings capture Scales?,2020,7.844362676459532e-05,2
W4287854450,Reframing Human-AI Collaboration for Generating Free-Text Explanations,2022,7.843023707344924e-05,2
W3155431862,Competency Problems: On Finding and Removing Artifacts in Language Data,2021,7.83404202825636e-05,2
W4253205364,Proceedings of the 2nd Workshop on Machine Reading for Question Answering,2019,7.831811521459542e-05,2
W4401754921,LLMs for knowledge graph construction and reasoning: recent capabilities and future opportunities,2024,7.830795502532078e-05,2
W2955654429,MCScript2.0: A Machine Comprehension Corpus Focused on Script Events and Participants,2019,7.824040186657707e-05,2
W2971193649,Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks,2019,7.819339223874715e-05,2
W3173805051,"ProofWriter: Generating Implications, Proofs, and Abductive Statements over Natural Language",2021,7.810364489334583e-05,2
W3099246072,TORQUE: A Reading Comprehension Dataset of Temporal Ordering Questions,2020,7.79995963131826e-05,2
W3186799149,What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams,2021,7.797917096850226e-05,2
W3035294872,A Label Attention Model for ICD Coding from Clinical Text,2020,7.790045319799975e-05,2
W4386566638,Should You Mask 15% in Masked Language Modeling?,2023,7.785320161202265e-05,2
W3120860016,"Moral Stories: Situated Reasoning about Norms, Intents, Actions, and their Consequences",2021,7.765731010408627e-05,2
W3035183674,Reranking for Efficient Transformer-based Answer Selection,2020,7.762611498730786e-05,2
W4388514671,OLaLa: Ontology Matching with Large Language Models,2023,7.76160257320464e-05,2
W3042795397,Can neural networks acquire a structural bias from raw linguistic data?,2020,7.757760521707788e-05,2
W3205803342,ZeRO-infinity,2021,7.757709759951203e-05,2
W2912860574,Predicate constraints based question answering over knowledge graph,2019,7.755712108299228e-05,2
W3047171714,ConvBERT: Improving BERT with Span-based Dynamic Convolution,2020,7.753225265147816e-05,2
W2986128786,Using Priming to Uncover the Organization of Syntactic Representations in Neural Language Models,2019,7.752421363528879e-05,2
W3169341408,CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark,2022,7.744110301956694e-05,2
W3196923642,Hardware Accelerator for Multi-Head Attention and Position-Wise Feed-Forward in the Transformer,2020,7.739335976517605e-05,2
W3086388855,Overview of BioASQ 2021: The Ninth BioASQ Challenge on Large-Scale Biomedical Semantic Indexing and Question Answering,2021,7.735623035107289e-05,2
W2963572446,Towards Automatic Generation of Shareable Synthetic Clinical Notes Using Neural Language Models,2019,7.734636814179498e-05,2
W3022006665,GenericsKB: A Knowledge Base of Generic Statements,2020,7.732849265440451e-05,2
W3098266846,BERT-MK: Integrating Graph Contextualized Knowledge into Pre-trained Language Models,2020,7.723863656616845e-05,2
W3174986053,TAT-QA: A Question Answering Benchmark on a Hybrid of Tabular and Textual Content in Finance,2021,7.712505295335185e-05,2
W3037128914,RepBERT: Contextualized Text Embeddings for First-Stage Retrieval,2020,7.698175456142781e-05,2
W3126960149,Making Pre-trained Language Models Better Few-shot Learners,2020,7.696337667797676e-05,2
W4221021831,From Discrimination to Generation: Knowledge Graph Completion with Generative Transformer,2022,7.660159616362447e-05,2
W3182696977,HTLM: Hyper-Text Pre-Training and Prompting of Language Models,2021,7.659056858032576e-05,2
W3168194750,What Will it Take to Fix Benchmarking in Natural Language Understanding?,2021,7.655462761291716e-05,2
W3120490999,"On the Stability of Fine-tuning BERT: Misconceptions, Explanations, and Strong Baselines",2021,7.654897605301044e-05,2
W3175627818,Learning Dense Representations of Phrases at Scale,2021,7.651830776139614e-05,2
W4286988498,So Cloze Yet So Far: N400 Amplitude Is Better Predicted by Distributional Information Than Human Predictability Judgements,2022,7.64945486533933e-05,2
W3156216837,Documenting the English Colossal Clean Crawled Corpus.,2021,7.648439089732546e-05,2
W3015569920,Evaluating Machines by their Real-World Language Use,2020,7.63638729396875e-05,2
W4404486407,Matching patients to clinical trials with large language models,2024,7.629645187534758e-05,2
W3113425182,SemEval-2020 Task 4: Commonsense Validation and Explanation,2020,7.619611219639031e-05,2
W3186545525,UniK-QA: Unified Representations of Structured and Unstructured Knowledge for Open-Domain Question Answering,2022,7.612366404967698e-05,2
W4367670019,Contextual semantic embeddings for ontology subsumption prediction,2023,7.606814693487927e-05,2
W3103901889,BERT-XML: Large Scale Automated ICD Coding Using BERT Pretraining,2020,7.603412009885329e-05,2
W3105949871,Modularized Transfomer-based Ranking Framework,2020,7.60220040386622e-05,2
W2997262687,Generative Adversarial Zero-Shot Relational Learning for Knowledge Graphs,2020,7.598156292611558e-05,2
W3174202502,"Automated Storytelling via Causal, Commonsense Plot Ordering",2021,7.596949982331123e-05,2
W2889446948,Toward Fast and Accurate Neural Discourse Segmentation,2018,7.596331926450058e-05,2
W3105082862,Exploiting Structured Knowledge in Text via Graph-Guided Representation Learning,2020,7.59472279681392e-05,2
W3202026671,LexGLUE: A Benchmark Dataset for Legal Language Understanding in English,2021,7.594076129103066e-05,2
W3099206682,Pretrain-KGE: Learning Knowledge Representation from Pretrained Language Models,2020,7.592409139826129e-05,2
W2970205254,Latent Suicide Risk Detection on Microblog via Suicide-Oriented Word Embeddings and Layered Attention,2019,7.589866241607289e-05,2
W4312634749,Complex Knowledge Base Question Answering: A Survey,2022,7.586876916628061e-05,2
W3167002899,Be Careful about Poisoned Word Embeddings: Exploring the Vulnerability of the Embedding Layers in NLP Models,2021,7.584184469705908e-05,2
W4385768178,Temporal Knowledge Graph Completion: A Survey,2023,7.582727601018296e-05,2
W3208821253,Pretrained Transformers for Text Ranking: BERT and Beyond,2021,7.574648817515166e-05,2
W4225418906,POLITICS: Pretraining with Same-story Article Comparison for Ideology Prediction and Stance Detection,2022,7.565030975480207e-05,2
W2984469754,Bridging the Gap between Relevance Matching and Semantic Matching for Short Text Similarity Modeling,2019,7.557173412171317e-05,2
W3034655581,DeSePtion: Dual Sequence Prediction and Adversarial Examples for Improved Fact-Checking,2020,7.556873354719859e-05,2
W3105868192,An Information Bottleneck Approach for Controlling Conciseness in Rationale Extraction,2020,7.55423773935747e-05,2
W2968210605,Attention is not not Explanation,2019,7.549474636176817e-05,2
W4392748121,MedChatZH: A tuning LLM for traditional Chinese medicine consultations,2024,7.547067482648932e-05,2
W3034212969,The Cascade Transformer: an Application for Efficient Answer Sentence Selection,2020,7.542634633457795e-05,2
W4385567201,Memory-assisted prompt editing to improve GPT-3 after deployment,2022,7.53730427669031e-05,2
W2612867916,Neural Paraphrase Identification of Questions with Noisy Pretraining,2017,7.536044879123983e-05,2
W2987972786,Biomedical Named Entity Recognition with Multilingual BERT,2019,7.534255763516063e-05,2
W3202070718,"Probing Classifiers: Promises, Shortcomings, and Advances",2021,7.528876477271442e-05,2
W4385664477,ThoughtSource: A central hub for large language model reasoning data,2023,7.511498741060218e-05,2
W2971455676,Reasoning Over Semantic-Level Graph for Fact Checking,2019,7.501768924860813e-05,2
W3013838212,Pre-trained Language Model for Biomedical Question Answering,2020,7.496653731181397e-05,2
W2950246755,NLProlog: Reasoning with Weak Unification for Question Answering in Natural Language,2019,7.496222009051505e-05,2
W2757177109,Reasoning with Heterogeneous Knowledge for Commonsense Machine Comprehension,2017,7.482341606899276e-05,2
W3176198948,When Do You Need Billions of Words of Pretraining Data?,2021,7.481769462084974e-05,2
W4221145545,Delta Tuning: A Comprehensive Study of Parameter Efficient Methods for Pre-trained Language Models,2022,7.480815821494748e-05,2
W4309685935,Prompt text classifications with transformer models! An exemplary introduction to prompt-based learning with large language models,2022,7.47622874595001e-05,2
W2963559137,Exploiting Explicit Paths for Multi-hop Reading Comprehension,2019,7.451754389612975e-05,2
W3029492690,Annotating and Analyzing Biased Sentences in News Articles using Crowdsourcing,2020,7.447312702351037e-05,2
W3183569911,SemEval-2021 Task 6: Detection of Persuasion Techniques in Texts and Images,2021,7.443172686227816e-05,2
W2970728484,Question Answering for Privacy Policies: Combining Computational and Legal Perspectives,2019,7.441427988847505e-05,2
W3016512233,PALM: Pre-training an Autoencoding&amp;Autoregressive Language Model for Context-conditioned Generation,2020,7.439464876862573e-05,2
W3198431451,BERT-based Dense Retrievers Require Interpolation with BM25 for Effective Passage Retrieval,2021,7.433400000685599e-05,2
W3212606841,The Fact Extraction and VERification Over Unstructured and Structured information (FEVEROUS) Shared Task,2021,7.432184344894832e-05,2
W2968250601,Few-shot Text Classification with Distributional Signatures,2019,7.431335971189061e-05,2
W3155151075,Legal Judgment Prediction with Multi-Stage Case Representation Learning in the Real Court Setting,2021,7.425710734593469e-05,2
W3115947671,Constructing A Multi-hop QA Dataset for Comprehensive Evaluation of Reasoning Steps,2020,7.424640324787284e-05,2
W2894740066,SNIP: Single-shot Network Pruning based on Connection Sensitivity,2018,7.422781222432326e-05,2
W2974593375,"Unifying Question Answering, Text Classification, and Regression via Span Extraction",2019,7.414389600178469e-05,2
W4385571271,Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions,2023,7.414263973206749e-05,2
W4321229682,CLSEP: Contrastive learning of sentence embedding with prompt,2023,7.411590005693757e-05,2
W2804243436,Challenging Reading Comprehension on Daily Conversation: Passage Completion on Multiparty Dialog,2018,7.396111008280829e-05,2
W2981133974,Classifying cancer pathology reports with hierarchical self-attention networks,2019,7.380353115731436e-05,2
W4284669679,InPars: Unsupervised Dataset Generation for Information Retrieval,2022,7.372319952842254e-05,2
W3153269634,Temporal Adaptation of BERT and Performance on Downstream Document Classification: Insights from Social Media,2021,7.36797595620908e-05,2
W3104350794,Analyzing Individual Neurons in Pre-trained Language Models,2020,7.364112646645479e-05,2
W3096912371,To BERT or not to BERT: Comparing Speech and Language-Based Approaches for Alzheimer’s Disease Detection,2020,7.362544526617387e-05,2
W3166464178,Single‐Stage Prediction Models Do Not Explain the Magnitude of Syntactic Disambiguation Difficulty,2021,7.361557906298179e-05,2
W4385694164,"Distinguishing ChatGPT(-3.5, -4)-generated and human-written papers through Japanese stylometric analysis",2023,7.359802088839629e-05,2
W4311903220,An overview of biomedical entity linking throughout the years,2022,7.34838479471696e-05,2
W3115729981,Specializing Unsupervised Pretraining Models for Word-Level Semantic Similarity,2020,7.346446896329041e-05,2
W3156359583,Progressively Pretrained Dense Corpus Index for Open-Domain Question Answering,2021,7.34330666650464e-05,2
W4389518756,Prompting is not a substitute for probability measurements in large language models,2023,7.342866446033071e-05,2
W2953075226,Simple and Effective Text Matching with Richer Alignment Features,2019,7.333675653215919e-05,2
W2970723181,Multi-Task Learning for Conversational Question Answering over a Large-Scale Knowledge Base,2019,7.330899313801856e-05,2
W2996507500,Towards Hierarchical Importance Attribution: Explaining Compositional Semantics for Neural Sequence Models,2019,7.326125625055465e-05,2
W3101662419,"The Language Interpretability Tool: Extensible, Interactive Visualizations and Analysis for NLP Models",2020,7.31968893654623e-05,2
W2948130861,Playing the lottery with rewards and multiple languages: lottery tickets in RL and NLP,2019,7.319023812206998e-05,2
W3045683288,Language Models as Fact Checkers?,2020,7.315504710652385e-05,2
W4389669106,"Systematic testing of three Language Models reveals low language accuracy, absence of response stability, and a yes-response bias",2023,7.314907218753662e-05,2
W2970243238,WIQA: A dataset for “What if...” reasoning over procedural text,2019,7.313327686954997e-05,2
W3175115403,"Anonymisation Models for Text Data: State of the art, Challenges and Future Directions",2021,7.309694973220826e-05,2
W3046527848,Humpty Dumpty: Controlling Word Meanings via Corpus Poisoning,2020,7.30348710333793e-05,2
W3166890286,Representing Numbers in NLP: a Survey and a Vision,2021,7.30294171825509e-05,2
W2971600926,Commonsense Knowledge Mining from Pretrained Models,2019,7.298219058425827e-05,2
W3020908159,UnifiedQA: Crossing Format Boundaries With a Single QA System,2020,7.297352196913037e-05,2
W3115195983,PROP: Pre-training with Representative Words Prediction for Ad-hoc Retrieval,2021,7.294689428501527e-05,2
W2986532682,An Exploration of Data Augmentation and Sampling Techniques for Domain-Agnostic Question Answering,2019,7.288965129373104e-05,2
W2995409942,LAMOL: LAnguage MOdeling for Lifelong Language Learning,2019,7.28876614350017e-05,2
W3106061119,Pre-Training Transformers as Energy-Based Cloze Models,2020,7.286442393953745e-05,2
W3175910413,UNICORN on RAINBOW: A Universal Commonsense Reasoning Model on a New Multitask Benchmark,2021,7.285416968306213e-05,2
W3083667980,Evolving CNN-LSTM Models for Time Series Prediction Using Enhanced Grey Wolf Optimizer,2020,7.274275986893842e-05,2
W3164323420,A systematic review of natural language processing applied to radiology reports,2021,7.269024768776412e-05,2
W2887005207,Unsupervised Random Walk Sentence Embeddings: A Strong but Simple Baseline,2018,7.267912403629123e-05,2
W2951107864,Modeling Intra-Relation in Math Word Problems with Different Functional Multi-Head Attentions,2019,7.253824334406269e-05,2
W4389518954,Evaluating Verifiability in Generative Search Engines,2023,7.250713289641026e-05,2
W3182536263,"Challenges, Techniques, and Trends of Simple Knowledge Graph Question Answering: A Survey",2021,7.247521829559296e-05,2
W3099843385,An Analysis of Natural Language Inference Benchmarks through the Lens of Negation,2020,7.247085246498219e-05,2
W3104215796,Recall and Learn: Fine-tuning Deep Pretrained Language Models with Less Forgetting,2020,7.246624297947631e-05,2
W3175052694,Turn the Combination Lock: Learnable Textual Backdoor Attacks via Word Substitution,2021,7.242069306841791e-05,2
W4388022708,Clinical Text Summarization: Adapting Large Language Models Can Outperform Human Experts,2023,7.24132753669562e-05,2
W4295808856,"Interpretable deep learning: interpretation, interpretability, trustworthiness, and beyond",2022,7.221384166665108e-05,2
W3013655557,The Limitations of Stylometry for Detecting Machine-Generated Fake News,2020,7.219922378225513e-05,2
W3102839769,BERT-kNN: Adding a kNN Search Component to Pretrained Language Models for Better QA,2020,7.218630489303621e-05,2
W3034417881,Span Selection Pre-training for Question Answering,2020,7.217224711833406e-05,2
W3171244865,Open-Domain Question Answering Goes Conversational via Question Rewriting,2021,7.215917340961737e-05,2
W3213472637,Generative Pre-Trained Transformer for Design Concept Generation: An Exploration,2022,7.206344070390969e-05,2
W2979196189,Multi-hop Question Answering via Reasoning Chains,2019,7.204845532480999e-05,2
W3034475796,Explaining Black Box Predictions and Unveiling Data Artifacts through Influence Functions,2020,7.201819539772641e-05,2
W3173169192,ERICA: Improving Entity and Relation Understanding for Pre-trained Language Models via Contrastive Learning,2021,7.191210839559617e-05,2
W4389524372,Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data,2023,7.175128315712982e-05,2
W3023419341,Intermediate-Task Transfer Learning with Pretrained Models for Natural Language Understanding: When and Why Does It Work?,2020,7.174662302952173e-05,2
W4389977189,A survey of GPT-3 family large language models including ChatGPT and GPT-4,2023,7.171927503812289e-05,2
W2971094176,Tree-structured Decoding for Solving Math Word Problems,2019,7.167283599167954e-05,2
W4389518784,HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models,2023,7.160645186565787e-05,2
W3004528428,From online texts to Landscape Character Assessment: Collecting and analysing first-person landscape perception computationally,2020,7.153532210084212e-05,2
W3171057731,Continual Learning for Text Classification with Information Disentanglement Based Regularization,2021,7.151230125307998e-05,2
W2988022164,Natural Language Generation for Effective Knowledge Distillation,2019,7.145983831351227e-05,2
W2551087083,LSTM-Based System-Call Language Modeling and Robust Ensemble Method for Designing Host-Based Intrusion Detection Systems,2016,7.138257425171628e-05,2
W2752337926,Automated Crowdturfing Attacks and Defenses in Online Review Systems,2017,7.130843456553879e-05,2
W3173374050,BinaryBERT: Pushing the Limit of BERT Quantization,2021,7.128589793975645e-05,2
W3169228325,Learning to Walk across Time for Interpretable Temporal Knowledge Graph Completion,2021,7.11522846309254e-05,2
W3199493219,Relevance-guided Supervision for OpenQA with ColBERT,2021,7.1141523178337e-05,2
W3172267148,Text Modular Networks: Learning to Decompose Tasks in the Language of Existing Models,2021,7.111732176626014e-05,2
W2995322030,Few-shot Text Classification with Distributional Signatures,2020,7.100247319889319e-05,2
W3092683697,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2020,7.093489045326033e-05,2
W3015298864,MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices,2020,7.092798444451096e-05,2
W2965826089,AmazonQA: A Review-Based Question Answering Task,2019,7.09212599511714e-05,2
W3187658747,Multi-Hop Fact Checking of Political Claims,2021,7.079520220122401e-05,2
W3166593409,Improving Biomedical Pretrained Language Models with Knowledge,2021,7.076265893662165e-05,2
W3100353583,Common Sense or World Knowledge? Investigating Adapter-Based Knowledge Injection into Pretrained Transformers,2020,7.070797547304014e-05,2
W3034831508,Mind the Trade-off: Debiasing NLU Models without Degrading the In-distribution Performance,2020,7.066863009849128e-05,2
W3201427244,Unsupervised law article mining based on deep pre-trained language representation models with application to the Italian civil code,2021,7.063273827232825e-05,2
W4205508242,FinQA: A Dataset of Numerical Reasoning over Financial Data,2021,7.062259718769586e-05,2
W4317898419,Improving the Domain Adaptation of Retrieval Augmented Generation (RAG) Models for Open Domain Question Answering,2023,7.056102206246857e-05,2
W2949629417,Scalable Syntax-Aware Language Models Using Knowledge Distillation,2019,7.048228473517292e-05,2
W3100742171,GenAug: Data Augmentation for Finetuning Text Generators,2020,7.041802227953973e-05,2
W2949399644,Compound Probabilistic Context-Free Grammars for Grammar Induction,2019,7.038637421049676e-05,2
W2751627669,Visual Exploration of Semantic Relationships in Neural Word Embeddings,2017,7.0347981829134e-05,2
W3089659770,A Simple but Tough-to-Beat Data Augmentation Approach for Natural Language Understanding and Generation,2020,7.025860123588847e-05,2
W2976833415,Reweighted Proximal Pruning for Large-Scale Language Representation,2019,7.022120119652006e-05,2
W4385573261,Ground-Truth Labels Matter: A Deeper Look into Input-Label Demonstrations,2022,7.014725632703365e-05,2
W3209273204,Complex Temporal Question Answering on Knowledge Graphs,2021,7.013910784816627e-05,2
W3112116031,Language models are an effective representation learning technique for electronic health record data,2020,7.006861389564465e-05,2
W3116073702,Explainability in deep reinforcement learning,2020,7.002742112926095e-05,2
W2952570576,Attention Is (not) All You Need for Commonsense Reasoning,2019,6.996877397377731e-05,2
W2963506049,CliCR: a Dataset of Clinical Case Reports for Machine Reading Comprehension,2018,6.992478072345892e-05,2
W2946606955,Old is Gold: Linguistic Driven Approach for Entity and Relation Linking of Short Text,2019,6.991750582193798e-05,2
W4389519118,Active Retrieval Augmented Generation,2023,6.988525544251337e-05,2
W4303579584,Using Computational Models to Test Syntactic Learnability,2022,6.988259464622898e-05,2
W3212213895,Hidden Backdoors in Human-Centric Language Models,2021,6.980737329183363e-05,2
W3022969335,"When BERT Plays the Lottery, All Tickets Are Winning",2020,6.979792422477359e-05,2
W3004119480,Discriminative Topic Mining via Category-Name Guided Text Embedding,2020,6.979064347688071e-05,2
W4386002582,Can ChatGPT provide intelligent diagnoses? A comparative study between predictive models and ChatGPT to define a new medical diagnostic bot,2023,6.974974706106466e-05,2
W2890152674,Multilingual Extractive Reading Comprehension by Runtime Machine Translation,2018,6.974742078203802e-05,2
W3045600569,Stance Prediction and Claim Verification: An Arabic Perspective,2020,6.971654715002052e-05,2
W3015440086,Knowledge Fusion and Semantic Knowledge Ranking for Open Domain Question Answering,2020,6.969072527705513e-05,2
W3100949878,What Are You Trying to Do? Semantic Typing of Event Processes,2020,6.968088499815383e-05,2
W4226163610,Transformer-Based Deep Neural Language Modeling for Construct-Specific Automatic Item Generation,2021,6.965212758015136e-05,2
W2980808611,Automatic Judgment Prediction via Legal Reading Comprehension,2019,6.964372076094725e-05,2
W3082429057,HittER: Hierarchical Transformers for Knowledge Graph Embeddings,2021,6.964291385643933e-05,2
W3014328670,Investigating Prior Knowledge for Challenging Chinese Machine Reading Comprehension,2020,6.962957271738047e-05,2
W4385574217,A Fine-grained Interpretability Evaluation Benchmark for Neural NLP,2022,6.961946280679499e-05,2
W2946379006,Cognitive Graph for Multi-Hop Reading Comprehension at Scale,2019,6.957402003749644e-05,2
W3085380432,Captum: A unified and generic model interpretability library for PyTorch,2020,6.95635928579859e-05,2
W2945878859,Learning to Denoise Distantly-Labeled Data for Entity Typing,2019,6.941425657319865e-05,2
W2953010614,Real-Time Open-Domain Question Answering with Dense-Sparse Phrase Index,2019,6.938988953649718e-05,2
W3166913490,X-Class: Text Classification with Extremely Weak Supervision,2021,6.937998274937865e-05,2
W3196813608,All Bark and No Bite: Rogue Dimensions in Transformer Language Models Obscure Representational Quality,2021,6.93733489264679e-05,2
W4385571789,Instruction Induction: From Few Examples to Natural Language Task Descriptions,2023,6.936914325768462e-05,2
W2951675429,Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets,2019,6.935183329993412e-05,2
W3169920290,Towards Few-shot Fact-Checking via Perplexity,2021,6.934679144100611e-05,2
W3104958909,Causal Inference of Script Knowledge,2020,6.927057916222754e-05,2
W3015667612,"Annotating social determinants of health using active learning, and characterizing determinants using neural event extraction",2020,6.921727275163429e-05,2
W3105892552,"Infusing Disease Knowledge into BERT for Health Question Answering, Medical Inference and Disease Name Recognition",2020,6.920397759240657e-05,2
W3154200459,Natural Instructions: Benchmarking Generalization to New Tasks from Natural Language Instructions,2021,6.915998476837978e-05,2
W4382202847,Contrastive Learning Reduces Hallucination in Conversations,2023,6.91487640578668e-05,2
W2986836624,Generalizing Question Answering System with Pre-trained Language Model Fine-tuning,2019,6.90768093630556e-05,2
W3177233335,Claim Matching Beyond English to Scale Global Fact-Checking,2021,6.906087981732944e-05,2
W3166441238,Pretrained Transformers for Text Ranking: BERT and Beyond,2021,6.898302496995185e-05,2
W3184978204,Dimensions of commonsense knowledge,2021,6.89394813541856e-05,2
W4283219089,Pretrained domain-specific language model for natural language processing tasks in the AEC domain,2022,6.890175253909056e-05,2
W4225454120,URLTran: Improving Phishing URL Detection Using Transformers,2021,6.888868090922044e-05,2
W2998099211,Getting Closer to AI Complete Question Answering: A Set of Prerequisite Real Tasks,2020,6.881695920818727e-05,2
W3174531908,Fusing Context Into Knowledge Graph for Commonsense Question Answering,2021,6.880339690768128e-05,2
W3098068947,Exploring and Predicting Transferability across NLP Tasks,2020,6.874559359583935e-05,2
W3104657626,Beyond [CLS] through Ranking by Generation,2020,6.874177491008851e-05,2
W4385574298,Prompt Consistency for Zero-Shot Task Generalization,2022,6.865564224220207e-05,2
W2965210982,ERNIE 2.0: A Continual Pre-training Framework for Language Understanding,2019,6.861461631472716e-05,2
W3213844504,Neural Media Bias Detection Using Distant Supervision With BABE - Bias Annotations By Experts,2021,6.858086611877128e-05,2
W3175795662,ReTraCk: A Flexible and Efficient Framework for Knowledge Base Question Answering,2021,6.857724286850464e-05,2
W3212176791,TURINGBENCH: A Benchmark Environment for Turing Test in the Age of Neural Text Generation,2021,6.857161661923048e-05,2
W2996164352,ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning,2020,6.85626424531532e-05,2
W3099876468,A Simple Yet Strong Pipeline for HotpotQA,2020,6.850929887874156e-05,2
W3103816537,Exploring BERT’s Sensitivity to Lexical Cues using Tests from Semantic Priming,2020,6.847482082986455e-05,2
W3105645800,SqueezeBERT: What can computer vision teach NLP about efficient neural networks?,2020,6.845043004570063e-05,2
W2995983533,Depth-adaptive Transformer,2020,6.842031558657085e-05,2
W2972896975,Hierarchical Representation in Neural Language Models: Suppression and Recovery of Expectations,2019,6.840908448326907e-05,2
W3174931845,MLMLM: Link Prediction with Mean Likelihood Masked Language Model,2021,6.832061625290095e-05,2
W3007523830,Comprehend Medical: A Named Entity Recognition and Relationship Extraction Web Service,2019,6.828719590884482e-05,2
W2980360762,A Mutual Information Maximization Perspective of Language Representation Learning,2019,6.828186289036893e-05,2
W2980418356,Answering Complex Open-domain Questions Through Iterative Query Generation,2019,6.818572795098836e-05,2
W4385757404,Clinical Prompt Learning With Frozen Language Models,2023,6.818310979174721e-05,2
W3104196571,Machine Generation and Detection of Arabic Manipulated and Fake News,2020,6.81755425867223e-05,2
W3185146124,Rethinking search,2021,6.811797829777672e-05,2
W2810134635,Subword-augmented Embedding for Cloze Reading Comprehension,2018,6.81062640328386e-05,2
W3209254806,Does the magic of BERT apply to medical code assignment? A quantitative study,2021,6.802564430561326e-05,2
W4390347092,Differentiating ChatGPT-Generated and Human-Written Medical Texts: Quantitative Study,2023,6.801051072042196e-05,2
W3156891177,Carbon Emissions and Large Neural Network Training.,2021,6.792958950819903e-05,2
W4385565351,Precise Zero-Shot Dense Retrieval without Relevance Labels,2023,6.791705502945535e-05,2
W3176757281,Question Answering Over Temporal Knowledge Graphs,2021,6.791491419639463e-05,2
W2904996081,Towards Sentence-Level Brain Decoding with Distributed Representations,2019,6.783461963353312e-05,2
W4385570569,Task-aware Retrieval with Instructions,2023,6.780338104174234e-05,2
W3169554260,A Comparison of Pre-Trained Language Models for Multi-Class Text Classification in the Financial Domain,2021,6.780140583579806e-05,2
W3047026265,Question and Answer Test-Train Overlap in Open-Domain Question Answering Datasets,2020,6.772144474488241e-05,2
W3174432697,Exploring Listwise Evidence Reasoning with T5 for Fact Verification,2021,6.77148647550167e-05,2
W3101066076,Contrastive Distillation on Intermediate Representations for Language Model Compression,2020,6.77045146536183e-05,2
W3099873751,Table Fact Verification with Structure-Aware Transformer,2020,6.76506999518621e-05,2
W3115462295,CharacterBERT: Reconciling ELMo and BERT for Word-Level Open-Vocabulary Representations From Characters,2020,6.764121785840773e-05,2
W3212990991,"BERT, XLNet or RoBERTa: The Best Transfer Learning Model to Detect Clickbaits",2021,6.75999693751949e-05,2
W4391653771,"Screening Smarter, Not Harder: A Comparative Analysis of Machine Learning Screening Algorithms and Heuristic Stopping Criteria for Systematic Reviews in Educational Research",2024,6.75999693751949e-05,2
W3098981070,A building regulation question answering system: A deep learning methodology,2020,6.759502333370005e-05,2
W2950738719,A Decomposable Attention Model for Natural Language Inference,2016,6.757249196640568e-05,2
W4285147034,KQA Pro: A Dataset with Explicit Compositional Programs for Complex Question Answering over Knowledge Base,2022,6.755517872471961e-05,2
W3155381456,Scientific Claim Verification with VERT5ERINI,2020,6.747951744108046e-05,2
W4308341600,Predictive Coding or Just Feature Discovery? An Alternative Account of Why Language Models Fit Brain Data,2022,6.744361142584665e-05,2
W3035718362,Probing Linguistic Systematicity,2020,6.742501711506106e-05,2
W3141847762,Natural language processing in medicine: A review,2021,6.739855466424393e-05,2
W3034487470,Similarity Analysis of Contextual Word Representation Models,2020,6.736753985507587e-05,2
W3103543556,"Reasoning about Goals, Steps, and Temporal Ordering with WikiHow",2020,6.729537250725096e-05,2
W3035620114,LogicalFactChecker: Leveraging Logical Operations for Fact Checking with Graph Module Network,2020,6.728179575665636e-05,2
W3172399575,Fine-Tuning Pre-trained Language Model with Weak Supervision: A Contrastive-Regularized Self-Training Approach,2021,6.727512023119267e-05,2
W3099142828,Calibrated Language Model Fine-Tuning for In- and Out-of-Distribution Data,2020,6.719047591900489e-05,2
W2945329331,Alignment over Heterogeneous Embeddings for Question Answering,2019,6.715680239945828e-05,2
W2986889180,Analysing Neural Language Models: Contextual Decomposition Reveals Default Reasoning in Number and Gender Assignment,2019,6.715522233029991e-05,2
W2995649781,Neural Module Networks for Reasoning over Text,2020,6.714171745760601e-05,2
W3021191241,E-BERT: Efficient-Yet-Effective Entity Embeddings for BERT,2019,6.709417503683213e-05,2
W3128288937,Sequential sentence classification in research papers using cross-domain multi-task learning,2024,6.709357990064057e-05,2
W3037115370,SyntaxGym: An Online Platform for Targeted Evaluation of Language Models,2020,6.708565065181093e-05,2
W4386701652,"GPT-3.5, GPT-4, or BARD? Evaluating LLMs reasoning ability in zero-shot setting and performance boosting through prompts",2023,6.698731307471367e-05,2
W2970619710,Shallow Syntax in Deep Water,2019,6.698145448088026e-05,2
W2965962253,Controllable Neural Story Plot Generation via Reward Shaping,2019,6.696759759676844e-05,2
W3103163889,Detection of Mental Health from Reddit via Deep Contextualized Representations,2020,6.691704548783112e-05,2
W3165416482,PTR: Prompt Tuning with Rules for Text Classification,2021,6.689039603459945e-05,2
W3199241049,Scale Efficiently: Insights from Pre-training and Fine-tuning Transformers,2021,6.687665315245919e-05,2
W4389520255,Demystifying Prompts in Language Models via Perplexity Estimation,2023,6.686023422401516e-05,2
W2952409498,Deep Unknown Intent Detection with Margin Loss,2019,6.684060787058325e-05,2
W3093871960,Language Models are Open Knowledge Graphs,2020,6.676226130384252e-05,2
W3177365697,AMBERT: A Pre-trained Language Model with Multi-Grained Tokenization,2021,6.675343755922402e-05,2
W3212748247,Few-Shot Self-Rationalization with Natural Language Prompts,2022,6.669925971344127e-05,2
W3176693010,On the Effectiveness of Adapter-based Tuning for Pretrained Language Model Adaptation,2021,6.669716129993623e-05,2
W4223492536,BioBART: Pretraining and Evaluation of A Biomedical Generative Language Model,2022,6.668808623267078e-05,2
W3035454789,GAN-BERT: Generative Adversarial Learning for Robust Text Classification with a Bunch of Labeled Examples,2020,6.664828710615464e-05,2
W3128431233,Spark NLP: Natural Language Understanding at Scale,2021,6.663500212070613e-05,2
W3035403290,DGL-KE,2020,6.663488822934892e-05,2
W2982206942,What does BERT Learn from Multiple-Choice Reading Comprehension Datasets?,2019,6.662043589107804e-05,2
W4285798540,On the Explainability of Natural Language Processing Deep Models,2022,6.661586760185116e-05,2
W3201503287,MEM-KGC: Masked Entity Model for Knowledge Graph Completion With Pre-Trained Language Model,2021,6.661549595374239e-05,2
W3035251378,HAT: Hardware-Aware Transformers for Efficient Natural Language Processing,2020,6.659020144190755e-05,2
W3198002980,Finetuned Language Models Are Zero-Shot Learners,2021,6.654118448154728e-05,2
W3103188966,SLM: Learning a Discourse Language Representation with Sentence Unshuffling,2020,6.651866276667885e-05,2
W3176751053,Causal Analysis of Syntactic Agreement Mechanisms in Neural Language Models,2021,6.649871445355206e-05,2
W4385567093,Efficient Large Scale Language Modeling with Mixtures of Experts,2022,6.64275959387013e-05,2
W4389262624,WellXplain: Wellness concept extraction and classification in Reddit posts for mental health analysis,2023,6.64269315435116e-05,2
W3101652466,PlotMachines: Outline-Conditioned Generation with Dynamic Plot State Tracking,2020,6.63811439285984e-05,2
W3116423158,Enhancing Clinical BERT Embedding using a Biomedical Knowledge Base,2020,6.630762631546623e-05,2
W3118027562,A Memory Efficient Baseline for Open Domain Question Answering,2020,6.626642234706858e-05,2
W4206221224,Classifying social determinants of health from unstructured electronic health records using deep learning-based natural language processing,2022,6.624897262365542e-05,2
W4200635123,GPL: Generative Pseudo Labeling for Unsupervised Domain Adaptation of Dense Retrieval,2022,6.623485186004172e-05,2
W3173618889,The Art of Abstention: Selective Prediction and Error Regularization for Natural Language Processing,2021,6.622059651791865e-05,2
W3202031169,Paradigm Shift in Natural Language Processing,2022,6.620829569364772e-05,2
W4385572854,Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs,2022,6.62003188917498e-05,2
W2962874939,Two-Stage Synthesis Networks for Transfer Learning in Machine Comprehension,2017,6.617252858187626e-05,2
W3104007871,Language Generation with Multi-Hop Reasoning on Commonsense Knowledge Graph,2020,6.616992836499108e-05,2
W3022717752,What Happens To BERT Embeddings During Fine-tuning?,2020,6.613181744303601e-05,2
W3173566921,Prompting Contrastive Explanations for Commonsense Reasoning Tasks,2021,6.60986390853457e-05,2
W3046423960,Improving Subject-Area Question Answering with External Knowledge,2019,6.607345820682085e-05,2
W4385572830,Re3: Generating Longer Stories With Recursive Reprompting and Revision,2022,6.605963858795544e-05,2
W3089862415,Machine Learning and Natural Language Processing in Mental Health: Systematic Review,2020,6.60452209872077e-05,2
W3035129496,Clinical Reading Comprehension: A Thorough Analysis of the emrQA Dataset,2020,6.602453735741418e-05,2
W4385572901,TemporalWiki: A Lifelong Benchmark for Training and Evaluating Ever-Evolving Language Models,2022,6.602360112916726e-05,2
W2949961827,Learning to Ask Unanswerable Questions for Machine Reading Comprehension,2019,6.596707222381903e-05,2
W4287888135,SKILL: Structured Knowledge Infusion for Large Language Models,2022,6.590861778458996e-05,2
W3099008231,exBERT: Extending Pre-trained Models with Domain-specific Vocabulary Under Constrained Training Resources,2020,6.575992201850606e-05,2
W2962925243,Supervised and Unsupervised Transfer Learning for Question Answering,2018,6.57090806722435e-05,2
W4388034436,Dissecting neural computations in the human auditory pathway using deep neural networks for speech,2023,6.567297111773243e-05,2
W3126553126,Pitfalls of Static Language Modelling.,2021,6.566831137581956e-05,2
W3101058639,BioBERTpt - A Portuguese Neural Language Model for Clinical Named Entity Recognition,2020,6.563284097380941e-05,2
W3100103516,Incorporating Commonsense Knowledge Graph in Pretrained Models for Social Commonsense Tasks,2020,6.562148695078025e-05,2
W4389403907,Legalbench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models,2023,6.56079485397113e-05,2
W3173681001,What Context Features Can Transformer Language Models Use?,2021,6.554458036844077e-05,2
W2986728023,Evidence Sentence Extraction for Machine Reading Comprehension,2019,6.53835842759165e-05,2
W3100475986,Assessing Phrasal Representation and Composition in Transformers,2020,6.535740298458875e-05,2
W4285116174,Pretrained Biomedical Language Models for Clinical NLP in Spanish,2022,6.5337889546892e-05,2
W3027639267,Query Resolution for Conversational Search with Limited Supervision,2020,6.52257167900768e-05,2
W3034503357,Code and Named Entity Recognition in StackOverflow,2020,6.52069708205578e-05,2
W3016339201,The Cost of Training NLP Models: A Concise Overview,2020,6.520088663068522e-05,2
W3020152921,Rapidly Bootstrapping a Question Answering Dataset for COVID-19,2020,6.518060424794524e-05,2
W3035707368,ReInceptionE: Relation-Aware Inception Network with Joint Local-Global Structural Information for Knowledge Graph Embedding,2020,6.50810900388322e-05,2
W2972342261,From Balustrades to Pierre Vinken: Looking for Syntax in Transformer Self-Attentions,2019,6.507858637204405e-05,2
W2972381305,A Simple but Effective Method to Incorporate Multi-turn Context with BERT for Conversational Machine Comprehension,2019,6.504670112710638e-05,2
W4225590069,PADA: Example-based Prompt Learning for on-the-fly Adaptation to Unseen Domains,2022,6.501886470157451e-05,2
W2788363870,Medical Exam Question Answering with Large-scale Reading Comprehension,2018,6.50127601385569e-05,2
W3099342932,WNUT-2020 Task 2: Identification of Informative COVID-19 English Tweets,2020,6.499949262690469e-05,2
W2973061659,Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT,2019,6.49681828525306e-05,2
W3196437953,LightNER: A Lightweight Generative Framework with Prompt-guided Attention for Low-resource NER,2021,6.493421328111286e-05,2
W3175655865,Learning Domain-Specialised Representations for Cross-Lingual Biomedical Entity Linking,2021,6.491430059570795e-05,2
W2968289784,SenseBERT: Driving Some Sense into BERT,2019,6.479203302867467e-05,2
W3097977265,Neural Natural Language Inference Models Partially Embed Theories of Lexical Entailment and Negation,2020,6.477322632899664e-05,2
W3129160532,A pre-training and self-training approach for biomedical named entity recognition,2021,6.474250389803904e-05,2
W2950733407,Improving the Robustness of Question Answering Systems to Question Paraphrasing,2019,6.473490967183219e-05,2
W4362696539,Strong Prediction: Language Model Surprisal Explains Multiple N400 Effects,2023,6.466174841181808e-05,2
W3124180615,Sentiment Polarity Detection for Software Development,2017,6.45946673487785e-05,2
W4362650350,HUKB at the COLIEE 2022 Statute Law Task,2023,6.459347312684496e-05,2
W2971096647,What’s Missing: A Knowledge Gap Guided Approach for Multi-hop Question Answering,2019,6.457005273170334e-05,2
W4385572965,Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations,2022,6.455609974629773e-05,2
W3199258975,RNG-KBQA: Generation Augmented Iterative Ranking for Knowledge Base Question Answering,2022,6.454282311838868e-05,2
W4221157571,Ontology-enhanced Prompt-tuning for Few-shot Learning,2022,6.452696564673771e-05,2
W3200076410,"Overview of the CLEF–2021 CheckThat! Lab on Detecting Check-Worthy Claims, Previously Fact-Checked Claims, and Fake News",2021,6.451521190617532e-05,2
W3179534853,Tailor: Generating and Perturbing Text with Semantic Controls,2022,6.447884473336112e-05,2
W3035490055,Neural Graph Matching Networks for Chinese Short Text Matching,2020,6.44425776802829e-05,2
W3110300144,Evaluating Explanations: How Much Do Explanations from the Teacher Aid Students?,2022,6.440625380988395e-05,2
W4283797513,Unsupervised Sentence Representation via Contrastive Learning with Mixing Negatives,2022,6.438892317460483e-05,2
W3174708387,"Length-Adaptive Transformer: Train Once with Length Drop, Use Anytime with Search",2021,6.438340368246575e-05,2
W2985671014,Dynamic Knowledge Graph Construction for Zero-shot Commonsense Question Answering,2019,6.438214564959378e-05,2
W2984775947,Do Multi-hop Readers Dream of Reasoning Chains?,2019,6.43801652720859e-05,2
W4385571886,Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers,2023,6.436671029758751e-05,2
W3202099651,Towards Continual Knowledge Learning of Language Models,2021,6.436332706207363e-05,2
W3117696238,A Survey of the State of Explainable AI for Natural Language Processing,2020,6.430541214407686e-05,2
W3100262863,Neural Deepfake Detection with Factual Structure of Text,2020,6.426666369942006e-05,2
W2964230347,A La Carte Embedding: Cheap but Effective Induction of Semantic Feature Vectors,2018,6.425875930342165e-05,2
W3098275893,When is a bishop not like a rook? When it’s like a rabbi! Multi-prototype BERT embeddings for estimating semantic relationships,2020,6.424591621072597e-05,2
W3023553115,It’s Morphin’ Time! Combating Linguistic Discrimination with Inflectional Perturbations,2020,6.422000513624037e-05,2
W3170822064,Clustering-based Inference for Biomedical Entity Linking,2021,6.420346885853359e-05,2
W4387846647,Neural Disentanglement of Query Difficulty and Semantics,2023,6.415653574025359e-05,2
W4385076927,PLPMpro: Enhancing promoter sequence prediction with prompt-learning based pre-trained language model,2023,6.415653574025359e-05,2
W3174660442,Dynamic Neuro-Symbolic Knowledge Graph Construction for Zero-shot Commonsense Question Answering,2021,6.415339265096917e-05,2
W4389523765,Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents,2023,6.414412174412601e-05,2
W3198080531,Biomedical Question Answering: A Survey of Approaches and Challenges,2022,6.414047446368623e-05,2
W3035599451,"To Test Machine Comprehension, Start by Defining Comprehension",2020,6.412734169966165e-05,2
W3035290244,Pre-training Is (Almost) All You Need: An Application to Commonsense Reasoning,2020,6.412333948371278e-05,2
W2973252307,Targeted Adversarial Examples for Black Box Audio Systems,2019,6.40838008264795e-05,2
W3103884771,BERT-EMD: Many-to-Many Layer Mapping for BERT Compression with Earth Mover’s Distance,2020,6.407649985492773e-05,2
W3202794254,Inductive Learning on Commonsense Knowledge Graph Completion,2021,6.407617507801936e-05,2
W3136888420,Paragraph-level Rationale Extraction through Regularization: A case study on European Court of Human Rights Cases,2021,6.407335108041502e-05,2
W4389520124,Consistency Analysis of ChatGPT,2023,6.406245524330121e-05,2
W3034985160,Contrastive Self-Supervised Learning for Commonsense Reasoning,2020,6.405810490876707e-05,2
W3173220653,LET: Linguistic Knowledge Enhanced Graph Transformer for Chinese Short Text Matching,2021,6.400543792160801e-05,2
W2987878148,Learning to Few-Shot Learn Across Diverse Natural Language Classification Tasks,2019,6.395542317660658e-05,2
W2995040292,A Mutual Information Maximization Perspective of Language Representation Learning,2020,6.391794608543436e-05,2
W3124523525,Deep Learning-Based Natural Language Processing for Screening Psychiatric Patients,2021,6.387057080222158e-05,2
W3095789240,"A Survey on Machine Reading Comprehension—Tasks, Evaluation Metrics and Benchmark Datasets",2020,6.38627256617606e-05,2
W3101747393,Learning to Rank Question Answer Pairs with Holographic Dual LSTM Architecture,2017,6.383637453415464e-05,2
W2963299810,Deep Enhanced Representation for Implicit Discourse Relation Recognition,2018,6.38332294073482e-05,2
W2969282568,Visual Interaction with Deep Learning Models through Collaborative Semantic Inference,2019,6.381114055953344e-05,2
W3044324512,"TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP",2020,6.379394789968419e-05,2
W4385570895,RankCSE: Unsupervised Sentence Representations Learning via Learning to Rank,2023,6.379099205116086e-05,2
W4392619039,Structured Prompt Interrogation and Recursive Extraction of Semantics (SPIRES): a method for populating knowledge bases using zero-shot learning,2024,6.376081636887348e-05,2
W3175603587,Reordering Examples Helps during Priming-based Few-Shot Learning,2021,6.373717689779363e-05,2
W3153414861,TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning,2021,6.372724947240117e-05,2
W4367047490,KRACL: Contrastive Learning with Graph Context Modeling for Sparse Knowledge Graph Completion,2023,6.372586231768728e-05,2
W3089102176,What Does My QA Model Know? Devising Controlled Probes Using Expert Knowledge,2020,6.372045124558943e-05,2
W2797585226,Discourse-Aware Neural Rewards for Coherent Text Generation,2018,6.36972822731065e-05,2
W3162734203,A Survey of Data Augmentation Approaches for NLP,2021,6.368905359226284e-05,2
W4294833327,Conversational question answering: a survey,2022,6.368166940543144e-05,2
W3026992186,Explicit Contextual Semantics for Text Comprehension,2018,6.367240997871917e-05,2
W4205694376,Efficient Nearest Neighbor Language Models,2021,6.365243408587245e-05,2
W3114142294,Molweni: A Challenge Multiparty Dialogues-based Machine Reading Comprehension Dataset with Discourse Structure,2020,6.357182304473399e-05,2
W3002226419,Named Entity Recognition Using BERT BiLSTM CRF for Chinese Electronic Health Records,2019,6.35414503493499e-05,2
W3167748596,Open Domain Question Answering over Tables via Dense Retrieval,2021,6.349462725152318e-05,2
W4386566526,"GrIPS: Gradient-free, Edit-based Instruction Search for Prompting Large Language Models",2023,6.347726749290318e-05,2
W4380591192,Clinical concept and relation extraction using prompt-based machine reading comprehension,2023,6.344466944875545e-05,2
W4310568840,A comparative study of pretrained language models for long clinical text,2022,6.344102513019817e-05,2
W4389520779,StructGPT: A General Framework for Large Language Model to Reason over Structured Data,2023,6.343333616680559e-05,2
W2986213397,Commonsense Properties from Query Logs and Question Answering Forums,2019,6.341747969234313e-05,2
W3156170450,Multilingual LAMA: Investigating Knowledge in Multilingual Pretrained Language Models,2021,6.338312007764641e-05,2
W3147292006,Rethink Training of BERT Rerankers in Multi-stage Retrieval Pipeline,2021,6.338032616563896e-05,2
W2964348592,HAS-QA: Hierarchical Answer Spans Model for Open-Domain Question Answering,2019,6.336624047419663e-05,2
W3135970112,Improving Skip-Gram Embeddings Using BERT,2021,6.331164539878864e-05,2
W4221160815,Rethinking Graph Convolutional Networks in Knowledge Graph Completion,2022,6.32805912863586e-05,2
W4388691863,Language Model Behavior: A Comprehensive Survey,2023,6.325808247281927e-05,2
W4283318325,BioRED: a rich biomedical relation extraction dataset,2022,6.325060988246031e-05,2
W4206136559,How to Train BERT with an Academic Budget,2021,6.318730857682524e-05,2
W4289865932,R&lt;sup&gt;3&lt;/sup&gt;: Reinforced Ranker-Reader for Open-Domain Question Answering,2018,6.310589972151603e-05,2
W2864258299,Deep Enhanced Representation for Implicit Discourse Relation Recognition,2018,6.31031283629359e-05,2
W2740205663,Chinese Medical Question Answer Matching Using End-to-End Character-Level Multi-Scale CNNs,2017,6.308681053647706e-05,2
W2895351178,Revisiting Correlations between Intrinsic and Extrinsic Evaluations of Word Embeddings,2018,6.308549838525964e-05,2
W3101479482,Generating Label Cohesive and Well-Formed Adversarial Claims,2020,6.296065417836352e-05,2
W3034763191,A Tale of a Probe and a Parser,2020,6.295845941071427e-05,2
W4385573569,Are Large Pre-Trained Language Models Leaking Your Personal Information?,2022,6.292461189294896e-05,2
W2951576127,Incorporating Priors with Feature Attribution on Text Classification,2019,6.290645415207818e-05,2
W3103573410,What Can We Do to Improve Peer Review in NLP?,2020,6.290062003721062e-05,2
W2969624041,Revealing the Dark Secrets of BERT,2019,6.281475977265806e-05,2
W2927599034,Natural Language Processing for the Identification of Silent Brain Infarcts From Neuroimaging Reports,2019,6.280870568643046e-05,2
W2970014349,Human-grounded Evaluations of Explanation Methods for Text Classification,2019,6.278389780680507e-05,2
W3101204082,Are Pretrained Language Models Symbolic Reasoners over Knowledge?,2020,6.277947933044295e-05,2
W3193158708,MT-clinical BERT: scaling clinical information extraction with multitask learning,2021,6.27717726217038e-05,2
W3176393001,Bad Characters: Imperceptible NLP Attacks,2022,6.267248839951766e-05,2
W3130196849,Teach Me to Explain: A Review of Datasets for Explainable NLP.,2021,6.259606323536903e-05,2
W3099729825,Imitation Attacks and Defenses for Black-box Machine Translation Systems,2020,6.258798103667722e-05,2
W3008851394,"Train Large, Then Compress: Rethinking Model Size for Efficient Training and Inference of Transformers",2020,6.256677357687584e-05,2
W2949959978,Understanding Dataset Design Choices for Multi-hop Reasoning,2019,6.253544856200561e-05,2
W3035453001,Ensemble Distillation for Robust Model Fusion in Federated Learning,2020,6.240108813508212e-05,2
W2798819017,Exploring Semantic Properties of Sentence Embeddings,2018,6.238861893420596e-05,2
W3102199783,Learning Numeral Embedding,2020,6.236900253048817e-05,2
W3115511229,LadaBERT: Lightweight Adaptation of BERT through Hybrid Model Compression,2020,6.234015934716924e-05,2
W4292215729,CorpusBrain: Pre-train a Generative Retrieval Model for Knowledge-Intensive Language Tasks,2022,6.23019041457198e-05,2
W2977720775,ZeRO: Memory Optimization Towards Training A Trillion Parameter Models.,2019,6.221350814899088e-05,2
W3206832494,Chimera,2021,6.218885937743e-05,2
W4308590518,Information extraction from electronic medical documents: state of the art and future research directions,2022,6.218348098481556e-05,2
W4221150520,HealthPrompt: A Zero-shot Learning Paradigm for Clinical Natural Language Processing,2022,6.218241255276793e-05,2
W3161374759,Understanding by Understanding Not: Modeling Negation in Language Models,2021,6.207351830628216e-05,2
W3001497429,Universals of word order reflect optimization of grammars for efficient communication,2020,6.201810355853878e-05,2
W4400681340,"Language models, like humans, show content effects on reasoning tasks",2024,6.199256975331617e-05,2
W2979928633,FriendsQA: Open-Domain Question Answering on TV Show Transcripts,2019,6.197999413742585e-05,2
W3173798466,Implicit Representations of Meaning in Neural Language Models,2021,6.191058508003171e-05,2
W3007595536,From static to dynamic word representations: a survey,2020,6.190763071167313e-05,2
W3101118235,CAT-Gen: Improving Robustness in NLP Models via Controlled Adversarial Text Generation,2020,6.189600627636404e-05,2
W3176793246,Can Generative Pre-trained Language Models Serve As Knowledge Bases for Closed-book QA?,2021,6.188917559476448e-05,2
W3125997628,A Survey of Contrastive and Counterfactual Explanation Generation Methods for Explainable Artificial Intelligence,2021,6.187987665984076e-05,2
W2970169050,Event Representation Learning Enhanced with External Commonsense Knowledge,2019,6.187331196872338e-05,2
W3014434762,Conversational Question Reformulation via Sequence-to-Sequence Architectures and Pretrained Language Models,2020,6.182776445665506e-05,2
W2952068915,Embedding Logical Queries on Knowledge Graphs,2018,6.181836359359701e-05,2
W3173788106,Parameter-efficient Multi-task Fine-tuning for Transformers via Shared Hypernetworks,2021,6.178403016497774e-05,2
W4285114657,HLDC: Hindi Legal Documents Corpus,2022,6.17772339147407e-05,2
W3034397670,A Reinforced Generation of Adversarial Examples for Neural Machine Translation,2020,6.173304425018987e-05,2
W3173787059,Self-Attention Attribution: Interpreting Information Interactions Inside Transformer,2021,6.169182889181459e-05,2
W2952354317,XQA: A Cross-lingual Open-domain Question Answering Dataset,2019,6.1671304339442e-05,2
W4383860112,End-to-End Multimodal Fact-Checking and Explanation Generation: A Challenging Dataset and Models,2023,6.164713759112376e-05,2
W4309623083,BERT-Log: Anomaly Detection for System Logs Based on Pre-trained Language Model,2022,6.162068657787934e-05,2
W3035027743,Pretraining with Contrastive Sentence Objectives Improves Discourse Performance of Language Models,2020,6.161563463778593e-05,2
W3040558716,Knowledge-Aware Language Model Pretraining,2020,6.160285844173111e-05,2
W4385572399,Knowledge Unlearning for Mitigating Privacy Risks in Language Models,2023,6.160078761764577e-05,2
W4389518664,Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data,2023,6.154920996671826e-05,2
W4389519044,"Speak, Memory: An Archaeology of Books Known to ChatGPT/GPT-4",2023,6.147514105520701e-05,2
W4386530347,An extensive benchmark study on biomedical text generation and mining with ChatGPT,2023,6.146250252569493e-05,2
W3171416056,TaxoClass: Hierarchical Multi-Label Text Classification Using Only Class Names,2021,6.145133770056554e-05,2
W3088049945,SberQuAD – Russian Reading Comprehension Dataset: Description and Analysis,2020,6.143093670898907e-05,2
W3011794880,Overview of the TREC 2019 deep learning track.,2020,6.142741300652437e-05,2
W2985797697,Understanding Commonsense Inference Aptitude of Deep Contextual Representations,2019,6.142029757476189e-05,2
W3199893015,Pairwise Supervised Contrastive Learning of Sentence Representations,2021,6.135249493968355e-05,2
W3211949750,Neurocomputational Models of Language Processing,2021,6.134781664493277e-05,2
W3169726359,Adaptable and Interpretable Neural MemoryOver Symbolic Knowledge,2021,6.134776521670403e-05,2
W3099524945,IIRC: A Dataset of Incomplete Information Reading Comprehension Questions,2020,6.134169995506524e-05,2
W3105643199,An Empirical Investigation of Contextualized Number Prediction,2020,6.131940803357381e-05,2
W3157651102,Comparing Pre-trained and Feature-Based Models for Prediction of Alzheimer's Disease Based on Speech,2021,6.126402617052376e-05,2
W4387824566,Assessing student errors in experimentation using artificial intelligence and large language models: A comparative study with human raters,2023,6.125436331430038e-05,2
W2907833097,"Learning to Transform, Combine, and Reason in Open-Domain Question Answering",2019,6.12494416315465e-05,2
W3208182228,BERT based clinical knowledge extraction for biomedical knowledge graph construction and analysis,2021,6.12402817832248e-05,2
W2986191653,Cost-Sensitive BERT for Generalisable Sentence Classification on Imbalanced Data,2019,6.119776402944659e-05,2
W3172794097,Robustness Gym: Unifying the NLP Evaluation Landscape,2021,6.119213999514188e-05,2
W3017463390,BioConceptVec: Creating and evaluating literature-based biomedical concept embeddings on a large scale,2020,6.117361829210202e-05,2
W4385573102,Training Language Models with Memory Augmentation,2022,6.111281736534497e-05,2
W4288368497,Shared functional specialization in transformer-based language models and the human brain,2022,6.108531785502163e-05,2
W3099143320,Attention is Not Only a Weight: Analyzing Transformers with Vector Norms,2020,6.105438846945839e-05,2
W3166904074,Adapting natural language processing for technical text,2021,6.103085951176485e-05,2
W4385572952,Interpreting Language Models with Contrastive Explanations,2022,6.102374661264793e-05,2
W3028836324,Multi-task learning for natural language processing in the 2020s: Where are we going?,2020,6.098636608023918e-05,2
W2987215000,On Making Reading Comprehension More Comprehensive,2019,6.097558376069426e-05,2
W3012568767,Enhanced-RCNN: An Efficient Method for Learning Sentence Similarity,2020,6.0953084927078225e-05,2
W3203259592,Provable Limitations of Acquiring Meaning from Ungrounded Form: What Will Future Language Models Understand?,2021,6.091472705865984e-05,2
W3155936402,Frequency-Guided Word Substitutions for Detecting Textual Adversarial Examples,2021,6.089323026648748e-05,2
W3170572542,Concealed Data Poisoning Attacks on NLP Models,2021,6.087376914030513e-05,2
W3100005111,Incorporating Relation Knowledge into Commonsense Reading Comprehension with Multi-task Learning,2019,6.084563075703446e-05,2
W4385572722,RankGen: Improving Text Generation with Large Ranking Models,2022,6.077927594859696e-05,2
W3175864309,X-Fact: A New Benchmark Dataset for Multilingual Fact Checking,2021,6.074804249915171e-05,2
W4353004366,Efficient Long-Text Understanding with Short-Text Models,2023,6.073558939068393e-05,2
W3198980621,A Survey on Recent Named Entity Recognition and Relationship Extraction Techniques on Clinical Texts,2021,6.072704337565134e-05,2
W2964047576,Effective Subword Segmentation for Text Comprehension,2019,6.0699687014103575e-05,2
W4383751019,Machine-Generated Text: A Comprehensive Survey of Threat Models and Detection Methods,2023,6.067247982877401e-05,2
W3103054319,Pareto Probing: Trading Off Accuracy for Complexity,2020,6.062099050437054e-05,2
W3100843744,Entity Linking in 100 Languages,2020,6.061627068554279e-05,2
W3103491646,Robustness to Modification with Shared Words in Paraphrase Identification,2020,6.0597125453651986e-05,2
W2897007327,Patient2Vec: A Personalized Interpretable Deep Representation of the Longitudinal Electronic Health Record,2018,6.056592709459493e-05,2
W3097252660,BERTnesia: Investigating the capture and forgetting of knowledge in BERT,2020,6.0550924654184405e-05,2
W3099756172,FQuAD: French Question Answering Dataset,2020,6.052304592490844e-05,2
W3035733645,WinoWhy: A Deep Diagnosis of Essential Commonsense Knowledge for Answering Winograd Schema Challenge,2020,6.0509473788624205e-05,2
W4306247398,Over-reliance on English hinders cognitive science,2022,6.0498640893152204e-05,2
W3038831159,Relevance-guided Supervision for OpenQA with ColBERT,2020,6.047369952747597e-05,2
W3161987470,Artificial Intelligence in Action: Addressing the COVID-19 Pandemic with Natural Language Processing,2021,6.044746367040246e-05,2
W4221142212,BERN2: an advanced neural biomedical named entity recognition and normalization tool,2022,6.043113127890919e-05,2
W4308294451,Feature-space selection with banded ridge regression,2022,6.04217751814123e-05,2
W4221142755,CAKE: A Scalable Commonsense-Aware Framework For Multi-View Knowledge Graph Completion,2022,6.040898919172989e-05,2
W4385573003,RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning,2022,6.0383630384845555e-05,2
W3117559572,"Aschern at SemEval-2020 Task 11: It Takes Three to Tango: RoBERTa, CRF, and Transfer Learning",2020,6.036393359501318e-05,2
W3005650752,Does BERT need domain adaptation for clinical negation detection?,2020,6.036103721934035e-05,2
W4284880643,Faster Learned Sparse Retrieval with Guided Traversal,2022,6.033871487641783e-05,2
W4206292538,COVID-19 increased censorship circumvention and access to sensitive topics in China,2022,6.029755688391758e-05,2
W4381617132,Constructionist Approaches,2023,6.029755688391758e-05,2
W4391648585,Establishment of the Norwegian Public Relations Club in the Context of the Cold War,2024,6.029755688391758e-05,2
W3153672153,Clinical Outcome Prediction from Admission Notes using Self-Supervised Knowledge Integration,2021,6.028387825594969e-05,2
W3104992282,Learning to Explain: Datasets and Models for Identifying Valid Reasoning Chains in Multihop Question-Answering,2020,6.026895506251947e-05,2
W4385605314,LAnoBERT: System log anomaly detection based on BERT masked language model,2023,6.022118301460638e-05,2
W3000752281,Graph Constrained Reinforcement Learning for Natural Language Action Spaces,2020,6.01249625783612e-05,2
W3159684727,Mechanisms for handling nested dependencies in neural-network language models and humans,2021,6.01242794044083e-05,2
W3103838460,Investigating Transferability in Pretrained Language Models,2020,6.011110835492426e-05,2
W3094024085,Bootleg: Chasing the Tail with Self-Supervised Named Entity Disambiguation,2020,6.010190810741159e-05,2
W3035556416,QuASE: Question-Answer Driven Sentence Encoding,2020,6.00208951361445e-05,2
W3102927624,KorNLI and KorSTS: New Benchmark Datasets for Korean Natural Language Understanding,2020,6.001523591676636e-05,2
W3133665323,Biomedical Named Entity Recognition at Scale,2021,6.0001402615566276e-05,2
W3176825161,Knowledge-driven Data Construction for Zero-shot Evaluation in Commonsense Question Answering,2021,5.999742468599884e-05,2
W3037234229,"Evidence Inference 2.0: More Data, Better Models",2020,5.998643380343788e-05,2
W3176495666,TIMEDIAL: Temporal Commonsense Reasoning in Dialog,2021,5.994322198565035e-05,2
W3030772833,Exploring Transformer Text Generation for Medical Dataset Augmentation.,2020,5.9929155871573124e-05,2
W3170037207,Towards Interpreting and Mitigating Shortcut Learning Behavior of NLU models,2021,5.992185980395976e-05,2
W2808571346,Attention-Fused Deep Matching Network for Natural Language Inference,2018,5.9921813965048545e-05,2
W2949276121,Augmenting Neural Networks with First-order Logic,2019,5.9891267912145905e-05,2
W3105107530,Understanding BERT Rankers Under Distillation,2020,5.986947049718362e-05,2
W3095771422,CharBERT: Character-aware Pre-trained Language Model,2020,5.98644763644005e-05,2
W3099641295,De-Biased Court’s View Generation with Causality,2020,5.9857662788065336e-05,2
W2921848006,To Tune or Not to Tune? Adapting Pretrained Representations to Diverse Tasks,2019,5.984988015656561e-05,2
W3115540322,A Paragraph-level Multi-task Learning Model for Scientific Fact-Verification,2020,5.982996970084592e-05,2
W3202082017,Weakly-supervised Text Classification Based on Keyword Graph,2021,5.9828845016508505e-05,2
W4221143523,Code Synonyms Do Matter: Multiple Synonyms Matching Network for Automatic ICD Coding,2022,5.982439514186365e-05,2
W3106394530,Look before you Hop: Conversational Question Answering over Knowledge Graphs Using Judicious Context Expansion,2019,5.9807111540652316e-05,2
W3177920269,A GPT-2 Language Model for Biomedical Texts in Portuguese,2021,5.9792394236857e-05,2
W4394782456,PMC-LLaMA: toward building open-source language models for medicine,2024,5.976374138452223e-05,2
W4361766487,Why Does Surprisal From Larger Transformer-Based Language Models Provide a Poorer Fit to Human Reading Times?,2023,5.972174163549438e-05,2
W2788751659,Memorize or generalize? Searching for a compositional RNN in a haystack,2018,5.9682307547697516e-05,2
W3215599159,Semantic Structure in Deep Learning,2021,5.9577762665862676e-05,2
W3167829962,Towards BERT-based Automatic ICD Coding: Limitations and Opportunities,2021,5.957095968462647e-05,2
W3104597016,A Wrong Answer or a Wrong Question? An Intricate Relationship between Question Reformulation and Answer Selection in Conversational Question Answering,2020,5.9569310103367774e-05,2
W3210877910,Answering Open-Domain Questions of Varying Reasoning Steps from Text,2021,5.9555875212312544e-05,2
W4287887646,Pretrained Models for Multilingual Federated Learning,2022,5.954883699388248e-05,2
W3174995573,COBERT: COVID-19 Question Answering System Using BERT,2021,5.950650566608769e-05,2
W3103111734,A Deep Cascade Model for Multi-Document Reading Comprehension,2019,5.949071629142124e-05,2
W2989536007,Hierarchical Graph Network for Multi-hop Question Answering,2019,5.947075703197317e-05,2
W3015253856,CLUE: A Chinese Language Understanding Evaluation Benchmark,2020,5.944408115898362e-05,2
W2963614567,Unsupervised Hierarchical Story Infilling,2019,5.944308313160114e-05,2
W3082665562,Understanding the role of individual units in a deep neural network,2020,5.944257574015816e-05,2
W4403499178,Large language models in law: A survey,2024,5.935756266452415e-05,2
W3100468923,Question Answering with Long Multiple-Span Answers,2020,5.930932655914863e-05,2
W4385571564,Patton: Language Model Pretraining on Text-Rich Networks,2023,5.9250132702634204e-05,2
W2784186414,Integrating Prior Knowledge into Deep Learning,2017,5.923734483319458e-05,2
W2964669873,T-CVAE: Transformer-Based Conditioned Variational Autoencoder for Story Completion,2019,5.9207179077955214e-05,2
W3102485638,How well does surprisal explain N400 amplitude under different experimental conditions?,2020,5.9206550468617807e-05,2
W3094444847,TwinBERT,2020,5.919947981329859e-05,2
W4391133530,Performance of 4 Pre-Trained Sentence Transformer Models in the Semantic Query of a Systematic Review Dataset on Peri-Implantitis,2024,5.9191428724588094e-05,2
W3034560159,AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural Architecture Search,2020,5.914559449725015e-05,2
W3103662468,STORIUM: A Dataset and Evaluation Platform for Machine-in-the-Loop Story Generation,2020,5.912498127301274e-05,2
W3154186000,ExplaGraphs: An Explanation Graph Generation Task for Structured Commonsense Reasoning,2021,5.899029864601589e-05,2
W3105959138,How Effective is Task-Agnostic Data Augmentation for Pretrained Transformers?,2020,5.89885885545307e-05,2
W3103934057,T3: Tree-Autoencoder Constrained Adversarial Text Generation for Targeted Attack,2020,5.894603449468077e-05,2
W3102762626,Self-Supervised Knowledge Triplet Learning for Zero-Shot Question Answering,2020,5.892401060825999e-05,2
W2963197830,What if We Simply Swap the Two Text Fragments? A Straightforward yet Effective Way to Test the Robustness of Methods to Confounding Signals in Nature Language Inference Tasks,2019,5.888782134894817e-05,2
W4389205282,Zero-shot interpretable phenotyping of postpartum hemorrhage using large language models,2023,5.887809184556524e-05,2
W4385573298,Revisiting Transformer-based Models for Long Document Classification,2022,5.886869328703708e-05,2
W3034987253,RikiNet: Reading Wikipedia Pages for Natural Question Answering,2020,5.880170274663688e-05,2
W3116231956,Hitachi at SemEval-2020 Task 11: An Empirical Study of Pre-Trained Transformer Family for Propaganda Detection,2020,5.879425757025997e-05,2
W4393147129,Benchmarking Large Language Models in Retrieval-Augmented Generation,2024,5.879180450412571e-05,2
W3175591618,Explanations for CommonsenseQA: New Dataset and Models,2021,5.8775913761230315e-05,2
W3105295588,Hierarchical Evidence Set Modeling for Automated Fact Extraction and Verification,2020,5.873258008613011e-05,2
W4295065948,Arabic machine reading comprehension on the Holy Qur’an using CL-AraBERT,2022,5.870586264057097e-05,2
W3003485993,Multi-hop Knowledge Base Question Answering with an Iterative Sequence Matching Model,2019,5.8653323227163455e-05,2
W2988346595,ERASER: A Benchmark to Evaluate Rationalized NLP Models,2019,5.8643362300728495e-05,2
W2970928735,Adversarial Domain Adaptation for Machine Reading Comprehension,2019,5.862273500773684e-05,2
W2970746059,A Logic-Driven Framework for Consistency of Neural Models,2019,5.862268483710298e-05,2
W4225632115,Language Models as Knowledge Embeddings,2022,5.861278493732548e-05,2
W2963863610,On Tree-Based Neural Sentence Modeling,2018,5.859967310000627e-05,2
W3102749280,Thinking Like a Skeptic: Defeasible Inference in Natural Language,2020,5.859393395430789e-05,2
W2936405048,Pun Generation with Surprise,2019,5.857861225581005e-05,2
W3177450194,Language Model Evaluation Beyond Perplexity,2021,5.853143143741838e-05,2
W4393277515,Exploring the Potential of Large Language Models (LLMs)in Learning on Graphs,2024,5.8507297154416634e-05,2
W4385567522,Neighborhood Contrastive Learning for Scientific Document Representations with Citation Embeddings,2022,5.847313395304021e-05,2
W4385571291,Pre-trained Language Models Can be Fully Zero-Shot Learners,2023,5.8439363725417895e-05,2
W4393156804,FlexKBQA: A Flexible LLM-Powered Framework for Few-Shot Knowledge Base Question Answering,2024,5.84349528189464e-05,2
W3035099133,Contextualized Sparse Representations for Real-Time Open-Domain Question Answering,2020,5.84320981841417e-05,2
W4287891033,Prompt Waywardness: The Curious Case of Discretized Interpretation of Continuous Prompts,2022,5.842270988272479e-05,2
W3035164567,R4C: A Benchmark for Evaluating RC Systems to Get the Right Answer for the Right Reason,2020,5.837211658322306e-05,2
W4200455899,Deep learning for patent landscaping using transformer and graph embedding,2021,5.8369621498657236e-05,2
W4311501806,Information flow across the cortical timescale hierarchy during narrative construction,2022,5.836035739857787e-05,2
W3118608099,BERT & Family Eat Word Salad: Experiments with Text Understanding,2021,5.831728791598628e-05,2
W2971134012,Improving Answer Selection and Answer Triggering using Hard Negatives,2019,5.829645260704185e-05,2
W4293463901,Probabilistic atlas for the language network based on precision fMRI data from &gt;800 individuals,2022,5.828978703180027e-05,2
W3155744586,Probing the Probing Paradigm: Does Probing Accuracy Entail Task Relevance?,2021,5.8281952842950544e-05,2
W4205456754,R2-D2: A Modular Baseline for Open-Domain Question Answering,2021,5.8274407989649055e-05,2
W3100071090,Open Domain Question Answering based on Text Enhanced Knowledge Graph with Hyperedge Infusion,2020,5.825679522071497e-05,2
W2996681978,Graph Constrained Reinforcement Learning for Natural Language Action Spaces,2020,5.819972762297167e-05,2
W4319079731,SecureBERT: A Domain-Specific Language Model for Cybersecurity,2023,5.8177252942938034e-05,2
W3006188107,Transformers as Soft Reasoners over Language,2020,5.815528279162627e-05,2
W2970501962,Machine Reading Comprehension Using Structural Knowledge Graph-aware Network,2019,5.8151943530310664e-05,2
W2970636124,FINBERT: FINANCIAL SENTIMENT ANALYSIS WITH PRE-TRAINED LANGUAGE MODELS,2019,5.8146775811643886e-05,2
W3213921583,Incorporating medical knowledge in BERT for clinical relation extraction,2021,5.8136522139604394e-05,2
W3035850279,Learning Dynamic Belief Graphs to Generalize on Text-Based Games,2020,5.81268772853624e-05,2
W3031043369,WorldTree V2: A corpus of science-domain structured explanations and inference patterns supporting multi-hop inference,2020,5.8119872698468575e-05,2
W3176549216,How effective is BERT without word ordering? Implications for language understanding and data privacy,2021,5.811510448115643e-05,2
W2955845608,Hierarchical Matching Network for Crime Classification,2019,5.810147927624055e-05,2
W3176546569,Zero-shot Fact Verification by Claim Generation,2021,5.8095650943181036e-05,2
W2984450720,Pingan Smart Health and SJTU at COIN - Shared Task: utilizing Pre-trained Language Models and Common-sense Knowledge in Machine Reading Tasks,2019,5.807451053272955e-05,2
W4385572928,Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space,2022,5.804065192735064e-05,2
W2970254524,Reconstructing Capsule Networks for Zero-shot Intent Classification,2019,5.803282008374851e-05,2
W4389105137,Overview of DrugProt task at BioCreative VII: data and methods for large-scale text mining and knowledge graph generation of heterogenous chemical–protein relations,2023,5.8024861121335925e-05,2
W4381956875,Matching Exemplar as Next Sentence Prediction (MeNSP): Zero-Shot Prompt Learning for Automatic Scoring in Science Education,2023,5.8019478045656325e-05,2
W3035408713,DeFormer: Decomposing Pre-trained Transformers for Faster Question Answering,2020,5.8019087142919184e-05,2
W3118831779,The Expando-Mono-Duo Design Pattern for Text Ranking with Pretrained Sequence-to-Sequence Models,2021,5.7989937308527265e-05,2
W3124034626,Predicting Inductive Biases of Pre-Trained Models,2021,5.7989796315016494e-05,2
W3198690080,Evaluating the Robustness of Neural Language Models to Input Perturbations,2021,5.795109950491107e-05,2
W3213748474,DeepRhole: deep learning for rhetorical role labeling of sentences in legal case documents,2021,5.7932826598532176e-05,2
W3201254286,Phrase-BERT: Improved Phrase Embeddings from BERT with an Application to Corpus Exploration,2021,5.7928514351668115e-05,2
W3199824684,CPT: a pre-trained unbalanced transformer for both Chinese language understanding and generation,2024,5.7913737407076386e-05,2
W3115913034,Task-Aware Representation of Sentences for Generic Text Classification,2020,5.7908876485190106e-05,2
W3035064549,Cross-Linguistic Syntactic Evaluation of Word Prediction Models,2020,5.7877430741515876e-05,2
W2977268464,Comparing gated and simple recurrent neural network architectures as models of human sentence processing,2018,5.785031515373057e-05,2
W3034873522,Obtaining Faithful Interpretations from Compositional Neural Networks,2020,5.7829130700481747e-05,2
W4392606373,Beyond Words: A Comparative Analysis of LLM Embeddings for Effective Clustering,2024,5.776158756107688e-05,2
W3104602136,AnswerFact: Fact Checking in Product Question Answering,2020,5.7747813333750204e-05,2
W4392357044,A Survey of Knowledge Enhanced Pre-trained Language Models,2024,5.772985084554746e-05,2
W4315643106,Lexical knowledge enhanced text matching via distilled word sense disambiguation,2023,5.772845893366619e-05,2
W3170962005,Lattice-BERT: Leveraging Multi-Granularity Representations in Chinese Pre-trained Language Models,2021,5.771728206582938e-05,2
W3004088204,Deep Learning for Natural Language Processing in Radiology—Fundamentals and a Systematic Review,2020,5.7711511673490934e-05,2
W3161820423,A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers,2021,5.766658383850337e-05,2
W2756946152,Deconvolutional Latent-Variable Model for Text Sequence Matching,2018,5.766595830386043e-05,2
W2903285529,Practical Text Classification With Large Pre-Trained Language Models,2018,5.765380300541772e-05,2
W4226252996,Eliciting Knowledge from Pretrained Language Models for Prototypical Prompt Verbalizer,2022,5.764276029559391e-05,2
W3117163888,UPB at SemEval-2020 Task 11: Propaganda Detection with Domain-Specific Trained BERT,2020,5.762386426811629e-05,2
W2984208213,Fine-Grained Propaganda Detection with Fine-Tuned BERT,2019,5.7610464797320965e-05,2
W3207604732,DialFact: A Benchmark for Fact-Checking in Dialogue,2022,5.7576948333770174e-05,2
W3121064530,Revisiting Mahalanobis Distance for Transformer-Based Out-of-Domain Detection,2021,5.756996418102822e-05,2
W3083835029,Generative Language Modeling for Automated Theorem Proving.,2020,5.7561840293426515e-05,2
W3189827190,Knowledge-aware Zero-Shot Learning: Survey and Perspective,2021,5.746936293907722e-05,2
W3024566755,Machine Reading Comprehension: The Role of Contextualized Language Models and Beyond,2020,5.7461993457975374e-05,2
W3177156688,Leveraging Type Descriptions for Zero-shot Named Entity Recognition and Classification,2021,5.7451827530182796e-05,2
W3153051631,Representations for Question Answering from Documents with Tables and Text,2021,5.7439578140446165e-05,2
W3173784240,Rethinking Stealthiness of Backdoor Attack against NLP Models,2021,5.740196354371227e-05,2
W4287855143,Learning to Retrieve Passages without Supervision,2022,5.7397802521080805e-05,2
W3175987672,Are Larger Pretrained Language Models Uniformly Better? Comparing Performance at the Instance Level,2021,5.736041953861334e-05,2
W4200444669,Learning from Disagreement: A Survey,2021,5.730387510211198e-05,2
W3165066581,CSKG: The CommonSense Knowledge Graph,2021,5.729572550414222e-05,2
W3100618740,Question Directed Graph Attention Network for Numerical Reasoning over Text,2020,5.729367368017468e-05,2
W4205137784,A Survey on Machine Reading Comprehension Systems,2022,5.722695546468187e-05,2
W4392283598,Large-scale evidence for logarithmic effects of word predictability on reading time,2024,5.7221925497976054e-05,2
W4206958985,Improving complex knowledge base question answering via structural information learning,2022,5.71453109882373e-05,2
W2970789589,Distributionally Robust Language Modeling,2019,5.713273681933423e-05,2
W3211777899,SituatedQA: Incorporating Extra-Linguistic Contexts into QA,2021,5.7121058787830057e-05,2
W2966774251,Knowledgeable Storyteller: A Commonsense-Driven Generative Model for Visual Storytelling,2019,5.711019356170642e-05,2
W4297903189,ReLMKG: reasoning with pre-trained language models and knowledge graphs for complex question answering,2022,5.708634975168977e-05,2
W2798966449,Generating Natural Language Adversarial Examples,2018,5.7081001680161115e-05,2
W2962782614,Text Processing Like Humans Do: Visually Attacking and Shielding,2019,5.707105656767773e-05,2
W2924606678,Argument Mining for Understanding Peer Reviews,2019,5.7044362788176946e-05,2
W3198490223,Label Verbalization and Entailment for Effective Zero and Few-Shot Relation Extraction,2021,5.704052942226046e-05,2
W3185326432,SemEval-2021 Task 11: NLPContributionGraph - Structuring Scholarly NLP Contributions for a Research Knowledge Graph,2021,5.703498243361517e-05,2
W4385571915,SimLM: Pre-training with Representation Bottleneck for Dense Passage Retrieval,2023,5.702123367558014e-05,2
W4285107714,Data Contamination: From Memorization to Exploitation,2022,5.6990237709485486e-05,2
W4310157637,Combining computational controls with natural text reveals aspects of meaning composition,2022,5.697619284109897e-05,2
W3117738520,Syntactic Structure Distillation Pretraining for Bidirectional Encoders,2020,5.695735233627816e-05,2
W3016263386,LadaBERT: Lightweight Adaptation of BERT through Hybrid Model Compression,2020,5.69542882409204e-05,2
W4399932275,CBR-RAG: Case-Based Reasoning for Retrieval Augmented Generation in LLMs for Legal Question Answering,2024,5.694172240990037e-05,2
W3138301265,Infusing Finetuning with Semantic Dependencies,2021,5.693036867770177e-05,2
W3092642435,InfoBERT: Improving Robustness of Language Models from An Information Theoretic Perspective,2020,5.6923737032006115e-05,2
W2983004086,"What do you mean, BERT? Assessing BERT as a Distributional Semantics Model",2019,5.6864833414330904e-05,2
W4281765107,Cross-domain multi-task learning for sequential sentence classification in research papers,2022,5.6855213124574e-05,2
W3169993339,Temporal Reasoning on Implicit Events from Distant Supervision,2021,5.679415312277252e-05,2
W3116099552,PharmKG: a dedicated knowledge graph benchmark for bomedical data mining,2020,5.679283708677249e-05,2
W4393156546,MedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models,2024,5.677774937966508e-05,2
W4400872202,Lingdan: enhancing encoding of traditional Chinese medicine knowledge for clinical reasoning tasks with large language models,2024,5.677774937966508e-05,2
W3152497014,Factual Probing Is [MASK]: Learning vs. Learning to Recall,2021,5.675526271076881e-05,2
W4385573468,Improved Universal Sentence Embeddings with Prompt-based Contrastive Learning and Energy-based Learning,2022,5.675119615206722e-05,2
W4224863259,KALA: Knowledge-Augmented Language Model Adaptation,2022,5.674847235516062e-05,2
W3081505754,Conceptualized Representation Learning for Chinese Biomedical Text Mining,2020,5.6745757746348076e-05,2
W3153632605,SICK-NL: A Dataset for Dutch Natural Language Inference,2021,5.674352788161579e-05,2
W3173188814,Bootstrapped Unsupervised Sentence Representation Learning,2021,5.6740044953592324e-05,2
W3175475697,Multi-Task Retrieval for Knowledge-Intensive Tasks,2021,5.673551369075002e-05,2
W2912907847,Automatic ICD code assignment of Chinese clinical notes based on multilayer attention BiRNN,2019,5.6727680370979514e-05,2
W3010108619,CLUECorpus2020: A Large-scale Chinese Corpus for Pre-training Language Model,2020,5.663305547431264e-05,2
W3174114019,Challenges in Information-Seeking QA: Unanswerable Questions and Paragraph Retrieval,2021,5.663232397938199e-05,2
W3035097102,Do Neural Models Learn Systematicity of Monotonicity Inference in Natural Language?,2020,5.6611012389337634e-05,2
W3034555021,ExpBERT: Representation Engineering with Natural Language Explanations,2020,5.660160514806647e-05,2
W3105601216,Inexpensive Domain Adaptation of Pretrained Language Models: Case Studies on Biomedical NER and Covid-19 QA,2020,5.6551820557961715e-05,2
W3087273879,Generation-Augmented Retrieval for Open-domain Question Answering,2020,5.6532684571329345e-05,2
W2995744795,Are Transformers universal approximators of sequence-to-sequence functions?,2019,5.6524969343485176e-05,2
W3121419306,Toward Using Twitter for Tracking COVID-19: A Natural Language Processing Pipeline and Exploratory Data Set,2021,5.651652174638825e-05,2
W2913293259,An Efficient Framework for Sentence Similarity Modeling,2019,5.649773011026699e-05,2
W4389519535,SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization,2023,5.648880486803693e-05,2
W4285149549,Adversarial Soft Prompt Tuning for Cross-Domain Sentiment Analysis,2022,5.645976450525856e-05,2
W3116216579,Do Neural Language Models Overcome Reporting Bias?,2020,5.645793258116482e-05,2
W3091091747,A BERT-based Approach with Relation-aware Attention for Knowledge Base Question Answering,2020,5.645207851942716e-05,2
W3177415603,Efficient Passage Retrieval with Hashing for Open-domain Question Answering,2021,5.645120857566968e-05,2
W4308791833,Improving embedded knowledge graph multi-hop question answering by introducing relational chain reasoning,2022,5.643428404339294e-05,2
W2984124903,A Review of Automated Speech and Language Features for Assessment of Cognitive and Thought Disorders,2019,5.643013890920459e-05,2
W4385570306,Ranking-Enhanced Unsupervised Sentence Representation Learning,2023,5.642326144923066e-05,2
W3096150021,Sentiment Analysis for Software Engineering: How Far Can Pre-trained Transformer Models Go?,2020,5.640859678710977e-05,2
W4395050972,Optimization of hepatological clinical guidelines interpretation by large language models: a retrieval augmented generation-based framework,2024,5.63096346731039e-05,2
W2951181836,TWEETQA: A Social Media Focused Question Answering Dataset,2019,5.628617076930623e-05,2
W4309483299,Semantic matching in machine reading comprehension: An empirical study,2022,5.625613469952566e-05,2
W4284685693,Curriculum Contrastive Context Denoising for Few-shot Conversational Dense Retrieval,2022,5.617453308694325e-05,2
W3111425437,Distilling Knowledge from Reader to Retriever for Question Answering,2020,5.616312768317409e-05,2
W3104613320,TopicBERT for Energy Efficient Document Classification,2020,5.6140337517249475e-05,2
W2971531230,The Bottom-up Evolution of Representations in the Transformer: A Study with Machine Translation and Language Modeling Objectives,2019,5.613091344148347e-05,2
W3212804087,BERT might be Overkill: A Tiny but Effective Biomedical Entity Linker based on Residual Convolutional Neural Networks,2021,5.612583897932862e-05,2
W2985482647,Commonsense Inference in Natural Language Processing (COIN) - Shared Task Report,2019,5.6114429490598426e-05,2
W3034256339,Roles and Utilization of Attention Heads in Transformer-based Neural Language Models,2020,5.6088127272286035e-05,2
W4385782731,Exploring the state of the art in legal QA systems,2023,5.607500782151379e-05,2
W4224134764,WikiDiverse: A Multimodal Entity Linking Dataset with Diversified Contextual Topics and Entity Types,2022,5.607500782151379e-05,2
W3037624666,The Microsoft Toolkit of Multi-Task Deep Neural Networks for Natural Language Understanding,2020,5.6074015319504785e-05,2
W4312091558,Predicting dementia from spontaneous speech using large language models,2022,5.607121442528905e-05,2
W2900874631,Attentive Convolution: Equipping CNNs with RNN-style Attention Mechanisms,2018,5.5992955948112e-05,2
W3034712001,GraphFlow: Exploiting Conversation Flow with Graph Neural Networks for Conversational Machine Comprehension,2020,5.597574214230763e-05,2
W4230262515,BeliefBank: Adding Memory to a Pre-Trained Language Model for a Systematic Notion of Belief,2021,5.591865122150699e-05,2
W4205725534,Types of Out-of-Distribution Texts and How to Detect Them,2021,5.590071239924931e-05,2
W3175360850,Rationale-Inspired Natural Language Explanations with Commonsense.,2021,5.5872971763209895e-05,2
W3213014097,BabyBERTa: Learning More Grammar With Small-Scale Child-Directed Language,2021,5.586754274489743e-05,2
W4310645210,Hi-BEHRT: Hierarchical Transformer-Based Model for Accurate Prediction of Clinical Events Using Multimodal Longitudinal Electronic Health Records,2022,5.586748961786002e-05,2
W3014568172,FastBERT: a Self-distilling BERT with Adaptive Inference Time,2020,5.585881384902286e-05,2
W3098371839,SubjQA: A Dataset for Subjectivity and Review Comprehension,2020,5.5813236413030377e-05,2
W4385163750,"Few-shot learning for medical text: A review of advances, trends, and opportunities",2023,5.5776944141431014e-05,2
W4225580830,Subgraph Retrieval Enhanced Model for Multi-hop Knowledge Base Question Answering,2022,5.5769145231988275e-05,2
W2971142670,Adapting Meta Knowledge Graph Information for Multi-Hop Reasoning over Few-Shot Relations,2019,5.5759897609725025e-05,2
W3116103312,Explaining NLP Models via Minimal Contrastive Editing (MiCE),2020,5.5752268212711e-05,2
W4385573504,Active Example Selection for In-Context Learning,2022,5.569409740416077e-05,2
W3179963059,Benchmarking for biomedical natural language processing tasks with a domain specific ALBERT,2022,5.5630191868928834e-05,2
W3215317537,Med-BERT: A Pretraining Framework for Medical Records Named Entity Recognition,2021,5.558910786467951e-05,2
W4290738699,Thirty years of artificial intelligence and law: the third decade,2022,5.5568384205094315e-05,2
W3018732874,Contextualized Representations Using Textual Encyclopedic Knowledge,2020,5.552390203978804e-05,2
W4390571036,Driving and suppressing the human language network using large language models,2024,5.549130973739533e-05,2
W3104313653,The Explanation Game: Towards Prediction Explainability through Sparse Communication,2020,5.54818455853541e-05,2
W3109919947,Identification of Semantically Similar Sentences in Clinical Notes: Iterative Intermediate Training Using Multi-Task Learning,2020,5.547147403058658e-05,2
W3137214022,All NLP Tasks Are Generation Tasks: A General Pretraining Framework,2021,5.545966818201228e-05,2
W3091406553,Leveraging Semantic and Lexical Matching to Improve the Recall of Document Retrieval Systems: A Hybrid Approach.,2020,5.544113869207879e-05,2
W3169113923,WuDaoCorpora: A super large-scale Chinese corpora for pre-training language models,2021,5.5412413931690645e-05,2
W2997561853,MMM: Multi-Stage Multi-Task Learning for Multi-Choice Reading Comprehension,2020,5.5382486574659856e-05,2
W2963351454,Studying the Inductive Biases of,2019,5.536496745447247e-05,2
W3092185277,A Mathematical Exploration of Why Language Models Help Solve Downstream Tasks,2020,5.535039513170137e-05,2
W3037116584,Interpretability and Analysis in Neural NLP,2020,5.534822269208988e-05,2
W2998696444,oLMpics -- On what Language Model Pre-training Captures,2019,5.531792723920726e-05,2
W4385571309,I2D2: Inductive Knowledge Distillation with NeuroLogic and Self-Imitation,2023,5.5312444308485635e-05,2
W4229377239,"Knowledge graphs: Introduction, history, and perspectives",2022,5.5301992107547365e-05,2
W4385734222,Distinguishing Fact from Fiction: A Benchmark Dataset for Identifying Machine-Generated Scientific Papers in the LLM Era.,2023,5.529842719935648e-05,2
W2998112083,Automatic Fact-Guided Sentence Modification,2020,5.5242208812270884e-05,2
W4285022096,Correspondence between the layered structure of deep language models and temporal structure of natural language processing in the human brain,2022,5.522794276544945e-05,2
W3176119108,Few-Shot Question Answering by Pretraining Span Selection,2021,5.5205985091752376e-05,2
W3182778088,Turning Tables: Generating Examples from Semi-structured Tables for Endowing Language Models with Reasoning Skills,2022,5.51943128227823e-05,2
W4389921502,Dense Text Retrieval Based on Pretrained Language Models: A Survey,2023,5.518424179908643e-05,2
W3184477871,SemEval-2021 Task 9: Fact Verification and Evidence Finding for Tabular Data in Scientific Documents (SEM-TAB-FACTS),2021,5.51408407648494e-05,2
W2946345909,ERNIE: Enhanced Language Representation with Informative Entities,2019,5.513384399063502e-05,2
W3106378800,LibKGE - A knowledge graph embedding library for reproducible research,2020,5.513022286805505e-05,2
W3044812140,Conformer-Kernel with Query Term Independence for Document Retrieval.,2020,5.511740196440444e-05,2
W4385570040,"Don’t Generate, Discriminate: A Proposal for Grounding Language Models to Real-World Environments",2023,5.5115838155929986e-05,2
W3203283460,LiterallyWikidata - A Benchmark for Knowledge Graph Completion Using Literals,2021,5.511244822663197e-05,2
W4226112939,Transfer Learning Approaches for Building Cross-Language Dense Retrieval Models,2022,5.5109958536968986e-05,2
W4287891024,On Transferability of Prompt Tuning for Natural Language Processing,2022,5.5107850421596167e-05,2
W3136558904,Communicating artificial neural networks develop efficient color-naming systems,2021,5.509609267154577e-05,2
W3100501376,With Little Power Comes Great Responsibility,2020,5.507562723200171e-05,2
W2981828710,Thieves on Sesame Street! Model Extraction of BERT-based APIs,2019,5.5050621028070653e-05,2
W4385569933,Can LMs Learn New Entities from Descriptions? Challenges in Propagating Injected Knowledge,2023,5.504261531271897e-05,2
W4236738970,Proceedings of the Seventh Workshop on Computational Linguistics and Clinical Psychology: Improving Access,2021,5.5021337262114246e-05,2
W4224865658,Pre-train a Discriminative Text Encoder for Dense Retrieval via Contrastive Span Prediction,2022,5.502048048882067e-05,2
W3105639882,RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark,2020,5.499857253114739e-05,2
W2973154071,SciBERT: A Pretrained Language Model for Scientific Text,2019,5.498783448636435e-05,2
W4385848332,Enhancing phenotype recognition in clinical notes using large language models: PhenoBCBERT and PhenoGPT,2023,5.498618911155665e-05,2
W3106954555,How Can We Know When Language Models Know,2020,5.490743732311707e-05,2
W3034912286,Probing Neural Language Models for Human Tacit Assumptions,2020,5.490235676430402e-05,2
W3043372854,Meta-learning for Few-shot Natural Language Processing: A Survey,2020,5.490071890738614e-05,2
W3046467166,Pairwise Multi-Class Document Classification for Semantic Relations between Wikipedia Articles,2020,5.489796778173198e-05,2
W4284674178,Explainable Legal Case Matching via Inverse Optimal Transport-based Rationale Extraction,2022,5.489004015432089e-05,2
W3034174970,Unsupervised Alignment-based Iterative Evidence Retrieval for Multi-hop Question Answering,2020,5.488954804122366e-05,2
W3209214366,Gophormer: Ego-Graph Transformer for Node Classification,2021,5.483193758451799e-05,2
W3105057865,Interpretable Entity Representations through Large-Scale Typing,2020,5.482694438509365e-05,2
W4313563649,PRCBERT: Prompt Learning for Requirement Classification using BERT-based Pretrained Language Models,2022,5.481007301684147e-05,2
W4310529830,Can language models automate data wrangling?,2022,5.480536505705005e-05,2
W4391126287,Evaluating the ChatGPT family of models for biomedical reasoning and classification,2024,5.4796018185678436e-05,2
W2949579048,Visually Grounded Neural Syntax Acquisition,2019,5.47953021044858e-05,2
W4385571831,Distilling Reasoning Capabilities into Smaller Language Models,2023,5.478699809878507e-05,2
W4388776291,Relphormer: Relational Graph Transformer for Knowledge Graph Representations,2023,5.475216249375305e-05,2
W4309267672,Deep lexical hypothesis: Identifying personality structure in natural language.,2022,5.4731726464436365e-05,2
W3174082608,BERT is to NLP what AlexNet is to CV: Can Pre-Trained Language Models Identify Analogies?,2021,5.4730598178851856e-05,2
W3136215575,Multilingual Autoregressive Entity Linking,2022,5.47163379843358e-05,2
W4205924343,Can NLI Models Verify QA Systems’ Predictions?,2021,5.46767979746518e-05,2
W3166444100,Differentiable Open-Ended Commonsense Reasoning,2021,5.4655220326916296e-05,2
W4399803256,Detecting hallucinations in large language models using semantic entropy,2024,5.460166911832505e-05,2
W3039578880,Facts as Experts: Adaptable and Interpretable Neural Memory over Symbolic Knowledge,2020,5.458158023665619e-05,2
W3190540921,DEMix Layers: Disentangling Domains for Modular Language Modeling,2022,5.455300883314376e-05,2
W3101033885,Adversarial Semantic Collisions,2020,5.45119609583198e-05,2
W3200809495,Frequency Effects on Syntactic Rule Learning in Transformers,2021,5.4509377246671404e-05,2
W4317892547,Computational Language Modeling and the Promise of In Silico Experimentation,2023,5.446674695560776e-05,2
W2904664992,DRr-Net: Dynamic Re-Read Network for Sentence Semantic Matching,2019,5.446290766723733e-05,2
W4225156065,On the Effect of Pretraining Corpora on In-context Learning by a Large-scale Language Model,2022,5.4457725356072824e-05,2
W3093553144,UmlsBERT: Clinical Domain Knowledge Augmentation of Contextual Embeddings Using the Unified Medical Language System Metathesaurus,2020,5.444272522092946e-05,2
W4283452667,CHEF: A Pilot Chinese Dataset for Evidence-Based Fact-Checking,2022,5.443925873860373e-05,2
W3103252405,Generating similes effortlessly like a Pro: A Style Transfer Approach for Simile Generation,2020,5.441723587421037e-05,2
W2889048825,Large-scale Cloze Test Dataset Created by Teachers,2018,5.4408490585506204e-05,2
W3032232719,LEDGAR : a large-scale multi-label corpus for text classification of legal provisions in contracts,2020,5.43873427774888e-05,2
W3098873988,Fully Quantized Transformer for Machine Translation,2020,5.43514736088246e-05,2
W4285310604,Data Augmentation for Intent Classification with Off-the-shelf Large Language Models,2022,5.4351123649421616e-05,2
W3161381829,"Text Analysis for Psychology: Methods, Principles, and Practices",2021,5.434731049502734e-05,2
W2949818215,HEAD-QA: A Healthcare Dataset for Complex Reasoning,2019,5.4331101588025744e-05,2
W3086456409,Filling the Gap of Utterance-aware and Speaker-aware Representation for Multi-turn Dialogue,2021,5.4319717173123655e-05,2
W4386947298,Prognostic models of in-hospital mortality of intensive care patients using neural representation of unstructured text: A systematic review and critical appraisal,2023,5.431815392613557e-05,2
W3037763555,Commonsense Reasoning for Natural Language Processing,2020,5.4303087916275536e-05,2
W3110926788,Prediction of Stroke Outcome Using Natural Language Processing-Based Machine Learning of Radiology Report of Brain MRI,2020,5.4292410061099484e-05,2
W3115897805,Predicting mortality in critically ill patients with diabetes using machine learning and clinical notes,2020,5.423243134085978e-05,2
W3168355451,Modeling Fine-Grained Entity Types with Box Embeddings,2021,5.42321284259315e-05,2
W4212902066,Representation Learning for Natural Language Processing,2020,5.422098423968058e-05,2
W4394743141,Evaluating the Ripple Effects of Knowledge Editing in Language Models,2024,5.4159194872571226e-05,2
W2946545670,Story Ending Prediction by Transferable BERT,2019,5.414768242461021e-05,2
W4294969216,BERT &amp; Family Eat Word Salad: Experiments with Text Understanding,2021,5.413226012396e-05,2
W3176693244,Evaluating Entity Disambiguation and the Role of Popularity in Retrieval-Based NLP,2021,5.41206197128953e-05,2
W4392919908,LeanContext: Cost-efficient domain-specific question answering using LLMs,2024,5.410770584515137e-05,2
W4295942986,The AI‐IP: Minimizing the guesswork of personality scale item development through artificial intelligence,2022,5.410054585754372e-05,2
W3110879614,On the Systematicity of Probing Contextualized Word Representations: The Case of Hypernymy in BERT,2020,5.4098186143627174e-05,2
W2937531012,Exploring Unsupervised Pretraining and Sentence Structure Modelling for Winograd Schema Challenge,2019,5.40974995887719e-05,2
W4376876984,An empirical study of pre-trained language models in simple knowledge graph question answering,2023,5.407812304789721e-05,2
W4205537036,Probing Across Time: What Does RoBERTa Know and When?,2021,5.405030917419784e-05,2
W3020206637,Recent Trends in Deep Learning Based Open-Domain Textual Question Answering Systems,2020,5.4036466004746045e-05,2
W4393343917,Alignment of brain embeddings and artificial contextual embeddings in natural language points to common geometric patterns,2024,5.402667374657852e-05,2
W2773143256,A deep network model for paraphrase detection in short text messages,2018,5.401492208230164e-05,2
W2993303751,Requirements Classification with Interpretable Machine Learning and Dependency Parsing,2019,5.397857798378321e-05,2
W4393021028,Foresight—a generative pretrained transformer for modelling of patient timelines using electronic health records: a retrospective modelling study,2024,5.394536253051209e-05,2
W4280583915,e-CARE: a New Dataset for Exploring Explainable Causal Reasoning,2022,5.39370616713983e-05,2
W3004117589,Are Pre-trained Language Models Aware of Phrases? Simple but Strong Baselines for Grammar Induction,2020,5.391365752640669e-05,2
W3035336738,Knowledge Graph-based Event Embedding Framework for Financial Quantitative Investments,2020,5.3831418753914675e-05,2
W4313215605,Constructing and analyzing domain-specific language model for financial text mining,2022,5.38203786557784e-05,2
W3089631405,Evaluating Models' Local Decision Boundaries via Contrast Sets,2020,5.3810771552537464e-05,2
W3173825754,Evidence-based Factual Error Correction,2021,5.3780405466427e-05,2
W4206294441,Contrastive Explanations for Model Interpretability,2021,5.375005306447983e-05,2
W4286905174,Salient Phrase Aware Dense Retrieval: Can a Dense Retriever Imitate a Sparse One?,2022,5.3745097008289146e-05,2
W4385571645,Contrastive Decoding: Open-ended Text Generation as Optimization,2023,5.3744696769579946e-05,2
W4388132131,Can ChatGPT Replace Traditional KBQA Models? An In-Depth Analysis of the Question Answering Performance of the GPT LLM Family,2023,5.373471559891954e-05,2
W4389520758,Query2doc: Query Expansion with Large Language Models,2023,5.37320722414312e-05,2
W2557579533,Deep Variational Information Bottleneck,2016,5.370735426744603e-05,2
W3034350582,Generating Hierarchical Explanations on Text Classification via Feature Interaction Detection,2020,5.370692408440237e-05,2
W3127227595,Measuring and Improving Consistency in Pretrained Language Models,2021,5.370347633441519e-05,2
W3139164912,Complex Factoid Question Answering with a Free-Text Knowledge Graph,2020,5.3650617751850016e-05,2
W3212725701,Less is More: Pretrain a Strong Siamese Encoder for Dense Text Retrieval Using a Weak Decoder,2021,5.362160298845902e-05,2
W3035451094,Using Language Processing and Speech Analysis for the Identification of Psychosis and Other Disorders,2020,5.361869929895472e-05,2
W3129965309,Deep Learning-Based Knowledge Graph Generation for COVID-19,2021,5.3615412367984277e-05,2
W3215981572,Unsupervised Topic Discovery in User Comments,2021,5.3615412367984277e-05,2
W3161222848,An NLP-Based Architecture for the Autocompletion of Partial Domain Models,2021,5.3611425999297875e-05,2
W3162404768,Counterfactual Interventions Reveal the Causal Effect of Relative Clause Representations on Agreement Prediction,2021,5.360307623802153e-05,2
W4385571671,What In-Context Learning “Learns” In-Context: Disentangling Task Recognition and Task Learning,2023,5.359647342243738e-05,2
W3034779619,How does BERT’s attention change when you fine-tune? An analysis methodology and a case study in negation scope,2020,5.356955638575785e-05,2
W4394877201,CGKPN: Cross-Graph Knowledge Propagation Network with Adaptive Connection for Reasoning-Based Machine Reading Comprehension,2024,5.355820438046404e-05,2
W4322006551,Large Language Models Demonstrate the Potential of Statistical Learning in Language,2023,5.353934716027862e-05,2
W2972312591,How Does BERT Answer Questions? A Layer-Wise Analysis of Transformer Representations,2019,5.3536299902795764e-05,2
W4362705335,FinBERT–MRC: Financial Named Entity Recognition Using BERT Under the Machine Reading Comprehension Paradigm,2023,5.353347051194469e-05,2
W4226059645,TopiOCQA: Open-domain Conversational Question Answering with Topic Switching,2022,5.3502336141877005e-05,2
W4200594764,Detecting computer-generated disinformation,2021,5.347562929169339e-05,2
W4385573017,A Survey of Active Learning for Natural Language Processing,2022,5.345460378956589e-05,2
W3099658661,An information theoretic view on selecting linguistic probes,2020,5.3443997107763486e-05,2
W4205266770,MFAQ: a Multilingual FAQ Dataset,2021,5.343823209018905e-05,2
W3133101440,PADA: A Prompt-based Autoregressive Approach for Adaptation to Unseen Domains.,2021,5.343701974984984e-05,2
W3103923992,Claim Check-Worthiness Detection as Positive Unlabelled Learning,2020,5.342970921203089e-05,2
W2810065831,How To Backdoor Federated Learning,2018,5.340215595716706e-05,2
W4287890137,Lifelong Pretraining: Continually Adapting Language Models to Emerging Corpora,2022,5.339881253532241e-05,2
W4294875919,"A Primer on Contrastive Pretraining in Language Processing: Methods, Lessons Learned, and Perspectives",2022,5.3360733286404136e-05,2
W3168251909,Looking Beyond Sentence-Level Natural Language Inference for Question Answering and Text Summarization,2021,5.335867735180404e-05,2
W4285195854,LEVEN: A Large-Scale Chinese Legal Event Detection Dataset,2022,5.333431574472376e-05,2
W4392913756,Natural language instructions induce compositional generalization in networks of neurons,2024,5.326222976343544e-05,2
W3102259594,Learning to Model and Ignore Dataset Bias with Mixed Capacity Ensembles,2020,5.320273603357755e-05,2
W3100778284,Probing for Multilingual Numerical Understanding in Transformer-Based Language Models,2020,5.320035072253712e-05,2
W3196295870,CascadeBERT: Accelerating Inference of Pre-trained Language Models via Calibrated Complete Models Cascade,2021,5.318577514075204e-05,2
W3196194504,Semantic Answer Similarity for Evaluating Question Answering Models,2021,5.3179300892877536e-05,2
W2984178847,Comprehensive Multi-Dataset Evaluation of Reading Comprehension,2019,5.3171960518036835e-05,2
W3176617251,CPM-2: Large-scale cost-effective pre-trained language models,2021,5.317103313125376e-05,2
W3097513514,A Survey of Text Data Augmentation,2020,5.3162575832555457e-05,2
W3212849024,Synthetic Data Augmentation for Zero-Shot Cross-Lingual Question Answering,2021,5.313746695197992e-05,2
W3208933101,Adversarial GLUE: A Multi-Task Benchmark for Robustness Evaluation of Language Models,2021,5.311526546779648e-05,2
W4385567008,"ZeroPrompt: Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization",2022,5.311376307193415e-05,2
W4362653953,Semantic-Based Classification of Relevant Case Law,2023,5.3094073718774686e-05,2
W4401242770,FinSoSent: Advancing Financial Market Sentiment Analysis through Pretrained Large Language Models,2024,5.3088356199370825e-05,2
W3198711991,It’s not Rocket Science: Interpreting Figurative Language in Narratives,2022,5.308690055275598e-05,2
W4205103289,Mr. TyDi: A Multi-lingual Benchmark for Dense Retrieval,2021,5.305275151170465e-05,2
W3136363192,On the effect of dropping layers of pre-trained transformer models,2022,5.303402295189956e-05,2
W4313459382,Investigating Reasons for Disagreement in Natural Language Inference,2022,5.300967459654011e-05,2
W4287889356,Cross-Domain Detection of GPT-2-Generated Technical Text,2022,5.2996150889720646e-05,2
W2984402309,Domain-agnostic Question-Answering with Adversarial Training,2019,5.297190046092714e-05,2
W4362654035,COLIEE 2022 Summary: Methods for Legal Document Retrieval and Entailment,2023,5.295959724354633e-05,2
W3104570641,Learning Music Helps You Read: Using Transfer to Study Linguistic Structure in Language Models,2020,5.2942822573386124e-05,2
W3104136798,Analyzing Redundancy in Pretrained Transformer Models,2020,5.289961242259969e-05,2
W3130583616,A clinical trials corpus annotated with UMLS entities to enhance the access to evidence-based medicine,2021,5.2879592730392566e-05,2
W3175234986,Named Entity Recognition with Small Strongly Labeled and Large Weakly Labeled Data,2021,5.2878853309196595e-05,2
W3211384372,The Perils of Using Mechanical Turk to Evaluate Open-Ended Text Generation,2021,5.287694821280672e-05,2
W2994896922,Thieves on Sesame Street! Model Extraction of BERT-based APIs,2020,5.2872688524707346e-05,2
W3198536471,Multi-Stage Conversational Passage Retrieval: An Approach to Fusing Term Importance Estimation and Neural Query Rewriting,2021,5.2861285689362745e-05,2
W4287887244,Models in the Loop: Aiding Crowdworkers with Generative Annotation Assistants,2022,5.2853799294186356e-05,2
W3103136066,Linguistically-Informed Transformations (LIT): A Method for Automatically Generating Contrast Sets,2020,5.284340726651479e-05,2
W4391765649,Domain-specific language models pre-trained on construction management systems corpora,2024,5.277487834745039e-05,2
W3117433489,Generating Natural Language Attacks in a Hard Label Black Box Setting,2021,5.277362530118521e-05,2
W3090395639,A Survey of the State of Explainable AI for Natural Language Processing,2020,5.2773394448185775e-05,2
W4287889465,EASE: Entity-Aware Contrastive Learning of Sentence Embedding,2022,5.2749766667456116e-05,2
W3176589722,Ultra-Fine Entity Typing with Weak Supervision from a Masked Language Model,2021,5.2715801766258554e-05,2
W3120075432,TexSmart: A Text Understanding System for Fine-Grained NER and Enhanced Semantic Analysis,2020,5.2705656132082305e-05,2
W4224325974,Multi-label classification for biomedical literature: an overview of the BioCreative VII LitCovid Track for COVID-19 literature topic annotations,2022,5.2698805830635716e-05,2
W4319985906,Natural Language Processing in Electronic Health Records in relation to healthcare decision-making: A systematic review,2023,5.269705692267294e-05,2
W2991316439,CAIL2019-SCM: A Dataset of Similar Case Matching in Legal Domain,2019,5.267338983121137e-05,2
W3173586048,KACE: Generating Knowledge Aware Contrastive Explanations for Natural Language Inference,2021,5.2664577653720534e-05,2
W3034385177,Guided Generation of Cause and Effect,2020,5.265042648031556e-05,2
W4385570090,Parallel Context Windows for Large Language Models,2023,5.260067998408498e-05,2
W3089988449,Paragraph-level Commonsense Transformers with Recurrent Memory,2021,5.25978500870663e-05,2
W4385572149,Knowledge-Augmented Language Model Prompting for Zero-Shot Knowledge Graph Question Answering,2023,5.25702938077455e-05,2
W4385573855,Successive Prompting for Decomposing Complex Questions,2022,5.255861760672193e-05,2
W3024368629,Using case-level context to classify cancer pathology reports,2020,5.254784603644072e-05,2
W2978170550,Exploiting Structural and Semantic Context for Commonsense Knowledge Base Completion,2019,5.2502936059554636e-05,2
W4287887100,"Re2G: Retrieve, Rerank, Generate",2022,5.249495977520151e-05,2
W4221159394,PromDA: Prompt-based Data Augmentation for Low-Resource NLU Tasks,2022,5.2478348305607997e-05,2
W2998386992,Parsing as Pretraining,2020,5.24739097550116e-05,2
W3104235802,Entity Enhanced BERT Pre-training for Chinese NER,2020,5.245933523344202e-05,2
W4393152682,Knowledge Graph Prompting for Multi-Document Question Answering,2024,5.242610720152888e-05,2
W3153543512,Do Syntax Trees Help Pre-trained Transformers Extract Information?,2021,5.242420900786394e-05,2
W3004304303,A Short Survey of Pre-trained Language Models for Conversational AI-A New Age in NLP,2020,5.242328627439432e-05,2
W4291012579,A comprehensive overview of knowledge graph completion,2022,5.241010411976116e-05,2
W3153866062,Self-Training with Weak Supervision,2021,5.2395504358304296e-05,2
W2948743095,Episodic Memory in Lifelong Language Learning,2019,5.239170965030546e-05,2
W3101767350,Sentence embeddings in NLI with iterative refinement encoders,2019,5.2373836408204586e-05,2
W3117034213,Scientific Keyphrase Identification and Classification by Pre-Trained Language Models Intermediate Task Transfer Learning,2020,5.23521603394758e-05,2
W4385570204,DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models,2023,5.235047756331196e-05,2
W4389519291,Enhancing Chat Language Models by Scaling High-quality Instructional Conversations,2023,5.234724729553673e-05,2
W3152562554,B-PROP,2021,5.233898519623324e-05,2
W4281479158,Prompt Tuning for Discriminative Pre-trained Language Models,2022,5.233619084265656e-05,2
W4390493562,Semantic Compression with Large Language Models,2023,5.231272052130046e-05,2
W3031001133,When Bert Forgets How To POS: Amnesic Probing of Linguistic Properties and MLM Predictions,2020,5.2243772324438514e-05,2
W3034300118,Learning to Extract Attribute Value from Product via Question Answering: A Multi-task Approach,2020,5.22391320151305e-05,2
W3155632693,Through the Looking Glass: Learning to Attribute Synthetic Text Generated by Language Models,2021,5.222975558907016e-05,2
W4287854750,AcTune: Uncertainty-Based Active Self-Training for Active Fine-Tuning of Pretrained Language Models,2022,5.2209346075730344e-05,2
W4206634569,Block Pruning For Faster Transformers,2021,5.2195980484909244e-05,2
W2998443519,A survey of semantic relatedness evaluation datasets and procedures,2019,5.2189918918300865e-05,2
W4321002059,The 2022 n2c2/UW shared task on extracting social determinants of health,2023,5.218769328143963e-05,2
W2971169991,Asking Clarification Questions in Knowledge-Based Question Answering,2019,5.212189386053511e-05,2
W3090196146,Self-training Improves Pre-training for Natural Language Understanding,2020,5.208225479513258e-05,2
W3207974842,Machine Learning Techniques for Biomedical Natural Language Processing: A Comprehensive Review,2021,5.208215805929057e-05,2
W4210744365,Improving Crisis Events Detection Using DistilBERT with Hunger Games Search Algorithm,2022,5.208215805929056e-05,2
W3104417388,Cross-Thought for Sentence Encoder Pre-training,2020,5.2078342438591885e-05,2
W3029927342,Contextualized Embeddings based Transformer Encoder for Sentence Similarity Modeling in Answer Selection Task,2020,5.2048030197848196e-05,2
W3160883893,Few-Shot Conversational Dense Retrieval,2021,5.2018582632787816e-05,2
W3114740437,Learn to Combine Linguistic and Symbolic Information for Table-based Fact Verification,2020,5.200541358458497e-05,2
W4327644588,Visconde: Multi-document QA with GPT-3 and Neural Reranking,2023,5.199878407937819e-05,2
W4287854971,PLM-ICD: Automatic ICD Coding with Pretrained Language Models,2022,5.1901141747484345e-05,2
W3185051273,Deriving Contextualised Semantic Features from BERT (and Other Transformer Model) Embeddings,2021,5.185855847260607e-05,2
W4367185264,Prompting Is Programming: A Query Language for Large Language Models,2023,5.185855847260607e-05,2
W4361829659,An Exploratory Analysis of GSDMM and BERTopic on Short Text Topic Modelling,2022,5.185855847260607e-05,2
W3159630167,Contrastive Out-of-Distribution Detection for Pretrained Transformers,2021,5.185284421771317e-05,2
W4401129934,Topic Modeling for Faster Literature Screening Using Transformer-Based Embeddings,2024,5.181264236399957e-05,2
W2971141916,Evaluation Benchmarks and Learning Criteria for Discourse-Aware Sentence Representations,2019,5.178608995066094e-05,2
W3158303960,TABBIE: Pretrained Representations of Tabular Data,2021,5.177252618450549e-05,2
W3099080236,TaxiNLI: Taking a Ride up the NLU Hill,2020,5.174804025551422e-05,2
W3103621845,Look at the First Sentence: Position Bias in Question Answering,2020,5.172065652494342e-05,2
W4285261371,Efficient Classification of Long Documents Using Transformers,2022,5.168016677515794e-05,2
W4285192560,Large Language Models are Not Models of Natural Language: They are Corpus Models,2022,5.164235440743403e-05,2
W4386607580,Benchmarks for Automated Commonsense Reasoning: A Survey,2023,5.1631089527703875e-05,2
W4401386758,Large Language Models in Healthcare and Medical Domain: A Review,2024,5.158234721846639e-05,2
W4285200483,Word Order Does Matter and Shuffled Language Models Know It,2022,5.157842613946162e-05,2
W3177448743,Learning to Rationalize for Nonmonotonic Reasoning with Distant Supervision,2021,5.157661675212105e-05,2
W3119652442,Machine Generation and Detection of Arabic Manipulated and Fake News,2020,5.157360200635537e-05,2
W4389519226,LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models,2023,5.156208688689635e-05,2
W3102532959,Investigating representations of verb bias in neural language models,2020,5.154979602488554e-05,2
W3103855731,Interpretation of NLP models through input marginalization,2020,5.1511333482022855e-05,2
W3111099392,Label Confusion Learning to Enhance Text Classification Models,2021,5.150606652733737e-05,2
W4307367874,Aggregating pairwise semantic differences for few-shot claim verification,2022,5.150186247025032e-05,2
W3157029757,Named Entity Recognition Using BERT with Whole World Masking in Cybersecurity Domain,2021,5.149137934970876e-05,2
W2892085193,I Know What You Want: Semantic Learning for Text Comprehension,2018,5.146671447364439e-05,2
W2964172681,,2019,5.146000940050587e-05,2
W3197979077,Avoiding Inference Heuristics in Few-shot Prompt-based Finetuning,2021,5.1457448243466886e-05,2
W3203135439,Towards a Robust Deep Neural Network against Adversarial Texts: A Survey,2021,5.145593539958514e-05,2
W4387428045,MarkBERT: Marking Word Boundaries Improves Chinese BERT,2023,5.14527789599559e-05,2
W4385573874,Help me write a Poem: Instruction Tuning as a Vehicle for Collaborative Poetry Writing,2022,5.1444044234376555e-05,2
W3169306793,Universal Adversarial Attacks with Natural Triggers for Text Classification,2021,5.1433336942320094e-05,2
W4309773749,Data augmentation techniques in natural language processing,2022,5.141967926093858e-05,2
W3194769714,ProoFVer: Natural Logic Theorem Proving for Fact Verification,2022,5.1416840957219236e-05,2
W4285302878,SGPT: A Generative Approach for SPARQL Query Generation From Natural Language Questions,2022,5.1401103760091886e-05,2
W4283815582,Commonsense Knowledge Reasoning and Generation with Pre-trained Language Models: A Survey,2022,5.139712799949235e-05,2
W4225795249,"Question Answering Survey: Directions, Challenges, Datasets, Evaluation Matrices",2021,5.139381774405162e-05,2
W3019779721,AmbigQA: Answering Ambiguous Open-domain Questions,2020,5.1378372245730735e-05,2
W3176178685,Decoding Word Embeddings with Brain-Based Semantic Features,2021,5.136663938190016e-05,2
W4225891352,The CLEF-2022 CheckThat! Lab on Fighting the COVID-19 Infodemic and Fake News Detection,2022,5.1354829973222524e-05,2
W2951568144,Selection Bias Explorations and Debias Methods for Natural Language Sentence Matching Datasets,2019,5.132830033759999e-05,2
W4307817449,A Siamese Neural Network for Learning Semantically-Informed Sentence Embeddings,2022,5.1283107350505055e-05,2
W3197780238,KELM: Knowledge Enhanced Pre-Trained Language Representations with Message Passing on Hierarchical Relational Graphs,2021,5.128271844602113e-05,2
W2926850261,Natural language processing of radiology reports for identification of skeletal site-specific fractures,2019,5.128210164430334e-05,2
W3172365208,Everything Has a Cause: Leveraging Causal Inference in Legal Text Analysis,2021,5.127117324379625e-05,2
W4385572768,HPT: Hierarchy-aware Prompt Tuning for Hierarchical Text Classification,2022,5.1238294428993244e-05,2
W3171397222,"Model Extraction and Adversarial Transferability, Your BERT is Vulnerable!",2021,5.1214298957221285e-05,2
W3211805281,Multitask Semi-Supervised Learning for Class-Imbalanced Discourse Classification,2021,5.116702414829245e-05,2
W4280612849,Problems with Cosine as a Measure of Embedding Similarity for High Frequency Words,2022,5.115581691445477e-05,2
W3104220682,Long Document Ranking with Query-Directed Sparse Transformer,2020,5.114456171357119e-05,2
W3216037316,"Do Language Models Have Beliefs? Methods for Detecting, Updating, and Visualizing Model Beliefs",2021,5.1137953339788184e-05,2
W4399854538,A comparative study of large language model-based zero-shot inference and task-specific supervised classification of breast cancer pathology reports,2024,5.1135148045097385e-05,2
W4366999416,SAILER: Structure-aware Pre-trained Language Model for Legal Case Retrieval,2023,5.108464582568521e-05,2
W4205412789,English Machine Reading Comprehension Datasets: A Survey,2021,5.1069353502755234e-05,2
W3037626499,Compositional Explanations of Neurons,2020,5.105647715204386e-05,2
W2981175810,Efficiently embedding dynamic knowledge graphs,2022,5.1052933015668806e-05,2
W4229868159,Think about it! Improving defeasible reasoning by first modeling the question scenario.,2021,5.105162825392147e-05,2
W3099219382,MultiCQA: Zero-Shot Transfer of Self-Supervised Text Matching Models on a Massive Scale,2020,5.104388905483824e-05,2
W3035449958,Generalized Zero-Shot Text Classification for ICD Coding,2020,5.10430763681174e-05,2
W3174481949,AIT-QA: Question Answering Dataset over Complex Tables in the Airline Industry,2022,5.1038498403418e-05,2
W3102009955,Discern: Discourse-Aware Entailment Reasoning Network for Conversational Machine Reading,2020,5.1033881144417295e-05,2
W2969307504,Multi-passage BERT: A Globally Normalized BERT Model for Open-domain Question Answering,2019,5.100832558295162e-05,2
W3156000544,Sequence tagging for biomedical extractive question answering,2022,5.0994278081104564e-05,2
W3034584102,Towards Robustifying NLI Models Against Lexical Dataset Biases,2020,5.0981775034258056e-05,2
W4298111738,Virtual prompt pre-training for prototype-based few-shot relation extraction,2022,5.097614389456618e-05,2
W2995856824,Are Pre-trained Language Models Aware of Phrases? Simple but Strong Baselines for Grammar Induction,2020,5.0968872371544005e-05,2
W4385574084,InfoCSE: Information-aggregated Contrastive Learning of Sentence Embeddings,2022,5.094101268895227e-05,2
W4398757454,Evaluating Correctness and Faithfulness of Instruction-Following Models for Question Answering,2024,5.0899389813641444e-05,2
W4224215750,Adversarial attack and defense technologies in natural language processing: A survey,2022,5.088756122364727e-05,2
W4389523666,Beyond Labels: Empowering Human Annotators with Natural Language Explanations through a Novel Active-Learning Architecture,2023,5.087472029119426e-05,2
W4213059241,Comparative Study of Long Document Classification,2021,5.087472029119426e-05,2
W4281743053,Improving Contrastive Learning of Sentence Embeddings with Case-Augmented Positives and Retrieved Negatives,2022,5.0871421944470935e-05,2
W3166417463,Capturing Row and Column Semantics in Transformer Based Question Answering over Tables,2021,5.0859835764916924e-05,2
W2975208319,Question Answering is a Format; When is it Useful?,2019,5.082886625119445e-05,2
W4392908117,The Inadequacy of Reinforcement Learning From Human Feedback—Radicalizing Large Language Models via Semantic Vulnerabilities,2024,5.0814623059171996e-05,2
W3201977280,ContractNLI: A Dataset for Document-level Natural Language Inference for Contracts,2021,5.080033796607449e-05,2
W3104566548,Teaching Machine Comprehension with Compositional Explanations,2020,5.078157064641341e-05,2
W4390043316,Shortcut Learning of Large Language Models in Natural Language Understanding,2023,5.0767745636403136e-05,2
W4385573862,Language Models that Seek for Knowledge: Modular Search &amp; Generation for Dialogue and Prompt Completion,2022,5.072393572822194e-05,2
W4324142429,A Review of Deep Transfer Learning and Recent Advancements,2023,5.07182091149498e-05,2
W3094657717,Prediction of breast cancer distant recurrence using natural language processing and knowledge-guided convolutional neural network,2020,5.070205706363503e-05,2
W4384819947,Leveraging pre-trained language models for mining microbiome-disease relationships,2023,5.0682230212222387e-05,2
W4285286749,Prototypical Verbalizer for Prompt-based Few-shot Tuning,2022,5.066672535820885e-05,2
W3183138634,NeuralLog: Natural Language Inference with Joint Neural and Logical Reasoning,2021,5.066128594590278e-05,2
W4367672504,Almanac: Retrieval-Augmented Language Models for Clinical Medicine,2023,5.063779855182725e-05,2
W3037082750,TURL: Table Understanding through Representation Learning,2020,5.063608318321698e-05,2
W4206199121,TAG: Gradient Attack on Transformer-based Language Models,2021,5.062891980395962e-05,2
W4296580689,Precision fMRI reveals that the language-selective network supports both phrase-structure building and lexical access during language production,2022,5.0620138816535984e-05,2
W4281632042,Quantum Natural Language Processing: Challenges and Opportunities,2022,5.060640078717286e-05,2
W2950695840,Simple and Effective Curriculum Pointer-Generator Networks for Reading Comprehension over Long Narratives,2019,5.0605529357327985e-05,2
W4285151662,Open Domain Question Answering with A Unified Knowledge Interface,2022,5.0574063464207326e-05,2
W4327499388,"Legal IR and NLP: The History, Challenges, and State-of-the-Art",2023,5.057150661702569e-05,2
W4285605214,Meta-Learning Based Knowledge Extrapolation for Knowledge Graphs in the Federated Setting,2022,5.056943347250631e-05,2
W4220835136,Unrestricted multi-hop reasoning network for interpretable question answering over knowledge graph,2022,5.055210739424706e-05,2
W4317797582,Grounding the Vector Space of an Octopus: Word Meaning from Raw Text,2023,5.0546774230723654e-05,2
W3161231563,Named Entity Aware Transfer Learning for Biomedical Factoid Question Answering,2021,5.0536522318837736e-05,2
W3123123873,Pre-training Text-to-Text Transformers for Concept-centric Common Sense,2021,5.0519774534498314e-05,2
W4385571920,FactKG: Fact Verification via Reasoning on Knowledge Graphs,2023,5.051617404848308e-05,2
W4385570354,Inseq: An Interpretability Toolkit for Sequence Generation Models,2023,5.0487815534765566e-05,2
W4283691240,Analyzing Encoded Concepts in Transformer Language Models,2022,5.0469125198243903e-05,2
W4226455589,How Pre-trained Language Models Capture Factual Knowledge? A Causal-Inspired Analysis,2022,5.045884218672914e-05,2
W4385572035,Improving Contrastive Learning of Sentence Embeddings from AI Feedback,2023,5.04563383807348e-05,2
W3174745742,Using Social and Linguistic Information to Adapt Pretrained Representations for Political Perspective Identification,2021,5.045416799347492e-05,2
W4367186096,Synwmd: Syntax-aware word Mover’s distance for sentence similarity evaluation,2023,5.043956109556981e-05,2
W4287889449,StATIK: Structure and Text for Inductive Knowledge Graph Completion,2022,5.042673141082021e-05,2
W2996125274,Introducing MANtIS: a novel Multi-Domain Information Seeking Dialogues Dataset,2019,5.042492479620874e-05,2
W4395101324,GPT-FinRE: In-context Learning for Financial Relation Extraction using Large Language Models,2023,5.041831266485711e-05,2
W3086560451,"Explanation in AI and law: Past, present and future",2020,5.040951493809942e-05,2
W3168552854,Causal Effects of Linguistic Properties,2021,5.040193231926124e-05,2
W3046209160,DeepMet: A Reading Comprehension Paradigm for Token-level Metaphor Detection,2020,5.040035897605802e-05,2
W3176001432,Counterfactual Inference for Text Classification Debiasing,2021,5.0390261850750586e-05,2
W4394975332,Distilling large language models for matching patients to clinical trials,2024,5.036738458606551e-05,2
W4389070894,Event Knowledge in Large Language Models: The Gap Between the Impossible and the Unlikely,2023,5.0351063588996244e-05,2
W3103092622,New Protocols and Negative Results for Textual Entailment Data Collection,2020,5.034814249328864e-05,2
W3025279871,An Analysis of Adversarial Attacks and Defenses on Autonomous Driving Models,2020,5.033499176654566e-05,2
W3201369838,Artificial Text Detection via Examining the Topology of Attention Maps,2021,5.032235598425256e-05,2
W3118796926,"Polyjuice: Automated, General-purpose Counterfactual Generation.",2021,5.031634289852364e-05,2
W3173423412,"Read, Retrospect, Select: An MRC Framework to Short Text Entity Linking",2021,5.0297795459012085e-05,2
W4391428886,Automated Smell Detection and Recommendation in Natural Language Requirements,2024,5.0269186381718343e-05,2
W3206066344,Differentially Private Fine-tuning of Language Models,2021,5.025492747981594e-05,2
W2883657435,Developing a portable natural language processing based phenotyping system,2019,5.0233959312077954e-05,2
W3034876042,Harvesting and Refining Question-Answer Pairs for Unsupervised QA,2020,5.023109659928049e-05,2
W3173256823,Meta-KD: A Meta Knowledge Distillation Framework for Language Model Compression across Domains,2021,5.0228009910682715e-05,2
W4376133440,Hospital-wide natural language processing summarising the health data of 1 million patients,2023,5.022782302369765e-05,2
W3205349317,A Few More Examples May Be Worth Billions of Parameters,2022,5.022098252305856e-05,2
W4210451781,FeTaQA: Free-form Table Question Answering,2022,5.0205830294416294e-05,2
W3015773279,Unsupervised Commonsense Question Answering with Self-Talk,2020,5.017781120286975e-05,2
W4292387193,Query Path Generation via Bidirectional Reasoning for Multihop Question Answering From Knowledge Bases,2022,5.01723138119473e-05,2
W3208646411,"Flexibly Focusing on Supporting Facts, Using Bridge Links, and Jointly Training Specialized Modules for Multi-Hop Question Answering",2021,5.016984286173641e-05,2
W3115965961,Improving Commonsense Question Answering by Graph-based Iterative Retrieval over Multiple Knowledge Sources,2020,5.016184581695887e-05,2
W3173699110,Which Linguist Invented the Lightbulb? Presupposition Verification for Question-Answering,2021,5.0147178283124415e-05,2
W3169141681,"Few-Shot Text Classification with Triplet Networks, Data Augmentation, and Curriculum Learning",2021,5.012458176543416e-05,2
W3090306696,Mining product innovation ideas from online reviews,2020,5.009871480071304e-05,2
W4301594491,Artificial neural network language models predict human brain responses to language even after a developmentally realistic amount of training,2022,5.009486617229219e-05,2
W3169971770,Emotion-Infused Models for Explainable Psychological Stress Detection,2021,5.006761447524343e-05,2
W3051333395,Hierarchical fusion of common sense knowledge and classifier decisions for answer selection in community question answering,2020,5.0063204000741116e-05,2
W3104108820,KERMIT: Complementing Transformer Architectures with Encoders of Explicit Syntactic Interpretations,2020,5.0055911734151346e-05,2
W4385570025,Few-shot In-context Learning on Knowledge Base Question Answering,2023,5.0033021065661016e-05,2
W3166143997,Why Do Pretrained Language Models Help in Downstream Tasks? An Analysis of Head and Prompt Tuning,2021,5.0026578812190436e-05,2
W2949181687,"Identification of Tasks, Datasets, Evaluation Metrics, and Numeric Scores for Scientific Leaderboards Construction",2019,5.001820442259599e-05,2
W4206808166,The World of an Octopus: How Reporting Bias Influences a Language Model’s Perception of Color,2021,5.0002312339827125e-05,2
W3136665819,Knowledge Graph Question Answering with semantic oriented fusion model,2021,4.998564574413922e-05,2
W4285157416,SCD: Self-Contrastive Decorrelation of Sentence Embeddings,2022,4.9975753115430175e-05,2
W3166920165,Refining Targeted Syntactic Evaluation of Language Models,2021,4.9958146452514875e-05,2
W4226101361,Read before Generate! Faithful Long Form Question Answering with Machine Reading,2022,4.993454551928079e-05,2
W3197388494,Lightweight URL-based phishing detection using natural language processing transformers for mobile devices,2021,4.993259749822453e-05,2
W3188660305,Let’s Play<tt>Mono</tt>-<tt>Poly</tt>: BERT Can Reveal Words’ Polysemy Level and Partitionability into Senses,2021,4.991810032729494e-05,2
W3207539211,Dict-BERT: Enhancing Language Model Pre-training with Dictionary,2022,4.989942814851621e-05,2
W4285239949,Multi-Stage Prompting for Knowledgeable Dialogue Generation,2022,4.988099132932882e-05,2
W3027982260,Extracting drug-drug interactions from texts with BioBERT and multiple entity-aware attentions,2020,4.986449295224147e-05,2
W3203176827,Swiss-Judgment-Prediction: A Multilingual Legal Judgment Prediction Benchmark,2021,4.9856213773279425e-05,2
W4206633687,Flexible Generation of Natural Language Deductions,2021,4.985012574098491e-05,2
W4200629808,ISEEQ: Information Seeking Question Generation Using Dynamic Meta-Information Retrieval and Knowledge Graphs,2022,4.984175002073361e-05,2
W4389009541,Preventing Generation of Verbatim Memorization in Language Models Gives a False Sense of Privacy,2023,4.9837492324299185e-05,2
W3037888463,BERTology Meets Biology: Interpreting Attention in Protein Language Models,2020,4.979261531974707e-05,2
W3103436911,Towards Interpretable Natural Language Understanding with Explanations as Latent Variables,2020,4.9782916635940734e-05,2
W3035287090,Harnessing the linguistic signal to predict scalar inferences,2020,4.978006244225585e-05,2
W3105391665,Natural Language Rationales with Full-Stack Visual Reasoning: From Pixels to Semantic Frames to Commonsense Graphs,2020,4.977869632094108e-05,2
W2971380169,Semantics-aware BERT for Language Understanding,2019,4.97725839647054e-05,2
W3034623328,Curriculum Learning for Natural Language Understanding,2020,4.976621128242635e-05,2
W3175752238,BERT Busters: Outlier Dimensions that Disrupt Transformers,2021,4.974243085933661e-05,2
W4362650374,Legal Textual Entailment Using Ensemble of Rule-Based and BERT-Based Method with Data Augmentation by Related Article Generation,2023,4.9723494880645264e-05,2
W4390239756,Exploring the Latest Highlights in Medical Natural Language Processing across Multiple Languages: A Survey,2023,4.972053462131658e-05,2
W4387430414,Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings,2023,4.971117092531438e-05,2
W3101786725,A Knowledge-Aware Sequence-to-Tree Network for Math Word Problem Solving,2020,4.970286388301037e-05,2
W4281989354,Disentangled Ontology Embedding for Zero-shot Learning,2022,4.968686494377909e-05,2
W3096331697,AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts,2020,4.968565497710131e-05,2
W4390590855,A Survey of Text Classification With Transformers: How Wide? How Large? How Long? How Accurate? How Expensive? How Safe?,2024,4.9680059642337075e-05,2
W3109435212,WabiQA: A Wikipedia-Based Thai Question-Answering System,2020,4.9661897102691325e-05,2
W3087148478,Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters & Less Data,2020,4.9632644459058766e-05,2
W3101717721,Asking without Telling: Exploring Latent Ontologies in Contextual Representations,2020,4.963182193781306e-05,2
W4221151543,Improving Biomedical Information Retrieval with Neural Retrievers,2022,4.961245178830866e-05,2
W4385567227,A Systematic Investigation of Commonsense Knowledge in Large Language Models,2022,4.960840000411269e-05,2
W4290994954,Reducing Conversational Agents’ Overconfidence Through Linguistic Calibration,2022,4.960654838395043e-05,2
W4221052873,ZeroBERTo: Leveraging Zero-Shot Text Classification by Topic Modeling,2022,4.96026100228864e-05,2
W3118741274,Benchmarking Knowledge-Enhanced Commonsense Question Answering via Knowledge-to-Text Transformation,2021,4.959930808974995e-05,2
W2869198903,Interactive Analysis of Word Vector Embeddings,2018,4.959083865084838e-05,2
W4392740458,CORAL: Expert-Curated Oncology Reports to Advance Language Model Inference,2024,4.954609733070329e-05,2
W3098987177,ConjNLI: Natural Language Inference Over Conjunctive Sentences,2020,4.954485407287766e-05,2
W3197868468,Searching for an Effective Defender: Benchmarking Defense against Adversarial Word Substitution,2021,4.953903346301726e-05,2
W3199467273,On the Validity of Pre-Trained Transformers for Natural Language Processing in the Software Engineering Domain,2022,4.9533540560220516e-05,2
W3198950523,DADgraph: A Discourse-aware Dialogue Graph Neural Network for Multiparty Dialogue Machine Reading Comprehension,2021,4.953245925141732e-05,2
W3170989320,A Package for Learning on Tabular and Text Data with Transformers,2021,4.9493887867702864e-05,2
W2995543961,Maze Made Easy: Better and easier measurement of incremental processing difficulty,2019,4.9490849988115065e-05,2
W3105601320,LIMIT-BERT : Linguistics Informed Multi-Task BERT,2020,4.948601980949662e-05,2
W4285254998,Generating Scientific Claims for Zero-Shot Scientific Fact Checking,2022,4.9434938896817655e-05,2
W3177468934,Evaluation Examples are not Equally Informative: How should that change NLP Leaderboards?,2021,4.942335783615173e-05,2
W3170883728,Can BERT Dig It? Named Entity Recognition for Information Retrieval in the Archaeology Domain,2022,4.942109507114829e-05,2
W3102970018,How does BERT capture semantics? A closer look at polysemous words,2020,4.940964438764127e-05,2
W3098794549,Weakly- and Semi-supervised Evidence Extraction,2020,4.940356599223976e-05,2
W4281740565,Pre-trained transformers: an empirical comparison,2022,4.9398963019076555e-05,2
W4283734474,Augmenting Textbooks with cQA Question-Answers and Annotated YouTube Videos to Increase Its Relevance,2022,4.9398963019076555e-05,2
W4385210537,Emotion-Semantic-Aware Dual Contrastive Learning for Epistemic Emotion Identification of Learner-Generated Reviews in MOOCs,2023,4.9398963019076555e-05,2
W4399465020,Large Language Model and Text Generation,2024,4.9398963019076555e-05,2
W4393379915,Detection of AI-Generated Text Using Large Language Model,2024,4.9398963019076555e-05,2
W4386494407,Surprisal From Language Models Can Predict ERPs in Processing Predicate-Argument Structures Only if Enriched by an Agent Preference Principle,2023,4.9398963019076555e-05,2
W4396953196,AI-based disease category prediction model using symptoms from low-resource Ethiopian language: Afaan Oromo text,2024,4.9398963019076555e-05,2
W4386588806,Supervised Machine-Generated Text Detectors: Family and Scale Matters,2023,4.9398963019076555e-05,2
W4389245454,"An Improved Transformer-based Model for Detecting Phishing, Spam, and Ham: A Large Language Model Approach",2023,4.9398963019076555e-05,2
W4281561077,Positive-Unlabeled Learning with Adversarial Data Augmentation for Knowledge Graph Completion,2022,4.9398963019076555e-05,2
W4364376167,A distributional assessment of rivalry in word formation,2023,4.9398963019076555e-05,2
W4389518958,On the Dimensionality of Sentence Embeddings,2023,4.9398963019076555e-05,2
W4387004608,Combining prompt learning with contextual semantics for inductive relation prediction,2023,4.9398963019076555e-05,2
W4294989880,Investigating Topic Modeling Techniques to Extract Meaningful Insights in Italian Long COVID Narration,2022,4.9398963019076555e-05,2
W3191330753,Distinct but correct: generating diversified and entity-revised medical response,2024,4.9398963019076555e-05,2
W4210518974,Delta-band neural activity primarily tracks sentences instead of semantic properties of words,2022,4.9398963019076555e-05,2
W4403577386,Multimodal Misinformation Detection using Large Vision-Language Models,2024,4.9398963019076555e-05,2
W4406870927,LLMs4OM: Matching Ontologies with Large Language Models,2025,4.9398963019076555e-05,2
W3135638847,Natural language understanding for argumentative dialogue systems in the opinion building domain,2022,4.9398963019076555e-05,2
W4319341221,Distributional evidence for derivational paradigms,2023,4.9398963019076555e-05,2
W4388230782,Large-Scale Simulation Study of Active Learning Models for Systematic Reviews,2023,4.9398963019076555e-05,2
W4294325323,Use of Data Augmentation Techniques in Detection of Antisocial Behavior Using Deep Learning Methods,2022,4.9398963019076555e-05,2
W4401813696,AMGPT: A large language model for contextual querying in additive manufacturing,2024,4.9398963019076555e-05,2
W4385478147,Exploring Large Language Models’ Emotion Detection Abilities: Use Cases From the Middle East,2023,4.9398963019076555e-05,2
W4377138005,An Analysis of Fusion Functions for Hybrid Retrieval,2023,4.9398963019076555e-05,2
W4387326738,A Natural Language Processing Model for COVID-19 Detection Based on Dutch General Practice Electronic Health Records by Using Bidirectional Encoder Representations From Transformers: Development and Validation Study,2023,4.9398963019076555e-05,2
W4289222848,Speech disturbances in schizophrenia: Assessing cross-linguistic generalizability of NLP automated measures of coherence,2022,4.9398963019076555e-05,2
W4361204756,Overlap in meaning is a stronger predictor of semantic activation in GPT-3 than in humans,2023,4.9398963019076555e-05,2
W4319662676,Unified benchmark for zero-shot Turkish text classification,2023,4.9398963019076555e-05,2
W3094057023,Mapping ESG Trends by Distant Supervision of Neural Language Models,2020,4.9398963019076555e-05,2
W3008918149,Explainable Authorship Verification in Social Media via Attention-based Similarity Learning,2019,4.9398963019076555e-05,2
W4397006720,The performance of large language models on quantitative and verbal ability tests: Initial evidence and implications for unproctored high‐stakes testing,2024,4.9398963019076555e-05,2
W4386265233,Towards Improving the Reliability and Transparency of ChatGPT for Educational Question Answering,2023,4.9398963019076555e-05,2
W3037843601,Feature-Based Explanations Don't Help People Detect Misclassifications of Online Toxicity,2020,4.9398963019076555e-05,2
W3109550251,Data Augmentation For Chinese Text Classification Using Back-Translation,2020,4.9398963019076555e-05,2
W4391100869,Artificial Neural Network Language Models Predict Human Brain Responses to Language Even After a Developmentally Realistic Amount of Training,2024,4.936125171780511e-05,2
W4385573552,PCL: Peer-Contrastive Learning with Diverse Augmentations for Unsupervised Sentence Embeddings,2022,4.934800141197533e-05,2
W3204085121,Entity Linking Meets Deep Learning: Techniques and Solutions,2021,4.933963748469683e-05,2
W4296783454,Transformers and the Representation of Biomedical Background Knowledge,2022,4.9330592758108775e-05,2
W3083182073,KILT: a Benchmark for Knowledge Intensive Language Tasks,2020,4.932644992462196e-05,2
W4385571325,A fine-grained comparison of pragmatic language understanding in humans and language models,2023,4.932429381732296e-05,2
W3034685497,Probing for Referential Information in Language Models,2020,4.930722388338441e-05,2
W3100055476,Quick and (not so) Dirty: Unsupervised Selection of Justification Sentences for Multi-hop Question Answering,2019,4.929970411496527e-05,2
W3098205952,Embeddings in Natural Language Processing: Theory and Advances in Vector Representations of Meaning,2020,4.929545177235414e-05,2
W3088599783,RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models,2020,4.927684804242557e-05,2
W4225378553,Analysis of community question‐answering issues via machine learning and deep learning: State‐of‐the‐art review,2022,4.926468843244756e-05,2
W2982944182,"When Choosing Plausible Alternatives, Clever Hans can be Clever",2019,4.9250397883867676e-05,2
W4311829616,Large-scale application of named entity recognition to biomedicine and epidemiology,2022,4.923428022055432e-05,2
W3202442632,Narrative event segmentation in the cortical reservoir,2021,4.92193614030788e-05,2
W3135542296,"Automated Coding of Under-Studied Medical Concept Domains: Linking Physical Activity Reports to the International Classification of Functioning, Disability, and Health",2021,4.9182758953904515e-05,2
W3176357828,A Targeted Assessment of Incremental Processing in Neural Language Models and Humans,2021,4.91753149907033e-05,2
W2970782003,Incorporating External Knowledge into Machine Reading for Generative Question Answering,2019,4.9156589136657713e-05,2
W4387846279,CLosER: Conversational Legal Longformer with Expertise-Aware Passage Response Ranker for Long Contexts,2023,4.91530034737236e-05,2
W3169976744,How to Motivate Your Dragon: Teaching Goal-Driven Agents to Speak and Act in Fantasy Worlds,2021,4.9143395718489905e-05,2
W4385567015,AdaPrompt: Adaptive Model Training for Prompt-based NLP,2022,4.9119320378314795e-05,2
W3176390686,UnitedQA: A Hybrid Approach for Open Domain Question Answering,2021,4.910564363970578e-05,2
W4206236515,Explanation-Based Human Debugging of NLP Models: A Survey,2021,4.909944263375715e-05,2
W4393157467,Visual Adversarial Examples Jailbreak Aligned Large Language Models,2024,4.9080978144670035e-05,2
W4285168837,Benchmarking for Public Health Surveillance tasks on Social Media with a Domain-Specific Pretrained Language Model,2022,4.906305502362408e-05,2
W2916562859,What can linguistics and deep learning contribute to each other? Response to Pater,2019,4.9057373179772906e-05,2
W4389524402,A Thorough Examination on Zero-shot Dense Retrieval,2023,4.905060612308254e-05,2
W4400526199,Fine-Tuning LLaMA for Multi-Stage Text Retrieval,2024,4.904579033856975e-05,2
W3092560821,Does Data Augmentation Improve Generalization in NLP?,2020,4.902163600932763e-05,2
W4391836239,"Mathematics, word problems, common sense, and artificial intelligence",2024,4.901787076433929e-05,2
W3157746834,GraphFormers: GNN-nested Language Models for Linked Text Representation.,2021,4.899441187430609e-05,2
W4297924045,S-Net: From Answer Extraction to Answer Synthesis for Machine Reading Comprehension,2018,4.8972907796492896e-05,2
W3047855687,Empirical evaluation of multi-task learning in deep neural networks for natural language processing,2020,4.895091729250006e-05,2
W4393262489,Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?,2024,4.8915545494136625e-05,2
W3080739421,Taming Pretrained Transformers for Extreme Multi-label Text Classification,2019,4.891549189554754e-05,2
W4324193559,Semantic matching based legal information retrieval system for COVID-19 pandemic,2023,4.891496570393311e-05,2
W4212865381,Do Language Embeddings capture Scales?,2020,4.8890808304189316e-05,2
W4385573451,Sentence-level Media Bias Analysis Informed by Discourse Structures,2022,4.886649667509875e-05,2
W3210968241,Improving Query Representations for Dense Retrieval with Pseudo Relevance Feedback,2021,4.8859622038501844e-05,2
W3214530841,FaBULOUS: Fact-checking Based on Understanding of Language Over Unstructured and Structured information,2021,4.8843971242742474e-05,2
W3104223418,Masking as an Efficient Alternative to Finetuning for Pretrained Language Models,2020,4.883136288110681e-05,2
W3094292782,"Retrieve, Rerank, Read, then Iterate: Answering Open-Domain Questions of Arbitrary Complexity from Text.",2020,4.882452001951561e-05,2
W3160359732,Improving clinical outcome predictions using convolution over medical entities with multimodal learning,2021,4.8822580374556005e-05,2
W3115413024,Aspect-based Document Similarity for Research Papers,2020,4.881288256442339e-05,2
W3210951978,Backdoor Pre-trained Models Can Transfer to All,2021,4.8811303800898864e-05,2
W3101786835,A Technical Question Answering System with Transfer Learning,2020,4.880971134071053e-05,2
W3171446474,DAGN: Discourse-Aware Graph Network for Logical Reasoning,2021,4.880882169096322e-05,2
W4385572435,Dipping PLMs Sauce: Bridging Structure and Text for Effective Knowledge Graph Completion via Conditional Soft Prompting,2023,4.88002056047269e-05,2
W3159588055,"Transformers: ""The End of History"" for NLP?",2021,4.879896605335984e-05,2
W3139002032,SELFEXPLAIN: A Self-Explaining Architecture for Neural Text Classifiers,2021,4.87663907294097e-05,2
W4307498511,Multimodal Data Matters: Language Model Pre-Training Over Structured and Unstructured Electronic Health Records,2022,4.875921975717368e-05,2
W4385187297,Deepfake Text Detection: Limitations and Opportunities,2023,4.874057269684433e-05,2
W3176390156,Ecco: An Open Source Library for the Explainability of Transformer Language Models,2021,4.8727017420259276e-05,2
W4389520361,PIEClass: Weakly-Supervised Text Classification with Prompting and Noise-Robust Iterative Ensemble Training,2023,4.8717844278099155e-05,2
W4387708435,Multi-task Pre-training Language Model for Semantic Network Completion,2023,4.8709624340829765e-05,2
W3182414670,FewCLUE: A Chinese Few-shot Learning Evaluation Benchmark,2021,4.870853021641913e-05,2
W4310640599,Transforming epilepsy research: A systematic review on natural language processing applications,2022,4.870640677333646e-05,2
W3001093703,Interactive knowledge-enhanced attention network for answer selection,2020,4.8694159184502146e-05,2
W4372260394,A Large-Scale Pretrained Deep Model for Phishing URL Detection,2023,4.8678282801836416e-05,2
W3176265725,HiddenCut: Simple Data Augmentation for Natural Language Understanding with Better Generalizability,2021,4.859282902846112e-05,2
W2970834904,On the Importance of Delexicalization for Fact Verification,2019,4.857872999912171e-05,2
W2987266335,Syntax-Infused Transformer and BERT models for Machine Translation and Natural Language Understanding,2019,4.8556664034506486e-05,2
W4385567121,Rainier: Reinforced Knowledge Introspector for Commonsense Question Answering,2022,4.855040524000326e-05,2
W3156248418,Scientific Discourse Tagging for Evidence Extraction,2021,4.8540280962620675e-05,2
W2973722444,Teaching Pretrained Models with Commonsense Reasoning: A Preliminary KB-Based Approach,2019,4.853693622909069e-05,2
W4210634745,Survey on English Entity Linking on Wikidata: Datasets and approaches,2022,4.853647853446483e-05,2
W4385569780,Evaluating Open-Domain Question Answering in the Era of Large Language Models,2023,4.852565929956287e-05,2
W3167783161,Unsupervised Multi-hop Question Answering by Question Generation,2021,4.8525471229696554e-05,2
W3092510499,DiPair: Fast and Accurate Distillation for Trillion-Scale Text Matching and Pair Modeling,2020,4.8512426906175814e-05,2
W3132730484,PAQ: 65 Million Probably-Asked Questions and What You Can Do With Them,2021,4.851184016800632e-05,2
W4224311069,A simple neural vector space model for medical concept normalization using concept embeddings,2022,4.850994617033969e-05,2
W4385572770,RetroMAE: Pre-Training Retrieval-oriented Language Models Via Masked Auto-Encoder,2022,4.85055913386417e-05,2
W3112631310,Artificial Intelligence in mental health and the biases of language based models,2020,4.850290977227461e-05,2
W2953337107,What Does BERT Look At? An Analysis of BERT's Attention,2019,4.8497636547324725e-05,2
W4385567182,Prompt Compression and Contrastive Conditioning for Controllability and Toxicity Reduction in Language Models,2022,4.8481300415722333e-05,2
W4385573007,Reasoning Like Program Executors,2022,4.8474734308166725e-05,2
W3201339301,Investigating Numeracy Learning Ability of a Text-to-Text Transfer Model,2021,4.84704141554287e-05,2
W4386566488,Large Language Models are few(1)-shot Table Reasoners,2023,4.8468141741050975e-05,2
W3011414630,Extracting medical entities from social media,2020,4.846642039859444e-05,2
W3007728469,The Microsoft Toolkit of Multi-Task Deep Neural Networks for Natural Language Understanding,2020,4.8458707159250586e-05,2
W4386002638,ChatAgri: Exploring potentials of ChatGPT on cross-linguistic agricultural text classification,2023,4.84440612547651e-05,2
W3170852693,Social media crowdsourcing for rapid damage assessment following a sudden-onset natural hazard event,2021,4.842477890104151e-05,2
W4385571505,Complementary Explanations for Effective In-Context Learning,2023,4.842202433615394e-05,2
W3211022409,Emerging trends: A gentle introduction to fine-tuning,2021,4.841512483766476e-05,2
W4385572490,Learning Better Masking for Better Language Model Pre-training,2023,4.8408907507281075e-05,2
W3177191283,The Curse of Dense Low-Dimensional Information Retrieval for Large Index Sizes,2021,4.838334153401037e-05,2
W2990752173,"Recent Advances in Natural Language Inference: A Survey of Benchmarks, Resources, and Approaches",2019,4.838304743023481e-05,2
W4385525774,Comparing sustainable product hashtags: Insights from a historical twitter dataset,2023,4.837839195077956e-05,2
W4226095990,Things not Written in Text: Exploring Spatial Commonsense from Visual Signals,2022,4.836244751392326e-05,2
W3107315802,CPM: A Large-scale Generative Chinese Pre-trained Language Model,2020,4.8359299895668604e-05,2
W3174785103,Combining Feature and Instance Attribution to Detect Artifacts,2022,4.8358495001052646e-05,2
W4385270279,Construction and Applications of Billion-Scale Pre-Trained Multimodal Business Knowledge Graph,2023,4.835656001232854e-05,2
W3103975738,A little goes a long way: Improving toxic language classification despite data scarcity,2020,4.83416222471628e-05,2
W4206555128,"Phrase Retrieval Learns Passage Retrieval, Too",2021,4.8340367388662666e-05,2
W2998369048,A Survey on Machine Reading Comprehension Systems,2020,4.832446630778214e-05,2
W3116594510,Compressing Pre-trained Language Models by Matrix Decomposition,2020,4.8320522294595755e-05,2
W2965362971,Discourse Analysis and Its Applications,2019,4.831277729688453e-05,2
W3168663263,FEVEROUS: Fact Extraction and VERification Over Unstructured and Structured information,2021,4.829438124546573e-05,2
W4309630085,Incorporating anticipation embedding into reinforcement learning framework for multi-hop knowledge graph question answering,2022,4.828963940454237e-05,2
W3152665347,Advanced Semantics for Commonsense Knowledge Extraction,2021,4.826739574694207e-05,2
W4385893874,Large Language Models as Instructors: A Study on Multilingual Clinical Entity Extraction,2023,4.8244408528298796e-05,2
W4392791588,Can large language models replace humans in systematic reviews? Evaluating <scp>GPT</scp>‐4's efficacy in screening and extracting data from peer‐reviewed and grey literature in multiple languages,2024,4.822263475869288e-05,2
W3176512822,Topic-Aware Evidence Reasoning and Stance-Aware Aggregation for Fact Verification,2021,4.8207049260704715e-05,2
W3197798882,MATE: Multi-view Attention for Table Transformer Efficiency,2021,4.818842609405402e-05,2
W4385572476,Steno AI at SemEval-2023 Task 6: Rhetorical Role Labelling of Legal Documents using Transformers and Graph Neural Networks,2023,4.818730956201322e-05,2
W4386776484,A survey of deep learning techniques for machine reading comprehension,2023,4.818561266507254e-05,2
W4398138749,MOSS: An Open Conversational Large Language Model,2024,4.8169165292311806e-05,2
W3158724005,Decontextualization: Making Sentences Stand-Alone,2021,4.816056562174832e-05,2
W4303614602,Annotation Error Detection: Analyzing the Past and Present for a More Coherent Future,2022,4.8156154871382785e-05,2
W4390789641,Lightweight transformers for clinical natural language processing,2024,4.815591461476345e-05,2
W3158360872,Gradient-based Adversarial Attacks against Text Transformers,2021,4.8144874960126736e-05,2
W3113790969,A Vietnamese Dataset for Evaluating Machine Reading Comprehension,2020,4.814468918530482e-05,2
W3036290069,"CO-Search: COVID-19 Information Retrieval with Semantic Search, Question Answering, and Abstractive Summarization",2020,4.813719064317535e-05,2
W3163322517,Logic-Driven Context Extension and Data Augmentation for Logical Reasoning of Text,2022,4.809649895060542e-05,2
W3002535714,Dual Multi-head Co-attention for Multi-choice Reading Comprehension.,2020,4.8087393858241284e-05,2
W4316039346,TaxonPrompt: Taxonomy-aware curriculum prompt learning for few-shot event classification,2023,4.808181199068286e-05,2
W3037530970,A Cross-Task Analysis of Text Span Representations,2020,4.8066984965702285e-05,2
W4226244192,ERNIE-GeoL: A Geography-and-Language Pre-trained Model and its Applications in Baidu Maps,2022,4.804032933998407e-05,2
W4391473819,Knowledge Graph Embedding: A Survey from the Perspective of Representation Spaces,2024,4.804032933998407e-05,2
W4320507288,RAILD: Towards Leveraging Relation Features for Inductive Link Prediction In Knowledge Graphs,2022,4.803107389765565e-05,2
W3104727373,Combining computational controls with natural text reveals new aspects of meaning composition,2020,4.797266033491618e-05,2
W3182352988,CokeBERT: Contextual knowledge selection and embedding towards enhanced pre-trained language models,2021,4.795828480848603e-05,2
W4400477691,Advancing multimodal diagnostics: Integrating industrial textual data and domain knowledge with large language models,2024,4.792320574695885e-05,2
W3087094142,FarsTail: a Persian natural language inference dataset,2023,4.791643010838022e-05,2
W3196948150,Overview of the CLEF-2021 CheckThat! Lab Task 2 on detecting previously fact-checked claims in tweets and political debates,2021,4.789153997569564e-05,2
W4385573529,TIARA: Multi-grained Retrieval for Robust Question Answering over Large Knowledge Base,2022,4.787986389884254e-05,2
W3207976211,Knowledge Enhanced Pretrained Language Models: A Compreshensive Survey,2021,4.7875730542542704e-05,2
W4285606726,Human Parity on CommonsenseQA: Augmenting Self-Attention with External Attention,2022,4.78711765187137e-05,2
W3085552234,QED: A Framework and Dataset for Explanations in Question Answering,2020,4.787071861649133e-05,2
W4225716497,Ultra-fine Entity Typing with Indirect Supervision from Natural Language Inference,2022,4.786942259014296e-05,2
W3104104399,Learning Variational Word Masks to Improve the Interpretability of Neural Text Classifiers,2020,4.786601150006976e-05,2
W3034928924,Bridging Anaphora Resolution as Question Answering,2020,4.7856286070026375e-05,2
W4285107336,Prompt-free and Efficient Few-shot Learning with Language Models,2022,4.78543118593624e-05,2
W3203587881,Improving Inductive Link Prediction Using Hyper-relational Facts,2021,4.7849113953478146e-05,2
W3088181395,Attention Meets Perturbations: Robust and Interpretable Attention With Adversarial Training,2021,4.7837070647812256e-05,2
W3133029875,Investigating the Limitations of Transformers with Simple Arithmetic Tasks,2021,4.782708142505413e-05,2
W3209632425,A Simple and Effective Positional Encoding for Transformers,2021,4.782422389998061e-05,2
W4285241989,Exploring the Impact of Negative Samples of Contrastive Learning: A Case Study of Sentence Embedding,2022,4.7817048127530044e-05,2
W3084470717,Critical Thinking for Language Models,2020,4.7798227067828684e-05,2
W2872710616,A Review on Deep Learning Techniques Applied to Answer Selection,2018,4.778765155843101e-05,2
W3035261420,Do Neural Language Models Show Preferences for Syntactic Formalisms?,2020,4.778620937558912e-05,2
W4220758630,Complex graph convolutional network for link prediction in knowledge graphs,2022,4.77859543436979e-05,2
W4282813613,Ask to Know More,2022,4.77810932817361e-05,2
W4307138871,"Automated clinical coding: what, why, and where we are?",2022,4.776093575713521e-05,2
W4221086307,A 28nm 15.59µJ/Token Full-Digital Bitline-Transpose CIM-Based Sparse Transformer Accelerator with Pipeline/Parallel Reconfigurable Modes,2022,4.775923271672355e-05,2
W4393946785,Improving dense retrieval models with LLM augmented data for dataset search,2024,4.775923271672355e-05,2
W2994636820,Cross-Lingual Machine Reading Comprehension,2019,4.775395242887321e-05,2
W3207622241,EdgeBERT: Sentence-Level Energy Optimizations for Latency-Aware Multi-Task NLP Inference,2021,4.774565057954409e-05,2
W3177071108,DynaSent: A Dynamic Benchmark for Sentiment Analysis,2021,4.774005875969206e-05,2
W3109507892,KGTK: A Toolkit for Large Knowledge Graph Manipulation and Analysis,2020,4.7738553614690375e-05,2
W3213189520,SimCSE: Simple Contrastive Learning of Sentence Embeddings,2021,4.7713028555030216e-05,2
W4389519059,Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations,2023,4.7706260670091856e-05,2
W4286567174,“Note Bloat” impacts deep learning-based NLP models for clinical prediction tasks,2022,4.768505495779598e-05,2
W4226391416,Squeezing Water from a Stone: A Bag of Tricks for Further Improving Cross-Encoder Effectiveness for Reranking,2022,4.767863739949859e-05,2
W2970688856,Incorporating Domain Knowledge into Medical NLI using Knowledge Graphs,2019,4.767662357779883e-05,2
W4242776313,Proceedings of the First Workshop on Commonsense Inference in Natural Language Processing,2019,4.767470250217944e-05,2
W2997521893,What Does My QA Model Know? Devising Controlled Probes using Expert Knowledge,2019,4.7664165853922294e-05,2
W4385573898,ASQA: Factoid Questions Meet Long-Form Answers,2022,4.765903105894708e-05,2
W4389518684,LLMaAA: Making Large Language Models as Active Annotators,2023,4.765488624293745e-05,2
W3130089296,Variational Information Bottleneck for Effective Low-Resource Fine-Tuning,2021,4.7645582446293116e-05,2
W4385568240,WebGLM: Towards An Efficient Web-Enhanced Question Answering System with Human Preferences,2023,4.7637347885267514e-05,2
W3035094063,Multi-source Meta Transfer for Low Resource Multiple-Choice Question Answering,2020,4.763677879085416e-05,2
W2971042182,Discourse-Aware Semantic Self-Attention for Narrative Reading Comprehension,2019,4.762233838013194e-05,2
W3213407400,How Much Do Language Models Copy From Their Training Data? Evaluating Linguistic Novelty in Text Generation Using RAVEN,2023,4.762225004576453e-05,2
W4313655989,Knowledge graph extension with a pre-trained language model via unified learning method,2023,4.7621715275270054e-05,2
W4367628274,A Unified Generative Retriever for Knowledge-Intensive Language Tasks via Prompt Learning,2023,4.7617471748036144e-05,2
W4385572905,Zero-Shot Text Classification with Self-Training,2022,4.761536865959102e-05,2
W3195376057,A Dataset for Answering Time-Sensitive Questions,2021,4.757340994768508e-05,2
W4376864968,Augmenting Low-Resource Text Classification with Graph-Grounded Pre-training and Prompting,2023,4.756914416901988e-05,2
W3158856706,Scholarly Text Classification with Sentence BERT and Entity Embeddings,2021,4.7567350303110996e-05,2
W2964146920,Lingke: a Fine-grained Multi-turn Chatbot for Customer Service,2018,4.756539193110901e-05,2
W4385572752,Generating Literal and Implied Subquestions to Fact-check Complex Claims,2022,4.75650175297277e-05,2
W4385573668,Towards Tracing Knowledge in Language Models Back to the Training Data,2022,4.755430496988589e-05,2
W4389009551,Analogy Generation by Prompting Large Language Models: A Case Study of InstructGPT,2022,4.753475380534723e-05,2
W3004153848,ERNIE-GEN: An Enhanced Multi-Flow Pre-training and Fine-tuning Framework for Natural Language Generation,2020,4.752806318443137e-05,2
W2978832950,Distilling Transformers into Simple Neural Networks with Unlabeled Transfer Data.,2019,4.750410728390394e-05,2
W3173209146,PsyQA: A Chinese Dataset for Generating Long Counseling Text for Mental Health Support,2021,4.749430577187985e-05,2
W3043240831,COVID-19 SignSym: a fast adaptation of a general clinical NLP tool to identify and normalize COVID-19 signs and symptoms to OMOP common data model,2021,4.74871485289923e-05,2
W3036927603,FasTag: Automatic text classification of unstructured medical narratives,2020,4.748314396049986e-05,2
W3162385798,How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering,2020,4.7482737345752506e-05,2
W3089695206,A Survey on Explainability in Machine Reading Comprehension,2020,4.7472344151930866e-05,2
W3035051781,Enhancing Pre-trained Chinese Character Representation with Word-aligned Attention,2020,4.746868008190126e-05,2
W3038445625,Representation Learning for Natural Language Processing,2023,4.745862470900745e-05,2
W3173854146,Syntax-Enhanced Pre-trained Model,2021,4.745252890359441e-05,2
W4241900798,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts,2020,4.744593279724192e-05,2
W3101056292,ProtoQA: A Question Answering Dataset for Prototypical Common-Sense Reasoning,2020,4.744458948856892e-05,2
W4210894209,Framework for Deep Learning-Based Language Models Using Multi-Task Learning in Natural Language Understanding: A Systematic Literature Review and Future Directions,2022,4.74306450225382e-05,2
W3179219974,FaVIQ: FAct Verification from Information-seeking Questions,2022,4.742850399603305e-05,2
W4391407054,Give us the Facts: Enhancing Large Language Models With Knowledge Graphs for Fact-Aware Language Modeling,2024,4.7407861937647906e-05,2
W3188635098,"Drop Redundant, Shrink Irrelevant: Selective Knowledge Injection for Language Pretraining",2021,4.74056552784038e-05,2
W2808281579,Hermitian Co-Attention Networks for Text Matching in Asymmetrical Domains,2018,4.7355477479098364e-05,2
W3093937844,A Multidimensional Dataset Based on Crowdsourcing for Analyzing and Detecting News Bias,2020,4.73355088530673e-05,2
W3173644040,Psycholinguistic Tripartite Graph Network for Personality Detection,2021,4.7323184623666934e-05,2
W3105302490,Avoiding the Hypothesis-Only Bias in Natural Language Inference via Ensemble Adversarial Training,2020,4.732019536525845e-05,2
W3195014936,Conversations with Search Engines: SERP-based Conversational Response Generation,2021,4.73200813085077e-05,2
W2996775350,Knowledge Graph Embedding via Graph Attenuated Attention Networks,2019,4.730935783988008e-05,2
W4381686872,Questions Are All You Need to Train a Dense Passage Retriever,2023,4.730499456579191e-05,2
W3094336525,Neural Passage Retrieval with Improved Negative Contrast,2020,4.730335905266007e-05,2
W4387847108,XuanYuan 2.0: A Large Chinese Financial Chat Model with Hundreds of Billions Parameters,2023,4.730242524386931e-05,2
W3153055969,B-PROP: Bootstrapped Pre-training with Representative Words Prediction for Ad-hoc Retrieval,2021,4.730113566856485e-05,2
W2981320891,MRQA 2019 Shared Task: Evaluating Generalization in Reading Comprehension,2019,4.729936022388015e-05,2
W3167361718,Scientific Language Models for Biomedical Knowledge Base Completion: An Empirical Study,2021,4.729741989408319e-05,2
W2968561320,A Study of BERT for Non-Factoid Question-Answering under Passage Length Constraints,2019,4.729591285040247e-05,2
W3133407825,Multi-Turn Dialogue Reading Comprehension With Pivot Turns and Knowledge,2021,4.7293002500090436e-05,2
W4392402185,Datasets for Large Language Models: A Comprehensive Survey,2024,4.725942187589938e-05,2
W3006942207,Text Similarity in Vector Space Models: A Comparative Study,2019,4.724301743261642e-05,2
W3157844032,RE-BERT,2021,4.721926827820164e-05,2
W4285149128,A Sentence is Worth 128 Pseudo Tokens: A Semantic-Aware Contrastive Learning Framework for Sentence Embeddings,2022,4.720672496792414e-05,2
W4307392750,BioKnowPrompt: Incorporating imprecise knowledge into prompt-tuning verbalizer with biomedical text for relation extraction,2022,4.7193670436174256e-05,2
W4385570326,Large Language Models with Controllable Working Memory,2023,4.71893699208315e-05,2
W3097239661,Is Graph Structure Necessary for Multi-hop Question Answering?,2020,4.718403191333977e-05,2
W4321749402,On the effectiveness of compact biomedical transformers,2023,4.717894976671167e-05,2
W4223651117,KCD: Knowledge Walks and Textual Cues Enhanced Political Perspective Detection in News Media,2022,4.717125498723838e-05,2
W4388116325,Natural language processing with machine learning methods to analyze unstructured patient-reported outcomes derived from electronic health records: A systematic review,2023,4.7162967152231545e-05,2
W3037636427,What’s in a Name? Are BERT Named Entity Representations just as Good for any other Name?,2020,4.7120395828272736e-05,2
W3140853032,Comparing Score Aggregation Approaches for Document Retrieval with Pretrained Transformers,2021,4.709463385710563e-05,2
W4285123725,On the Importance of Effectively Adapting Pretrained Language Models for Active Learning,2022,4.7091854258124823e-05,2
W4398183427,Evaluating the accuracy of a state-of-the-art large language model for prediction of admissions from the emergency room,2024,4.708615172236825e-05,2
W2984673553,Higher-order Comparisons of Sentence Encoder Representations,2019,4.708606139616356e-05,2
W3152979241,DISCOS: Bridging the Gap between Discourse Knowledge and Commonsense Knowledge,2021,4.7076387004135276e-05,2
W4285254489,Memorisation versus Generalisation in Pre-trained Language Models,2022,4.7059484699618764e-05,2
W3175049034,A Cluster-based Approach for Improving Isotropy in Contextual Embedding Space,2021,4.705523360147287e-05,2
W3098147269,The Go Transformer: Natural Language Modeling for Game Play,2020,4.704901671728525e-05,2
W4389519438,LEXTREME: A Multi-Lingual and Multi-Task Benchmark for the Legal Domain,2023,4.70209447911172e-05,2
W3167227435,Discourse Probing of Pretrained Language Models,2021,4.701350885207989e-05,2
W4226325130,Out-of-Domain Semantics to the Rescue! Zero-Shot Hybrid Retrieval Models,2022,4.6987298324266185e-05,2
W3102783139,Noisy Text Data: Achilles’ Heel of BERT,2020,4.697577417603826e-05,2
W3180037928,Learned Token Pruning for Transformers,2022,4.6960546929003996e-05,2
W4387171578,Transferring Procedural Knowledge Across Commonsense Tasks,2023,4.693936756554705e-05,2
W4385572867,Iteratively Prompt Pre-trained Language Models for Chain of Thought,2022,4.693771888156695e-05,2
W3030406438,Why Attention is Not Explanation: Surgical Intervention and Causal Reasoning about Neural Models.,2020,4.690772339948339e-05,2
W4389519219,Med-HALT: Medical Domain Hallucination Test for Large Language Models,2023,4.6904604874100674e-05,2
W3175287561,COM2SENSE: A Commonsense Reasoning Benchmark with Complementary Sentences,2021,4.6899181309398416e-05,2
W3136275640,Customizing Contextualized Language Models for Legal Document Reviews,2020,4.689225101321481e-05,2
W3176647794,Super Tickets in Pre-Trained Language Models: From Model Compression to Improving Generalization,2021,4.688531717856893e-05,2
W3034403033,On the Importance of Word and Sentence Representation Learning in Implicit Discourse Relation Classification,2020,4.68717617425433e-05,2
W3173647480,Making the Relation Matters: Relation of Relation Learning Network for Sentence Semantic Matching,2021,4.6866905544017526e-05,2
W3089285634,Ape210K: A Large-Scale and Template-Rich Dataset of Math Word Problems,2020,4.684886979022701e-05,2
W3163313089,The Low-Dimensional Linear Geometry of Contextualized Word Representations,2021,4.6845334018951335e-05,2
W3172097791,Coarse-grained decomposition and fine-grained interaction for multi-hop question answering,2021,4.6844420483712655e-05,2
W3088652013,Embedding-based Zero-shot Retrieval through Query Generation,2020,4.683573278166568e-05,2
W4200427693,An attentive joint model with transformer-based weighted graph convolutional network for extracting adverse drug event relation,2021,4.6835379273796995e-05,2
W3109746361,Two Stage Transformer Model for COVID-19 Fake News Detection and Fact Checking,2020,4.6804142710249726e-05,2
W3175236579,Dynamic Contextualized Word Embeddings,2021,4.6801824569728884e-05,2
W4285309087,An Analysis of Negation in Natural Language Understanding Corpora,2022,4.6800309696502654e-05,2
W3008219293,TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural Language Processing,2020,4.6789701686481884e-05,2
W4385573119,The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models,2022,4.676990747115311e-05,2
W3161801106,e-ViL: A Dataset and Benchmark for Natural Language Explanations in Vision-Language Tasks,2021,4.676513485302803e-05,2
W4280546523,Transkimmer: Transformer Learns to Layer-wise Skim,2022,4.6730199843729016e-05,2
W4309625848,Self-attention presents low-dimensional knowledge graph embeddings for link prediction,2022,4.672854509810166e-05,2
W4404719247,Contextual feature extraction hierarchies converge in large language models and the brain,2024,4.6722383271793884e-05,2
W3034470897,Reverse Engineering Configurations of Neural Text Generation Models,2020,4.669291654960793e-05,2
W4296878971,Kformer: Knowledge Injection in Transformer Feed-Forward Layers,2022,4.668596920318632e-05,2
W3048018176,Does BERT Solve Commonsense Task via Commonsense Knowledge,2020,4.668201334496659e-05,2
W3173902720,Positional Artefacts Propagate Through Masked Language Model Embeddings,2021,4.6675591182420376e-05,2
W3154732937,CHOLAN: A Modular Approach for Neural Entity Linking on Wikipedia and Wikidata,2021,4.665626452551549e-05,2
W3195296860,A Statutory Article Retrieval Dataset in French,2022,4.6653677625867556e-05,2
W3035091181,Teaching Pre-Trained Models to Systematically Reason Over Implicit Knowledge.,2020,4.662573018598417e-05,2
W3028004046,Recent advances in biomedical literature mining,2020,4.6610414658815974e-05,2
W4220997345,FedQAS: Privacy-Aware Machine Reading Comprehension with Federated Learning,2022,4.660556532542519e-05,2
W4367396999,DictPrompt: Comprehensive dictionary-integrated prompt tuning for pre-trained language model,2023,4.660556532542519e-05,2
W2971339032,Catastrophic Forgetting Meets Negative Transfer: Batch Spectral Shrinkage for Safe Transfer Learning,2019,4.6596700043293366e-05,2
W3184259550,Event-Centric Natural Language Processing,2021,4.659517657698781e-05,2
W3196986263,Neuron-level Interpretation of Deep NLP Models: A Survey,2022,4.6591279681321534e-05,2
W4386852102,"A systematic review on media bias detection: What is media bias, how it is expressed, and how to detect it",2023,4.6587996786471404e-05,2
W3116878798,Intent Mining from past conversations for Conversational Agent,2020,4.6587996786471404e-05,2
W4389523675,Context-faithful Prompting for Large Language Models,2023,4.658516872255574e-05,2
W2949803292,RankQA: Neural Question Answering with Answer Re-Ranking,2019,4.658017617992265e-05,2
W4205523551,Automated Essay Scoring Using Transformer Models,2021,4.6572145843239084e-05,2
W4388144292,SORBET: A Siamese Network for Ontology Embeddings Using a Distance-Based Regression Loss and BERT,2023,4.6560230459486145e-05,2
W3090789254,Cost-effective Selection of Pretraining Data: A Case Study of Pretraining BERT on Social Media,2020,4.6559427210726985e-05,2
W4378472501,Constructing a disease database and using natural language processing to capture and standardize free text clinical information,2023,4.654164970906221e-05,2
W3154449322,Syntax-BERT: Improving Pre-trained Transformers with Syntax Trees,2021,4.6540204223732094e-05,2
W4293140814,A Review of Knowledge Graph Completion,2022,4.6539897152922003e-05,2
W3144600905,ASER: Towards large-scale commonsense knowledge acquisition via higher-order selectional preference over eventualities,2022,4.6533499782383864e-05,2
W4225858632,A Survey of Adversarial Defenses and Robustness in NLP,2023,4.6532720023302754e-05,2
W3102812725,Intrinsic Probing through Dimension Selection,2020,4.652785454075095e-05,2
W4243640523,"Attention Mechanism, Transformers, BERT, and GPT: Tutorial and Survey",2020,4.651625901138134e-05,2
W3018642446,Attention is Not Only a Weight: Analyzing Transformers with Vector Norms,2020,4.646113973428249e-05,2
W4382202657,On the Effectiveness of Parameter-Efficient Fine-Tuning,2023,4.643003325048139e-05,2
W4383618720,AD-BERT: Using pre-trained language model to predict the progression from mild cognitive impairment to Alzheimer's disease,2023,4.642464979845328e-05,2
W3174461835,Accelerating BERT Inference for Sequence Labeling via Early-Exit,2021,4.6419279650278524e-05,2
W4229038710,Refined Commonsense Knowledge from Large-Scale Web Contents,2022,4.639990608396965e-05,2
W3024171804,Movement Pruning: Adaptive Sparsity by Fine-Tuning,2020,4.6385834772991174e-05,2
W3174583470,Math Word Problem Solving with Explicit Numerical Values,2021,4.637593257053058e-05,2
W3168591151,Accounting for Agreement Phenomena in Sentence Comprehension with Transformer Language Models: Effects of Similarity-based Interference on Surprisal and Attention,2021,4.6362831633610854e-05,2
W2965536863,Answering Binary Causal Questions Through Large-Scale Text Mining: An Evaluation Using Cause-Effect Pairs from Human Experts,2019,4.63621267860642e-05,2
W4385573637,ClinicalT5: A Generative Language Model for Clinical Text,2022,4.6360070758355125e-05,2
W4297238006,Stepwise relation prediction with dynamic reasoning network for multi-hop knowledge graph question answering,2022,4.636003904565539e-05,2
W3155933491,Bi-GRU Urgent Classification for MOOC Discussion Forums Based on BERT,2021,4.635941731093163e-05,2
W3174870841,Zero-shot Event Extraction via Transfer Learning: Challenges and Insights,2021,4.635358226952876e-05,2
W3168386607,Too Much in Common: Shifting of Embeddings in Transformer Language Models and its Implications,2021,4.635040515737782e-05,2
W4285286514,ExtEnD: Extractive Entity Disambiguation,2022,4.6348605404669414e-05,2
W4292939077,Overview of the CLEF–2022 CheckThat! Lab on Fighting the COVID-19 Infodemic and Fake News Detection,2022,4.6347207030284153e-05,2
W3107377711,Self-Explaining Structures Improve NLP Models,2020,4.634503129504868e-05,2
W2986650838,Team SVMrank: Leveraging Feature-rich Support Vector Machines for Ranking Explanations to Elementary Science Questions,2019,4.6343286891161584e-05,2
W4384659456,Learn from Relational Correlations and Periodic Events for Temporal Knowledge Graph Reasoning,2023,4.6337859503996405e-05,2
W3034364750,Document Modeling with Graph Attention Networks for Multi-grained Machine Reading Comprehension,2020,4.6310484167555016e-05,2
W3207699717,Yuan 1.0: Large-Scale Pre-trained Language Model in Zero-Shot and Few-Shot Learning,2021,4.63017586133182e-05,2
W2963408280,Neural Machine Translation Inspired Binary Code Similarity Comparison beyond Function Pairs,2019,4.627753088943572e-05,2
W3175515348,Reader-Guided Passage Reranking for Open-Domain Question Answering,2021,4.626720288173788e-05,2
W3165773193,External features enriched model for biomedical question answering,2021,4.626685629801273e-05,2
W2986138048,CogniVal: A Framework for Cognitive Word Embedding Evaluation,2019,4.625526959367369e-05,2
W3170894870,Automatic Story Generation: Challenges and Attempts,2021,4.625495839586928e-05,2
W4287887983,A Shoulder to Cry on: Towards A Motivational Virtual Assistant for Assuaging Mental Agony,2022,4.6236626007395765e-05,2
W2998536339,ManyModalQA: Modality Disambiguation and QA over Diverse Inputs,2020,4.623475757864464e-05,2
W4221142828,Can Prompt Probe Pretrained Language Models? Understanding the Invisible Risks from a Causal View,2022,4.621676544137693e-05,2
W4385059308,Medical Reports Summarization Using Text-To-Text Transformer,2023,4.621595713803837e-05,2
W4378232119,Automated Classification for Open-Ended Questions with BERT,2023,4.621595713803837e-05,2
W4385562555,Heterformer: Transformer-based Deep Node Representation Learning on Heterogeneous Text-Rich Networks,2023,4.620664672094916e-05,2
W4287890934,In-BoXBART: Get Instructions into Biomedical Multi-Task Learning,2022,4.61822456482483e-05,2
W3105661746,"Compositional and Lexical Semantics in RoBERTa, BERT and DistilBERT: A Case Study on CoQA",2020,4.617138640319608e-05,2
W4321480042,Effective Seed-Guided Topic Discovery by Integrating Multiple Types of Contexts,2023,4.6165454918626196e-05,2
W2915478146,Improving Neural Network Quantization without Retraining using Outlier Channel Splitting,2019,4.6163394186039555e-05,2
W4283790835,Enhanced Story Comprehension for Large Language Models through Dynamic Document-Based Knowledge Graphs,2022,4.6160871746393264e-05,2
W2949611393,Beyond BLEU:Training Neural Machine Translation with Semantic Similarity,2019,4.615168867339717e-05,2
W4287887524,Global Entity Disambiguation with BERT,2022,4.6149662442861485e-05,2
W4285605599,Subgraph Neighboring Relations Infomax for Inductive Link Prediction on Knowledge Graphs,2022,4.61201103851048e-05,2
W4287887107,"When a sentence does not introduce a discourse entity, Transformer-based models still sometimes refer to it",2022,4.6117691670285295e-05,2
W3007978994,Differentiable Reasoning over a Virtual Knowledge Base,2020,4.6110532398782284e-05,2
W4385572714,"Tomayto, Tomahto. Beyond Token-level Answer Equivalence for Question Answering Evaluation",2022,4.609152181461432e-05,2
W3199761064,Raise a Child in Large Language Model: Towards Effective and Generalizable Fine-tuning,2021,4.608759952377365e-05,2
W4385573834,E-NER — An Annotated Named Entity Recognition Corpus of Legal Text,2022,4.608736561340737e-05,2
W4200186624,Hierarchical BERT with an adaptive fine-tuning strategy for document classification,2021,4.6078509156811725e-05,2
W3093452197,Attention Flows: Analyzing and Comparing Attention Mechanisms in Language Models,2020,4.607393367498688e-05,2
W4206529673,Discrete and Soft Prompting for Multilingual Models,2021,4.606317160913672e-05,2
W3049254243,A Survey of Active Learning for Text Classification using Deep Neural Networks,2020,4.6060294779529714e-05,2
W4210497109,Testing Your Question Answering Software via Asking Recursively,2021,4.604122138706348e-05,2
W3102466593,Word Rotator’s Distance,2020,4.6022750287232504e-05,2
W4386504863,Can GPT-3 Perform Statutory Reasoning?,2023,4.6007561780982405e-05,2
W3166298099,Incorporating External Knowledge to Enhance Tabular Reasoning,2021,4.59989728089802e-05,2
W4221152557,Just Rank: Rethinking Evaluation with Word and Sentence Similarities,2022,4.599721148559107e-05,2
W4310993626,A Paradigm Shift from “Human Writing” to “Machine Generation” in Personality Test Development: an Application of State-of-the-Art Natural Language Processing,2022,4.598418844952661e-05,2
W3119017286,Improving question answering for event-focused questions in temporal collections of news articles,2021,4.595242044513602e-05,2
W3201193395,MirrorWiC: On Eliciting Word-in-Context Representations from Pretrained Language Models,2021,4.594034105083e-05,2
W4225104598,LaPraDoR: Unsupervised Pretrained Dense Retriever for Zero-Shot Text Retrieval,2022,4.5925253624718766e-05,2
W3211781298,"COVID-19 in Bulgarian Social Media: Factuality, Harmfulness, Propaganda, and Framing",2021,4.5925158450134745e-05,2
W3005187732,Description Based Text Classification with Reinforcement Learning,2020,4.591061898036724e-05,2
W4385570982,Increasing Diversity While Maintaining Accuracy: Text Data Generation with Large Language Models and Human Interventions,2023,4.5909177580342186e-05,2
W3170719901,Are Pretrained Convolutions Better than Pretrained Transformers?,2021,4.5906807536829416e-05,2
W4384891026,The Tale of Two MSMARCO - and Their Unfair Comparisons,2023,4.588525522832012e-05,2
W4385571534,Synthetic Text Generation with Differential Privacy: A Simple and Practical Recipe,2023,4.58792756752905e-05,2
W3157651462,"Neural, symbolic and neural-symbolic reasoning on knowledge graphs",2021,4.5858272348849345e-05,2
W4285288079,SciNLI: A Corpus for Natural Language Inference on Scientific Text,2022,4.585809768155029e-05,2
W4206104244,Dynamic Graph Reasoning for Conversational Open-Domain Question Answering,2022,4.584802857664128e-05,2
W3137492414,Inductive Relation Prediction by BERT,2022,4.584104135709648e-05,2
W3079786700,"Language Models as Knowledge Bases: On Entity Representations, Storage Capacity, and Paraphrased Queries",2020,4.583981181941893e-05,2
W3177308635,xMoCo: Cross Momentum Contrastive Learning for Open-Domain Question Answering,2021,4.579978296717604e-05,2
W4286252375,A review on Natural Language Processing Models for COVID-19 research,2022,4.5796525233604046e-05,2
W3034624105,DoQA - Accessing Domain-Specific FAQs via Conversational QA,2020,4.5779781537850505e-05,2
W3099965312,Table Search Using a Deep Contextualized Language Model,2020,4.577039643096163e-05,2
W3006881356,A Primer in BERTology: What we know about how BERT works,2020,4.576969044239414e-05,2
W3170739233,SPARTA: Efficient Open-Domain Question Answering via Sparse Transformer Matching Retrieval,2021,4.576714605620879e-05,2
W4391019401,Short text classification with Soft Knowledgeable Prompt-tuning,2024,4.5763039305163374e-05,2
W3166574921,Know what you don't need: Single-Shot Meta-Pruning for attention heads,2021,4.574615622237319e-05,2
W2898936689,Sequence Classification with Human Attention,2018,4.574102642963169e-05,2
W3104591237,Counterfactual Generator: A Weakly-Supervised Method for Named Entity Recognition,2020,4.572888155224129e-05,2
W3172045361,Fool Me Twice: Entailment from Wikipedia Gamification,2021,4.5726941586229995e-05,2
W3175352680,End-to-End Self-Debiasing Framework for Robust NLU Training,2021,4.572372641803606e-05,2
W4393994727,Language models accurately infer correlations between psychological items and scales from text alone,2024,4.57095698387823e-05,2
W3118423825,Building Machine Learning Systems for Automated ESG Scoring,2021,4.57095698387823e-05,2
W4303648884,State-of-the-art generalisation research in NLP: A taxonomy and review,2022,4.570889348268934e-05,2
W3031912764,Beyond Leaderboards: A survey of methods for revealing weaknesses in Natural Language Inference data and models,2020,4.57085403085649e-05,2
W4385571276,Sequential Integrated Gradients: a simple but effective method for explaining language models,2023,4.570715672193769e-05,2
W3156413894,Intra-Document Cascading,2021,4.5682698742104325e-05,2
W3213868621,Shortcutted Commonsense: Data Spuriousness in Deep Learning of Commonsense Reasoning,2021,4.567951569659103e-05,2
W3094756469,Accenture at CheckThat! 2020: If you say so: Post-hoc fact-checking of claims using transformer-based models,2020,4.567477268806311e-05,2
W4388936696,Prompt-Learning for Short Text Classification,2023,4.566846961323614e-05,2
W4310390625,Transformers for Tabular Data Representation: A Survey of Models and Applications,2023,4.565617745669453e-05,2
W3115242847,Mixup-Transformer: Dynamic Data Augmentation for NLP Tasks,2020,4.564421344900543e-05,2
W3034651559,A Self-Training Method for Machine Reading Comprehension with Soft Evidence Extraction,2020,4.564130059238909e-05,2
W4200629408,JointLK: Joint Reasoning with Language Models and Knowledge Graphs for Commonsense Question Answering,2022,4.5637489395723176e-05,2
W2988584128,Multi-Paragraph Reasoning with Knowledge-enhanced Graph Neural Network,2019,4.5618742725142574e-05,2
W3166035055,RECONSIDER: Improved Re-Ranking using Span-Focused Cross-Attention for Open Domain Question Answering,2021,4.5604570499363685e-05,2
W4385572697,When FLUE Meets FLANG: Benchmarks and Large Pretrained Language Model for Financial Domain,2022,4.559321982756351e-05,2
W4296606109,Learning knowledge graph embedding with a dual-attention embedding network,2022,4.557639227807435e-05,2
W3175505246,EarlyBERT: Efficient BERT Training via Early-bird Lottery Tickets,2021,4.555290893045392e-05,2
W4285292976,CICERO: A Dataset for Contextualized Commonsense Inference in Dialogues,2022,4.554640280094235e-05,2
W4385570864,KILM: Knowledge Injection into Encoder-Decoder Language Models,2023,4.553110062227449e-05,2
W4311711471,Reinforcement learning-driven deep question generation with rich semantics,2022,4.552939978447226e-05,2
W2936615257,Quizbowl: The Case for Incremental Question Answering.,2019,4.55249941495226e-05,2
W2963259903,WinoGrande: An Adversarial Winograd Schema Challenge at Scale,2019,4.5518369871751425e-05,2
W4385571795,Preserving Commonsense Knowledge from Pre-trained Language Models via Causal Inference,2023,4.550972485784267e-05,2
W4385571765,Exploring Zero and Few-shot Techniques for Intent Classification,2023,4.5499121757798104e-05,2
W3174102190,Embracing Ambiguity: Shifting the Training Target of NLI Models,2021,4.549706586519348e-05,2
W3105478389,Recurrent babbling: evaluating the acquisition of grammar from limited input data,2020,4.549628602437355e-05,2
W4221159558,PTM4Tag,2022,4.549079411789538e-05,2
W3174738170,Learning Contextualized Knowledge Structures for Commonsense Reasoning,2021,4.549019924368969e-05,2
W4385570391,A Survey of Deep Learning for Mathematical Reasoning,2023,4.548486567598017e-05,2
W3156476125,Analyzing the Forgetting Problem in Pretrain-Finetuning of Open-domain Dialogue Response Models,2021,4.547600766658836e-05,2
W3156584161,AraFacts: The First Large Arabic Dataset of Naturally Occurring Claims,2021,4.5471027919755604e-05,2
W4402407635,Prompt Engineering Paradigms for Medical Applications: Scoping Review,2024,4.546361029342934e-05,2
W4225392244,Deep learning-based approach for Arabic open domain question answering,2022,4.546361029342934e-05,2
W3175423875,SMedBERT: A Knowledge-Enhanced Pre-trained Language Model with Structured Semantics for Medical Text Mining,2021,4.5452072302942745e-05,2
W3213645763,“Will You Find These Shortcuts?” A Protocol for Evaluating the Faithfulness of Input Salience Methods for Text Classification,2022,4.5450929347196604e-05,2
W3156194904,Deep Subjecthood: Higher-Order Grammatical Features in Multilingual BERT,2021,4.543661168669998e-05,2
W4285298468,Interpreting the Robustness of Neural NLP Models to Textual Perturbations,2022,4.541580085948665e-05,2
W3209619108,PathReasoner: Explainable reasoning paths for commonsense question answering,2021,4.5404725273089796e-05,2
W4389518953,NLP Evaluation in trouble: On the Need to Measure LLM Data Contamination for each Benchmark,2023,4.5399676122863484e-05,2
W4384697713,"Lexical-Semantic Content, Not Syntactic Structure, Is the Main Contributor to ANN-Brain Similarity of fMRI Responses in the Language Network",2023,4.539943432726094e-05,2
W2742940593,A Hybrid Framework for Text Modeling with Convolutional RNN,2017,4.539877410989685e-05,2
W3207663303,Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning.,2021,4.5371331473526866e-05,2
W3014961314,A Question Answering-Based Framework for One-Step Event Argument Extraction,2020,4.536460727561152e-05,2
W2985436116,CLER: Cross-task Learning with Expert Representation to Generalize Reading and Understanding,2019,4.535572117652104e-05,2
W4284689801,Automated handling of anaphoric ambiguity in requirements,2022,4.534999547465933e-05,2
W3213059131,Effective Convolutional Attention Network for Multi-label Clinical Document Classification,2021,4.53410509170829e-05,2
W3207796810,KG-FiD: Infusing Knowledge Graph in Fusion-in-Decoder for Open-Domain Question Answering,2022,4.5332392122514234e-05,2
W3166933661,Multi-Step Reasoning Over Unstructured Text with Beam Dense Retrieval,2021,4.533108554876934e-05,2
W4385574113,Calibrating Factual Knowledge in Pretrained Language Models,2022,4.530379339919046e-05,2
W4377100957,KPT++: Refined knowledgeable prompt tuning for few-shot text classification,2023,4.5299637263194045e-05,2
W3115652744,Self-Supervised Hyperboloid Representations from Logical Queries over Knowledge Graphs,2021,4.5299637263194045e-05,2
W4386507114,Pre-trained Language Models for the Legal Domain,2023,4.5299637263194045e-05,2
W4385574265,Control Prefixes for Parameter-Efficient Text Generation,2022,4.529370844907714e-05,2
W3006963874,Improving BERT Fine-Tuning via Self-Ensemble and Self-Distillation,2023,4.528872508327613e-05,2
W4402567773,Biomedical knowledge graph-optimized prompt generation for large language models,2024,4.527574186901594e-05,2
W2768346313,Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing Their Input Gradients,2018,4.527372690259781e-05,2
W3103671331,DagoBERT: Generating Derivational Morphology with a Pretrained Language Model,2020,4.5265862516925525e-05,2
W3197499505,CREAK: A Dataset for Commonsense Reasoning over Entity Knowledge,2021,4.526421610225274e-05,2
W4327927574,Exposing the Vulnerabilities of Deep Learning Models in News Classification,2023,4.526123473909563e-05,2
W3103940211,AxCell: Automatic Extraction of Results from Machine Learning Papers,2020,4.5259622682220234e-05,2
W4385570599,BertNet: Harvesting Knowledge Graphs with Arbitrary Relations from Pretrained Language Models,2023,4.525912357130787e-05,2
W4292474994,Transformer models used for text-based question answering systems,2022,4.525278782598396e-05,2
W3022870761,Question Rewriting for Conversational Question Answering,2020,4.522374349438439e-05,2
W4385573607,Transformer Language Models without Positional Encodings Still Learn Positional Information,2022,4.522018044650957e-05,2
W3175304423,Retrieval Enhanced Model for Commonsense Generation,2021,4.521954494006278e-05,2
W3166859509,BRECQ: Pushing the Limit of Post-Training Quantization by Block Reconstruction,2021,4.521624596812558e-05,2
W4389520670,Enabling Large Language Models to Generate Text with Citations,2023,4.521088327348433e-05,2
W2963058357,Combining Similarity Features and Deep Representation Learning for Stance Detection in the Context of Checking Fake News,2019,4.520140740557792e-05,2
W4388820628,FactLLaMA: Optimizing Instruction-Following Language Models with External Knowledge for Automated Fact-Checking,2023,4.5179523893654027e-05,2
W3148437589,From natural language processing to neural databases,2021,4.5172749979656565e-05,2
W4386857681,"A Survey on Legal Judgment Prediction: Datasets, Metrics, Models and Challenges",2023,4.5169638118699036e-05,2
W4210452949,Construct validity for computational linguistic metrics in individuals at clinical risk for psychosis: Associations with clinical ratings,2022,4.516905967585219e-05,2
W4283796192,LOREN: Logic-Regularized Reasoning for Interpretable Fact Verification,2022,4.5144647534330735e-05,2
W3188599330,Explainable zero-shot learning via attentive graph convolutional network and knowledge graphs,2021,4.513181775474716e-05,2
W3167364369,MelBERT: Metaphor Detection via Contextualized Late Interaction using Metaphorical Identification Theories,2021,4.510186550343562e-05,2
W2970819455,BiPaR: A Bilingual Parallel Dataset for Multilingual and Cross-lingual Reading Comprehension on Novels,2019,4.509277856170435e-05,2
W3091311542,Biomedical Named-Entity Recognition by Hierarchically Fusing BioBERT Representations and Deep Contextual-Level Word-Embedding,2020,4.5089775028365346e-05,2
W4224315024,LitMC-BERT: Transformer-Based Multi-Label Classification of Biomedical Literature With An Application on COVID-19 Literature Curation,2022,4.508636908997891e-05,2
W4360992621,Knowledge graph representation learning with simplifying hierarchical feature propagation,2023,4.507955935342024e-05,2
W3164054899,ConSERT: A Contrastive Framework for Self-Supervised Sentence Representation Transfer,2021,4.507452247430119e-05,2
W2998231212,Infusing Knowledge into the Textual Entailment Task Using Graph Convolutional Networks,2020,4.5056181898543466e-05,2
W3103227045,Context-Aware Answer Extraction in Question Answering,2020,4.504769724516996e-05,2
W3121076170,FiD-Ex: Improving Sequence-to-Sequence Models for Extractive Rationale Generation,2021,4.5044649278037785e-05,2
W4376956580,Check-worthy claim detection across topics for automated fact-checking,2023,4.503957353732672e-05,2
W3087922520,RICA: Evaluating Robust Inference Capabilities Based on Commonsense Axioms,2021,4.503781961432707e-05,2
W4319918988,Joint reasoning with knowledge subgraphs for Multiple Choice Question Answering,2023,4.503541229463954e-05,2
W4287855173,Explaining Toxic Text via Knowledge Enhanced Text Generation,2022,4.503172910719651e-05,2
W3199484478,Mixture-of-Partitions: Infusing Large Biomedical Knowledge Graphs into BERT,2021,4.502698262547112e-05,2
W3174234060,Common Sense Beyond English: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning,2021,4.5024796603806974e-05,2
W3044749682,The Lottery Ticket Hypothesis for Pre-trained BERT Networks,2020,4.500679502248118e-05,2
W3106290101,A matter of framing: The impact of linguistic formalism on probing results,2020,4.500036714953691e-05,2
W3035083185,Knowledge-Aided Open-Domain Question Answering,2020,4.499877103448009e-05,2
W4205881250,Comparison of different feature extraction methods for applicable automated ICD coding,2022,4.499378991804422e-05,2
W3168921656,MERMAID: Metaphor Generation with Symbolism and Discriminative Decoding,2021,4.498443581839212e-05,2
W3021393209,Contrastive Self-Supervised Learning for Commonsense Reasoning,2020,4.4984353932045443e-05,2
W3158542464,Bidirectional Language Modeling: A Systematic Literature Review,2021,4.497255834989078e-05,2
W4385570670,Clustering-Aware Negative Sampling for Unsupervised Sentence Representation,2023,4.497169120272345e-05,2
W4387968301,SUR-adapter: Enhancing Text-to-Image Pre-trained Diffusion Models with Large Language Models,2023,4.497169120272345e-05,2
W2767852858,Towards Accurate Duplicate Bug Retrieval Using Deep Learning Techniques,2017,4.497169120272345e-05,2
W2989622715,Semantic Textual Similarity with Siamese Neural Networks,2019,4.497169120272345e-05,2
W3034760557,Probing Linguistic Features of Sentence-Level Representations in Relation Extraction,2020,4.492765976774453e-05,2
W4366003941,Driving and suppressing the human language network using large language models,2023,4.492443053193006e-05,2
W3113816342,SemGloVe: Semantic Co-Occurrences for GloVe From BERT,2022,4.4913541851271475e-05,2
W3087623576,BioALBERT: A Simple and Effective Pre-trained Language Model for Biomedical Named Entity Recognition,2020,4.491079877369689e-05,2
W3101381894,BiTeM at WNUT 2020 Shared Task-1: Named Entity Recognition over Wet Lab Protocols using an Ensemble of Contextual Language Models,2020,4.491017671321435e-05,2
W4226087293,Compression of Generative Pre-trained Language Models via Quantization,2022,4.489309120922051e-05,2
W3136149525,UNICORN on RAINBOW: A Universal Commonsense Reasoning Model on a New Multitask Benchmark,2021,4.489256064647616e-05,2
W4220913575,Negation and uncertainty detection in clinical texts written in Spanish: a deep learning-based approach,2022,4.4879711699428274e-05,2
W3152409010,Exploring the Role of BERT Token Representations to Explain Sentence Probing Results,2021,4.4864425541646553e-05,2
W3162542754,Accelerating Transformer-based Deep Learning Models on FPGAs using Column Balanced Block Pruning,2021,4.484669696214763e-05,2
W3174429158,What Ingredients Make for an Effective Crowdsourcing Protocol for Difficult NLU Data Collection Tasks?,2021,4.483482552789052e-05,2
W3213176494,A Second Pandemic? Analysis of Fake News About COVID-19 Vaccines in Qatar,2021,4.481081228311053e-05,2
W3190936700,Asynchronous Multi-grained Graph Network For Interpretable Multi-hop Reading Comprehension,2021,4.480718555236741e-05,2
W3198052459,Aligning Cross-lingual Sentence Representations with Dual Momentum Contrast,2021,4.47965304008397e-05,2
W2946582982,On the Importance of Distinguishing Word Meaning Representations: A Case Study on Reverse Dictionary Mapping,2019,4.4780321909468525e-05,2
W3121309507,On Position Embeddings in BERT,2021,4.4773097399341156e-05,2
W2967659330,Visualizing and Understanding the Effectiveness of BERT,2019,4.475316997212635e-05,2
W2945655519,,2019,4.4748435423201576e-05,2
W4327594639,A survey on legal question–answering systems,2023,4.471401929806797e-05,2
W2972984751,Evaluating shallow and deep learning strategies for the 2018 n2c2 shared task on clinical text classification,2019,4.4703371698702046e-05,2
W2769216919,Modelling Domain Relationships for Transfer Learning on Retrieval-based Question Answering Systems in E-commerce,2018,4.470286068839227e-05,2
W3035597164,An Analysis of the Utility of Explicit Negative Examples to Improve the Syntactic Abilities of Neural Language Models,2020,4.469889903408071e-05,2
W3174781928,Neural-Symbolic Solver for Math Word Problems with Auxiliary Tasks,2021,4.468812769479478e-05,2
W4224921946,Using Natural Language Processing and Machine Learning to Preoperatively Predict Lymph Node Metastasis for Non–Small Cell Lung Cancer With Electronic Medical Records: Development and Validation Study,2022,4.466604175005577e-05,2
W3186583010,A novel deep learning approach to extract Chinese clinical entities for lung cancer screening and staging,2021,4.466604175005577e-05,2
W4400199239,Shared functional specialization in transformer-based language models and the human brain,2024,4.4665999023333616e-05,2
W3117435054,Hierarchical Chinese Legal event extraction via Pedal Attention Mechanism,2020,4.466148928547975e-05,2
W3173736278,Improving Paraphrase Detection with the Adversarial Paraphrasing Task,2021,4.466144901964801e-05,2
W3081317618,Clinical information extraction for preterm birth risk prediction,2020,4.465173542386058e-05,2
W3212197935,Benchmarking knowledge-driven zero-shot learning,2022,4.4644602541786825e-05,2
W4382239620,ConTextual Masked Auto-Encoder for Dense Passage Retrieval,2023,4.4643745142252845e-05,2
W4384211302,Efficient Methods for Natural Language Processing: A Survey,2023,4.463802716431065e-05,2
W3194005300,Chatbot Interaction with Artificial Intelligence: human data augmentation with T5 and language transformer ensemble for text classification,2021,4.4636250310220194e-05,2
W3022116759,The Effect of Natural Distribution Shift on Question Answering Models,2020,4.463205900268558e-05,2
W3202408265,Parallel Refinements for Lexically Constrained Text Generation with BART,2021,4.462771770320729e-05,2
W3193647133,Natural Language Understanding with Privacy-Preserving BERT,2021,4.461879878327089e-05,2
W4308749892,Informative pseudo-labeling for graph neural networks with few labels,2022,4.4618183638652725e-05,2
W3012592703,DeepEnroll: Patient-Trial Matching with Deep Embedding and Entailment Prediction,2020,4.460849154104272e-05,2
W4225380759,Entity-aware Transformers for Entity Search,2022,4.459217763704019e-05,2
W3201352722,A Path for Translation of Machine Learning Products into Healthcare Delivery,2020,4.4591370340893186e-05,2
W3176443126,ERNIE-Doc: A Retrospective Long-Document Modeling Transformer,2021,4.458255108259678e-05,2
W4382463911,FacT: Factor-Tuning for Lightweight Adaptation on Vision Transformer,2023,4.457824176399392e-05,2
W3104667152,Which *BERT? A Survey Organizing Contextualized Encoders,2020,4.4577084181494786e-05,2
W4213122582,Identifying Machine-Paraphrased Plagiarism,2022,4.456978306686031e-05,2
W4392282268,Taiyi: a bilingual fine-tuned large language model for diverse biomedical tasks,2024,4.456175862713519e-05,2
W4285174271,Coloring the Blank Slate: Pre-training Imparts a Hierarchical Inductive Bias to Sequence-to-sequence Models,2022,4.4554178773828105e-05,2
W3105261549,Is Multihop QA in DiRe Condition? Measuring and Reducing Disconnected Reasoning,2020,4.453955576495012e-05,2
W4287120901,"Generate, Annotate, and Learn: NLP with Synthetic Text",2022,4.453151522058978e-05,2
W4379379356,Clinical named entity recognition and relation extraction using natural language processing of medical free text: A systematic review,2023,4.452768630916422e-05,2
W3164786495,Convolutional Complex Knowledge Graph Embeddings,2021,4.450360348623743e-05,2
W4312158512,Boosting question answering over knowledge graph with reward integration and policy evaluation under weak supervision,2022,4.4495088640602616e-05,2
W4399391263,LLM-Generated Word Association Norms,2024,4.447977211201754e-05,2
W4295714264,<scp>Semi‐automatic</scp> coding of <scp>open‐ended</scp> text responses in <scp>large‐scale</scp> assessments,2022,4.447977211201754e-05,2
W4399077053,Beyond extraction accuracy: addressing the quality of geographical named entity through advanced recognition and correction models using a modified BERT framework,2024,4.447977211201754e-05,2
W4394810471,Natural language processing (NLP) to facilitate abstract review in medical research: the application of BioBERT to exploring the 20-year use of NLP in medical research,2024,4.447977211201754e-05,2
W4403659146,Enhancing Chinese comprehension and reasoning for large language models: an efficient LoRA fine-tuning and tree of thoughts framework,2024,4.447977211201754e-05,2
W4378375354,Examining transaction-specific satisfaction and trust in Airbnb and hotels. An application of BERTopic and Zero-shot text classification,2023,4.447977211201754e-05,2
W4212975397,Detecting Language Associated With Home Healthcare Patient’s Risk for Hospitalization and Emergency Department Visit,2022,4.447977211201754e-05,2
W4391099575,Towards Faithful Model Explanation in NLP: A Survey,2024,4.447977211201754e-05,2
W4399205954,ArguSense: Argument-Centric Analysis of Online Discourse,2024,4.447977211201754e-05,2
W4382465573,Parameter-Efficient Model Adaptation for Vision Transformers,2023,4.447977211201754e-05,2
W3126934640,Comparative Analysis of Different Transformer Based Architectures Used in Sentiment Analysis,2020,4.447977211201754e-05,2
W4318679823,How can voting mechanisms improve the robustness and generalizability of toponym disambiguation?,2023,4.447977211201754e-05,2
W2963485691,Parametric Noise Injection: Trainable Randomness to Improve Deep Neural Network Robustness Against Adversarial Attack,2019,4.447977211201754e-05,2
W4394995253,"Enhancing Customer Segmentation Using Large Language Models (LLMs) and Deterministic, Independent-of-Corpus Embeddings (DICE)",2024,4.447977211201754e-05,2
W4391724817,MASTERKEY: Automated Jailbreaking of Large Language Model Chatbots,2024,4.447977211201754e-05,2
W4385565160,Hybrid Uncertainty Quantification for Selective Text Classification in Ambiguous Tasks,2023,4.447977211201754e-05,2
W3150055540,Recommending metamodel concepts during modeling activities with pre-trained language models,2022,4.447977211201754e-05,2
W4396498719,Large language models leverage external knowledge to extend clinical insight beyond language boundaries,2024,4.447977211201754e-05,2
W4385570691,NOTABLE: Transferable Backdoor Attacks Against Prompt-based NLP Models,2023,4.447977211201754e-05,2
W4320065330,Extracting Medical Information From Free-Text and Unstructured Patient-Generated Health Data Using Natural Language Processing Methods: Feasibility Study With Real-world Data,2023,4.447977211201754e-05,2
W4385688710,Balanced Knowledge Distillation with Contrastive Learning for Document Re-ranking,2023,4.447977211201754e-05,2
W4385570657,Prompt-based Zero-shot Text Classification with Conceptual Knowledge,2023,4.447977211201754e-05,2
W4313590997,Biologically Inspired Design Concept Generation Using Generative Pre-Trained Transformers,2023,4.447977211201754e-05,2
W4385573394,Detecting Euphemisms with Literal Descriptions and Visual Imagery,2022,4.447977211201754e-05,2
W4398201981,Use of Artificial Intelligence Chatbots in Interpretation of Pathology Reports,2024,4.447977211201754e-05,2
W4402270921,Language Model Crossover: Variation through Few-Shot Prompting,2024,4.447977211201754e-05,2
W3174781392,An Empirical Study on Hyperparameter Optimization for Fine-Tuning Pre-trained Language Models,2021,4.447977211201754e-05,2
W4391582407,Revolutionizing Cyber Threat Detection With Large Language Models: A Privacy-Preserving BERT-Based Lightweight Model for IoT/IIoT Devices,2024,4.447977211201754e-05,2
W4392812489,UTP: A Unified Term Presentation Tool for Clinical Textual Data Using Pattern-Matching Rules and Dictionary-Based Ontologies,2024,4.447977211201754e-05,2
W4221148482,Exploring and Adapting Chinese GPT to Pinyin Input Method,2022,4.447977211201754e-05,2
W3179867916,Answering Any-hop Open-domain Questions with Iterative Document Reranking,2021,4.4458242322238366e-05,2
W4389520380,Dissecting Recall of Factual Associations in Auto-Regressive Language Models,2023,4.445264671326001e-05,2
W4205458180,Recent progress in leveraging deep learning methods for question answering,2022,4.444582625393845e-05,2
W4224321652,"Text Adversarial Attacks and Defenses: Issues, Taxonomy, and Perspectives",2022,4.444094482419894e-05,2
W4372342402,From Easy to Hard: Two-Stage Selector and Reader for Multi-Hop Question Answering,2023,4.443311194608291e-05,2
W3200275576,A simple and efficient text matching model based on deep interaction,2021,4.4413748739085404e-05,2
W3155979791,Modeling Context in Answer Sentence Selection Systems on a Latency Budget,2021,4.441349571371447e-05,2
W4385573708,Injecting Domain Knowledge in Language Models for Task-oriented Dialogue Systems,2022,4.4399889494818845e-05,2
W4285141652,KNN-Contrastive Learning for Out-of-Domain Intent Classification,2022,4.43965942688144e-05,2
W3206240757,Virtual Augmentation Supported Contrastive Learning of Sentence Representations,2022,4.43913134313462e-05,2
W3106231035,Validation of deep learning natural language processing algorithm for keyword extraction from pathology reports in electronic health records,2020,4.4390568944041226e-05,2
W3203502727,A proposed conceptual framework for a representational approach to information retrieval,2021,4.438494942203817e-05,2
W3166720688,UDALM: Unsupervised Domain Adaptation through Language Modeling,2021,4.43762726638487e-05,2
W3035990700,"Understanding spatial language in radiology: Representation framework, annotation, and spatial relation extraction from chest X-ray reports using deep learning",2020,4.437300079399722e-05,2
W2963916998,Is it Time to Swish? Comparing Deep Learning Activation Functions Across NLP tasks,2018,4.436798096873771e-05,2
W4385573616,Natural Language Deduction through Search over Statement Compositions,2022,4.4364996012688515e-05,2
W4327657958,Injecting the BM25 Score as Text Improves BERT-Based Re-rankers,2023,4.436216905557051e-05,2
W3104213339,Retrofitting Structure-aware Transformer Language Model for End Tasks,2020,4.435611578181299e-05,2
W4386566424,Crawling The Internal Knowledge-Base of Language Models,2023,4.4333479008725816e-05,2
W3205616434,LFPT5: A Unified Framework for Lifelong Few-shot Language Learning Based on Prompt Tuning of T5,2021,4.433128384278374e-05,2
W3165195746,A deep database of medical abbreviations and acronyms for natural language processing,2021,4.4309982041661504e-05,2
W4362602149,Position-Aware Relational Transformer for Knowledge Graph Embedding,2023,4.43025806969895e-05,2
W4323782875,A Comparison of SVM Against Pre-trained Language Models (PLMs) for Text Classification Tasks,2023,4.429057246174604e-05,2
W4389520742,Model-tuning Via Prompts Makes NLP Models Adversarially Robust,2023,4.429057246174604e-05,2
W3041843309,A Survey on Transfer Learning in Natural Language Processing,2020,4.429057246174604e-05,2
W4399803382,Language is primarily a tool for communication rather than thought,2024,4.429057246174604e-05,2
W4385574077,Inferring the Reader: Guiding Automated Story Generation with Commonsense Reasoning,2022,4.4284211296927076e-05,2
W3205810519,Rewire-then-Probe: A Contrastive Recipe for Probing Biomedical Knowledge of Pre-trained Language Models,2022,4.427095801549433e-05,2
W4366595110,A Comprehensive Benchmark Study on Biomedical Text Generation and Mining with ChatGPT,2023,4.4250410148636914e-05,2
W4388764805,The unreasonable effectiveness of large language models in zero-shot semantic annotation of legal texts,2023,4.424552492596711e-05,2
W3158086504,GermanQuAD and GermanDPR: Improving Non-English Question Answering and Passage Retrieval,2021,4.4242617717658906e-05,2
W4283795504,C2L: Causally Contrastive Learning for Robust Text Classification,2022,4.4209421880895706e-05,2
W4385570731,Dynamic Heterogeneous-Graph Reasoning with Language Models and Knowledge Representation Learning for Commonsense Question Answering,2023,4.4192458158373354e-05,2
W3106339673,PALM: Pre-training an Autoencoding&amp;Autoregressive Language Model for Context-conditioned Generation,2020,4.4188951535208284e-05,2
W3118846367,HopRetriever: Retrieve Hops over Wikipedia to Answer Complex Questions,2021,4.417554913398777e-05,2
W4296965999,Selecting Better Samples from Pre-trained LLMs: A Case Study on Question Generation,2023,4.4174453496414704e-05,2
W4285127912,Probing for the Usage of Grammatical Number,2022,4.417417775335201e-05,2
W3210694367,Pragmatic competence of pre-trained language models through the lens of discourse connectives,2021,4.4167504884105836e-05,2
W4226198567,DoCoGen: Domain Counterfactual Generation for Low Resource Domain Adaptation,2022,4.4161182298853015e-05,2
W3015766957,A Systematic Analysis of Morphological Content in BERT Models for Multiple Languages,2020,4.415822659409934e-05,2
W3034834827,Understanding Attention for Text Classification,2020,4.414596546329757e-05,2
W3104597243,Predicting Clinical Diagnosis from Patients Electronic Health Records Using BERT-Based Neural Networks,2020,4.4130162407396694e-05,2
W4307935822,KEPT: Knowledge Enhanced Prompt Tuning for event causality identification,2022,4.4128401332941904e-05,2
W4282597027,Adapting vs. Pre-training Language Models for Historical Languages,2022,4.4128401332941904e-05,2
W3033346947,Application of Machine Learning and Word Embeddings in the Classification of Cancer Diagnosis Using Patient Anamnesis,2020,4.4111417967408566e-05,2
W4287887263,Aligning to Social Norms and Values in Interactive Narratives,2022,4.410382590710937e-05,2
W3105956114,Tell Me How to Ask Again: Question Data Augmentation with Controllable Rewriting in Continuous Space,2020,4.408710381290669e-05,2
W4281254837,Modeling Multi-hop Question Answering as Single Sequence Prediction,2022,4.4084900319654393e-05,2
W3152151101,CEQE: Contextualized Embeddings for Query Expansion,2021,4.4073913825321765e-05,2
W4385570355,Fact-Checking Complex Claims with Program-Guided Reasoning,2023,4.4051023453654345e-05,2
W3101284630,Pretrained Language Model Embryology: The Birth of ALBERT,2020,4.404275949386062e-05,2
W3176017841,LeeBERT: Learned Early Exit for BERT with cross-level optimization,2021,4.404272154945682e-05,2
W4386275705,A Survey of Knowledge Enhanced Pre-Trained Language Models,2023,4.404239157984675e-05,2
W4401876324,Language models align with human judgments on key grammatical constructions,2024,4.4039811194044286e-05,2
W3099550034,SLEDGE-Z: A Zero-Shot Baseline for COVID-19 Literature Search,2020,4.4037694841258206e-05,2
W4313492484,Comparison of BERT implementations for natural language processing of narrative medical documents,2022,4.403767133464678e-05,2
W4229022551,SemAttack: Natural Textual Attacks via Different Semantic Spaces,2022,4.403492794371166e-05,2
W3127787589,Extremely Small BERT Models from Mixed-Vocabulary Training,2019,4.4027653467784106e-05,2
W4391385527,Emergence of syntax and word prediction in an artificial neural circuit of the cerebellum,2024,4.4018067948190813e-05,2
W4399276598,Viability of Open Large Language Models for Clinical Documentation in German Health Care: Real-World Model Evaluation Study,2024,4.4018067948190813e-05,2
W3154707883,Unification-based Reconstruction of Multi-hop Explanations for Science Questions,2021,4.399513914882272e-05,2
W4386740843,Testing the limits of natural language models for predicting human language judgements,2023,4.398785302131164e-05,2
W3217374296,DKPLM: Decomposable Knowledge-Enhanced Pre-trained Language Model for Natural Language Understanding,2022,4.3978031014242686e-05,2
W4249111509,Proceedings of the 1st Workshop on NLP for COVID-19 (Part 2) at EMNLP 2020,2020,4.397741025361983e-05,2
W4382279906,Deep speech-to-text models capture the neural basis of spontaneous speech in everyday conversations,2023,4.3972386514802516e-05,2
W4206068491,Numeracy enhances the Literacy of Language Models,2021,4.3970904054384645e-05,2
W4200136492,A contextual multi-task neural approach to medication and adverse events identification from clinical text,2021,4.396553861724675e-05,2
W3176229980,Database reasoning over text,2021,4.395795712026748e-05,2
W4385572734,GeoMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models,2022,4.3952649487954347e-05,2
W3110846353,Reinforced Multi-Teacher Selection for Knowledge Distillation,2021,4.3952530648059465e-05,2
W4385570444,Nonparametric Masked Language Modeling,2023,4.3933456190990624e-05,2
W3184516261,Syntactic Perturbations Reveal Representational Correlates of Hierarchical Phrase Structure in Pretrained Language Models,2021,4.391913840887801e-05,2
W3169432135,Characterizing English Variation across Social Media Communities with BERT,2021,4.3884184273161104e-05,2
W4385734218,Knowledge-Augmented Language Model Prompting for Zero-Shot Knowledge Graph Question Answering,2023,4.388416986640162e-05,2
W2931212643,A Multi-Task Approach for Disentangling Syntax and Semantics in Sentence Representations,2019,4.387820104233973e-05,2
W4226218072,DREAM: Improving Situational QA by First Elaborating the Situation,2022,4.387628352069938e-05,2
W3203041483,The reporting quality of natural language processing studies: systematic review of studies of radiology reports,2021,4.386433468402424e-05,2
W4389524085,Exploiting Asymmetry for Synthetic Training Data Generation: SynthIE and the Case of Information Extraction,2023,4.386303397865031e-05,2
W3105987139,NLP North at WNUT-2020 Task 2: Pre-training versus Ensembling for Detection of Informative COVID-19 English Tweets,2020,4.3862163328126334e-05,2
W3171636201,DATE: Detecting Anomalies in Text via Self-Supervision of Transformers,2021,4.384806865892893e-05,2
W3118017018,Linguistic Profiling of a Neural Language Model,2020,4.3843333588099926e-05,2
W3215569511,Lexicon-Based Methods vs. BERT for Text Sentiment Analysis,2022,4.383488725222632e-05,2
W4385573075,You Only Need One Model for Open-domain Question Answering,2022,4.383369395242084e-05,2
W4399557940,CLSESSP: Contrastive learning of sentence embedding with strong semantic prototypes,2024,4.383050002024733e-05,2
W4389524456,NORMSAGE: Multi-Lingual Multi-Cultural Norm Discovery from Conversations On-the-Fly,2023,4.382939279144338e-05,2
W3199301749,ECONET: Effective Continual Pretraining of Language Models for Event Temporal Reasoning,2021,4.382387999107634e-05,2
W4231844697,Learning and Evaluating a Differentially Private Pre-trained Language Model,2021,4.381317148010288e-05,2
W4385572475,Alleviating Over-smoothing for Unsupervised Sentence Representation,2023,4.379865337104014e-05,2
W4385572323,Do PLMs Know and Understand Ontological Knowledge?,2023,4.3780888293608006e-05,2
W3209721572,Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey,2021,4.377703055386625e-05,2
W4225989348,Comparison of machine-learning algorithms for the prediction of Current Procedural Terminology (CPT) codes from pathology reports,2022,4.377703055386625e-05,2
W3175729092,Scaling Federated Learning for Fine-Tuning of Large Language Models,2021,4.377703055386625e-05,2
W4394943312,Large Language Models Are Poor Medical Coders — Benchmarking of Medical Code Querying,2024,4.377703055386625e-05,2
W2994803089,Extending Machine Language Models toward Human-Level Language Understanding,2019,4.3774814955444496e-05,2
W3170925726,On the Transformer Growth for Progressive BERT Training,2021,4.3765692838871566e-05,2
W3198963570,Adaptive Information Seeking for Open-Domain Question Answering,2021,4.375860658921456e-05,2
W3173826007,On the Efficacy of Adversarial Data Collection for Question Answering: Results from a Large-Scale Randomized Study,2021,4.374650281751753e-05,2
W4287888456,MultiSpanQA: A Dataset for Multi-Span Question Answering,2022,4.374341587874608e-05,2
W3196538463,Challenges in Generalization in Open Domain Question Answering,2022,4.372792815539508e-05,2
W3034842695,What Question Answering can Learn from Trivia Nerds,2020,4.3716589707217167e-05,2
W4400462656,Flexible multitask computation in recurrent networks utilizes shared dynamical motifs,2024,4.37165556532394e-05,2
W3212993480,Generate & Rank: A Multi-task Framework for Math Word Problems,2021,4.371103954929323e-05,2
W4386566910,CHARD: Clinical Health-Aware Reasoning Across Dimensions for Text Generation Models,2023,4.370936944631345e-05,2
W3184200018,MinD at SemEval-2021 Task 6: Propaganda Detection using Transfer Learning and Multimodal Fusion,2021,4.3706972673965275e-05,2
W3094815596,Dynamic Neuro-Symbolic Knowledge Graph Construction for Zero-shot Commonsense Question Answering,2019,4.3700746843798304e-05,2
W2970912185,WikiCREM: A Large Unsupervised Corpus for Coreference Resolution,2019,4.367187433656061e-05,2
W3094500738,EIGEN: Event Influence GENeration using Pre-trained Language Models,2020,4.3667444739644946e-05,2
W3034520363,Transformers to Learn Hierarchical Contexts in Multiparty Dialogue for Span-based Question Answering,2020,4.3664974682467244e-05,2
W3102372184,Towards Medical Machine Reading Comprehension with Structural Knowledge and Plain Text,2020,4.3660464312581085e-05,2
W4221099399,Construction and Evaluation of a High-Quality Corpus for Legal Intelligence Using Semiautomated Approaches,2022,4.3659906960841034e-05,2
W4379599778,Automatic knowledge extraction from Chinese electronic medical records and rheumatoid arthritis knowledge graph construction,2023,4.363058491914379e-05,2
W2997924070,ORB: An Open Reading Benchmark for Comprehensive Evaluation of Machine Reading Comprehension.,2019,4.361923722267365e-05,2
W3136035550,Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2,2021,4.360625084057134e-05,2
W4385570658,Exploring the Effectiveness of Prompt Engineering for Legal Reasoning Tasks,2023,4.3604991691889826e-05,2
W3034329603,(Re)construing Meaning in NLP,2020,4.3601964118169555e-05,2
W4225707828,Neural reality of argument structure constructions,2022,4.359157701824414e-05,2
W4386566752,"Methods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models",2023,4.358847093801967e-05,2
W3198593990,NumGPT: Improving Numeracy Ability of Generative Pre-trained Models,2021,4.358829099125507e-05,2
W3084489656,Multi-Hop Fact Checking of Political Claims,2020,4.357606733913248e-05,2
W3100894295,Undersensitivity in Neural Reading Comprehension,2020,4.357103423448361e-05,2
W4385572819,SafeText: A Benchmark for Exploring Physical Safety in Language Models,2022,4.356289496674545e-05,2
W2997915791,Order Matters: Semantic-Aware Neural Networks for Binary Code Similarity Detection,2020,4.3527791036890334e-05,2
W3087714553,Multi-turn intent determination and slot filling with neural networks and regular expressions,2020,4.352412942676699e-05,2
W3099543642,Lifelong Language Knowledge Distillation,2020,4.3516479524616204e-05,2
W3213074177,TaCL: Improving BERT Pre-training with Token-aware Contrastive Learning,2022,4.351493749577962e-05,2
W3171847983,Posterior Differential Regularization with f-divergence for Improving Model Robustness,2021,4.351254669417909e-05,2
W3015347994,The Russian Drug Reaction Corpus and neural models for drug reactions and effectiveness detection in user reviews,2020,4.3511145089341594e-05,2
W4386333898,What are large language models supposed to model?,2023,4.34988503042179e-05,2
W3215490307,DATLMedQA: A Data Augmentation and Transfer Learning Based Solution for Medical Question Answering,2021,4.34898916677593e-05,2
W3168125510,Rethinking Network Pruning – under the Pre-train and Fine-tune Paradigm,2021,4.3482751914650804e-05,2
W4319730829,Information extraction from German radiological reports for general clinical text and language understanding,2023,4.347925592283926e-05,2
W3036879053,Memory-Efficient Pipeline-Parallel DNN Training,2020,4.347919118212282e-05,2
W4377695655,"Towards electronic health record-based medical knowledge graph construction, completion, and applications: A literature study",2023,4.347357397193729e-05,2
W3183822815,"SemEval 2021 Task 7: HaHackathon, Detecting and Rating Humor and Offense",2021,4.3472422285387654e-05,2
W2966033979,Post-Processing of Word Representations via Variance Normalization and Dynamic Embedding,2019,4.346807291581645e-05,2
W4399971973,Differentially Private Fine-tuning of Language Models,2024,4.346042005540839e-05,2
W4322757661,Assessment of Natural Language Processing of Electronic Health Records to Measure Goals-of-Care Discussions as a Clinical Trial Outcome,2023,4.3459919987712156e-05,2
W3173446720,Dual Reader-Parser on Hybrid Textual and Tabular Evidence for Open Domain Question Answering,2021,4.3454058365204496e-05,2
W3113909409,Asking Crowdworkers to Write Entailment Examples: The Best of Bad Options,2020,4.342293724666087e-05,2
W4385574373,Contrastive Learning with Prompt-derived Virtual Semantic Prototypes for Unsupervised Sentence Embedding,2022,4.342289935945214e-05,2
W3206387060,Deep Transfer Learning &amp; Beyond: Transformer Language Models in Information Systems Research,2022,4.341570507037722e-05,2
W4400222836,KnowledgeNavigator: leveraging large language models for enhanced reasoning over knowledge graph,2024,4.3398631253323254e-05,2
W3019882988,Collecting Entailment Data for Pretraining: New Protocols and Negative Results.,2020,4.3393744141438854e-05,2
W4224736673,Persona-Guided Planning for Controlling the Protagonist’s Persona in Story Generation,2022,4.338699956879672e-05,2
W3173436762,Learning from the Best: Rationalizing Predictions by Adversarial Information Calibration,2021,4.3383397379033e-05,2
W3102793471,Document Classification for COVID-19 Literature,2020,4.338316306829758e-05,2
W4389520468,Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy,2023,4.33756400107027e-05,2
W4304192668,Knowledge Injected Prompt Based Fine-tuning for Multi-label Few-shot ICD Coding,2022,4.3361774178595045e-05,2
W3201363102,STraTA: Self-Training with Task Augmentation for Better Few-shot Learning,2021,4.335136872463969e-05,2
W3205544360,bert2BERT: Towards Reusable Pretrained Language Models,2022,4.333744335795735e-05,2
W3212706150,On Transferability of Prompt Tuning for Natural Language Understanding,2021,4.3312855925574796e-05,2
W3021347125,PlotMachines: Outline-Conditioned Generation with Dynamic Plot State Tracking,2020,4.331112399299677e-05,2
W4296564631,Structural Persistence in Language Models: Priming as a Window into Abstract Language Representations,2022,4.330206877729763e-05,2
W4287887895,Learning to repair: Repairing model output errors after deployment using a dynamic memory of feedback,2022,4.32994472554078e-05,2
W4385573004,An Empirical Analysis of Memorization in Fine-tuned Autoregressive Language Models,2022,4.329196990350796e-05,2
W3015612646,Diagnosing BERT with Retrieval Heuristics,2020,4.329051986796381e-05,2
W3177028045,Benchmarking Robustness of Machine Reading Comprehension Models,2021,4.328234168091641e-05,2
W4223546521,Generative Biomedical Entity Linking via Knowledge Base-Guided Pre-training and Synonyms-Aware Fine-tuning,2022,4.3278874265943794e-05,2
W3170841641,Pre-trained Language Model based Ranking in Baidu Search,2021,4.3273772885972254e-05,2
W3171391618,Empirical Evaluation of Pre-trained Transformers for Human-Level NLP: The Role of Sample Size and Dimensionality,2021,4.326811169728969e-05,2
W4387105248,A Benchmark Dataset to Distinguish Human-Written and Machine-Generated Scientific Papers,2023,4.3266421758013525e-05,2
W4225410153,AdapterBias: Parameter-efficient Token-dependent Representation Shift for Adapters in NLP Tasks,2022,4.326285640639409e-05,2
W4385573139,SimANS: Simple Ambiguous Negatives Sampling for Dense Text Retrieval,2022,4.325863736544793e-05,2
W4404826238,On the creativity of large language models,2024,4.325738116379325e-05,2
W4311404181,A Survey on Negative Transfer,2022,4.324997438525279e-05,2
W4386165948,Improving short text classification with augmented data using GPT-3,2023,4.324997438525279e-05,2
W3199422761,BioALBERT: A Simple and Effective Pre-trained Language Model for Biomedical Named Entity Recognition,2021,4.324791844756777e-05,2
W3212511129,"Reason first, then respond: Modular Generation for Knowledge-infused Dialogue",2022,4.3246976996244566e-05,2
W3034444624,Human Attention Maps for Text Classification: Do Humans and Neural Networks Focus on the Same Words?,2020,4.3242616276942486e-05,2
W3045620180,Distilling the Evidence to Augment Fact Verification Models,2020,4.323378710895263e-05,2
W4309729081,An Overview of Knowledge Graph Reasoning: Key Technologies and Applications,2022,4.322761442658434e-05,2
W4392369006,"Evaluating Large Language Models: ChatGPT-4, Mistral 8x7B, and Google Gemini Benchmarked Against MMLU",2024,4.322761442658434e-05,2
W4285269500,Parameter-Efficient Abstractive Question Answering over Tables or Text,2022,4.322760521498552e-05,2
W3212522196,jurBERT: A Romanian BERT Model for Legal Judgement Prediction,2021,4.322122928658202e-05,2
W3197298549,NSP-BERT: A Prompt-based Few-Shot Learner Through an Original Pre-training Task--Next Sentence Prediction,2021,4.319551836771939e-05,2
W4282960293,How can natural language processing help model informed drug development?: a review,2022,4.318999542888229e-05,2
W3170113752,A Global Past-Future Early Exit Method for Accelerating Inference of Pre-trained Language Models,2021,4.318912605100679e-05,2
W3077627272,Clinical trial search: Using biomedical language understanding models for re-ranking,2020,4.318585029421077e-05,2
W3176514068,Measuring and Improving BERT’s Mathematical Abilities by Predicting the Order of Reasoning.,2021,4.317757271152537e-05,2
W4292793781,The Text Anonymization Benchmark (TAB): A Dedicated Corpus and Evaluation Framework for Text Anonymization,2022,4.314789014609251e-05,2
W3169066049,Improving BERT Model Using Contrastive Learning for Biomedical Relation Extraction,2021,4.314662840343771e-05,2
W4394752750,The language network as a natural kind within the broader landscape of the human brain,2024,4.314645011884845e-05,2
W2982111970,HUBERT Untangles BERT to Improve Transfer across NLP Tasks,2019,4.314077736640604e-05,2
W3021934057,VisBERT: Hidden-State Visualizations for Transformers,2020,4.313779091700204e-05,2
W4312605747,Multi-task Active Learning for Pre-trained Transformer-based Models,2022,4.311913272742296e-05,2
W3154922002,Consistent Accelerated Inference via Confident Adaptive Transformers,2021,4.309838908220076e-05,2
W4385893872,ScoNe: Benchmarking Negation Reasoning in Language Models With Fine-Tuning and In-Context Learning,2023,4.3093094201141844e-05,2
W4287854822,Exploring the Role of Task Transferability in Large-Scale Multi-Task Learning,2022,4.3092901080492414e-05,2
W3161024824,"Incremental Few-shot Text Classification with Multi-round New Classes: Formulation, Dataset and System",2021,4.3092608602764796e-05,2
W3015372447,Multi-Step Inference for Reasoning Over Paragraphs,2020,4.308337800911462e-05,2
W4285228888,AMR-DA: Data Augmentation by Abstract Meaning Representation,2022,4.307452826607249e-05,2
W4385763801,Generalizing to Unseen Elements: A Survey on Knowledge Extrapolation for Knowledge Graphs,2023,4.307428899571497e-05,2
W2989202909,Generating Diverse Story Continuations with Controllable Semantics,2019,4.307003839245357e-05,2
W4311987334,Refining fine-tuned transformers with hand-crafted features for gender screening on question-answering communities,2022,4.3069804330942755e-05,2
W3176245452,Language Models Use Monotonicity to Assess NPI Licensing,2021,4.306710197299236e-05,2
W3174987059,CiteWorth: Cite-Worthiness Detection for Improved Scientific Document Understanding,2021,4.306138601793459e-05,2
W3035172163,The Sensitivity of Language Models and Humans to Winograd Schema Perturbations,2020,4.304150884984691e-05,2
W4229005744,Learning to Transfer Prompts for Text Generation,2022,4.3037462151233876e-05,2
W3175148050,A Multi-Level Attention Model for Evidence-Based Fact Checking,2021,4.303718530090262e-05,2
W4385573115,PASTA: Table-Operations Aware Fact Verification via Sentence-Table Cloze Pre-training,2022,4.303377755689296e-05,2
W3176398225,From Discourse to Narrative: Knowledge Projection for Event Relation Extraction,2021,4.3025973299232e-05,2
W4385570369,Large Language Models are Built-in Autoregressive Search Engines,2023,4.301579308315254e-05,2
W3153184434,KeyBLD: Selecting Key Blocks with Local Pre-ranking for Long Document Information Retrieval,2021,4.301577893911489e-05,2
W3093582159,ANLIzing the Adversarial Natural Language Inference Dataset.,2020,4.301550091473559e-05,2
W4285183303,RuMedBench: A Russian Medical Language Understanding Benchmark,2022,4.301102149415749e-05,2
W3174859448,Argument Pair Extraction via Attention-guided Multi-Layer Multi-Cross Encoding,2021,4.30096726435772e-05,2
W4385571791,Analyzing Transformers in Embedding Space,2023,4.300711398899997e-05,2
W4311762778,Predicting medical specialty from text based on a domain-specific pre-trained BERT,2022,4.2997073258153526e-05,2
W3165941178,Evaluating Saliency Methods for Neural Language Models,2021,4.299574139536992e-05,2
W4285603001,PPT: Backdoor Attacks on Pre-trained Models via Poisoned Prompt Tuning,2022,4.298735797421959e-05,2
W3174510164,One Teacher is Enough? Pre-trained Language Model Distillation from Multiple Teachers,2021,4.298605839490057e-05,2
W2962829230,ThisIsCompetition at SemEval-2019 Task 9: BERT is unstable for out-of-domain samples,2019,4.2980701978757985e-05,2
W3177005832,RAW-C: Relatedness of Ambiguous Words in Context (A New Lexical Resource for English),2021,4.29799851873088e-05,2
W3130347092,Using Prior Knowledge to Guide BERT’s Attention in Semantic Textual Matching Tasks,2021,4.296729145900057e-05,2
W4385573687,Empowering Language Models with Knowledge Graph Reasoning for Open-Domain Question Answering,2022,4.294119943225574e-05,2
W3012038618,Document Ranking with a Pretrained Sequence-to-Sequence Model,2020,4.294070386500251e-05,2
W3202028501,Understanding and Overcoming the Challenges of Efficient Transformer Quantization,2021,4.2924904189658114e-05,2
W3157950068,Do Feature Attribution Methods Correctly Attribute Features?,2022,4.2920617820329675e-05,2
W4392167104,Automated Scoring of Translations with BERT Models: Chinese and English Language Case Study,2024,4.291457500522604e-05,2
W3185011771,TAPAS at SemEval-2021 Task 9: Reasoning over tables with intermediate pre-training,2021,4.289544573509458e-05,2
W4385570371,A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets,2023,4.2888365464065586e-05,2
W3174691662,A DQN-based Approach to Finding Precise Evidences for Fact Verification,2021,4.286692536470427e-05,2
W4379379858,Post Hoc Explanations of Language Models Can Improve Language Models,2023,4.2861821518877565e-05,2
W3175530221,Stylized Story Generation with Style-Guided Planning,2021,4.284999665061727e-05,2
W4386647230,Evading text based emotion detection mechanism via adversarial attacks,2023,4.2841896708196607e-05,2
W4391758695,Do AIs know what the most important issue is? Using language models to code open-text social survey responses at scale,2024,4.284004180966454e-05,2
W3047988254,The Chess Transformer: Mastering Play using Generative Language Models,2020,4.284004180966454e-05,2
W3171899052,“I’m Not Mad”: Commonsense Implications of Negation and Contradiction,2021,4.283785550418585e-05,2
W3112891652,Causal BERT: Language Models for Causality Detection Between Events Expressed in Text,2021,4.2808466635739036e-05,2
W3033077667,Classification aware neural topic model for COVID-19 disinformation categorisation,2021,4.2802735394470574e-05,2
W4388329494,Embracing ambiguity: Improving similarity-oriented tasks with contextual synonym knowledge,2023,4.2800585725564076e-05,2
W3037965442,Adversarial Training for Commonsense Inference,2020,4.2797472305338615e-05,2
W3200130628,Conditional probing: measuring usable information beyond a baseline,2021,4.2788516947784e-05,2
W3100458477,HyperText: Endowing FastText with Hyperbolic Geometry,2020,4.278579982410021e-05,2
W3174863418,Answer Generation for Retrieval-based Question Answering Systems,2021,4.278236904859871e-05,2
W2611099133,Neural Models for Information Retrieval,2017,4.2781823627931505e-05,2
W3198757395,How much pretraining data do language models need to learn syntax?,2021,4.2781769413269814e-05,2
W4292938144,Overview of BioASQ 2022: The Tenth BioASQ Challenge on Large-Scale Biomedical Semantic Indexing and Question Answering,2022,4.278116989826763e-05,2
W4390822940,"Overview and Discussion of the Competition on Legal Information, Extraction/Entailment (COLIEE) 2023",2024,4.278094085879392e-05,2
W4385231746,Truth-O-Meter: Collaborating with LLM in Fighting its Hallucinations,2023,4.277953183786038e-05,2
W4385570140,Say What You Mean! Large Language Models Speak Too Positively about Negative Commonsense Knowledge,2023,4.2775735296343015e-05,2
W4385571981,AntContentTech at SemEval-2023 Task 6: Domain-adaptive Pretraining and Auxiliary-task Learning for Understanding Indian Legal Texts,2023,4.2772334777659414e-05,2
W4282049100,SsciBERT: a pre-trained language model for social science texts,2022,4.276400639058307e-05,2
W3217387898,A Review on Fact Extraction and Verification,2021,4.2762493692667925e-05,2
W3174445427,TGEA: An Error-Annotated Dataset and Benchmark Tasks for TextGeneration from Pretrained Language Models,2021,4.276026438360684e-05,2
W3103939752,Point to the Expression: Solving Algebraic Word Problems using the Expression-Pointer Transformer Model,2020,4.275372580692536e-05,2
W3176197839,Exploring the Efficacy of Automatically Generated Counterfactuals for Sentiment Analysis,2021,4.2745769229505835e-05,2
W3046747294,A Text Generation and Prediction System: Pre-training on New Corpora Using BERT and GPT-2,2020,4.273708749291595e-05,2
W3184074368,SemEval-2021 Task 12: Learning with Disagreements,2021,4.2736016319317614e-05,2
W3154271556,Conversational Question Answering over Knowledge Graphs with Transformer and Graph Attention Networks,2021,4.2731320824276374e-05,2
W3156031972,Distributed NLI: Learning to Predict Human Opinion Distributions for Language Reasoning,2022,4.2728924153372875e-05,2
W3112689365,Extracting Training Data from Large Language Models,2020,4.2722359260676725e-05,2
W4381435827,Leveraging Symbolic Knowledge Bases for Commonsense Natural Language Inference using Pattern Theory,2023,4.2718433551867116e-05,2
W4283793506,TempoQR: Temporal Question Reasoning over Knowledge Graphs,2022,4.2706521874130276e-05,2
W3092806700,CoDA: Contrast-enhanced and Diversity-promoting Data Augmentation for Natural Language Understanding,2020,4.270054168739681e-05,2
W4386566916,ferret: a Framework for Benchmarking Explainers on Transformers,2023,4.269984376714607e-05,2
W4293248701,The Role of Complex NLP in Transformers for Text Ranking,2022,4.2689937733010814e-05,2
W4287889353,METGEN: A Module-Based Entailment Tree Generation Framework for Answer Explanation,2022,4.268300954745206e-05,2
W4385574313,Leveraging QA Datasets to Improve Generative Data Augmentation,2022,4.2682547336038846e-05,2
W3205718179,Retrieval-guided Counterfactual Generation for QA,2022,4.268209778952067e-05,2
W3117422238,Conversational Machine Comprehension: a Literature Review,2020,4.2672407999076256e-05,2
W2922565841,Linguistic Knowledge and Transferability of Contextual Representations,2019,4.266702531225288e-05,2
W4287855052,Cross-Domain Classification of Moral Values,2022,4.265084215939304e-05,2
W3098415518,Interpreting Predictions of NLP Models,2020,4.264288182940247e-05,2
W3100980998,Efficient Transformer-based Large Scale Language Representations using Hardware-friendly Block Structured Pruning,2020,4.264176006243299e-05,2
W3167525829,DReCa: A General Task Augmentation Strategy for Few-Shot Natural Language Inference,2021,4.262350295893202e-05,2
W4389520743,DSI++: Updating Transformer Memory with New Documents,2023,4.262044813046596e-05,2
W4295885374,SpaDE,2022,4.2620282894855336e-05,2
W3173526187,Knowledge-Enriched Event Causality Identification via Latent Structure Induction Networks,2021,4.26116408350937e-05,2
W4285249364,"MMCoQA: Conversational Question Answering over Text, Tables, and Images",2022,4.261106871389163e-05,2
W4286512643,Multiview Incomplete Knowledge Graph Integration with application to cross-institutional EHR data harmonization,2022,4.2602940527733044e-05,2
W4385569968,Making Language Models Better Reasoners with Step-Aware Verifier,2023,4.259967424962451e-05,2
W4362679551,Evaluation of ChatGPT Family of Models for Biomedical Reasoning and Classification,2023,4.2590739601387963e-05,2
W2919057541,Chinese medical question answer selection via hybrid models based on CNN and GRU,2019,4.258857144784753e-05,2
W3153839026,SPARTQA: A Textual Question Answering Benchmark for Spatial Reasoning,2021,4.2572334829176705e-05,2
W4295807725,Natural language processing in clinical neuroscience and psychiatry: A review,2022,4.25472328271015e-05,2
W4285223485,"E8-IJS@LT-EDI-ACL2022 - BERT, AutoML and Knowledge-graph backed Detection of Depression",2022,4.25472328271015e-05,2
W4401251180,A shared model-based linguistic space for transmitting our thoughts from brain to brain in natural conversations,2024,4.2546495685606936e-05,2
W4220844058,Deep learning-based methods for natural hazard named entity recognition,2022,4.25454887908012e-05,2
W3176075895,Conversational Neuro-Symbolic Commonsense Reasoning,2021,4.253730838415037e-05,2
W4367046683,Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer,2023,4.2515793509950166e-05,2
W4287888039,"QuALITY: Question Answering with Long Input Texts, Yes!",2022,4.2501623143957765e-05,2
W4206778668,ReasonBERT: Pre-trained to Reason with Distant Supervision,2021,4.249435428941052e-05,2
W3164896303,Knowledge Inheritance for Pre-trained Language Models,2022,4.2493829713444544e-05,2
W3093778498,FAQ-Based Question Answering via Knowledge Anchors,2020,4.249228153261056e-05,2
W3196841052,Learning with Different Amounts of Annotation: From Zero to Many Labels,2021,4.248945694543996e-05,2
W4385567134,Language Models as Agent Models,2022,4.248889659825564e-05,2
W4281641068,The state of the art in open domain complex question answering: a survey,2022,4.248767931280948e-05,2
W4385569706,miCSE: Mutual Information Contrastive Learning for Low-shot Sentence Embeddings,2023,4.248369951998595e-05,2
W3174318939,Joint Verification and Reranking for Open Fact Checking Over Tables,2021,4.247682246757471e-05,2
W3102232851,Multi-label Few/Zero-shot Learning with Knowledge Aggregated from Multiple Label Graphs,2020,4.246863306468424e-05,2
W3110664450,MASKER: Masked Keyword Regularization for Reliable Text Classification,2021,4.246228530931902e-05,2
W3169890186,On the Inductive Bias of Masked Language Modeling: From Statistical to Syntactic Dependencies,2021,4.244572301372855e-05,2
W4389514989,"Beyond rating scales: With targeted evaluation, large language models are poised for psychological assessment",2023,4.243374919678883e-05,2
W4323315336,“Transforming” Personality Scale Development: Illustrating the Potential of State-of-the-Art Natural Language Processing,2023,4.243374919678883e-05,2
W3209030604,Decomposing Complex Questions Makes Multi-Hop QA Easier and More Interpretable,2021,4.242173249479125e-05,2
W4285226597,WatClaimCheck: A new Dataset for Claim Entailment and Inference,2022,4.242083539965286e-05,2
W3196704868,Contextualized Knowledge-aware Attentive Neural Network: Enhancing Answer Selection with Knowledge,2021,4.2408565767297274e-05,2
W4389519586,MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions,2023,4.240562347003618e-05,2
W4386302269,Continual Learning for Generative Retrieval over Dynamic Corpora,2023,4.238911597651746e-05,2
W4205377692,Learning with Instance Bundles for Reading Comprehension,2021,4.238225356097843e-05,2
W2970645034,"PANLP at MEDIQA 2019: Pre-trained Language Models, Transfer Learning and Knowledge Distillation",2019,4.236919600367086e-05,2
W4285115684,An Attack Detection Framework Based on BERT and Deep Learning,2022,4.236556788453407e-05,2
W4385565015,A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models,2023,4.235396891276248e-05,2
W2971350781,Discourse-Aware Semantic Self-Attention for Narrative Reading Comprehension,2019,4.2347387996574925e-05,2
W4385270408,Relational Message Passing for Fully Inductive Knowledge Graph Completion,2023,4.2338048304305516e-05,2
W4294955582,How to Dissect a Muppet: The Structure of Transformer Embedding Spaces,2022,4.233509725980398e-05,2
W3202120412,A Survey of Knowledge Enhanced Pre-trained Models,2021,4.231055773468316e-05,2
W4385572290,Chain of Thought Prompting Elicits Knowledge Augmentation,2023,4.230426005207523e-05,2
W3090732401,Long-Tail Zero and Few-Shot Learning via Contrastive Pretraining on and for Small Data,2022,4.230173813376661e-05,2
W3103629016,Why do you think that? Exploring Faithful Sentence-Level Rationales Without Supervision,2020,4.229404471471477e-05,2
W4283793025,Pushing the Limits of Rule Reasoning in Transformers through Natural Language Satisfiability,2022,4.22875979077704e-05,2
W4367046920,PROD: Progressive Distillation for Dense Retrieval,2023,4.2282548638389385e-05,2
W3186065854,Dual‐Channel Reasoning Model for Complex Question Answering,2021,4.2273046236186775e-05,2
W3105184673,This is a BERT. Now there are several of them. Can they generalize to novel words?,2020,4.2268916089201346e-05,2
W3174088532,How transfer learning impacts linguistic knowledge in deep NLP models?,2021,4.226732005368807e-05,2
W3194310511,Pre-training for Ad-hoc Retrieval: Hyperlink is Also You Need,2021,4.2263864934433644e-05,2
W4280637601,ProQA: Structural Prompt-based Pre-training for Unified Question Answering,2022,4.225404234468608e-05,2
W3007306981,Training Question Answering Models From Synthetic Data,2020,4.2252280485301775e-05,2
W4389518895,Self-Knowledge Guided Retrieval Augmentation for Large Language Models,2023,4.224842901908996e-05,2
W4285251104,How does the pre-training objective affect what large language models learn about linguistic properties?,2022,4.2246599671128294e-05,2
W4288057740,Piccolo: Exposing Complex Backdoors in NLP Transformer Models,2022,4.2245892261579014e-05,2
W4285222754,Tree-KGQA: An Unsupervised Approach for Question Answering Over Knowledge Graphs,2022,4.224377624517253e-05,2
W4292199287,A pre-trained BERT for Korean medical natural language processing,2022,4.223528605902436e-05,2
W4366090965,Transformers in the Real World: A Survey on NLP Applications,2023,4.223375497518107e-05,2
W3175557894,Robust Transfer Learning with Pretrained Language Models through Adapters,2021,4.223347619420302e-05,2
W3176609328,AUBER: Automated BERT regularization,2021,4.22301222609474e-05,2
W3115686121,SMART: A Situation Model for Algebra Story Problems via Attributed Grammar,2021,4.222972396814286e-05,2
W3199712787,Semantic Networks for Engineering Design: State of the Art and Future Directions,2021,4.2223823662297884e-05,2
W3173361789,Learn to Resolve Conversational Dependency: A Consistency Training Framework for Conversational Question Answering,2021,4.2206422184574717e-05,2
W4223609000,Hyperlink-induced Pre-training for Passage Retrieval in Open-domain Question Answering,2022,4.2203830930375724e-05,2
W3174223793,Corpus-Level Evaluation for Event QA: The IndiaPoliceEvents Corpus Covering the 2002 Gujarat Violence,2021,4.219903955138462e-05,2
W4226157820,A Label Dependence-Aware Sequence Generation Model for Multi-Level Implicit Discourse Relation Recognition,2022,4.218809587573942e-05,2
W3177466351,Rational LAMOL: A Rationale-based Lifelong Learning Framework,2021,4.218558339897045e-05,2
W4283790703,Siamese BERT-Based Model for Web Search Relevance Ranking Evaluated on a New Czech Dataset,2022,4.218414968872333e-05,2
W4313327571,"Short Text Clustering Algorithms, Application and Challenges: A Survey",2022,4.218414968872333e-05,2
W4389518647,DetectLLM: Leveraging Log Rank Information for Zero-Shot Detection of Machine-Generated Text,2023,4.218414968872333e-05,2
W4385573917,Generative Language Models for Paragraph-Level Question Generation,2022,4.2178849948944554e-05,2
W2987241137,D-NET: A Pre-Training and Fine-Tuning Framework for Improving the Generalization of Machine Reading Comprehension,2019,4.215766134481803e-05,2
W3131755153,A Mathematical Exploration of Why Language Models Help Solve Downstream Tasks,2021,4.2149895499319696e-05,2
W3174731106,"MATE-KD: Masked Adversarial TExt, a Companion to Knowledge Distillation",2021,4.214174574022077e-05,2
W3189383166,Multi-modal Retrieval of Tables and Texts Using Tri-encoder Models,2021,4.214043631465101e-05,2
W3021037761,Understanding and Improving Information Transfer in Multi-Task Learning,2020,4.213689957006779e-05,2
W4389519413,Large Language Models Know Your Contextual Search Intent: A Prompting Framework for Conversational Search,2023,4.2126531905329375e-05,2
W3211384762,Parameter-Efficient Domain Knowledge Integration from Multiple Sources for Biomedical Pre-trained Language Models,2021,4.21246552311834e-05,2
W3206210649,Analyzing Dynamic Adversarial Training Data in the Limit,2022,4.210920741384908e-05,2
W4385574006,FLUTE: Figurative Language Understanding through Textual Explanations,2022,4.21025003975041e-05,2
W3214608568,What’s in a Name? Answer Equivalence For Open-Domain Question Answering,2021,4.209184651680084e-05,2
W4289849144,Multi-label classification of symptom terms from free-text bilingual adverse drug reaction reports using natural language processing,2022,4.208617907169005e-05,2
W3152996058,Relational World Knowledge Representation in Contextual Language Models: A Review,2021,4.206796822910445e-05,2
W3204650139,GNN is a Counter? Revisiting GNN for Question Answering,2021,4.206546388470379e-05,2
W4396636677,A Dataset for Evaluating Contextualized Representation of Biomedical Concepts in Language Models,2024,4.206528604727271e-05,2
W3156587088,Language Models for Lexical Inference in Context,2021,4.2048810208553285e-05,2
W2980346149,Deep Feature Fusion Model for Sentence Semantic Matching,2019,4.2041065790866434e-05,2
W3153705853,Exploring Transitivity in Neural NLI Models through Veridicality,2021,4.203876167321687e-05,2
W4224616393,Multilabel classification of medical concepts for patient clinical profile identification,2022,4.203212559596294e-05,2
W4390970344,FDHFUI: Fusing Deep Representation and Hand-Crafted Features for User Identification,2024,4.202017665848804e-05,2
W4287854682,Paragraph-based Transformer Pre-training for Multi-Sentence Inference,2022,4.202017665848804e-05,2
W4406141444,Large language models as oracles for instantiating ontologies with domain-specific knowledge,2025,4.202017665848804e-05,2
W4397029707,Navigating Ontology Development with Large Language Models,2024,4.202017665848804e-05,2
W3203149535,Towards Efficient Post-training Quantization of Pre-trained Language Models,2021,4.202017665848804e-05,2
W4385572282,Impact of Adversarial Training on Robustness and Generalizability of Language Models,2023,4.202017665848804e-05,2
W4389518962,Explainable Claim Verification via Knowledge-Grounded Reasoning with Large Language Models,2023,4.202017665848804e-05,2
W4285254250,Zero- and Few-Shot NLP with Pretrained Language Models,2022,4.202017665848804e-05,2
W3156187258,Supporting policy-making with social media and e-participation platforms data: A policy analytics framework,2021,4.202017665848804e-05,2
W4400520877,Multi-schema prompting powered token-feature woven attention network for short text classification,2024,4.202017665848804e-05,2
W3217459502,Pretrained Natural Language Processing Model for Intent Recognition (BERT-IR),2021,4.202017665848804e-05,2
W4401798709,Contrasting Linguistic Patterns in Human and LLM-Generated News Text,2024,4.202017665848804e-05,2
W4385573096,Optimizing text representations to capture (dis)similarity between political parties,2022,4.202017665848804e-05,2
W4281806276,THE-X: Privacy-Preserving Transformer Inference with Homomorphic Encryption,2022,4.202017665848804e-05,2
W4393156193,G-Adapter: Towards Structure-Aware Parameter-Efficient Transfer Learning for Graph Transformer Networks,2024,4.202017665848804e-05,2
W3110715780,Imperio: Robust Over-the-Air Adversarial Examples for Automatic Speech Recognition Systems,2020,4.202017665848804e-05,2
W4381705785,NLP techniques for automating responses to customer queries: a systematic review,2023,4.202017665848804e-05,2
W4389518637,Exploring the Numerical Reasoning Capabilities of Language Models: A Comprehensive Analysis on Tabular Data,2023,4.202017665848804e-05,2
W3215147048,Backdoor Attacks on Image Classification Models in Deep Neural Networks,2022,4.202017665848804e-05,2
W4402701904,Potential of Multimodal Large Language Models for Data Mining of Medical Images and Free-text Reports,2024,4.202017665848804e-05,2
W4389520705,Copyright Violations and Large Language Models,2023,4.202017665848804e-05,2
W4311165730,KGML-xDTD: A Knowledge Graph-based Machine Learning Framework for Drug Treatment Prediction and Mechanism Description,2022,4.202017665848804e-05,2
W4385718075,Language models are not naysayers: an analysis of language models on negation benchmarks,2023,4.202017665848804e-05,2
W4390607929,Identifying and Extracting Rare Diseases and Their Phenotypes with Large Language Models,2024,4.202017665848804e-05,2
W3198300102,FinBERT—A Deep Learning Approach to Extracting Textual Information,2020,4.202017665848804e-05,2
W4214933629,Developing a Cancer Digital Twin: Supervised Metastases Detection From Consecutive Structured Radiology Reports,2022,4.202017665848804e-05,2
W4392692817,LLM–Assisted Data Augmentation for Chinese Dialogue–Level Dependency Parsing,2024,4.202017665848804e-05,2
W4318147141,Analysing Longitudinal Social Science Questionnaires: Topic modelling with BERT-based Embeddings,2022,4.202017665848804e-05,2
W4312687935,Knowledge Distillation of Russian Language Models with Reduction of Vocabulary,2022,4.202017665848804e-05,2
W3122031519,Geospatial and Semantic Mapping Platform for Massive COVID-19 Scientific Publication Search,2021,4.202017665848804e-05,2
W4390579019,Entity recognition from colloquial text,2024,4.202017665848804e-05,2
W4367318870,Bootstrapping Contrastive Learning Enhanced Music Cold-Start Matching,2023,4.202017665848804e-05,2
W4287889735,"Great Power, Great Responsibility: Recommendations for Reducing Energy for Training Language Models",2022,4.202017665848804e-05,2
W4407914316,A Review of the Challenges with Massive Web-Mined Corpora Used in Large Language Models Pre-training,2025,4.202017665848804e-05,2
W4313531743,Research on semantic representation and citation recommendation of scientific papers with multiple semantics fusion,2023,4.202017665848804e-05,2
W3209096362,Evaluating Unsupervised Text Embeddings on Software User Feedback,2021,4.202017665848804e-05,2
W4392202731,Applying large language models and chain-of-thought for automatic scoring,2024,4.202017665848804e-05,2
W3036353984,Exploiting non-taxonomic relations for measuring semantic similarity and relatedness in WordNet,2020,4.202017665848804e-05,2
W3100659335,Exploring the Role of Argument Structure in Online Debate Persuasion,2020,4.202017665848804e-05,2
W4389520007,Understanding HTML with Large Language Models,2023,4.202017665848804e-05,2
W4385973406,Automated reading passage generation with OpenAI's large language model,2023,4.202017665848804e-05,2
W4407622810,Augmenting general-purpose large-language models with domain-specific multimodal knowledge graph for question-answering in construction project management,2025,4.202017665848804e-05,2
W4385570047,Is Anisotropy Truly Harmful? A Case Study on Text Clustering,2023,4.202017665848804e-05,2
W2963740900,Unsupervised sentence representations as word information series: Revisiting TF–IDF,2019,4.202017665848804e-05,2
W4285495954,A Narrative Literature Review of Natural Language Processing Applied to the Occupational Exposome,2022,4.202017665848804e-05,2
W4386566672,Unified Neural Topic Model via Contrastive Learning and Term Weighting,2023,4.202017665848804e-05,2
W4392951810,A Model Ensemble Approach with LLM for Chinese Text Classification,2024,4.202017665848804e-05,2
W3006631416,Sparse low rank factorization for deep neural network compression,2020,4.201951180353433e-05,2
W3200033622,The Stem Cell Hypothesis: Dilemma behind Multi-Task Learning with Transformer Encoders,2021,4.2019137167909435e-05,2
W4385571894,ThinkSum: Probabilistic reasoning over sets using large language models,2023,4.200971244068621e-05,2
W3167303745,Progressive Generation of Long Text with Pretrained Language Models,2021,4.200955620534525e-05,2
W3095642204,Measurement of Semantic Textual Similarity in Clinical Texts: Comparison of Transformer-Based Models,2020,4.199225602245626e-05,2
W3169394946,Are we there yet? Exploring clinical domain knowledge of BERT models,2021,4.1986515592330373e-05,2
W3037337776,Progressive Generation of Long Text.,2020,4.1982417453570225e-05,2
W3171355829,Multilingual Language Models Predict Human Reading Behavior,2021,4.197928127415166e-05,2
W4287854995,Aligning Generative Language Models with Human Values,2022,4.197575323889995e-05,2
W3143557598,Automatic question-answer pairs generation and question similarity mechanism in question answering system,2021,4.197103937094893e-05,2
W3112158532,Multilingual Transfer Learning for QA using Translation as Data Augmentation,2021,4.196116510610686e-05,2
W3093767665,NumClaim,2020,4.195807663509888e-05,2
W4308939312,Is neuro-symbolic AI meeting its promises in natural language processing? A structured review,2022,4.1956072076172345e-05,2
W3155192455,CLiMP: A Benchmark for Chinese Language Model Evaluation,2021,4.1953096782482686e-05,2
W3170666909,Learning to Recognize Dialect Features,2021,4.192347194008525e-05,2
W4318960928,TextGuise: Adaptive adversarial example attacks on text classification model,2023,4.192126175360925e-05,2
W3213415226,TransPrompt: Towards an Automatic Transferable Prompting Framework for Few-shot Text Classification,2021,4.1897820859549647e-05,2
W4312443713,Automated Question Answering for Improved Understanding of Compliance Requirements: A Multi-Document Study,2022,4.188601690647734e-05,2
W3137353858,Hidden Biases in Unreliable News Detection Datasets,2021,4.187873368715077e-05,2
W2994967700,Pre-Training of Deep Bidirectional Protein Sequence Representations with Structural Information,2019,4.187860263262474e-05,2
W4385574345,LogicSolver: Towards Interpretable Math Word Problem Solving with Logical Prompt-enhanced Learning,2022,4.187067660928309e-05,2
W3156311852,Medical Specialty Recommendations by an Artificial Intelligence Chatbot on a Smartphone: Development and Deployment,2021,4.186123219423729e-05,2
W4287646439,Pareto Probing: Trading Off Accuracy for Complexity,2020,4.185756770051672e-05,2
W3167266074,NAS-BERT,2021,4.184977305668801e-05,2
W3049366647,Is Supervised Syntactic Parsing Beneficial for Language Understanding? An Empirical Investigation,2020,4.184352422585357e-05,2
W3170826848,Do Syntactic Probes Probe Syntax? Experiments with Jabberwocky Probing,2021,4.1839579369057453e-05,2
W4385571807,Hierarchical Verbalizer for Few-Shot Hierarchical Text Classification,2023,4.183097700821654e-05,2
W4403195962,Knowledge Editing for Large Language Models: A Survey,2024,4.183097700821654e-05,2
W4380738738,Contextualized medication event extraction with striding NER and multi-turn QA,2023,4.182768657951616e-05,2
W3199373335,The Grammar-Learning Trajectories of Neural Language Models,2022,4.18258839334312e-05,2
W4396823873,Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering,2024,4.1817729213404364e-05,2
W4224873813,Table-based Fact Verification with Self-adaptive Mixture of Experts,2022,4.181688715301733e-05,2
W3015646487,MedLinker: Medical Entity Linking with Neural Representations and Dictionary Matching,2020,4.1816042798380326e-05,2
W3212093422,Will this Question be Answered? Question Filtering via Answer Model Distillation for Efficient Question Answering,2021,4.1803691185331076e-05,2
W4324098937,Does ChatGPT resemble humans in language use?,2023,4.180323978960708e-05,2
W4391559941,Fine-tuning ChatGPT for automatic scoring,2024,4.180119927274882e-05,2
W2983049545,Beyond English-Only Reading Comprehension: Experiments in Zero-Shot Multilingual Transfer for Bulgarian,2019,4.1795483491053646e-05,2
W4287854873,Informativeness and Invariance: Two Perspectives on Spurious Correlations in Natural Language,2022,4.179406729384918e-05,2
W4287854464,TreeMix: Compositional Constituency-based Data Augmentation for Natural Language Understanding,2022,4.17842276517224e-05,2
W4385571289,Detecting Edit Failures In Large Language Models: An Improved Specificity Benchmark,2023,4.1772574441026274e-05,2
W3199350934,NegatER: Unsupervised Discovery of Negatives in Commonsense Knowledge Bases,2021,4.1768689865322525e-05,2
W4377091689,KEBLM: Knowledge-Enhanced Biomedical Language Models,2023,4.176526060308022e-05,2
W4375870244,Programming-by-Demonstration for Long-Horizon Robot Tasks,2024,4.1758087271717355e-05,2
W3174848559,Defending Pre-trained Language Models from Adversarial Word Substitution Without Performance Sacrifice,2021,4.175000551578406e-05,2
W4385188677,"Predict, pretrained, select and answer: Interpretable and scalable complex question answering over knowledge bases",2023,4.174700181078998e-05,2
W3209329320,CyBERT: Cybersecurity Claim Classification by Fine-Tuning the BERT Language Model,2021,4.1727163106979964e-05,2
W4224115290,IDPG: An Instance-Dependent Prompt Generation Method,2022,4.171554407978771e-05,2
W4382052727,Bypassing Deep Learning based Sentiment Analysis from Business Reviews,2023,4.170669880656761e-05,2
W4229335055,A Deep Language Model for Symptom Extraction From Clinical Text and its Application to Extract COVID-19 Symptoms From Social Media,2021,4.1706017016003e-05,2
W2951335443,Can You Tell Me How to Get Past Sesame Street? Sentence-Level Pretraining Beyond Language Modeling,2018,4.168515174863946e-05,2
W4214876417,What Can Knowledge Bring to Machine Learning?—A Survey of Low-shot Learning for Structured Data,2022,4.167595457434524e-05,2
W3169436637,DirectProbe: Studying Representations without Classifiers,2021,4.166300539153609e-05,2
W3199969499,Coarse2Fine: Fine-grained Text Classification on Coarsely-grained Annotated Data,2021,4.164613271566037e-05,2
W4363625523,A-maze of Natural Stories: Comprehension and surprisal in the Maze task,2023,4.161075934899564e-05,2
W4399740794,Leveraging LLM: Implementing an Advanced AI Chatbot for Healthcare,2024,4.161024408289978e-05,2
W3106210592,Improve Transformer Models with Better Relative Position Embeddings,2020,4.159792838425863e-05,2
W3021813138,Data Augmentation for Spoken Language Understanding via Pretrained Models.,2020,4.158832698415644e-05,2
W3186681099,UIUC_BioNLP at SemEval-2021 Task 11: A Cascade of Neural Models for Structuring Scholarly NLP Contributions,2021,4.158291786909314e-05,2
W3154451896,Process-Level Representation of Scientific Protocols with Interactive Annotation,2021,4.158030682566353e-05,2
W3106070274,Pruning Redundant Mappings in Transformer Models via Spectral-Normalized Identity Prior,2020,4.157506938496188e-05,2
W3114725666,Text Classification by Contrastive Learning and Cross-lingual Data Augmentation for Alzheimer’s Disease Detection,2020,4.156972694552724e-05,2
W4206281850,Differentiable Subset Pruning of Transformer Heads,2021,4.156306865891447e-05,2
W2970069267,EntEval: A Holistic Evaluation Benchmark for Entity Representations,2019,4.155321576662186e-05,2
W4393990831,Enhancing Early Detection of Cognitive Decline in the Elderly: A Comparative Study Utilizing Large Language Models in Clinical Notes,2024,4.155206195192686e-05,2
W2972353900,"Decomposing Generalization: Models of Generic, Habitual, and Episodic Statements",2019,4.154994777092387e-05,2
W4287887293,Political Ideology and Polarization: A Multi-dimensional Approach,2022,4.154237809237905e-05,2
W4285148079,Local Structure Matters Most: Perturbation Study in NLU,2022,4.154167685109147e-05,2
W4380729715,PharmBERT: a domain-specific BERT model for drug labels,2023,4.1541034687021255e-05,2
W2952841984,A Minimax Game for Instance based Selective Transfer Learning,2019,4.152825756778214e-05,2
W4385571571,ReGen: Zero-Shot Text Classification via Training Data Generation with Progressive Dense Retrieval,2023,4.152809361100038e-05,2
W3120793869,CoDA: Contrast-enhanced and Diversity-promoting Data Augmentation for Natural Language Understanding,2021,4.152597528567401e-05,2
W4388214929,Harnessing GPT-3.5-Turbo for Rhetorical Role Prediction in Legal Cases,2023,4.152439278119325e-05,2
W4385572727,Entailer: Answering Questions with Faithful and Truthful Chains of Reasoning,2022,4.1522070275510644e-05,2
W3196340340,Large Biomedical Question Answering Models with ALBERT and ELECTRA.,2021,4.151956917962226e-05,2
W3092448486,On the Interplay Between Fine-tuning and Sentence-Level Probing for Linguistic Knowledge in Pre-Trained Transformers,2020,4.151504595998819e-05,2
W3017779903,Quantifying the Contextualization of Word Representations with Semantic Class Probing,2020,4.150976800238883e-05,2
W3167841296,Case Study: Deontological Ethics in NLP,2021,4.1507494243641166e-05,2
W4310424784,Pre-training language model incorporating domain-specific heterogeneous knowledge into a unified representation,2022,4.1497411212339766e-05,2
W3106229690,F1 is Not Enough! Models and Evaluation Towards User-Centered Explainable Question Answering,2020,4.148615008440773e-05,2
W3105771185,EXAMS: A Multi-subject High School Examinations Dataset for Cross-lingual and Multilingual Question Answering,2020,4.147126270974779e-05,2
W3174693310,AND does not mean OR: Using Formal Languages to Study Language Models’ Representations,2021,4.146935506865587e-05,2
W4225090118,Testing the Ability of Language Models to Interpret Figurative Language,2022,4.145324176081346e-05,2
W2953130735,Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Autoencoders,2019,4.145032527866264e-05,2
W4287888691,Efficient Hierarchical Domain Adaptation for Pretrained Language Models,2022,4.144683782371555e-05,2
W2966750840,GraphFlow: Exploiting Conversation Flow with Graph Neural Networks for Conversational Machine Comprehension,2019,4.144360570682217e-05,2
W4210489638,Word Acquisition in Neural Language Models,2022,4.144164911130484e-05,2
W4387489715,"Information-Restricted Neural Language Models Reveal Different Brain Regions’ Sensitivity to Semantics, Syntax, and Context",2023,4.142885415648668e-05,2
W4287855115,Masked Measurement Prediction: Learning to Jointly Predict Quantities and Units from Textual Context,2022,4.142693231247173e-05,2
W3176540316,Multi-Document Transformer for Personality Detection,2021,4.142015553519611e-05,2
W3083978629,Task-specific Objectives of Pre-trained Language Models for Dialogue Adaptation,2020,4.1410250949884406e-05,2
W3119854206,Contextualized Word Embeddings Encode Aspects of Human-Like Word Sense Knowledge,2020,4.138000665928185e-05,2
W3213719910,Learning to Rank in the Age of Muppets: Effectiveness–Efficiency Tradeoffs in Multi-Stage Ranking,2021,4.137474425549397e-05,2
W4229019932,Improving In-Context Few-Shot Learning via Self-Supervised Training,2022,4.135136055486819e-05,2
W3035391452,Recurrent Chunking Mechanisms for Long-Text Machine Reading Comprehension,2020,4.134655617966578e-05,2
W3210489413,WhatTheWikiFact,2021,4.133869988865432e-05,2
W3194983542,Validation on machine reading comprehension software without annotated labels: a property-based method,2021,4.133625184536404e-05,2
W3100776995,Visually Grounded Compound PCFGs,2020,4.133321360688645e-05,2
W3199848231,Assisting the Human Fact-Checkers: Detecting All Previously Fact-Checked Claims in a Document,2022,4.132802320480241e-05,2
W3096160408,Achieving Reliable Sentiment Analysis in the Software Engineering Domain using BERT,2020,4.132197089572232e-05,2
W3208602306,WikiCheck,2021,4.131380552956378e-05,2
W3092932788,Neural Databases,2020,4.130972316446164e-05,2
W4400529373,LLM-Ensemble: Optimal Large Language Model Ensemble Method for E-commerce Product Attribute Value Extraction,2024,4.129676623097936e-05,2
W4366779715,Using Bidirectional Encoder Representations from Transformers (BERT) to classify traffic crash severity types,2023,4.129676623097936e-05,2
W4400118952,When large language models meet personalization: perspectives of challenges and opportunities,2024,4.129676623097936e-05,2
W4389519496,Unlearn What You Want to Forget: Efficient Unlearning for LLMs,2023,4.129676623097936e-05,2
W4285265874,Knowledge-Augmented Language Models for Cause-Effect Relation Classification,2022,4.1295067105367714e-05,2
W4403679878,Efficiency at scale: Investigating the performance of diminutive language models in clinical tasks,2024,4.1291051550009495e-05,2
W3172750682,Pre-trained Language Model for Web-scale Retrieval in Baidu Search,2021,4.12909787514373e-05,2
W3170369042,"Generate, Annotate, and Learn: Generative Models Advance Self-Training and Knowledge Distillation.",2021,4.1288619124455915e-05,2
W4307217099,Transformer-based models for ICD-10 coding of death certificates with Portuguese text,2022,4.128567777106839e-05,2
W4312782030,A Neighborhood Re-Ranking Model With Relation Constraint for Knowledge Graph Completion,2022,4.1282298022429186e-05,2
W4221154651,MERIt: Meta-Path Guided Contrastive Learning for Logical Reasoning,2022,4.128208477232107e-05,2
W4309659061,Chemical–protein relation extraction with ensembles of carefully tuned pretrained language models,2022,4.126914783354543e-05,2
W4385573618,Towards Unified Prompt Tuning for Few-shot Text Classification,2022,4.1252924581633576e-05,2
W4380757924,Chinese mineral question and answering system based on knowledge graph,2023,4.124443512071815e-05,2
W3034878914,Probabilistically Masked Language Model Capable of Autoregressive Generation in Arbitrary Word Order,2020,4.123973979809438e-05,2
W3211653317,Putting Words in BERT’s Mouth: Navigating Contextualized Vector Spaces with Pseudowords,2021,4.12291899536325e-05,2
W3184454880,Hardware Acceleration of Fully Quantized BERT for Efficient Natural Language Processing,2021,4.1207547955181474e-05,2
W3174090807,Ethical-Advice Taker: Do Language Models Understand Natural Language Interventions?,2021,4.12031059402083e-05,2
W4389518671,Query Rewriting in Retrieval-Augmented Large Language Models,2023,4.1200311507311535e-05,2
W4388594219,Retrieval for Extremely Long Queries and Documents with RPRS: A Highly Efficient and Effective Transformer-based Re-Ranker,2023,4.1200311507311535e-05,2
W3207707577,On the Study of Transformers for Query Suggestion,2021,4.1200311507311535e-05,2
W3183229893,Report on the future conversations workshop at CHIIR 2021,2021,4.1200311507311535e-05,2
W3046238651,"The role of explainability in creating trustworthy artificial intelligence for health care: A comprehensive survey of the terminology, design choices, and evaluation strategies",2020,4.1200311507311535e-05,2
W3106278732,ISAAQ - Mastering Textbook Questions with Pre-trained Transformers and Bottom-Up and Top-Down Attention,2020,4.1200311507311535e-05,2
W2198584637,An End-to-End Neural Network for Polyphonic Piano Music Transcription,2016,4.1200311507311535e-05,2
W3176776997,Learning Event Graph Knowledge for Abductive Reasoning,2021,4.1192617310164216e-05,2
W4385574274,Generating Natural Language Proofs with Verifier-Guided Search,2022,4.1192160126974636e-05,2
W4393147193,Editing Language Model-Based Knowledge Graph Embeddings,2024,4.1189925614539634e-05,2
W4389524200,Self-ICL: Zero-Shot In-Context Learning with Self-Generated Demonstrations,2023,4.1174195989843166e-05,2
W3156782505,Word Senses as Clusters of Meaning Modulations: A Computational Model of Polysemy,2021,4.117345750802941e-05,2
W4385574243,Grape: Knowledge Graph Enhanced Passage Reader for Open-domain Question Answering,2022,4.116572653491966e-05,2
W4389524159,Large Language Models are Better Reasoners with Self-Verification,2023,4.1158870475896315e-05,2
W3205058818,Meta-learning via Language Model In-context Tuning,2022,4.1154416025402075e-05,2
W3197287583,Self- and Pseudo-self-supervised Prediction of Speaker and Key-utterance for Multi-party Dialogue Reading Comprehension,2021,4.115382603160359e-05,2
W3095156104,ABNIRML: Analyzing the Behavior of Neural IR Models,2022,4.113626555913147e-05,2
W4385573164,Fine-tuned Language Models are Continual Learners,2022,4.11324961214529e-05,2
W4394579747,An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing: Algorithm Development and Validation Study,2024,4.109053845724464e-05,2
W4393160124,Mitigating Large Language Model Hallucinations via Autonomous Knowledge Graph-Based Retrofitting,2024,4.108019813777151e-05,2
W3038495045,Transferability of Natural Language Inference to Biomedical Question Answering,2020,4.107684396774631e-05,2
W4285113702,Adaptive Testing and Debugging of NLP Models,2022,4.107109081646697e-05,2
W3099548761,Biomedical Event Extraction as Multi-turn Question Answering,2020,4.106929757638042e-05,2
W3024226488,Digital begriffsgeschichte: Tracing semantic change using word embeddings,2020,4.1055207002713066e-05,2
W4287887877,Proceedings of the 2nd Workshop on Trustworthy Natural Language Processing (TrustNLP 2022),2022,4.103633847707623e-05,2
W3101493110,Extremely Low Bit Transformer Quantization for On-Device Neural Machine Translation,2020,4.103601249030101e-05,2
W4367609927,Semantic reconstruction of continuous language from non-invasive brain recordings,2023,4.103301378907767e-05,2
W4385571951,Distilling Script Knowledge from Large Language Models for Constrained Language Planning,2023,4.101397851840779e-05,2
W4200632828,Reasoning over Hybrid Chain for Table-and-Text Open Domain Question Answering,2022,4.10043272547765e-05,2
W4312805275,OERL: Enhanced Representation Learning via Open Knowledge Graphs,2022,4.099222615419478e-05,2
W2983721890,Layerwise Relevance Visualization in Convolutional Text Graph Classifiers,2019,4.098056055746132e-05,2
W3173277859,Joint Models for Answer Verification in Question Answering Systems,2021,4.097282747826965e-05,2
W3154376977,Syntactic Perturbations Reveal Representational Correlates of Hierarchical Phrase Structure in Pretrained Language Models,2021,4.0968666672041985e-05,2
W3163109966,Conversational Entity Linking: Problem Definition and Datasets,2021,4.09660643212611e-05,2
W3211142893,Question Answering for the Curated Web: Tasks and Methods in QA over Knowledge Bases and Text Collections,2021,4.096266509565183e-05,2
W4226346873,CyBERT: Contextualized Embeddings for the Cybersecurity Domain,2021,4.0960084768231484e-05,2
W4285287265,Context Matters: A Pragmatic Study of PLMs’ Negation Understanding,2022,4.09520567129326e-05,2
W4226208236,Divide and Conquer: Text Semantic Matching with Disentangled Keywords and Intents,2022,4.094890526846967e-05,2
W3176450819,Towards Semantics-Enhanced Pre-Training: Can Lexicon Definitions Help Learning Sentence Meanings?,2021,4.094870929034593e-05,2
W4379197269,An analysis of entity normalization evaluation biases in specialized domains,2023,4.0947410380212274e-05,2
W3034654962,Language (Re)modelling: Towards Embodied Language Understanding,2020,4.0926463686635916e-05,2
W3209946909,Wacky Weights in Learned Sparse Representations and the Revenge of Score-at-a-Time Query Evaluation,2021,4.0922294617572416e-05,2
W4286008391,A Review on the Application of Knowledge Graph Technology in the Medical Field,2022,4.0916360788169955e-05,2
W3206996280,CCQA: A New Web-Scale Question Answering Dataset for Model Pre-Training,2022,4.091124769303812e-05,2
W2898858752,MemoReader: Large-Scale Reading Comprehension through Neural Memory Controller,2018,4.0905169319762464e-05,2
W4298324482,Biomedical Question Answering: A Survey of Approaches and Challenges,2021,4.0903521013585144e-05,2
W4385572060,Saliency Map Verbalization: Comparing Feature Importance Representations from Model-free and Instruction-based Methods,2023,4.090217872506553e-05,2
W3197907569,Contrastive Domain Adaptation for Question Answering using Limited Text Corpora,2021,4.087821445550695e-05,2
W3118280924,An entity-graph based reasoning method for fact verification,2021,4.0877334326545034e-05,2
W4388778142,How Abstract Is Linguistic Generalization in Large Language Models? Experiments with Argument Structure,2023,4.087236544684093e-05,2
W3211525823,Softermax: Hardware/Software Co-Design of an Efficient Softmax for Transformers,2021,4.087236544684093e-05,2
W4386488973,<b>MIRACL</b>: A Multilingual Retrieval Dataset Covering 18 Diverse Languages,2023,4.087236544684093e-05,2
W4323359744,EHR foundation models improve robustness in the presence of temporal distribution shift,2023,4.08560797277436e-05,2
W3015339533,Generating Fact Checking Explanations,2020,4.0845712860154254e-05,2
W3003404702,Bringing Stories Alive: Generating Interactive Fiction Worlds,2020,4.084247805089659e-05,2
W3200808010,Dynamic Knowledge Distillation for Pre-trained Language Models,2021,4.082973201129913e-05,2
W2955315229,Deep Learning for Natural Language Inference,2019,4.0829635202872e-05,2
W4287887900,PCEE-BERT: Accelerating BERT Inference via Patient and Confident Early Exiting,2022,4.08271707552582e-05,2
W4293812374,Stable Contrastive Learning for Self-Supervised Sentence Embeddings With Pseudo-Siamese Mutual Learning,2022,4.082712616736061e-05,2
W4385571396,Contrastive Learning with Generated Representations for Inductive Knowledge Graph Embedding,2023,4.082551600963085e-05,2
W4283078630,Constructing Domain Ontology for Alzheimer Disease Using Deep Learning Based Approach,2022,4.082551600963085e-05,2
W3104298168,RNNs can generate bounded hierarchical languages with optimal memory,2020,4.082531313866008e-05,2
W4205513945,KFCNet: Knowledge Filtering and Contrastive Learning for Generative Commonsense Reasoning,2021,4.0820280108250104e-05,2
W3199246732,Distilling Linguistic Context for Language Model Compression,2021,4.0816854836368775e-05,2
W3197680083,"Learn Continually, Generalize Rapidly: Lifelong Knowledge Accumulation for Few-shot Learning",2021,4.0815637059163446e-05,2
W4385571914,IRIT_IRIS_A at SemEval-2023 Task 6: Legal Rhetorical Role Labeling Supported by Dynamic-Filled Contextualized Sentence Chunks,2023,4.0808523201424696e-05,2
W3160858468,Assessing BERT’s ability to learn Italian syntax: a study on null-subject and agreement phenomena,2021,4.080442187572327e-05,2
W3200704197,Incorporating Residual and Normalization Layers into Analysis of Masked Language Models,2021,4.0795113663140794e-05,2
W3088577908,Analyzing ELMo and DistilBERT on Socio-political News Classification,2020,4.0791561021461515e-05,2
W3127307050,Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters & Less Data,2021,4.0787166669382954e-05,2
W3199207650,Broaden the Vision: Geo-Diverse Visual Commonsense Reasoning,2021,4.078343597049108e-05,2
W4389524585,In-Context Learning for Text Classification with Many Labels,2023,4.0772671746972265e-05,2
W4385570290,Retrieval-based Language Models and Applications,2023,4.0772671746972265e-05,2
W3171639130,TellMeWhy: A Dataset for Answering Why-Questions in Narratives,2021,4.076496920296969e-05,2
W3173588320,Improving Document Representations by Generating Pseudo Query Embeddings for Dense Retrieval,2021,4.076105207495294e-05,2
W3213468647,A Multilingual Benchmark for Probing Negation-Awareness with Minimal Pairs,2021,4.075825360232392e-05,2
W3102400851,WNUT-2020 Task 1 Overview: Extracting Entities and Relations from Wet Lab Protocols,2020,4.0746973902350197e-05,2
W4406152279,Toward expert-level medical question answering with large language models,2025,4.074565901438639e-05,2
W4320921249,Transformer-based language models for mental health issues: A survey,2023,4.073698654963552e-05,2
W4385573097,Knowledge Prompting in Pre-trained Language Model for Natural Language Understanding,2022,4.0729270005193634e-05,2
W3134100302,Contrastive Explanations for Model Interpretability,2021,4.0728688297968216e-05,2
W3099576124,FastFormers: Highly Efficient Transformer Models for Natural Language Understanding,2020,4.071727967185193e-05,2
W4287854917,MultiVerS: Improving scientific claim verification with weak supervision and full-document context,2022,4.070773729131936e-05,2
W3206816211,UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning,2022,4.0705970891124316e-05,2
W4283784468,Multisource financial sentiment analysis for detecting Bitcoin price change indications using deep learning,2022,4.070141507076132e-05,2
W4389518888,"Toward Human Readable Prompt Tuning: Kubrick’s The Shining is a good movie, and a good prompt too?",2023,4.069986953967399e-05,2
W2986380433,Generation-Distillation for Efficient Natural Language Understanding in Low-Data Settings,2019,4.0697306758108234e-05,2
W4386566774,A Psycholinguistic Analysis of BERT’s Representations of Compounds,2023,4.068873750158999e-05,2
W3163504421,Certified Robustness to Text Adversarial Attacks by Randomized [MASK],2023,4.0688137859572405e-05,2
W3176574162,Taming Pre-trained Language Models with N-gram Representations for Low-Resource Domain Adaptation,2021,4.068110219449854e-05,2
W4229031767,Unified Semantic Typing with Meaningful Label Inference,2022,4.065265205535991e-05,2
W4383481224,Modeling Structure‐Building in the Brain With CCG Parsing and Large Language Models,2023,4.0648269791217085e-05,2
W3035187263,Contextual Re-Ranking with Behavior Aware Transformers,2020,4.06269542913764e-05,2
W3207715300,Lifelong Pretraining: Continually Adapting Language Models to Emerging Corpora,2022,4.062226430007727e-05,2
W3195153845,Uniqorn: Unified question answering over RDF knowledge graphs and natural language text,2024,4.0621856689841506e-05,2
W3139145960,Local Interpretations for Explainable Natural Language Processing: A Survey,2021,4.0621182353537736e-05,2
W4386284317,Towards More Generalizable and Accurate Sentence Classification in Medical Abstracts with Less Data,2023,4.0619288235896134e-05,2
W4285291532,FairLex: A Multilingual Benchmark for Evaluating Fairness in Legal Text Processing,2022,4.061626322840684e-05,2
W3036463250,SqueezeBERT: What can computer vision teach NLP about efficient neural networks?,2020,4.061215228900629e-05,2
W3139266014,Global citation recommendation employing generative adversarial network,2021,4.061020887741325e-05,2
W3171218748,End-to-End Multihop Retrieval for Compositional Question Answering over Long Documents,2021,4.060640732822419e-05,2
W2787296320,Deep neural networks for bot detection,2018,4.060404594281953e-05,2
W4388342038,Spatial Commonsense Reasoning for Machine Reading Comprehension,2023,4.060404594281953e-05,2
W4389518706,Let’s Synthesize Step by Step: Iterative Dataset Synthesis with Large Language Models by Extrapolating Errors from Small Models,2023,4.060404594281953e-05,2
W2998604177,Towards a Robust Deep Neural Network in Texts: A Survey,2019,4.06038382770831e-05,2
W3148237218,TAPAS at SemEval-2021 Task 9: Reasoning over tables with intermediate pre-training,2021,4.060310175841264e-05,2
W4296701495,A lexicon-based approach to examine depression detection in social media: the case of Twitter and university community,2022,4.059402467282807e-05,2
W3211582110,Retrieval Augmentation Reduces Hallucination in Conversation,2021,4.0591600131690157e-05,2
W4225639074,A joint FrameNet and element focusing Sentence-BERT method of sentence similarity computation,2022,4.059098818408535e-05,2
W4367189613,Generative Relevance Feedback with Large Language Models,2023,4.0590371890625976e-05,2
W3176142035,Don’t Miss the Labels: Label-semantic Augmented Meta-Learner for Few-Shot Text Classification,2021,4.058760332370744e-05,2
W4225661174,LOT: A Story-Centric Benchmark for Evaluating Chinese Long Text Understanding and Generation,2022,4.058453891816697e-05,2
W3198948523,Exploring Decomposition for Table-based Fact Verification,2021,4.057306803375957e-05,2
W4385567255,InforMask: Unsupervised Informative Masking for Language Model Pretraining,2022,4.05682776462878e-05,2
W4220832158,iSEA: An Interactive Pipeline for Semantic Error Analysis of NLP Models,2022,4.0567959214443734e-05,2
W3012932209,Leveraging Sentiment Distributions to Distinguish Figurative From Literal Health Reports on Twitter,2020,4.056143112506763e-05,2
W3128654100,InfoBERT: Improving Robustness of Language Models from An Information Theoretic Perspective,2020,4.0553643261035614e-05,2
W4389665359,Task and Motion Planning with Large Language Models for Object Rearrangement,2023,4.054441938637033e-05,2
W4392669928,ConDA: Contrastive Domain Adaptation for AI-generated Text Detection,2023,4.054441938637033e-05,2
W4386566852,CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation Verification,2023,4.054441938637033e-05,2
W4226086464,TA-SBERT: Token Attention Sentence-BERT for Improving Sentence Representation,2022,4.054441938637033e-05,2
W3128630643,BiasFinder: Metamorphic Test Generation to Uncover Bias for Sentiment Analysis Systems,2021,4.054441938637033e-05,2
W4281687075,A comparative evaluation of biomedical similar article recommendation,2022,4.054441938637033e-05,2
W4399269329,"Enhancing Complex Linguistic Tasks Resolution Through Fine-Tuning LLMs, RAG and Knowledge Graphs (Short Paper)",2024,4.054441938637033e-05,2
W3175019732,Adversarial Learning for Discourse Rhetorical Structure Parsing,2021,4.054441938637033e-05,2
W3153719108,MultiReQA: A Cross-Domain Evaluation for Retrieval Question Answering Models,2020,4.054441938637033e-05,2
W3159323659,Arabic Question Answering Systems: Gap Analysis,2021,4.054441938637033e-05,2
W4391464262,Large-scale text analysis using generative language models: A case study in discovering public value expressions in AI patents,2024,4.054441938637033e-05,2
W4383818636,Unifying Sentence Transformer Embedding and Softmax Voting Ensemble for Accurate News Category Prediction,2023,4.054441938637033e-05,2
W4382202848,LIQUID: A Framework for List Question Answering Dataset Generation,2023,4.054441938637033e-05,2
W4397029721,Leveraging Pre-trained Language Models for Time Interval Prediction in Text-Enhanced Temporal Knowledge Graphs,2024,4.054441938637033e-05,2
W4389579575,STRING-ing together protein complexes: corpus and methods for extracting physical protein interactions from the biomedical literature,2023,4.054441938637033e-05,2
W4380136067,Intrinsic Dimension Estimation for Robust Detection of AI-Generated Texts,2023,4.054441938637033e-05,2
W4390590960,Intelligent Practices of Large Language Models in Digital Government Services,2024,4.054441938637033e-05,2
W3011373955,A Survey on Computational Metaphor Processing,2020,4.054441938637033e-05,2
W4388267439,Can Large Language Models Revolutionalize Open Government Data Portals? A Case of Using ChatGPT in statistics.gov.scot,2023,4.054441938637033e-05,2
W4206105765,"Automated recognition of functioning, activity and participation in COVID-19 from electronic patient records by natural language processing: a proof- of- concept",2022,4.054441938637033e-05,2
W4388491879,Classification of Human- and AI-Generated Texts: Investigating Features for ChatGPT,2023,4.054441938637033e-05,2
W4389519056,A Mechanistic Interpretation of Arithmetic Reasoning in Language Models using Causal Mediation Analysis,2023,4.054441938637033e-05,2
W4396620533,Infusing internalized knowledge of language models into hybrid prompts for knowledgeable dialogue generation,2024,4.054441938637033e-05,2
W4389946433,Advancing Mental Health Diagnostics: GPT-Based Method for Depression Detection,2023,4.054441938637033e-05,2
W4327503230,Improving Log-Based Anomaly Detection by Pre-Training Hierarchical Transformers,2023,4.054441938637033e-05,2
W3199638386,Transformers: “The End of History” for Natural Language Processing?,2021,4.054441938637033e-05,2
W4382202519,Orders Are Unwanted: Dynamic Deep Graph Convolutional Network for Personality Detection,2023,4.054441938637033e-05,2
W4403582442,Towards Completeness-Oriented Tool Retrieval for Large Language Models,2024,4.054441938637033e-05,2
W4224068866,A Transfer Learning Method for Detecting Alzheimer's Disease Based on Speech and Natural Language Processing,2022,4.054441938637033e-05,2
W4403825982,PRISM: Patient Records Interpretation for Semantic clinical trial Matching system using large language models,2024,4.054441938637033e-05,2
W4392928544,Leveraging large language models for generating responses to patient messages—a subjective analysis,2024,4.054441938637033e-05,2
W4406421570,"Improving large language model applications in biomedicine with retrieval-augmented generation: a systematic review, meta-analysis, and clinical development guidelines",2025,4.054441938637033e-05,2
W4393902605,Question-answering system extracts information on injection drug use from clinical notes,2024,4.054441938637033e-05,2
W4389519206,SeqXGPT: Sentence-Level AI-Generated Text Detection,2023,4.054441938637033e-05,2
W3215779969,Evaluating Topic Models in Portuguese Political Comments About Bills from Brazil’s Chamber of Deputies,2021,4.054441938637033e-05,2
W4384789477,Information Retrieval from Legal Documents with Ontology and Graph Embeddings Approach,2023,4.054441938637033e-05,2
W4322625799,Top-down information shapes lexical processing when listening to continuous speech,2023,4.054441938637033e-05,2
W4392567331,Spectrum-BERT: Pretraining of Deep Bidirectional Transformers for Spectral Classification of Chinese Liquors,2024,4.054441938637033e-05,2
W4392405493,LEVA: Using Large Language Models to Enhance Visual Analytics,2024,4.054441938637033e-05,2
W4310910011,Identifying women with postdelivery posttraumatic stress disorder using natural language processing of personal childbirth narratives,2022,4.054441938637033e-05,2
W4389523905,How Does Generative Retrieval Scale to Millions of Passages?,2023,4.054441938637033e-05,2
W4385567900,RecruitPro: A Pretrained Language Model with Skill-Aware Prompt Learning for Intelligent Recruitment,2023,4.054441938637033e-05,2
W4389519063,FedID: Federated Interactive Distillation for Large-Scale Pretraining Language Models,2023,4.054441938637033e-05,2
W4383376720,One-Class Learning for AI-Generated Essay Detection,2023,4.054441938637033e-05,2
W4206557209,Am I Being Bullied on Social Media? An Ensemble Approach to Categorize Cyberbullying,2021,4.054441938637033e-05,2
W4385570504,Counterfactual Debiasing for Fact Verification,2023,4.054441938637033e-05,2
W3204414009,Graph Reasoning with Context-Aware Linearization for Interpretable Fact Extraction and Verification,2021,4.054155181874997e-05,2
W3159682551,Did they answer? Subjective acts and intents in conversational discourse,2021,4.053732722042559e-05,2
W3020987135,Pre-training Is (Almost) All You Need: An Application to Commonsense Reasoning,2020,4.052812491155882e-05,2
W4287887710,Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables,2022,4.052596354746939e-05,2
W2951732656,Empirical Linguistic Study of Sentence Embeddings,2019,4.050809635660733e-05,2
W3015721781,What do Models Learn from Question Answering Datasets?,2020,4.050495595251137e-05,2
W3084742463,Accelerating Real-Time Question Answering via Question Generation,2020,4.0503742751084367e-05,2
W4386566764,Augmenting Pre-trained Language Models with QA-Memory for Open-Domain Question Answering,2023,4.050027891151152e-05,2
W4385572602,ColD Fusion: Collaborative Descent for Distributed Multitask Finetuning,2023,4.049417016699719e-05,2
W3154863804,Generating Datasets with Pretrained Language Models,2021,4.049335389058423e-05,2
W4289323723,Fact Checking with Insufficient Evidence,2022,4.049112494673932e-05,2
W3167126457,Constructing Taxonomies from Pretrained Language Models,2021,4.048974467728621e-05,2
W3177898556,A Systematic Survey of Text Worlds as Embodied Natural Language Environments,2022,4.0483739025864144e-05,2
W4385572102,World Models for Math Story Problems,2023,4.0475706177506365e-05,2
W3175560839,How is BERT surprised? Layerwise detection of linguistic anomalies,2021,4.0464677850436444e-05,2
W4281564455,Phrase-level Textual Adversarial Attack with Label Preservation,2022,4.046153192053711e-05,2
W4308083513,DFX: A Low-latency Multi-FPGA Appliance for Accelerating Transformer-based Text Generation,2022,4.0454979551696534e-05,2
W3035183289,On the Robustness of Language Encoders against Grammatical Errors,2020,4.045016163516445e-05,2
W4385572879,How Large Language Models are Transforming Machine-Paraphrase Plagiarism,2022,4.0422194591469715e-05,2
W3204669968,Single-dataset Experts for Multi-dataset Question Answering,2021,4.0412558099226154e-05,2
W3085329811,DDRQA: Dynamic Document Reranking for Open-domain Multi-hop Question Answering.,2020,4.0408102060624414e-05,2
W4365148488,AI chatbots not yet ready for clinical use,2023,4.038944120957962e-05,2
W4385570778,FEDLEGAL: The First Real-World Federated Learning Benchmark for Legal NLP,2023,4.038044635613503e-05,2
W4399035903,CAPTAIN at COLIEE 2024: Large Language Model for Legal Text Retrieval and Entailment,2024,4.037572828813247e-05,2
W4381856660,Tourism Information QA Datasets for Smart Tourism Chatbot,2023,4.037572828813247e-05,2
W4385984841,A Purely Entity-Based Semantic Search Approach for Document Retrieval,2023,4.037572828813247e-05,2
W3099864716,A survey on Recognizing Textual Entailment as an NLP Evaluation,2020,4.037231953294386e-05,2
W3132730420,Decoding EEG Brain Activity for Multi-Modal Natural Language Processing,2021,4.035502845318678e-05,2
W3134929386,Enhancing Transformer-based language models with commonsense representations for knowledge-driven machine comprehension,2021,4.034250127112067e-05,2
W4283790681,The King Is Naked: On the Notion of Robustness for Natural Language Processing,2022,4.034007636889782e-05,2
W3097861677,Quantifying the Contextualization of Word Representations with Semantic Class Probing,2020,4.0335496663675206e-05,2
W4380267320,Adversarial Attacks on Large Language Model-Based System and Mitigating Strategies: A Case Study on ChatGPT,2023,4.0333556354499256e-05,2
W4224308764,Efficient Neural Ranking using Forward Indexes,2022,4.033052788304168e-05,2
W3209527742,"Abstract, Rationale, Stance: A Joint Model for Scientific Claim Verification",2021,4.030753682601525e-05,2
W3171589458,Disentangling Syntax and Semantics in the Brain with Deep Networks,2021,4.030254933896434e-05,2
W4385570579,Entity Tracking in Language Models,2023,4.029845984101738e-05,2
W4224950688,Can Rationalization Improve Robustness?,2022,4.0276809460319023e-05,2
W4385572464,WebCPM: Interactive Web Search for Chinese Long-form Question Answering,2023,4.027609988234893e-05,2
W4394866292,AI for crop production – Where can large language models (LLMs) provide substantial value?,2024,4.027609988234893e-05,2
W4288679905,A novel locality-sensitive hashing relational graph matching network for semantic textual similarity measurement,2022,4.027609988234893e-05,2
W4385574240,Are Neural Topic Models Broken?,2022,4.027609988234893e-05,2
W2997868155,Attending to Entities for Better Text Understanding,2020,4.026723806836898e-05,2
W4221144388,Continual Sequence Generation with Adaptive Compositional Modules,2022,4.026294904104547e-05,2
W3093811011,A novel joint biomedical event extraction framework via two-level modeling of documents,2020,4.026286721765572e-05,2
W4285119699,Clickbait Spoiling via Question Answering and Passage Retrieval,2022,4.026242583015537e-05,2
W3171494313,ReadTwice: Reading Very Large Documents with Memories,2021,4.025997236040717e-05,2
W3098198541,Improving Sequence Modeling Ability of Recurrent Neural Networks via Sememes,2020,4.025267779504633e-05,2
W3173581459,Natural Language Inference in Context - Investigating Contextual Reasoning over Long Texts,2021,4.0248717064245816e-05,2
W3196783364,Enhanced Speaker-Aware Multi-Party Multi-Turn Dialogue Comprehension,2023,4.024593460609695e-05,2
W4307647693,Understanding models understanding language,2022,4.023840315624737e-05,2
W3215670835,Triggerless Backdoor Attack for NLP Tasks with Clean Labels,2022,4.02366102717666e-05,2
W4385571457,Generating Deep Questions with Commonsense Reasoning Ability from the Text by Disentangled Adversarial Inference,2023,4.0227800856525606e-05,2
W3210432446,E.T.,2021,4.0205399265844276e-05,2
W3174370755,Weakly Supervised Pre-Training for Multi-Hop Retriever,2021,4.019983665048537e-05,2
W3176175390,What if This Modified That? Syntactic Interventions with Counterfactual Embeddings,2021,4.019954497843406e-05,2
W4287887967,ConfliBERT: A Pre-trained Language Model for Political Conflict and Violence,2022,4.019943716691424e-05,2
W4229447062,Interactive Model Cards: A Human-Centered Approach to Model Documentation,2022,4.019943716691424e-05,2
W3173511996,Obtaining Better Static Word Embeddings Using Contextual Embedding Models,2021,4.0198259362133804e-05,2
W4280649755,AFS Graph: Multidimensional Axiomatic Fuzzy Set Knowledge Graph for Open-Domain Question Answering,2022,4.019124670586353e-05,2
W4285217123,Uncovering Values: Detecting Latent Moral Content from Natural Language with Explainable and Non-Trained Methods,2022,4.019124670586353e-05,2
W4389519012,KICGPT: Large Language Model with Knowledge in Context for Knowledge Graph Completion,2023,4.019124670586353e-05,2
W4385571730,PESCO: Prompt-enhanced Self Contrastive Learning for Zero-shot Text Classification,2023,4.019124670586353e-05,2
W3109356881,Second-Order NLP Adversarial Examples,2020,4.019086378836296e-05,2
W3212246833,T3-Vis: visual analytic for Training and fine-Tuning Transformers in NLP,2021,4.019059824419823e-05,2
W4226265091,Zero-Shot Commonsense Question Answering with Cloze Translation and Consistency Optimization,2022,4.0183668669934017e-05,2
W3094242471,Decoupled Graph Convolution Network for Inferring Substitutable and Complementary Items,2020,4.0180943590856206e-05,2
W3211024016,CLIMATEBERT: A Pretrained Language Model for Climate-Related Text,2022,4.0175601884090745e-05,2
W3163018411,Sentence Similarity Based on Contexts,2022,4.01754800683409e-05,2
W3159838520,Learning Passage Impacts for Inverted Indexes.,2021,4.016652473239611e-05,2
W3156830884,COIL: Revisit Exact Lexical Match in Information Retrieval with Contextualized Inverted List,2021,4.016652473239611e-05,2
W4385572570,Language Model Analysis for Ontology Subsumption Inference,2023,4.0160368446361225e-05,2
W3207576321,Knowledge Enhanced Fact Checking and Verification,2021,4.0142554566542925e-05,2
W3043747042,Adversarial active learning for the identification of medical concepts and annotation inconsistency,2020,4.0142177037300194e-05,2
W4389524473,Adapting Language Models to Compress Contexts,2023,4.013548046342825e-05,2
W4385571597,Multi-Level Knowledge Distillation for Out-of-Distribution Detection in Text,2023,4.013548046342825e-05,2
W4390064615,Zero-shot information extraction from radiological reports using ChatGPT,2023,4.012401744835183e-05,2
W4385571728,Zero-Shot Information Extraction for Clinical Meta-Analysis using Large Language Models,2023,4.012401744835183e-05,2
W3153289922,Attention Can Reflect Syntactic Structure (If You Let It),2021,4.0121722518395296e-05,2
W3120706522,Robustness Gym: Unifying the NLP Evaluation Landscape,2021,4.011929888537502e-05,2
W3155775551,Relational Learning with Gated and Attentive Neighbor Aggregator for Few-Shot Knowledge Graph Completion,2021,4.0116297512848837e-05,2
W4385728911,A divide and conquer framework for Knowledge Editing,2023,4.011267850704902e-05,2
W3174311454,SSMix: Saliency-Based Span Mixup for Text Classification,2021,4.011207122074547e-05,2
W3139632155,Evidence-based Verification for Real World Information Needs.,2021,4.010245545026488e-05,2
W3106388706,Interpreting Attention Models with Human Visual Attention in Machine Reading Comprehension,2020,4.009734698524562e-05,2
W4287855194,Entailment Tree Explanations via Iterative Retrieval-Generation Reasoner,2022,4.0097235771440687e-05,2
W3142869857,Answer Sentence Selection Using Local and Global Context in Transformer Models,2021,4.00798975062333e-05,2
W3176355530,Dynamic Semantic Graph Construction and Reasoning for Explainable Multi-hop Science Question Answering,2021,4.0077833992429996e-05,2
W4386566485,Selective-LAMA: Selective Prediction for Confidence-Aware Evaluation of Language Models,2023,4.006365975264233e-05,2
W3126258442,Can Small and Synthetic Benchmarks Drive Modeling Innovation? A Retrospective Study of Question Answering Modeling Approaches.,2021,4.0060353744332254e-05,2
W3162752841,TabularNet,2021,4.0053376068900255e-05,2
W4385282679,Tele-Knowledge Pre-training for Fault Analysis,2023,4.0027082392716186e-05,2
W3175277088,On Commonsense Cues in BERT for Solving Commonsense Tasks,2021,4.0024396668361605e-05,2
W3088572095,Generating Commonsense Explanation by Extracting Bridge Concepts from Reasoning Paths,2020,4.0008557850318836e-05,2
W4280550797,Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence,2022,4.000556430139773e-05,2
W4327709862,Importance-aware contrastive learning via semantically augmented instances for unsupervised sentence embeddings,2023,4.000234137506995e-05,2
W3174657338,EBERT: Efficient BERT Inference with Dynamic Structured Pruning,2021,3.999964339245572e-05,2
W3013629728,Shaping Visual Representations with Language for Few-Shot Classification,2020,3.9986650921666116e-05,2
W4402512774,Large language models predict human sensory judgments across six modalities,2024,3.998085573325619e-05,2
W4379206827,Multimodal learning on graphs for disease relation extraction,2023,3.997937204396824e-05,2
W3035357591,DC-BERT: Decoupling Question and Document for Efficient Contextual Encoding,2020,3.9978961090467386e-05,2
W4385372118,HOMOCHAR: A novel adversarial attack framework for exposing the vulnerability of text based neural sentiment classifiers,2023,3.997051378054678e-05,2
W4205788858,SPECTRA: Sparse Structured Text Rationalization,2021,3.9961352798953435e-05,2
W4404021177,"A survey on augmenting knowledge graphs (KGs) with large language models (LLMs): models, evaluation metrics, benchmarks, and challenges",2024,3.99572659857346e-05,2
W3171291687,ERNIE-Gram: Pre-Training with Explicitly N-Gram Masked Language Modeling for Natural Language Understanding,2021,3.9950091553999674e-05,2
W3112776819,Segatron: Segment-Aware Transformer for Language Modeling and Understanding,2021,3.9944313899603666e-05,2
W4224491635,Zero-shot Query Contextualization for Conversational Search,2022,3.992682663169884e-05,2
W3173195958,GhostBERT: Generate More Features with Cheap Operations for BERT,2021,3.991330631778649e-05,2
W4290927860,Joint Knowledge Graph Completion and Question Answering,2022,3.9912784723309824e-05,2
W3092539409,Review of Natural Language Processing in Radiology,2020,3.991045709577677e-05,2
W3128169560,"Revealing Opinions for COVID-19 Questions Using a Context Retriever, Opinion Aggregator, and Question-Answering Model: Model Development Study",2021,3.990785826636016e-05,2
W3164123300,Dynamic Semantic Graph Construction and Reasoning for Explainable Multi-hop Science Question Answering,2021,3.9896275329946314e-05,2
W4285178177,JGLUE: Japanese General Language Understanding Evaluation,2022,3.9884705095602415e-05,2
W4389524484,CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code,2023,3.98771892925878e-05,2
W3163458033,QAConv: Question Answering on Informative Conversations,2022,3.987642607028259e-05,2
W2978124139,MMM: Multi-stage Multi-task Learning for Multi-choice Reading Comprehension,2019,3.98675215340839e-05,2
W2951855948,Reading Turn by Turn: Hierarchical Attention Architecture for Spoken Dialogue Comprehension,2019,3.986659216523795e-05,2
W4392202585,Automatic quantitative stroke severity assessment based on Chinese clinical named entity recognition with domain-adaptive pre-trained large language model,2024,3.9863300645392934e-05,2
W3161694370,Intra-Document Cascading: Learning to Select Passages for Neural Document Ranking,2021,3.9860090169241066e-05,2
W3173591450,Knowing More About Questions Can Help: Improving Calibration in Question Answering,2021,3.985235741313932e-05,2
W3116466566,Hy-NLI: a Hybrid system for Natural Language Inference,2020,3.984029255366322e-05,2
W3003289092,Does an LSTM forget more than a CNN? An empirical study of catastrophic forgetting in NLP,2019,3.983403431069099e-05,2
W2997636389,Unsupervised Domain Adaptation on Reading Comprehension,2020,3.983347060739046e-05,2
W3138149011,A Survey on Knowledge Graph Embeddings for Link Prediction,2021,3.98284686784542e-05,2
W4385574263,Measuring the Mixing of Contextual Information in the Transformer,2022,3.982298812307221e-05,2
W3105192994,Social Commonsense Reasoning with Multi-Head Knowledge Attention,2020,3.9816788993599024e-05,2
W3023532425,Benchmarking Robustness of Machine Reading Comprehension Models,2020,3.980535327185978e-05,2
W3035179945,Overestimation of Syntactic Representation in Neural Language Models,2020,3.980298649632889e-05,2
W4206217845,Coreference Resolution for the Biomedical Domain: A Survey,2021,3.978418079164303e-05,2
W3129717984,An ecologically motivated image dataset for deep learning yields better models of human vision,2021,3.9782055402294887e-05,2
W3138794547,Visualizing Transformers for NLP: A Brief Survey,2020,3.9771904778983014e-05,2
W3159795318,KoreALBERT: Pretraining a Lite BERT Model for Korean Language Understanding,2021,3.9765547492752655e-05,2
W4396768561,CrisisTransformers: Pre-trained language models and sentence encoders for crisis-related social media texts,2024,3.9765547492752655e-05,2
W4385569782,Language model acceptability judgements are not always robust to context,2023,3.97649026370269e-05,2
W3157498557,Let's Play Mono-Poly: BERT Can Reveal Words' Polysemy Level and Partitionability into Senses.,2021,3.975227596530986e-05,2
W3098469895,Learning from Unlabelled Data for Clinical Semantic Textual Similarity,2020,3.975100218202274e-05,2
W3195369073,Data Augmentation for Low-Resource Named Entity Recognition Using Backtranslation,2021,3.9750811790040534e-05,2
W3198196226,A Review of Recent Work in Transfer Learning and Domain Adaptation for Natural Language Processing of Electronic Health Records,2021,3.974995956827156e-05,2
W3152936485,Does Putting a Linguist in the Loop Improve NLU Data Collection?,2021,3.974990317107835e-05,2
W3090254696,Dataset for Evaluation of Mathematical Reasoning Abilities in Russian,2020,3.974728651515818e-05,2
W4385573342,Zero-Shot Learners for Natural Language Understanding via a Unified Multiple Choice Perspective,2022,3.974299277200519e-05,2
W4385574202,SciFact-Open: Towards open-domain scientific claim verification,2022,3.9738788527290106e-05,2
W4283798680,Hybrid Autoregressive Inference for Scalable Multi-Hop Explanation Regeneration,2022,3.973583480759699e-05,2
W4287887196,Robust Conversational Agents against Imperceptible Toxicity Triggers,2022,3.9727782581319024e-05,2
W4327960869,"Short-Text Semantic Similarity (STSS): Techniques, Challenges and Future Perspectives",2023,3.9701129516588784e-05,2
W4285141429,"When classifying grammatical role, BERT doesn’t care about word order... except when it matters",2022,3.9701129516588784e-05,2
W3174413662,Improving BERT with Syntax-aware Local Attention,2021,3.96974726784457e-05,2
W3035413376,Explicit Memory Tracker with Coarse-to-Fine Reasoning for Conversational Machine Reading,2020,3.9687914910085675e-05,2
W3098757391,MOCHA: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics,2020,3.9682178240200096e-05,2
W3177281527,Improving Gradient-based Adversarial Training for Text Classification by Contrastive Learning and Auto-Encoder,2021,3.967600979288055e-05,2
W3100363073,DeSMOG: Detecting Stance in Media On Global Warming,2020,3.9672380998300775e-05,2
W4281262985,Are Prompt-based Models Clueless?,2022,3.967062791238744e-05,2
W3175204434,Comparing Test Sets with Item Response Theory,2021,3.967024304604228e-05,2
W4379986648,"Less Annotating, More Classifying: Addressing the Data Scarcity Issue of Supervised Machine Learning with Deep Transfer Learning and BERT-NLI",2023,3.966977813029307e-05,2
W3105350614,SRLGRN: Semantic Role Labeling Graph Reasoning Network,2020,3.965554628038438e-05,2
W3172883962,Extracting a Knowledge Base of Mechanisms from COVID-19 Papers,2021,3.964306142719204e-05,2
W4385734153,Expanding Scope: Adapting English Adversarial Attacks to Chinese,2023,3.963171206494721e-05,2
W4385734111,Can we trust the evaluation on ChatGPT?,2023,3.962430522770223e-05,2
W3205586399,"Seeking Patterns, Not just Memorizing Procedures: Contrastive Learning for Solving Math Word Problems",2022,3.9614050671339605e-05,2
W3197901717,Beyond Preserved Accuracy: Evaluating Loyalty and Robustness of BERT Compression,2021,3.960106777258357e-05,2
W3194157311,Mr. TyDi: A Multi-lingual Benchmark for Dense Retrieval,2021,3.959555810255997e-05,2
W3102373121,Text Segmentation by Cross Segment Attention,2020,3.959498114137153e-05,2
W2890194160,Listening Comprehension over Argumentative Content,2018,3.959365240618424e-05,2
W4287887942,"Heroes, Villains, and Victims, and GPT-3: Automated Extraction of Character Roles Without Training Data",2022,3.959356938761349e-05,2
W3177743683,Pretrained Transformers for Text Ranking: BERT and Beyond,2021,3.959302481208217e-05,2
W3176634681,Unleash GPT-2 Power for Event Detection,2021,3.959302481208217e-05,2
W4285214521,Data Augmentation for Biomedical Factoid Question Answering,2022,3.958948174504747e-05,2
W4287887934,Boosted Dense Retriever,2022,3.9571666004466926e-05,2
W3174264667,Long Text Generation by Modeling Sentence-Level and Discourse-Level Coherence,2021,3.956880189625637e-05,2
W4389506426,Visual clustering network-based intelligent power lines inspection system,2023,3.956058120495853e-05,2
W4399205996,Theme-Driven Keyphrase Extraction to Analyze Social Media Discourse,2024,3.956058120495853e-05,2
W4250944796,Proceedings of the 13th Linguistic Annotation Workshop,2019,3.956058120495853e-05,2
W4405114593,Simple and effective embedding model for single-cell biology built from ChatGPT,2024,3.956058120495853e-05,2
W4221147232,elBERto: Self-supervised commonsense learning for question answering,2022,3.956058120495853e-05,2
W4387221452,Question answering over knowledge graphs using BERT based relation mapping,2023,3.956058120495853e-05,2
W4382396063,Enhancing text representations separately with entity descriptions,2023,3.956058120495853e-05,2
W4391572936,VEM$$^2$$L: an easy but effective framework for fusing text and structure knowledge on sparse knowledge graph completion,2024,3.956058120495853e-05,2
W4296306361,Research and Implementation of Text Generation Based on Text Augmentation and Knowledge Understanding,2022,3.956058120495853e-05,2
W3194589868,Verification mechanism to obtain an elaborate answer span in machine reading comprehension,2021,3.956058120495853e-05,2
W4386566768,Can Pretrained Language Models (Yet) Reason Deductively?,2023,3.956058120495853e-05,2
W4318147441,Media Coverage and Public Perception of Distance Learning During the COVID-19 Pandemic: A Topic Modeling Approach Based on BERTopic,2022,3.956058120495853e-05,2
W4312679697,Systematized Nomenclature of Medicine–Clinical Terminology (SNOMED CT) Clinical Use Cases in the Context of Electronic Health Record Systems: Systematic Literature Review,2022,3.956058120495853e-05,2
W3036413095,STEAM: Self-Supervised Taxonomy Expansion with Mini-Paths,2020,3.956058120495853e-05,2
W4389518901,Search Augmented Instruction Learning,2023,3.956058120495853e-05,2
W4307807303,MADLINK: Attentive multihop and entity descriptions for link prediction in knowledge graphs,2022,3.956058120495853e-05,2
W4382318497,COSMOS: Catching Out-of-Context Image Misuse Using Self-Supervised Learning,2023,3.956058120495853e-05,2
W4380086855,Generating Better Items for Cognitive Assessments Using Large Language Models,2023,3.956058120495853e-05,2
W4368616878,Ontology-driven and weakly supervised rare disease identification from clinical notes,2023,3.956058120495853e-05,2
W4380875839,Description-Enhanced Label Embedding Contrastive Learning for Text Classification,2023,3.956058120495853e-05,2
W4389518752,Contrastive Learning of Sentence Embeddings from Scratch,2023,3.956058120495853e-05,2
W4389520133,Is ChatGPT a Financial Expert? Evaluating Language Models on Financial Natural Language Processing,2023,3.956058120495853e-05,2
W4385734176,Training Data Extraction From Pre-trained Language Models: A Survey,2023,3.956058120495853e-05,2
W4226136917,A Simple Hash-Based Early Exiting Approach For Language Understanding and Generation,2022,3.956058120495853e-05,2
W4385570325,ANALOGICAL - A Novel Benchmark for Long Text Analogy Evaluation in Large Language Models,2023,3.956058120495853e-05,2
W4319988693,Membership Inference Attacks With Token-Level Deduplication on Korean Language Models,2023,3.956058120495853e-05,2
W4386519508,Legal Holding Extraction from Italian Case Documents using Italian-LEGAL-BERT Text Summarization,2023,3.956058120495853e-05,2
W4309190714,Technology identification from patent texts: A novel named entity recognition method,2022,3.956058120495853e-05,2
W4367281801,A Multi-Level Supervised Contrastive Learning Framework for Low-Resource Natural Language Inference,2023,3.956058120495853e-05,2
W4200630739,Open Vocabulary Electroencephalography-to-Text Decoding and Zero-Shot Sentiment Classification,2022,3.956058120495853e-05,2
W4281742449,A COVID-19 Search Engine (CO-SE) with Transformer-based architecture,2022,3.956058120495853e-05,2
W4313276100,Coding energy knowledge in constructed responses with explainable<scp>NLP</scp>models,2022,3.956058120495853e-05,2
W4402404817,"Right to be forgotten in the Era of large language models: implications, challenges, and solutions",2024,3.956058120495853e-05,2
W4389955489,An information fusion based approach to context-based fine-tuning of GPT models,2023,3.956058120495853e-05,2
W4385571246,Multi-granularity Temporal Question Answering over Knowledge Graphs,2023,3.956058120495853e-05,2
W3174231090,Semi-Supervised Text Classification with Balanced Deep Representation Distributions,2021,3.956058120495853e-05,2
W4391122821,What is the Consumer Attitude toward Healthcare Services? A Transfer Learning Approach for Detecting Emotions from Consumer Feedback,2024,3.956058120495853e-05,2
W4408128017,Question-Answering (QA) Model for a Personalized Learning Assistant for Arabic Language,2025,3.956058120495853e-05,2
W4285300583,Modular and Parameter-Efficient Multimodal Fusion with Prompting,2022,3.956058120495853e-05,2
W4378627669,Dual-use implications of AI text generation,2023,3.956058120495853e-05,2
W4379469539,Using Social Media to Help Understand Patient-Reported Health Outcomes of Post–COVID-19 Condition: Natural Language Processing Approach,2023,3.956058120495853e-05,2
W4385570973,Towards Adaptive Prefix Tuning for Parameter-Efficient Language Model Fine-tuning,2023,3.956058120495853e-05,2
W3170790933,"Polyjuice: Generating Counterfactuals for Explaining, Evaluating, and Improving Models",2021,3.955976046694068e-05,2
W3117841010,KaLM at SemEval-2020 Task 4: Knowledge-aware Language Models for Comprehension and Generation,2020,3.955900671672317e-05,2
W3173841754,"Writing Polishment with Simile: Task, Dataset and A Neural Approach",2021,3.9552922791577896e-05,2
W3186135811,Towards Unifying Feature Attribution and Counterfactual Explanations: Different Means to the Same End,2021,3.952638416078158e-05,2
W3200368352,Connecting Attributions and QA Model Behavior on Realistic Counterfactuals,2021,3.952197680738445e-05,2
W4224950137,MCSE: Multimodal Contrastive Learning of Sentence Embeddings,2022,3.952163636554237e-05,2
W4285204619,SkipBERT: Efficient Inference with Shallow Layer Skipping,2022,3.951538651337579e-05,2
W4385569886,Explaining How Transformers Use Context to Build Predictions,2023,3.951492286402198e-05,2
W3152670075,Improving Biomedical Pretrained Language Models with Knowledge,2021,3.949179273802253e-05,2
W3093844431,RECONSIDER: Re-Ranking using Span-Focused Cross-Attention for Open Domain Question Answering,2020,3.9480361180891586e-05,2
W3040863728,Meta-Learning Requires Meta-Augmentation,2020,3.947601856318373e-05,2
W3094629756,Transfer fine-tuning of BERT with phrasal paraphrases,2020,3.947225498306429e-05,2
W3116605602,How Relevant Are Selectional Preferences for Transformer-based Language Models?,2020,3.9464357860680136e-05,2
W3209145439,Improving legal judgment prediction through reinforced criminal element extraction,2021,3.946381540051575e-05,2
W3017549762,MT-Clinical BERT: Scaling Clinical Information Extraction with Multitask Learning,2020,3.94464499946698e-05,2
W4401226718,Academic expert finding using BERT pre-trained language model,2024,3.9442978148511494e-05,2
W4387059191,2SCE-4SL: a 2-stage causality extraction framework for scientific literature,2023,3.9442978148511494e-05,2
W4389519222,Findings of the BabyLM Challenge: Sample-Efficient Pretraining on Developmentally Plausible Corpora,2023,3.9438865416498796e-05,2
W4387212306,Efficient Federated Learning for Modern NLP,2023,3.943760143228205e-05,2
W3175270222,RiddleSense: Reasoning about Riddle Questions Featuring Linguistic Creativity and Commonsense Knowledge,2021,3.9436225279237634e-05,2
W4385573990,ScienceWorld: Is your Agent Smarter than a 5th Grader?,2022,3.94336707481524e-05,2
W3099590177,doc2dial: A Goal-Oriented Document-Grounded Dialogue Dataset,2020,3.941493369512473e-05,2
W4226217623,Adaptable Closed-Domain Question Answering Using Contextualized CNN-Attention Models and Question Expansion,2022,3.940540228570694e-05,2
W3172318343,Noise Stability Regularization for Improving BERT Fine-tuning,2021,3.939750371589044e-05,2
W4387058885,Rationalization for explainable NLP: a survey,2023,3.939660817472323e-05,2
W3165015862,InferBERT: A Transformer-Based Causal Inference Framework for Enhancing Pharmacovigilance,2021,3.939660817472323e-05,2
W3021677691,Progressively Pretrained Dense Corpus Index for Open-Domain Question Answering,2020,3.939197114311737e-05,2
W4386566901,Understanding Transformer Memorization Recall Through Idioms,2023,3.9381801802871433e-05,2
W4285255684,E-KAR: A Benchmark for Rationalizing Natural Language Analogical Reasoning,2022,3.937233808291263e-05,2
W4403945759,Clinical information extraction for lower-resource languages and domains with few-shot learning using pretrained language models and prompting,2024,3.937138155468703e-05,2
W3169934659,Question Answering Infused Pre-training of General-Purpose Contextualized Representations,2022,3.935743810065103e-05,2
W3114544027,CosMo: Conditional Seq2Seq-based Mixture Model for Zero-Shot Commonsense Question Answering,2020,3.935401853343373e-05,2
W4385570688,Zemi: Learning Zero-Shot Semi-Parametric Language Models from Multiple Tasks,2023,3.935256610393105e-05,2
W4353069824,Knowledge-Guided Prompt Learning for Few-Shot Text Classification,2023,3.9349327128177186e-05,2
W3092462689,FIND: Human-in-the-Loop Debugging Deep Text Classifiers,2020,3.9346040820401664e-05,2
W3186095502,Can Transformer Language Models Predict Psychometric Properties?,2021,3.9342973136366686e-05,2
W3185070134,Demystifying Neural Language Models' Insensitivity to Word-Order,2021,3.93372958823255e-05,2
W3169445878,EntityBERT: Entity-centric Masking Strategy for Model Pretraining for the Clinical Domain,2021,3.933416886562423e-05,2
W3119200132,Deep bi-directional interaction network for sentence matching,2021,3.9332599684721716e-05,2
W3049039618,Finding Fast Transformers: One-Shot Neural Architecture Search by Component Composition,2020,3.933169734328699e-05,2
W3119636502,UnNatural Language Inference,2020,3.9331018436002237e-05,2
W2990953743,QKD: Quantization-aware Knowledge Distillation,2019,3.932989584678742e-05,2
W4206208161,Rethinking Why Intermediate-Task Fine-Tuning Works,2021,3.932553215036176e-05,2
W4389668679,Many but not all deep neural network audio models capture brain responses and exhibit correspondence between model stages and brain regions,2023,3.93054508887911e-05,2
W4389519070,Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study,2023,3.9296914474854556e-05,2
W4389523857,CoAnnotating: Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation,2023,3.929226170093713e-05,2
W4221148719,FaiRR: Faithful and Robust Deductive Reasoning over Natural Language,2022,3.928550753202107e-05,2
W3166550823,A Comparative Study of Using Pre-trained Language Models for Toxic Comment Classification,2021,3.9274440229968165e-05,2
W3099299360,When Do You Need Billions of Words of Pretraining Data?,2020,3.927384166713334e-05,2
W3117312003,Out of Order: How Important Is The Sequential Order of Words in a Sentence in Natural Language Understanding Tasks?,2020,3.9273491556105026e-05,2
W3197746952,Memory and Knowledge Augmented Language Models for Inferring Salience in Long-Form Stories,2021,3.9248638226255646e-05,2
W4385573010,An Efficient Memory-Augmented Transformer for Knowledge-Intensive NLP Tasks,2022,3.9248638226255646e-05,2
W3199004261,What Changes Can Large-scale Language Models Bring? Intensive Study on HyperCLOVA: Billions-scale Korean Generative Pretrained Transformers,2021,3.924842247195911e-05,2
W4385573222,"Generate, Discriminate and Contrast: A Semi-Supervised Sentence Representation Learning Framework",2022,3.9244989339473334e-05,2
W4386942346,Retrieving Supporting Evidence for Generative Question Answering,2023,3.923263514448793e-05,2
W2952603081,BAM! Born-Again Multi-Task Networks for Natural Language Understanding,2019,3.922938949333331e-05,2
W2986495993,Identifying Supporting Facts for Multi-hop Question Answering with Document Graph Networks,2019,3.9222310539111134e-05,2
W4392914055,Evaluation of Transfer Learning and Adaptability in Large Language Models with the GLUE Benchmark,2024,3.921938734967575e-05,2
W3175096440,LNN-EL: A Neuro-Symbolic Approach to Short-text Entity Linking,2021,3.920439755789241e-05,2
W4389518441,Qur’an QA 2023 Shared Task: Overview of Passage Retrieval and Reading Comprehension Tasks over the Holy Qur’an,2023,3.919709277405141e-05,2
W3193084543,How to Query Language Models?,2021,3.919191649172379e-05,2
W3199446690,Few-Shot Cross-Lingual Stance Detection with Sentiment-Based Pre-training,2022,3.9188474246982524e-05,2
W3175534941,Unsupervised Out-of-Domain Detection via Pre-trained Transformers,2021,3.917181497282693e-05,2
W4226084703,Establishing Strong Baselines For TripClick Health Retrieval,2022,3.9169281928260655e-05,2
W3154295049,"Back to Square One: Bias Detection, Training and Commonsense Disentanglement in the Winograd Schema",2021,3.9167652354335827e-05,2
W4385569626,Open-Domain Hierarchical Event Schema Induction by Incremental Prompting and Verification,2023,3.9154298026483806e-05,2
W3021774381,Exploring and Predicting Transferability across NLP Tasks,2020,3.915115897896299e-05,2
W3115149992,Graph-Based Knowledge Integration for Question Answering over Dialogue,2020,3.9139971452391775e-05,2
W3036737707,New Vietnamese Corpus for Machine Reading Comprehension of Health News Articles,2022,3.913506070488918e-05,2
W4225881819,UNIREX: A Unified Learning Framework for Language Model Rationale Extraction,2022,3.912798525212253e-05,2
W4225377340,Clues Before Answers: Generation-Enhanced Multiple-Choice QA,2022,3.912505639810616e-05,2
W4385573205,Missing Counter-Evidence Renders NLP Fact-Checking Unrealistic for Misinformation,2022,3.911883325422125e-05,2
W4385573264,Natural Logic-guided Autoregressive Multi-hop Document Retrieval for Fact Verification,2022,3.911220007652321e-05,2
W4224903411,Exploring the Universal Vulnerability of Prompt-based Learning Paradigm,2022,3.91074579504963e-05,2
W3131259441,Less is More: Pre-training a Strong Siamese Encoder Using a Weak Decoder.,2021,3.910590752325632e-05,2
W3167166933,ERNIE-NLI: Analyzing the Impact of Domain-Specific External Knowledge on Enhanced Representations for NLI,2021,3.910468042093231e-05,2
W4285199989,Probing BERT’s priors with serial reproduction chains,2022,3.910148834300372e-05,2
W4393094733,Advancing entity recognition in biomedicine via instruction tuning of large language models,2024,3.9101456720299686e-05,2
W3198691721,Dealing with Typos for BERT-based Passage Retrieval and Ranking,2021,3.9099121189503e-05,2
W4285301802,ProtoTEx: Explaining Model Decisions with Prototype Tensors,2022,3.9098475392477226e-05,2
W3106156541,Adversarial Augmentation Policy Search for Domain and Cross-Lingual Generalization in Reading Comprehension,2020,3.9088160297035346e-05,2
W4223956331,Label Semantic Aware Pre-training for Few-shot Text Classification,2022,3.9087300166791644e-05,2
W2889283903,Question Answering by Reasoning Across Documents with Graph Convolutional Networks,2018,3.908487065568153e-05,2
W3175866696,LIREx: Augmenting Language Inference with Relevant Explanations,2021,3.908225634388763e-05,2
W2983772459,SentiLR: Linguistic Knowledge Enhanced Language Representation for Sentiment Analysis.,2019,3.907489214445187e-05,2
W4383199647,Attribution and Obfuscation of Neural Text Authorship: A Data Mining Perspective,2023,3.906077036413435e-05,2
W3172706523,Learning Domain-Specialised Representations for Cross-Lingual Biomedical Entity Linking,2021,3.9038595823710616e-05,2
W3169965252,Grey-box Adversarial Attack And Defence For Sentiment Classification,2021,3.9022547364989326e-05,2
W3199885074,Benchmarking Commonsense Knowledge Base Population with an Effective Evaluation Dataset,2021,3.901445742328085e-05,2
W3206375861,Prix-LM: Pretraining for Multilingual Knowledge Base Construction,2022,3.900838819719175e-05,2
W4385573926,Mitigating Spurious Correlation in Natural Language Understanding with Counterfactual Inference,2022,3.900578523799699e-05,2
W3099414857,Know What You Don't Need: Single-Shot Meta-Pruning for Attention Heads,2020,3.900314167649518e-05,2
W4385573374,Pre-training Language Models with Deterministic Factual Knowledge,2022,3.89913998629126e-05,2
W4385574162,Beyond prompting: Making Pre-trained Language Models Better Zero-shot Learners by Clustering Representations,2022,3.8986053145887724e-05,2
W3116968030,Sentence Matching with Syntax- and Semantics-Aware BERT,2020,3.8979878971152015e-05,2
W4385564918,Elaboration-Generating Commonsense Question Answering at Scale,2023,3.896688447363671e-05,2
W3094607200,Learning Effective Representations for Person-Job Fit by Feature Fusion,2020,3.896056008166661e-05,2
W4385574115,Acceptability Judgements via Examining the Topology of Attention Maps,2022,3.896056008166661e-05,2
W3080951367,Top2Vec: Distributed Representations of Topics,2020,3.896056008166661e-05,2
W4385572504,What Are You Token About? Dense Retrieval as Distributions Over the Vocabulary,2023,3.895800999233625e-05,2
W3154463028,"Identify, Align, and Integrate: Matching Knowledge Graphs to Commonsense Reasoning Tasks",2021,3.895427459791173e-05,2
W4388478664,Named Entity Recognition in Electronic Health Records: A Methodological Review,2023,3.894568234157616e-05,2
W4386566482,"RedHOT: A Corpus of Annotated Medical Questions, Experiences, and Claims on Social Media",2023,3.894568234157616e-05,2
W3205305305,Contrastive Document Representation Learning with Graph Attention Networks,2021,3.893967667309915e-05,2
W4394579953,Language Models in the Loop: Incorporating Prompting into Weak Supervision,2024,3.8934502362241924e-05,2
W4385574127,SEAL: Interactive Tool for Systematic Error Analysis and Labeling,2022,3.8934502362241924e-05,2
W4229073922,Question answering system for chemistry—A semantic agent extension,2022,3.892832023314117e-05,2
W4287854458,Textual Entailment for Event Argument Extraction: Zero- and Few-Shot with Multi-Source Learning,2022,3.8918653820108794e-05,2
W3003943678,Transfer Learning for Risk Classification of Social Media Posts: Model Evaluation Study,2020,3.891412334683574e-05,2
W4385571329,Language acquisition: do children and language models follow similar learning stages?,2023,3.890766194823333e-05,2
W4385574088,Prompting ELECTRA: Few-Shot Learning with Discriminative Pre-Trained Models,2022,3.8889373970798054e-05,2
W3207964656,Interpreting Deep Learning Models in Natural Language Processing: A Review,2021,3.888581879362969e-05,2
W4225992558,Evidentiality-guided Generation for Knowledge-Intensive NLP Tasks,2022,3.8880850273390996e-05,2
W3214536449,KLMo: Knowledge Graph Enhanced Pretrained Language Model with Fine-Grained Relationships,2021,3.8878440833395764e-05,2
W4206727248,Knowledge-Guided Paraphrase Identification,2021,3.8876172035280754e-05,2
W4385572492,FLamE: Few-shot Learning from Natural Language Explanations,2023,3.8873522149497676e-05,2
W3197309300,Contrasting Human- and Machine-Generated Word-Level Adversarial Examples for Text Classification,2021,3.887242181847849e-05,2
W4287854513,Detecting Suicidality with a Contextual Graph Neural Network,2022,3.885783964680724e-05,2
W4367680667,Contrastive Learning Models for Sentence Representations,2023,3.885783964680724e-05,2
W3204793433,Question Answering Chatbot for Troubleshooting Queries based on Transfer Learning,2021,3.885783964680724e-05,2
W4393950419,Collaborative and privacy-enhancing workflows on a clinical data warehouse: an example developing natural language processing pipelines to detect medical conditions,2024,3.885783964680724e-05,2
W4221009220,StruBERT: Structure-aware BERT for Table Search and Matching,2022,3.885783964680724e-05,2
W3015158377,Knowledge graph fusion for smart systems: A Survey,2020,3.885783964680724e-05,2
W3196692796,Open Aspect Target Sentiment Classification with Natural Language Prompts,2021,3.885783964680724e-05,2
W4284685989,BERT-ER,2022,3.885783964680724e-05,2
W4399280731,Fine-tuning large language models for rare disease concept normalization,2024,3.885783964680724e-05,2
W4401343632,IQAGPT: computed tomography image quality assessment with vision-language and ChatGPT models,2024,3.885783964680724e-05,2
W4391680357,Revisiting Bag of Words Document Representations for Efficient Ranking with Transformers,2024,3.885783964680724e-05,2
W4380302165,Happenstance: Utilizing Semantic Search to Track Russian State Media Narratives about the Russo-Ukrainian War on Reddit,2023,3.885783964680724e-05,2
W4385565358,Zshot: An Open-source Framework for Zero-Shot Named Entity Recognition and Relation Extraction,2023,3.885783964680724e-05,2
W4383340139,LogiQA 2.0—An Improved Dataset for Logical Reasoning in Natural Language Understanding,2023,3.885783964680724e-05,2
W4389670098,SDFormer: A shallow-to-deep feature interaction for knowledge graph embedding,2023,3.885783964680724e-05,2
W4401103265,Improving biomedical entity linking for complex entity mentions with LLM-based text simplification,2024,3.885783964680724e-05,2
W4224330577,Where is your app frustrating users?,2022,3.885783964680724e-05,2
W3199807247,Numerical reasoning in machine reading comprehension tasks: are we there yet?,2021,3.885783964680724e-05,2
W4399512647,Text-enhanced knowledge graph representation learning with local structure,2024,3.885783964680724e-05,2
W4384642795,Adapting Learned Sparse Retrieval for Long Documents,2023,3.885783964680724e-05,2
W4385574224,BioSimCSE: BioMedical Sentence Embeddings using Contrastive learning,2022,3.885783964680724e-05,2
W4313895174,Text-to-Ontology Mapping via Natural Language Processing with Application to Search for Relevant Ontologies in Catalysis,2023,3.885783964680724e-05,2
W4383198091,Multi-class categorization of reasons behind mental disturbance in long texts,2023,3.885783964680724e-05,2
W3109431378,"Survey and open problems in privacy-preserving knowledge graph: merging, query, representation, completion, and applications",2024,3.885783964680724e-05,2
W4310231311,Fusing external knowledge resources for natural language understanding techniques: A survey,2022,3.885783964680724e-05,2
W4389519532,NLI4CT: Multi-Evidence Natural Language Inference for Clinical Trial Reports,2023,3.885783964680724e-05,2
W4397029679,A Language Model Based Framework for New Concept Placement in Ontologies,2024,3.885783964680724e-05,2
W3034902472,Premise Selection in Natural Language Mathematical Texts,2020,3.8857677024329276e-05,2
W3200247363,Explainable Natural Language Processing,2021,3.885559731442114e-05,2
W3174672330,Issues with Entailment-based Zero-shot Text Classification,2021,3.8852458049080585e-05,2
W4385572441,Text Augmented Open Knowledge Graph Completion via Pre-Trained Language Models,2023,3.884988639336571e-05,2
W4221141037,Are You Robert or RoBERTa? Deceiving Online Authorship Attribution Models Using Neural Text Generators,2022,3.884567234321582e-05,2
W3094476119,Discriminative Nearest Neighbor Few-Shot Intent Detection by Transferring Natural Language Inference,2020,3.884560957553112e-05,2
W4389520360,From Parse-Execute to Parse-Execute-Refine: Improving Semantic Parser for Complex Question Answering over Knowledge Base,2023,3.883912068012568e-05,2
W4316015028,Data-driven Cross-lingual Syntax: An Agreement Study with Massively Multilingual Models,2023,3.883717077744985e-05,2
W3178926106,Trusting RoBERTa over BERT: Insights from CheckListing the Natural Language Inference Task.,2021,3.882607419490819e-05,2
W4389518925,Automatic Evaluation of Attribution by Large Language Models,2023,3.881886791926881e-05,2
W4401123261,Can language models handle recursively nested grammatical structures? A case study on comparing models and humans,2024,3.881567485053605e-05,2
W4291653336,An Algorithm–Hardware Co-Optimized Framework for Accelerating N:M Sparse Transformers,2022,3.881524924934353e-05,2
W4385893847,GreenKGC: A Lightweight Knowledge Graph Completion Method,2023,3.880599160420701e-05,2
W3021649351,Scalable Multi-Hop Relational Reasoning for Knowledge-Aware Question Answering,2020,3.879687979048267e-05,2
W3198192082,Debiasing Methods in Natural Language Understanding Make Bias More Accessible,2021,3.879651252587704e-05,2
W4230636291,NewsBERT: Distilling Pre-trained Language Model for Intelligent News Application,2021,3.8787534022589556e-05,2
W2887557046,A Multi-Stage Memory Augmented Neural Network for Machine Reading Comprehension,2018,3.8786245965202745e-05,2
W3111364951,Semantics Altering Modifications for Evaluating Comprehension in Machine Reading,2021,3.8775732191218145e-05,2
W3101244625,Pre-training Text-to-Text Transformers for Concept-centric Common Sense,2020,3.877550611150304e-05,2
W3171530662,A Review on Medical Textual Question Answering Systems Based on Deep Learning Approaches,2021,3.87743167924648e-05,2
W4403257570,Learning to match patients to clinical trials using large language models,2024,3.8771191787875754e-05,2
W4385573354,Why Should Adversarial Perturbations be Imperceptible? Rethink the Research Paradigm in Adversarial NLP,2022,3.875648269130466e-05,2
W3100117936,Cold-Start and Interpretability: Turning Regular Expressions into Trainable Recurrent Neural Networks,2020,3.8747641263365495e-05,2
W4285601776,DictBERT: Dictionary Description Knowledge Enhanced Language Model Pre-training via Contrastive Learning,2022,3.874701028948232e-05,2
W3169508552,Detecting Multilingual COVID-19 Misinformation on Social Media via Contextualized Embeddings,2021,3.8745153118447835e-05,2
W3175349176,A Unified Pretraining Framework for Passage Ranking and Expansion,2021,3.8742132542455055e-05,2
W4200635688,ValueNet: A New Dataset for Human Value Driven Dialogue System,2022,3.872855254479301e-05,2
W4387966251,AttentionViz: A Global View of Transformer Attention,2023,3.8717291335176987e-05,2
W3100554158,Train No Evil: Selective Masking for Task-Guided Pre-Training,2020,3.871443880726183e-05,2
W3155638556,Subsentence Extraction from Text Using Coverage-Based Deep Learning Language Models,2021,3.871246626817731e-05,2
W3111165175,LIREx: Augmenting Language Inference with Relevant Explanation,2020,3.870888866446242e-05,2
W4312349643,Evidence Extraction to Validate Medical Claims in Fake News Detection,2022,3.870546245257191e-05,2
W3212354382,Patterns of Polysemy and Homonymy in Contextualised Language Models,2021,3.870177248701114e-05,2
W3116527904,Investigating Learning Dynamics of BERT Fine-Tuning,2020,3.869713561788992e-05,2
W3145602566,A Practical Survey on Faster and Lighter Transformers,2023,3.867936481611991e-05,2
W3035025198,A Frame-based Sentence Representation for Machine Reading Comprehension,2020,3.867683596998344e-05,2
W4385567113,XPrompt: Exploring the Extreme of Prompt Tuning,2022,3.8676830457586454e-05,2
W3174342531,Unified Dual-view Cognitive Model for Interpretable Claim Verification,2021,3.867359162185601e-05,2
W4389298188,Language inference-based learning for Low-Resource Chinese clinical named entity recognition using language model,2023,3.867323469024642e-05,2
W3088342637,Multilingual Probing of Deep Pre-Trained Contextual Encoders,2019,3.866896241245885e-05,2
W4287891006,Proceedings of the Eighth Workshop on Computational Linguistics and Clinical Psychology,2022,3.865944724546832e-05,2
W3037310559,Entity-Enriched Neural Models for Clinical Question Answering,2020,3.86551671605655e-05,2
W3201087948,RoR: Read-over-Read for Long Document Machine Reading Comprehension,2021,3.865323512941787e-05,2
W3205352824,Schrödinger's tree—On syntax and neural language models,2022,3.8648947811157636e-05,2
W4284682639,Document Expansion Baselines and Learned Sparse Lexical Representations for MS MARCO V1 and V2,2022,3.864567177993019e-05,2
W3213159541,Mitigating False-Negative Contexts in Multi-document Question Answering with Retrieval Marginalization,2021,3.864546298712678e-05,2
W3214576388,SeqAttack: On Adversarial Attacks for Named Entity Recognition,2021,3.863837464547318e-05,2
W4389524305,Selectively Answering Ambiguous Questions,2023,3.863529728950108e-05,2
W4367047001,Learning Denoised and Interpretable Session Representation for Conversational Search,2023,3.8631429550447366e-05,2
W3033182847,GMAT: Global Memory Augmentation for Transformers,2020,3.862165102950764e-05,2
W3035446106,"MATINF: A Jointly Labeled Large-Scale Dataset for Classification, Question Answering and Summarization",2020,3.8620605627875865e-05,2
W4389612030,KI-MAG: A knowledge-infused abstractive question answering system in medical domain,2023,3.862060268424201e-05,2
W4206674056,DUMA: Reading Comprehension With Transposition Thinking,2021,3.861930943587037e-05,2
W4210777822,Natural language based analysis of SQuAD: An analytical approach for BERT,2022,3.8617045570681424e-05,2
W4385567756,Semantic-Enhanced Differentiable Search Index Inspired by Learning Strategies,2023,3.861616664843528e-05,2
W3201734921,FewNLU: Benchmarking State-of-the-Art Methods for Few-Shot Natural Language Understanding,2022,3.8608652509417694e-05,2
W3199619722,BERT Has Uncommon Sense: Similarity Ranking for Word Sense BERTology,2021,3.8605948990201106e-05,2
W3022845607,Self-supervised Knowledge Triplet Learning for Zero-shot Question Answering,2020,3.860473165537135e-05,2
W3199212893,Relation-Guided Pre-Training for Open-Domain Question Answering,2021,3.8602001701743165e-05,2
W4382463788,A Survey on Model Compression and Acceleration for Pretrained Language Models,2023,3.859811755123056e-05,2
W4386566794,Quantifying Context Mixing in Transformers,2023,3.8596922612991045e-05,2
W3138967041,Open Domain Question Answering over Tables via Dense Retrieval,2021,3.8596177261271424e-05,2
W3200245893,Efficient Test Time Adapter Ensembling for Low-resource Language Varieties,2021,3.859431156250051e-05,2
W4389524313,We’re Afraid Language Models Aren’t Modeling Ambiguity,2023,3.8576743023546734e-05,2
W3034467872,Enhancing Answer Boundary Detection for Multilingual Machine Reading Comprehension,2020,3.857614854311684e-05,2
W3101777798,“I’d rather just go to bed”: Understanding Indirect Answers,2020,3.8571985640858895e-05,2
W3201531807,Tiered Reasoning for Intuitive Physics: Toward Verifiable Commonsense Language Understanding,2021,3.8565578235141986e-05,2
W4391578379,Claude 2.0 large language model: Tackling a real-world classification problem with a new iterative prompt engineering approach,2024,3.8551516403510533e-05,2
W4385572887,Prompt-Based Meta-Learning For Few-shot Text Classification,2022,3.8551516403510533e-05,2
W4249001067,"Closed and Open Vocabulary Approaches to Text Analysis: A Review, Quantitative Comparison, and Recommendations",2020,3.854101660131498e-05,2
W4229673855,Does Vision-and-Language Pretraining Improve Lexical Grounding?,2021,3.852758866677904e-05,2
W3099475240,Combining BERT with Static Word Embeddings for Categorizing Social Media,2020,3.8522337300992816e-05,2
W4386576718,Causal Reasoning of Entities and Events in Procedural Texts,2023,3.852038231434223e-05,2
W4385572404,Prompting Language Models for Linguistic Structure,2023,3.851921175634093e-05,2
W2972969579,Knowledge Enhanced Contextual Word Representations,2019,3.851629918903457e-05,2
W4385572831,What Makes Instruction Learning Hard? An Investigation and a New Challenge in a Synthetic Environment,2022,3.851601189097991e-05,2
W3094804884,LM4KG: Improving Common Sense Knowledge Graphs with Language Models,2020,3.851462856037555e-05,2
W3207523779,Sharpness-Aware Minimization Improves Language Model Generalization,2022,3.850625259411087e-05,2
W4205131770,Generate &amp; Rank: A Multi-task Framework for Math Word Problems,2021,3.850087824151426e-05,2
W4319793479,Training-free Lexical Backdoor Attacks on Language Models,2023,3.849651416331821e-05,2
W4285297805,RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining,2022,3.849651416331821e-05,2
W2905016804,Gaussian Transformer: A Lightweight Approach for Natural Language Inference,2019,3.848854534021621e-05,2
W4224903949,Imagination-Augmented Natural Language Understanding,2022,3.848380681403101e-05,2
W3173109101,On learning and representing social meaning in NLP: a sociolinguistic perspective,2021,3.848249432369878e-05,2
W4230908641,Exploiting Reasoning Chains for Multi-hop Science Question Answering,2021,3.8475760115905846e-05,2
W2970344931,Sieg at MEDIQA 2019: Multi-task Neural Ensemble for Biomedical Inference and Entailment,2019,3.847276770841823e-05,2
W4385572408,MolXPT: Wrapping Molecules with Text for Generative Pre-training,2023,3.846769143547048e-05,2
W4389520407,Explicit Planning Helps Language Models in Logical Reasoning,2023,3.8446427620105196e-05,2
W3202125623,DialogueCSE: Dialogue-based Contrastive Learning of Sentence Embeddings,2021,3.844218809090653e-05,2
W3174730533,AutoTinyBERT: Automatic Hyper-parameter Optimization for Efficient Pre-trained Language Models,2021,3.843446927244376e-05,2
W3210948652,EviDR: Evidence-Emphasized Discrete Reasoning for Reasoning Machine Reading Comprehension,2021,3.8422068832814684e-05,2
W3173247797,Improving the Faithfulness of Attention-based Explanations with Task-specific Information for Text Classification,2021,3.8421317960133486e-05,2
W2985283356,GF-Net: Improving machine reading comprehension with feature gates,2019,3.841686387174111e-05,2
W3103702973,Constrained Fact Verification for FEVER,2020,3.841276535292807e-05,2
W4385565472,DisentQA: Disentangling Parametric and Contextual Knowledge with Counterfactual Question Answering,2023,3.8404078346181465e-05,2
W3028930880,A Framework for Evaluation of Machine Reading Comprehension Gold Standards,2020,3.8398878295288204e-05,2
W4393852514,Detecting the Clinical Features of Difficult-to-Treat Depression Using Synthetic Data from Large Language Models,2024,3.839422349215278e-05,2
W3175462020,Developing a Vietnamese Tourism Question Answering System Using Knowledge Graph and Deep Learning,2021,3.8393668579358004e-05,2
W3175042000,Neural Retrieval for Question Answering with Cross-Attention Supervised Data Augmentation,2021,3.8393519949182366e-05,2
W4385573755,Prompt-based Connective Prediction Method for Fine-grained Implicit Discourse Relation Recognition,2022,3.8387543373275225e-05,2
W4385572001,GLUE-X: Evaluating Natural Language Understanding Models from an Out-of-Distribution Generalization Perspective,2023,3.838389213594931e-05,2
W4210277770,Comparison of Neural Language Modeling Pipelines for Outcome Prediction From Unstructured Medical Text Notes,2022,3.837869767534046e-05,2
W4225141790,HybriDialogue: An Information-Seeking Dialogue Dataset Grounded on Tabular and Textual Data,2022,3.83631564230773e-05,2
W3199064974,CSS-LM: A Contrastive Framework for Semi-Supervised Fine-Tuning of Pre-Trained Language Models,2021,3.836263180193505e-05,2
W4388405827,The Impact of Large Language Modeling on Natural Language Processing in Legal Texts: A Comprehensive Survey,2023,3.835497630425141e-05,2
W4385571278,Legal_try at SemEval-2023 Task 6: Voting Heterogeneous Models for Entities identification in Legal Documents,2023,3.83489277478952e-05,2
W4385570378,LRL_NC at SemEval-2023 Task 6: Sequential Sentence Classification for Legal Documents Using Topic Modeling Features,2023,3.83489277478952e-05,2
W4385570558,TeamShakespeare at SemEval-2023 Task 6: Understand Legal Documents with Contextualized Large Language Models,2023,3.83489277478952e-05,2
W4385571523,PoliToHFI at SemEval-2023 Task 6: Leveraging Entity-Aware and Hierarchical Transformers For Legal Entity Recognition and Court Judgment Prediction,2023,3.83489277478952e-05,2
W4385571097,YNU-HPCC at SemEval-2023 Task 6: LEGAL-BERT Based Hierarchical BiLSTM with CRF for Rhetorical Roles Prediction,2023,3.83489277478952e-05,2
W4385571582,VTCC-NLP at SemEval-2023 Task 6:Long-Text Representation Based on Graph Neural Network for Rhetorical Roles Prediction,2023,3.83489277478952e-05,2
W4385571733,ResearchTeam_HCN at SemEval-2023 Task 6: A knowledge enhanced transformers based legal NLP system,2023,3.83489277478952e-05,2
W4385570734,uOttawa at SemEval-2023 Task 6: Deep Learning for Legal Text Understanding,2023,3.83489277478952e-05,2
W4385571561,LTRC at SemEval-2023 Task 6: Experiments with Ensemble Embeddings,2023,3.83489277478952e-05,2
W4385572153,Viettel-AI at SemEval-2023 Task 6: Legal Document Understanding with Longformer for Court Judgment Prediction with Explanation,2023,3.83489277478952e-05,2
W4385571248,NLP-Titan at SemEval-2023 Task 6: Identification of Rhetorical Roles Using Sequential Sentence Classification,2023,3.83489277478952e-05,2
W4385572563,Jus Mundi at SemEval-2023 Task 6: Using a Frustratingly Easy Domain Adaption for a Legal Named Entity Recognition System,2023,3.83489277478952e-05,2
W4385570437,IRIT_IRIS_C at SemEval-2023 Task 6: A Multi-level Encoder-based Architecture for Judgement Prediction of Legal Cases and their Explanation,2023,3.83489277478952e-05,2
W4385570476,TeamUnibo at SemEval-2023 Task 6: A transformer based approach to Rhetorical Roles prediction and NER in Legal Texts,2023,3.83489277478952e-05,2
W4385572179,nclu_team at SemEval-2023 Task 6: Attention-based Approaches for Large Court Judgement Prediction with Explanation,2023,3.83489277478952e-05,2
W4385570484,Nonet at SemEval-2023 Task 6: Methodologies for Legal Evaluation,2023,3.83489277478952e-05,2
W4385570123,NITK_LEGAL at SemEval-2023 Task 6: A Hierarchical based system for identification of Rhetorical Roles in legal judgements,2023,3.83489277478952e-05,2
W4385571522,CSECU-DSG at SemEval-2023 Task 6: Segmenting Legal Documents into Rhetorical Roles via Fine-tuned Transformer Architecture,2023,3.83489277478952e-05,2
W4385569955,UO-LouTAL at SemEval-2023 Task 6: Lightweight Systems for Legal Processing,2023,3.83489277478952e-05,2
W3100083965,A Qualitative Evaluation of Language Models on Automatic Question-Answering for COVID-19,2020,3.834802621005532e-05,2
W3155396033,"MultiModalQA: Complex Question Answering over Text, Tables and Images",2021,3.8341904275887254e-05,2
W4402423338,Extractive Question Answering with Contrastive Puzzles and Reweighted Clues,2024,3.8330783478193774e-05,2
W4285219308,SciDeBERTa: Learning DeBERTa for Science Technology Documents and Fine-Tuning Information Extraction Tasks,2022,3.8330783478193774e-05,2
W4390489251,Investigating ChatGPT’s Potential to Assist in Requirements Elicitation Processes,2023,3.8330783478193774e-05,2
W4387521241,BlendCSE: Blend contrastive learnings for sentence embeddings with rich semantics and transferability,2023,3.8330783478193774e-05,2
W4400524696,GraphGPT: Graph Instruction Tuning for Large Language Models,2024,3.8330783478193774e-05,2
W4379280737,NASTyLinker: NIL-Aware Scalable Transformer-Based Entity Linker,2023,3.8330783478193774e-05,2
W4313596849,"Beyond Rating Scales: With Targeted Evaluation, Language Models are Poised for Psychological Assessment",2023,3.8330783478193774e-05,2
W4401626333,Document-Level Event Extraction with Definition-Driven ICL,2024,3.8330783478193774e-05,2
W4327644597,Domain-Aligned Data Augmentation for Low-Resource and Imbalanced Text Classification,2023,3.8330783478193774e-05,2
W4213132190,Proceedings of the Third Workshop on Narrative Understanding,2021,3.8330783478193774e-05,2
W4390872859,Knowledge-Aware Prompt Tuning for Generalizable Vision-Language Models,2023,3.8330783478193774e-05,2
W4320018401,TaughtNet: Learning Multi-Task Biomedical Named Entity Recognition From Single-Task Teachers,2023,3.8330783478193774e-05,2
W3017490534,Automatic Annotation Service APPI: Named Entity Linking in Legal Domain,2020,3.8330783478193774e-05,2
W4384642334,Relation-Aware Multi-Positive Contrastive Knowledge Graph Completion with Embedding Dimension Scaling,2023,3.8330783478193774e-05,2
W4385718101,Can ChatGPT Understand Causal Language in Science Claims?,2023,3.8330783478193774e-05,2
W4391255995,Embedding-Based Entity Alignment of Cross-Lingual Temporal Knowledge Graphs,2024,3.8330783478193774e-05,2
W4221151670,Incorporating Commonsense Knowledge into Story Ending Generation via Heterogeneous Graph Networks,2022,3.8330783478193774e-05,2
W4389520346,Text Embeddings Reveal (Almost) As Much As Text,2023,3.8330783478193774e-05,2
W4389461439,Deep LSTM and LSTM-Attention Q-learning based reinforcement learning in oil and gas sector prediction,2023,3.8330783478193774e-05,2
W4393322202,Similarity Matching for Patent Documents Using Ensemble BERT-Related Model and Novel Text Processing Method,2024,3.8330783478193774e-05,2
W4384824496,A Short-Text Similarity Model Combining Semantic and Syntactic Information,2023,3.8330783478193774e-05,2
W3156316299,Development and evaluation of novel ophthalmology domain-specific neural word embeddings to predict visual prognosis,2021,3.8330783478193774e-05,2
W4320507246,Evaluation of Incremental Entity Extraction with Background Knowledge and Entity Linking,2022,3.8330783478193774e-05,2
W4396929025,An in-depth evaluation of federated learning on biomedical natural language processing for information extraction,2024,3.8330783478193774e-05,2
W4390512419,SimRE: Simple contrastive learning with soft logical rule for knowledge graph embedding,2024,3.8330783478193774e-05,2
W3036116903,Learning Lexical Subspaces in a Distributional Vector Space,2020,3.8330783478193774e-05,2
W4402353529,QLSC: A Query Latent Semantic Calibrator for Robust Extractive Question Answering,2024,3.8330783478193774e-05,2
W4400721704,Do Generative Large Language Models Need Billions of Parameters?,2024,3.8330783478193774e-05,2
W4403221502,"Survey on Knowledge Distillation for Large Language Models: Methods, Evaluation, and Application",2024,3.8330783478193774e-05,2
W4287854777,Meta Learning for Natural Language Processing: A Survey,2022,3.8330783478193774e-05,2
W4399422471,Lv-Adapter: Adapting Vision Transformers for Visual Classification with Linear-layers and Vectors,2024,3.8330783478193774e-05,2
W4392337553,A comparative analysis of knowledge injection strategies for large language models in the scholarly domain,2024,3.8330783478193774e-05,2
W4284689799,A Non-Factoid Question-Answering Taxonomy,2022,3.8330783478193774e-05,2
W4385573153,"MAVEN-ERE: A Unified Large-scale Dataset for Event Coreference, Temporal, Causal, and Subevent Relation Extraction",2022,3.8330783478193774e-05,2
W4400517951,TurkishBERTweet: Fast and reliable large language model for social media analysis,2024,3.8330783478193774e-05,2
W4385570718,The Magic of IF: Investigating Causal Reasoning Abilities in Large Language Models of Code,2023,3.8330783478193774e-05,2
W3191230274,APER: AdaPtive Evidence-driven Reasoning Network for machine reading comprehension with unanswerable questions,2021,3.8330783478193774e-05,2
W4385766704,TopoBERT: a plug and play toponym recognition module harnessing fine-tuned BERT,2023,3.8330783478193774e-05,2
W4386324432,Synthesize high-dimensional longitudinal electronic health records via hierarchical autoregressive language model,2023,3.8330783478193774e-05,2
W4384211326,Chinese Idiom Paraphrasing,2023,3.8330783478193774e-05,2
W4389523828,Jina Embeddings: A Novel Set of High-Performance Sentence Embedding Models,2023,3.8330783478193774e-05,2
W4393950444,The Explainability of Transformers: Current Status and Directions,2024,3.8330783478193774e-05,2
W4391613817,Exploring the performance and explainability of fine-tuned BERT models for neuroradiology protocol assignment,2024,3.8330783478193774e-05,2
W4312767993,Benchmarking library recognition in tweets,2022,3.8330783478193774e-05,2
W4362456756,"Extracting social determinants of health events with transformer-based multitask, multilabel named entity recognition",2023,3.8330783478193774e-05,2
W4285158689,Knowledge Enhanced Reflection Generation for Counseling Dialogues,2022,3.8330783478193774e-05,2
W4392876888,Difficulty-controllable question generation over knowledge graphs: A counterfactual reasoning approach,2024,3.8330783478193774e-05,2
W4405867157,xMEN: a modular toolkit for cross-lingual medical entity normalization,2024,3.8330783478193774e-05,2
W3008811720,Towards End-to-End Multilingual Question Answering,2020,3.831824845061739e-05,2
W4210794564,Adversarial Machine Learning in Text Processing: A Literature Survey,2022,3.83096898451162e-05,2
W4225808286,"Adapting GPT, GPT-2 and BERT Language Models for Speech Recognition",2021,3.8304987109635585e-05,2
W4402794779,Low-Parameter Federated Learning with Large Language Models,2024,3.8304987109635585e-05,2
W4393160809,EcomGPT: Instruction-Tuning Large Language Models with Chain-of-Task Tasks for E-commerce,2024,3.8304987109635585e-05,2
W4221141197,A Simple but Effective Pluggable Entity Lookup Table for Pre-trained Language Models,2022,3.82970789759405e-05,2
W3180374035,Wordcraft: a Human-AI Collaborative Editor for Story Writing,2021,3.8295725388495525e-05,2
W3135665608,CEQE: Contextualized Embeddings for Query Expansion,2021,3.828806720547602e-05,2
W3101190870,Examining the rhetorical capacities of neural language models,2020,3.828375516736371e-05,2
W3126259453,Aligning AI With Shared Human Values,2020,3.8272600644134726e-05,2
W4385571554,Enhancing text comprehension for Question Answering with Contrastive Learning,2023,3.827072679342377e-05,2
W4285112556,An Empirical Study on Explanations in Out-of-Domain Settings,2022,3.826867776449649e-05,2
W3173197792,DoT: An efficient Double Transformer for NLP tasks with tables,2021,3.826435684626535e-05,2
W4318147473,Continuous Prompt Tuning Based Textual Entailment Model for E-commerce Entity Typing,2022,3.826429993817077e-05,2
W4393213239,ChatGPT Incorrectness Detection in Software Reviews,2024,3.826429993817077e-05,2
W4313563818,Natural Test Generation for Precise Testing of Question Answering Software,2022,3.826429993817077e-05,2
W3089314434,Unsupervised Pre-training for Biomedical Question Answering,2020,3.8261140064181585e-05,2
W2995755016,Embedding Comparator: Visualizing Differences in Global Structure and Local Neighborhoods via Small Multiples,2022,3.825914393675462e-05,2
W3172481377,Zero-shot Node Classification with Decomposed Graph Prototype Network,2021,3.82512426710468e-05,2
W3007257988,DC-BERT: Decoupling Question and Document for Efficient Contextual Encoding,2020,3.8250399493366835e-05,2
W4389520508,Parameter-Efficient Prompt Tuning Makes Generalized and Calibrated Neural Text Retrievers,2023,3.8231851694443955e-05,2
W4385567137,ClassActionPrediction: A Challenging Benchmark for Legal Judgment Prediction of Class Action Cases in the US,2022,3.823115358392022e-05,2
W4364860029,A Survey on BERT and Its Applications,2023,3.821898368485153e-05,2
W4361017888,Semantic Representations during Language Comprehension Are Affected by Context,2023,3.8209853396305235e-05,2
W3212781905,Diagnosing the First-Order Logical Reasoning Ability Through LogicNLI,2021,3.820728152348629e-05,2
W3209717315,Dense Hierarchical Retrieval for Open-domain Question Answering,2021,3.8206697168887785e-05,2
W2998811572,CLUENER2020: Fine-grained Named Entity Recognition Dataset and Benchmark for Chinese,2020,3.818465726189478e-05,2
W4226365369,Relational Memory-Augmented Language Models,2022,3.817312522043046e-05,2
W3032960712,An Overview of Neural Network Compression,2020,3.816978215439105e-05,2
W3171364227,Fully Hyperbolic Neural Networks,2022,3.816952688132319e-05,2
W4386576705,COMPS: Conceptual Minimal Pair Sentences for testing Robust Property Knowledge and its Inheritance in Pre-trained Language Models,2023,3.816601545839309e-05,2
W3172224317,Probing Contextual Language Models for Common Ground with Visual Representations,2021,3.8159014457052504e-05,2
W3167354871,On Attention Redundancy: A Comprehensive Study,2021,3.8154615849851815e-05,2
W3174782183,Investigating Transfer Learning in Multilingual Pre-trained Language Models through Chinese Natural Language Inference,2021,3.815374278520648e-05,2
W2985964562,Bend but Don’t Break? Multi-Challenge Stress Test for QA Models,2019,3.814316899820058e-05,2
W3118568258,I-BERT: Integer-only BERT Quantization,2021,3.8141473848994974e-05,2
W4396913708,PromptLink: Leveraging Large Language Models for Cross-Source Biomedical Concept Linking,2024,3.813615914310905e-05,2
W4385573090,Whose Language Counts as High Quality? Measuring Language Ideologies in Text Data Selection,2022,3.813569043661031e-05,2
W4385572334,A Survey for Efficient Open Domain Question Answering,2023,3.813100780055232e-05,2
W2917001081,R-Trans: RNN Transformer Network for Chinese Machine Reading Comprehension,2019,3.8129569040846494e-05,2
W3091783050,"Optimizing Transformers with Approximate Computing for Faster, Smaller and more Accurate NLP Models",2021,3.812471619617865e-05,2
W4392637089,LambdaKG: A Library for Pre-trained Language Model-Based Knowledge Graph Embeddings,2023,3.812425173321359e-05,2
W4386566654,A Survey of Multi-task Learning in Natural Language Processing: Regarding Task Relatedness and Training Methods,2023,3.8113749737489234e-05,2
W4315481736,Pseudo Relevance Feedback with Deep Language Models and Dense Retrievers: Successes and Pitfalls,2023,3.810061058103582e-05,2
W3023293091,Temporal Common Sense Acquisition with Minimal Supervision,2020,3.809631876224599e-05,2
W3113521481,Read and Reason with MuSeRC and RuCoS: Datasets for Machine Reading Comprehension for Russian,2020,3.8090667224438456e-05,2
W4385573952,Improving HowNet-Based Chinese Word Sense Disambiguation with Translations,2022,3.8085498380637634e-05,2
W3184599456,A Differentiable Language Model Adversarial Attack on Text Classifiers,2022,3.808482393284083e-05,2
W3205235328,Pre-trained Language Models in Biomedical Domain: A Systematic Survey,2021,3.8070679673058184e-05,2
W3198480521,Table-based Fact Verification With Salience-aware Learning,2021,3.8068932176210465e-05,2
W4385573021,Retrieval as Attention: End-to-end Learning of Retrieval and Reading within a Single Transformer,2022,3.8064227822120476e-05,2
W3202390784,MultiDoc2Dial: Modeling Dialogues Grounded in Multiple Documents,2021,3.806345220751038e-05,2
W3169602049,Static Embeddings as Efficient Knowledge Bases?,2021,3.806012751537417e-05,2
W3211511509,"Back to Square One: Artifact Detection, Training and Commonsense Disentanglement in the Winograd Schema",2021,3.805554708555721e-05,2
W3216626696,A Survey on Event Extraction for Natural Language Understanding: Riding the Biomedical Literature Wave,2021,3.80454029347689e-05,2
W3163314873,Evaluating Pretrained Transformer-based Models for COVID-19 Fake News Detection,2021,3.8042546864629263e-05,2
W4386566833,A Discerning Several Thousand Judgments: GPT-3 Rates the Article + Adjective + Numeral + Noun Construction,2023,3.803143414735755e-05,2
W4385574039,"The better your Syntax, the better your Semantics? Probing Pretrained Language Models for the English Comparative Correlative",2022,3.803143414735755e-05,2
W3172364764,Explainable Multi-hop Verbal Reasoning Through Internal Monologue,2021,3.802928426352133e-05,2
W3041897721,Latent Retrieval for Large-Scale Fact-Checking and Question Answering with NLI training,2020,3.802695109864013e-05,2
W4205424278,Not All Models Localize Linguistic Knowledge in the Same Place: A Layer-wise Probing on BERToids’ Representations,2021,3.802250815458113e-05,2
W4287889344,SemEval-2022 Task 4: Patronizing and Condescending Language Detection,2022,3.8019568612860155e-05,2
W4386576886,Analyzing the Effectiveness of the Underlying Reasoning Tasks in Multi-hop Question Answering,2023,3.8014549777025695e-05,2
W4385574183,Rich Knowledge Sources Bring Complex Knowledge Conflicts: Recalibrating Models to Reflect Conflicting Evidence,2022,3.8012903414365006e-05,2
W4221139076,Adversarial Training for Improving Model Robustness? Look at Both Prediction and Interpretation,2022,3.797541675941274e-05,2
W4292963003,UnCommonSense: Informative Negative Knowledge about Everyday Concepts,2022,3.7964871805262345e-05,2
W4382202605,Instance Smoothed Contrastive Learning for Unsupervised Sentence Embedding,2023,3.7957612906010046e-05,2
W4321485718,Making Pre-trained Language Models End-to-end Few-shot Learners with Contrastive Prompt Tuning,2023,3.794257400979256e-05,2
W3082392125,Reading Comprehension in Czech via Machine Translation and Cross-Lingual Transfer,2020,3.7935276405212434e-05,2
W3049275545,Narrative Interpolation for Generating and Understanding Stories,2020,3.7934475002784074e-05,2
W4283792669,Supervising Model Attention with Human Explanations for Robust Natural Language Inference,2022,3.792517519418429e-05,2
W4392251150,Large language models as a substitute for human experts in annotating political text,2024,3.792085090260553e-05,2
W4392904187,Retrieval-Generation Synergy Augmented Large Language Models,2024,3.792085090260553e-05,2
W4404634776,Soft prompt tuning for augmenting dense retrieval with large language models,2024,3.792085090260553e-05,2
W4311457721,Demystifying BERT: System Design Implications,2022,3.792085090260553e-05,2
W2967269971,QuGAN: Quasi Generative Adversarial Network for Tibetan Question Answering Corpus Generation,2019,3.792085090260553e-05,2
W4200237457,Novelty Detection: A Perspective from Natural Language Processing,2021,3.792085090260553e-05,2
W4389518753,Do Language Models Have a Common Sense regarding Time? Revisiting Temporal Commonsense Reasoning in the Era of Large Language Models,2023,3.792085090260553e-05,2
W3205835614,Småprat: DialoGPT for Natural Language Generation of Swedish Dialogue by Transfer Learning,2022,3.792085090260553e-05,2
W4324108774,An Overview on Language Models: Recent Developments and Outlook,2023,3.792085090260553e-05,2
W4385573404,Holistic Sentence Embeddings for Better Out-of-Distribution Detection,2022,3.792085090260553e-05,2
W4385570587,Client-Customized Adaptation for Parameter-Efficient Federated Learning,2023,3.792085090260553e-05,2
W3188759137,Improving Social Meaning Detection with Pragmatic Masking and Surrogate Fine-Tuning,2022,3.792085090260553e-05,2
W3108757211,Transformer-Based Models for Automatic Identification of Argument Relations: A Cross-Domain Evaluation,2021,3.792085090260553e-05,2
W4388094126,Intelligent detection on construction project contract missing clauses based on deep learning and NLP,2023,3.792085090260553e-05,2
W4392881223,The application of multimodal large language models in medicine,2024,3.792085090260553e-05,2
W4403791697,Enhancing Question Answering for Enterprise Knowledge Bases using Large Language Models,2024,3.792085090260553e-05,2
W4380686953,DyGen: Learning from Noisy Labels via Dynamics-Enhanced Generative Modeling,2023,3.792085090260553e-05,2
W4385572063,FedPETuning: When Federated Learning Meets the Parameter-Efficient Tuning Methods of Pre-trained Language Models,2023,3.792085090260553e-05,2
W4409100492,A Modified Word Saliency-Based Adversarial Attack on Text Classification Models,2025,3.792085090260553e-05,2
W4382630911,KR4SL: knowledge graph reasoning for explainable prediction of synthetic lethality,2023,3.792085090260553e-05,2
W4389523721,TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks,2023,3.792085090260553e-05,2
W4387816220,Chinese legal judgment prediction via knowledgeable prompt learning,2023,3.792085090260553e-05,2
W4323656451,The Emotional Impact of COVID-19 News Reporting: A Longitudinal Study Using Natural Language Processing,2023,3.792085090260553e-05,2
W4403791927,Making Large Language Models Perform Better in Knowledge Graph Completion,2024,3.792085090260553e-05,2
W4404349757,Testing AI on language comprehension tasks reveals insensitivity to underlying meaning,2024,3.792085090260553e-05,2
W4225882738,Diaformer: Automatic Diagnosis via Symptoms Sequence Generation,2022,3.792085090260553e-05,2
W3172066753,"Geographic Question Answering: Challenges, Uniqueness, Classification, and Future Directions",2021,3.792085090260553e-05,2
W3156831596,NeurJudge: A Circumstance-aware Neural Framework for Legal Judgment Prediction,2021,3.792085090260553e-05,2
W4392612897,Empowering digital twins with large language models for global temporal feature learning,2024,3.792085090260553e-05,2
W4388946674,BIR: Biomedical Information Retrieval System for Cancer Treatment in Electronic Health Record Using Transformers,2023,3.792085090260553e-05,2
W3203241482,"Artificial intelligence in the construction industry: A review of present status, opportunities and future challenges",2021,3.792085090260553e-05,2
W4401943272,When Search Engine Services meet Large Language Models: Visions and Challenges,2024,3.792085090260553e-05,2
W4393090023,"The CLEF-2024 CheckThat! Lab: Check-Worthiness, Subjectivity, Persuasion, Roles, Authorities, and Adversarial Robustness",2024,3.792085090260553e-05,2
W4385718077,Limits for learning with language models,2023,3.792085090260553e-05,2
W4372311765,GS-InGAT: An interaction graph attention network with global semantic for knowledge graph completion,2023,3.792085090260553e-05,2
W4386566979,MAUPQA: Massive Automatically-created Polish Question Answering Dataset,2023,3.792085090260553e-05,2
W4312140420,Complex Knowledge Base Question Answering for Intelligent Bridge Management Based on Multi-Task Learning and Cross-Task Constraints,2022,3.792085090260553e-05,2
W4399205875,SLaNT: A Semi-supervised Label Noise-Tolerant Framework for Text Sentiment Analysis,2024,3.792085090260553e-05,2
W4390750480,Fraud's Bargain Attack: Generating Adversarial Text Samples via Word Manipulation Process,2024,3.792085090260553e-05,2
W4393147146,Can Large Language Models Understand Real-World Complex Instructions?,2024,3.792085090260553e-05,2
W3206730738,StaResGRU-CNN with CMedLMs: A stacked residual GRU-CNN with pre-trained biomedical language models for predictive intelligence,2021,3.791958251256894e-05,2
W3179633195,Contextualized query expansion via unsupervised chunk selection for text retrieval,2021,3.788803561085113e-05,2
W3144312515,"Exploring Classic and Neural Lexical Translation Models for Information Retrieval: Interpretability, Effectiveness, and Efficiency Benefits",2021,3.788011841520341e-05,2
W4327498760,"The CLEF-2023 CheckThat! Lab: Checkworthiness, Subjectivity, Political Bias, Factuality, and Authority",2023,3.787280555478952e-05,2
W4286530321,Aspect-Based API Review Classification: How Far Can Pre-Trained Transformer Model Go?,2022,3.787261589406314e-05,2
W3154498239,Text-to-Text Multi-view Learning for Passage Re-ranking,2021,3.787178806745864e-05,2
W4282829375,"A Concise Survey on Datasets, Tools and Methods for Biomedical Text",2022,3.7868231000413985e-05,2
W4402923149,Towards building multilingual language model for medicine,2024,3.7868231000413985e-05,2
W4385572766,Sentence Representation Learning with Generative Objective rather than Contrastive Objective,2022,3.786005967680915e-05,2
W4387789854,Unifying Structure Reasoning and Language Pre-Training for Complex Reasoning Tasks,2023,3.785826586811542e-05,2
W4283721470,Few-Shot Fine-Grained Entity Typing with Automatic Label Interpretation and Instance Generation,2022,3.78487758943048e-05,2
W4283818721,Exploring Relational Semantics for Inductive Knowledge Graph Completion,2022,3.784590170959083e-05,2
W4385573365,PAR: Political Actor Representation Learning with Social Context and Expert Knowledge,2022,3.784481548352406e-05,2
W4385718022,KGLM: Integrating Knowledge Graph Structure in Language Models for Link Prediction,2023,3.78348583419009e-05,2
W4391061229,MED-Prompt: A novel prompt engineering framework for medicine prediction on free-text clinical notes,2024,3.780832200329098e-05,2
W4389520299,Orthogonal Subspace Learning for Language Model Continual Learning,2023,3.780335358751596e-05,2
W4385571070,Team:PULSAR at ProbSum 2023:PULSAR: Pre-training with Extracted Healthcare Terms for Summarising Patients’ Problems and Data Augmentation with Black-box Large Language Models,2023,3.78012710789759e-05,2
W3175930218,"On Sample Based Explanation Methods for NLP: Faithfulness, Efficiency and Semantic Evaluation",2021,3.777903439684253e-05,2
W4385574272,IDK-MRC: Unanswerable Questions for Indonesian Machine Reading Comprehension,2022,3.7776480421148554e-05,2
W4389519937,Are Language Models Worse than Humans at Following Prompts? It’s Complicated,2023,3.7775373658199065e-05,2
W3214020110,NLP From Scratch Without Large-Scale Pretraining: A Simple and Efficient Framework,2021,3.777427333991729e-05,2
W3211961299,BERT-SMAP: Paying attention to Essential Terms in passage ranking beyond BERT,2021,3.777284101455573e-05,2
W3113280695,KgPLM: Knowledge-guided Language Model Pre-training via Generative and Discriminative Learning,2020,3.777148753071747e-05,2
W3168830259,On the Impact of Random Seeds on the Fairness of Clinical Classifiers,2021,3.776781796330536e-05,2
W4205952419,Compression of Deep Learning Models for Text: A Survey,2022,3.776737860829662e-05,2
W3201266133,Improving Unsupervised Question Answering via Summarization-Informed Question Generation,2021,3.776254558288088e-05,2
W3152559633,Multi-Step Reasoning Over Unstructured Text with Beam Dense Retrieval,2021,3.7759979103154945e-05,2
W4306661307,Generating Fluent Fact Checking Explanations with Unsupervised Post-Editing,2022,3.775421336401959e-05,2
W3156389890,Consistency Training with Virtual Adversarial Discrete Perturbation,2022,3.774869086326473e-05,2
W3103520839,diagNNose: A Library for Neural Activation Analysis,2020,3.7748251726478304e-05,2
W4312314464,Compositional Evaluation on Japanese Textual Entailment and Similarity,2022,3.774824771288416e-05,2
W4221154673,Metadata-Induced Contrastive Learning for Zero-Shot Multi-Label Text Classification,2022,3.7744264562352125e-05,2
W3167528419,AraStance: A Multi-Country and Multi-Domain Dataset of Arabic Stance Detection for Fact Checking,2021,3.773268583847421e-05,2
W4366779175,Identifying stroke-related quantified evidence from electronic health records in real-world studies,2023,3.772975629978836e-05,2
W4321485427,Knowledge-Augmented Methods for Natural Language Processing,2023,3.77291327868622e-05,2
W4285266914,"Detection, Disambiguation, Re-ranking: Autoregressive Entity Linking as a Multi-Task Problem",2022,3.772679823394312e-05,2
W4385573674,Automatic Rule Induction for Efficient Semi-Supervised Learning,2022,3.7720691496830084e-05,2
W3097132740,Accelerating Training of Transformer-Based Language Models with Progressive Layer Dropping,2020,3.7717076526660366e-05,2
W4385571986,Faithfulness Tests for Natural Language Explanations,2023,3.7714824019793194e-05,2
W3174687042,Automatic Fake News Detection: Are Models Learning to Reason?,2021,3.771367858341535e-05,2
W2999791086,Ensemble Approach for Natural Language Question Answering Problem,2019,3.770370704460982e-05,2
W3152258780,What Will it Take to Fix Benchmarking in Natural Language Understanding,2021,3.7697630665521544e-05,2
W4225297420,OPERA: Operation-Pivoted Discrete Reasoning over Text,2022,3.76866037165551e-05,2
W4401549296,GS-CBR-KBQA: Graph-structured case-based reasoning for knowledge base question answering,2024,3.76866037165551e-05,2
W3113389843,REM-Net: Recursive Erasure Memory Network for Commonsense Evidence Refinement,2021,3.767455785101585e-05,2
W4297347707,SupMPN: Supervised Multiple Positives and Negatives Contrastive Learning Model for Semantic Textual Similarity,2022,3.767057627750954e-05,2
W3201344816,NOPE: A Corpus of Naturally-Occurring Presuppositions in English,2021,3.766441684026795e-05,2
W3167972416,Self-Supervised Test-Time Learning for Reading Comprehension,2021,3.7661896715279305e-05,2
W3204886703,DeepA2: A Modular Framework for Deep Argument Analysis with Pretrained Neural Text2Text Language Models,2022,3.766152581050099e-05,2
W3200936406,Pre-train or Annotate? Domain Adaptation with a Constrained Budget,2021,3.7645044188564235e-05,2
W3098300729,On the Interplay Between Fine-tuning and Sentence-level Probing for Linguistic Knowledge in Pre-trained Transformers,2020,3.7596147590911034e-05,2
W4387966945,"Transmission Versus Truth, Imitation Versus Innovation: What Children Can Do That Large Language and Language-and-Vision Models Cannot (Yet)",2023,3.759582121574709e-05,2
W4390873328,Introducing Language Guidance in Prompt-based Continual Learning,2023,3.759290484213492e-05,2
W4392932503,A simple and efficient dialogue generation model incorporating commonsense knowledge,2024,3.759290484213492e-05,2
W4226094293,A Cross-Lingual Sentence Similarity Calculation Method With Multifeature Fusion,2022,3.759290484213492e-05,2
W4367679848,TopoBERT: Exploring the topology of fine-tuned word representations,2023,3.759290484213492e-05,2
W4389523985,UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation,2023,3.759290484213492e-05,2
W4391092830,Prompting Large Language Models for Topic Modeling,2023,3.759290484213492e-05,2
W4385573127,NewsClaims: A New Benchmark for Claim Detection from News with Attribute Knowledge,2022,3.759290484213492e-05,2
W4384705353,ByteTransformer: A High-Performance Transformer Boosted for Variable-Length Inputs,2023,3.759290484213492e-05,2
W4400526908,Large Language Models can Accurately Predict Searcher Preferences,2024,3.759290484213492e-05,2
W4285999563,ScienceQA: a novel resource for question answering on scholarly articles,2022,3.759290484213492e-05,2
W4392688439,Leveraging Text-to-Text Pretrained Language Models for Question Answering in Chemistry,2024,3.759290484213492e-05,2
W4396736142,Improving Retrieval in Theme-specific Applications using a Corpus Topical Taxonomy,2024,3.759290484213492e-05,2
W4387424307,Contrastive sentence representation learning with adaptive false negative cancellation,2023,3.759290484213492e-05,2
W4389777721,An Efficient Self-Supervised Cross-View Training For Sentence Embedding,2023,3.759290484213492e-05,2
W3113833985,Applying Distilled BERT for Question Answering on ASRS Reports,2020,3.759290484213492e-05,2
W4378648500,"An intent classification method for questions in ""Treatise on Febrile diseases"" based on TinyBERT-CNN fusion model",2023,3.759290484213492e-05,2
W3129155125,FAD-BERT: Improved prediction of FAD binding sites using pre-training of deep bidirectional transformers,2021,3.759290484213492e-05,2
W4285294837,Emergent Structures and Training Dynamics in Large Language Models,2022,3.759290484213492e-05,2
W4382561244,ELECTRA-based graph network model for multi-hop question answering,2023,3.759290484213492e-05,2
W4382322807,Constraint-aware and Ranking-distilled Token Pruning for Efficient Transformer Inference,2023,3.759290484213492e-05,2
W4385570856,UPPAM: A Unified Pre-training Architecture for Political Actor Modeling based on Language,2023,3.759290484213492e-05,2
W4312408631,An End-to-End Contrastive Self-Supervised Learning Framework for Language Understanding,2022,3.759290484213492e-05,2
W4385764034,A Survey on Efficient Training of Transformers,2023,3.759290484213492e-05,2
W4387575740,Meaning Modulations and Stability in Large Language Models: An Analysis of BERT Embeddings for Psycholinguistic Research,2023,3.759290484213492e-05,2
W4312108492,A survey on complex factual question answering,2022,3.759290484213492e-05,2
W4309532049,Miko Team: Deep Learning Approach for Legal Question Answering in ALQAC 2022,2022,3.759290484213492e-05,2
W3114100246,CS-NLP Team at SemEval-2020 Task 4: Evaluation of State-of-the-art NLP Deep Learning Architectures on Commonsense Reasoning Task,2020,3.759133035389956e-05,2
W3109752844,SLICE: Supersense-based Lightweight Interpretable Contextual Embeddings,2020,3.758871915501419e-05,2
W3203380178,Probing Language Models for Understanding of Temporal Expressions,2021,3.757904053143588e-05,2
W4385572451,Rarely a problem? Language models exhibit inverse scaling in their predictions following few-type quantifiers,2023,3.7569354060709413e-05,2
W4386155665,Marie and BERT─A Knowledge Graph Embedding Based Question Answering System for Chemistry,2023,3.753792938565286e-05,2
W4226403411,Text Smoothing: Enhance Various Data Augmentation Methods on Text Classification Tasks,2022,3.751091832701728e-05,2
W3175175610,Alignment Rationale for Natural Language Inference,2021,3.749209392815996e-05,2
W3208397797,Magic Pyramid: Accelerating Inference with Early Exiting and Token Pruning,2021,3.748658142448617e-05,2
W4385573361,PACIFIC: Towards Proactive Conversational Question Answering over Tabular and Textual Data in Finance,2022,3.7453224795846294e-05,2
W4382202569,Feature-Level Debiased Natural Language Understanding,2023,3.745235653050467e-05,2
W4385893893,A Better Way to Do Masked Language Model Scoring,2023,3.745049286657416e-05,2
W3174776104,Doing Good or Doing Right? Exploring the Weakness of Commonsense Causal Reasoning Models,2021,3.7441553026168435e-05,2
W3217177838,DiLBERT: Cheap Embeddings for Disease Related Medical NLP,2021,3.7433637563823105e-05,2
W4385572907,DRLK: Dynamic Hierarchical Reasoning with Language Model and Knowledge Graph for Question Answering,2022,3.7433637563823105e-05,2
W4385574253,ComFact: A Benchmark for Linking Contextual Commonsense Knowledge,2022,3.7433481441830825e-05,2
W4389518298,GYM at Qur’an QA 2023 Shared Task: Multi-Task Transfer Learning for Quranic Passage Retrieval and Question Answering with Large Language Models,2023,3.742491108041844e-05,2
W3168767448,Why Attentions May Not Be Interpretable?,2021,3.741998161574327e-05,2
W4283796213,Debiasing NLU Models via Causal Intervention and Counterfactual Reasoning,2022,3.7410075838300804e-05,2
W3126974869,Combining pre-trained language models and structured knowledge.,2021,3.740734958087437e-05,2
W2798237655,QA4IE: A Question Answering Based Framework for Information Extraction,2018,3.740326645413509e-05,2
W3184074798,Fine-grained Classification of Political Bias in German News: A Data Set and Initial Experiments,2021,3.7397266997151874e-05,2
W4385002643,Exploring the Landscape of Natural Language Processing Research,2023,3.738058376101853e-05,2
W4205332217,Joint Passage Ranking for Diverse Multi-Answer Retrieval,2021,3.7368421737416364e-05,2
W3045441970,An Effective Domain Adaptive Post-Training Method for BERT in Response Selection,2019,3.7364054570638213e-05,2
W4213450276,Efficient Prediction of Court Judgments Using an LSTM+CNN Neural Network Model with an Optimal Feature Set,2022,3.7363561868166795e-05,2
W3197482624,Explainable Sentiment Analysis: A Hierarchical Transformer-Based Extractive Summarization Approach,2021,3.73633926695427e-05,2
W4293182797,"Robust Natural Language Processing: Recent Advances, Challenges, and Future Directions",2022,3.73509930311842e-05,2
W3037620288,BERTology Meets Biology: Interpreting Attention in Protein Language Models,2020,3.734971758745457e-05,2
W4386566517,Trained on 100 million words and still in shape: BERT meets British National Corpus,2023,3.7341285634519665e-05,2
W4366824871,Contextualized medication information extraction using Transformer-based deep learning architectures,2023,3.733014060734792e-05,2
W4385574466,ConGen: Unsupervised Control and Generalization Distillation For Sentence Representation,2022,3.732469703719666e-05,2
W4288048729,Multi-granularity interaction model based on pinyins and radicals for Chinese semantic matching,2022,3.732458533811353e-05,2
W4385571775,Minding Language Models’ (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker,2023,3.732458533811353e-05,2
W4389010498,Syndicom: Improving Conversational Commonsense with Error-Injection and Natural Language Feedback,2023,3.732458533811353e-05,2
W4394932682,Knowledge-Enhanced Prompt Learning for Few-Shot Text Classification,2024,3.732458533811353e-05,2
W3164109169,Generating Synthetic Training Data for Supervised De-Identification of Electronic Health Records,2021,3.732458533811353e-05,2
W4366336804,Multi-task learning for few-shot biomedical relation extraction,2023,3.732458533811353e-05,2
W3037101098,Efficient Automatic Punctuation Restoration Using Bidirectional Transformers with Robust Inference,2020,3.732458533811353e-05,2
W4367165010,On the Robustness of Dialogue History Representation in Conversational Question Answering: A Comprehensive Study and a New Prompt-based Method,2023,3.732458533811353e-05,2
W4321242372,A semantics-aware approach for multilingual natural language inference,2023,3.732458533811353e-05,2
W4311173007,Developing a deep learning natural language processing algorithm for automated reporting of adverse drug reactions,2022,3.732458533811353e-05,2
W4403983018,Reconciling the contrasting narratives on the environmental impact of large language models,2024,3.732458533811353e-05,2
W4381436391,DesPrompt: Personality-descriptive prompt tuning for few-shot personality recognition,2023,3.732458533811353e-05,2
W4393160461,Task Contamination: Language Models May Not Be Few-Shot Anymore,2024,3.732458533811353e-05,2
W4382202590,FiTs: Fine-Grained Two-Stage Training for Knowledge-Aware Question Answering,2023,3.732458533811353e-05,2
W4221074805,Comparing PSO-based clustering over contextual vector embeddings to modern topic modeling,2022,3.732458533811353e-05,2
W4385571944,Symbolic Chain-of-Thought Distillation: Small Models Can Also “Think” Step-by-Step,2023,3.732458533811353e-05,2
W4386566639,Enriching Biomedical Knowledge for Low-resource Language Through Large-scale Translation,2023,3.732458533811353e-05,2
W4389524274,Symbol tuning improves in-context learning in language models,2023,3.732458533811353e-05,2
W4390222516,Year 2022 in Medical Natural Language Processing: Availability of Language Models as a Step in the Democratization of NLP in the Biomedical Area,2023,3.732458533811353e-05,2
W2953413383,Explorations into the Use of Word Embedding in Math Search and Math Semantics,2019,3.732458533811353e-05,2
W3169404852,Factorization-Aware Training of Transformers for Natural Language Understanding on the Edge,2021,3.732458533811353e-05,2
W4390420065,PAL-BERT: An Improved Question Answering Model,2023,3.732458533811353e-05,2
W4221165884,Toward Interpretable Semantic Textual Similarity via Optimal Transport-based Contrastive Sentence Learning,2022,3.732458533811353e-05,2
W4389524424,Not all layers are equally as important: Every Layer Counts BERT,2023,3.7311164285959005e-05,2
W4281884846,Natural Language Processing: from Bedside to Everywhere,2022,3.729036411474205e-05,2
W4385573380,One size does not fit all: Investigating strategies for differentially-private learning across NLP tasks,2022,3.728694297947401e-05,2
W4385756485,Learning to Perturb for Contrastive Learning of Unsupervised Sentence Representations,2023,3.727221565357393e-05,2
W4306317476,Cross-Domain Aspect Extraction using Transformers Augmented with Knowledge Graphs,2022,3.726246693180667e-05,2
W4281293760,ARNN-QA: Adaptive Recurrent Neural Network with feature optimization for incremental learning-based Question Answering system,2022,3.726246693180667e-05,2
W3177474387,SyGNS: A Systematic Generalization Testbed Based on Natural Language Semantics,2021,3.725841003859748e-05,2
W4385574060,Are All Spurious Features in Natural Language Alike? An Analysis through a Causal Lens,2022,3.725626901948358e-05,2
W4389524330,DEPN: Detecting and Editing Privacy Neurons in Pretrained Language Models,2023,3.724712240432778e-05,2
W2982346747,Towards Generalizable Neuro-Symbolic Systems for Commonsense Question Answering,2019,3.7233690842081194e-05,2
W3106916526,Deep learning based question answering system in Bengali,2020,3.7221684454187014e-05,2
W3129415623,SparseBERT: Rethinking the Importance Analysis in Self-attention,2021,3.722086519370189e-05,2
W4385569751,Mixture-of-Domain-Adapters: Decoupling and Injecting Domain Knowledge to Pre-trained Language Models’ Memories,2023,3.722086519370189e-05,2
W3156572742,Benchmarking Machine Reading Comprehension: A Psychological Perspective,2021,3.7217263559976747e-05,2
W4389520367,Crystal: Introspective Reasoners Reinforced with Self-Feedback,2023,3.720792468419118e-05,2
W3171324702,Assertion Detection in Clinical Notes: Medical Language Models to the Rescue?,2021,3.7206564733763736e-05,2
W3175291199,Robustifying Multi-hop QA through Pseudo-Evidentiality Training,2021,3.7189355630926786e-05,2
W4386576728,Robustness Challenges in Model Distillation and Pruning for Natural Language Understanding,2023,3.718709862951436e-05,2
W4226325987,Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction,2022,3.717955830660183e-05,2
W3093543164,TweetBERT: A Pretrained Language Representation Model for Twitter Text Analysis,2020,3.7154007871723994e-05,2
W3201023666,Continual knowledge infusion into pre-trained biomedical language models,2021,3.714020204742683e-05,2
W3104655669,CHARM: Inferring Personal Attributes from Conversations,2020,3.7135192484683685e-05,2
W4389520386,SimCSE++: Improving Contrastive Learning for Sentence Embeddings from Two Perspectives,2023,3.7134911205960465e-05,2
W3098405901,Dissecting Lottery Ticket Transformers: Structural and Behavioral Study of Sparse Neural Machine Translation,2020,3.7134496902739184e-05,2
W4388680526,Diagnosing AI Explanation Methods with Folk Concepts of Behavior,2023,3.7131297762336917e-05,2
W3200655919,Efficient Contrastive Learning via Novel Data Augmentation and Curriculum Learning,2021,3.7115964019699936e-05,2
W4385570695,PeaCoK: Persona Commonsense Knowledge for Consistent and Engaging Narratives,2023,3.7110881778648486e-05,2
W4313887409,cpgQA: A Benchmark Dataset for Machine Reading Comprehension Tasks on Clinical Practice Guidelines and a Case Study Using Transfer Learning,2023,3.710948731719499e-05,2
W3090260555,How Effective is Task-Agnostic Data Augmentation for Pretrained Transformers?.,2020,3.710801295562702e-05,2
W4385569969,Modeling Cross-Cultural Pragmatic Inference with Codenames Duet,2023,3.7100985751429025e-05,2
W4379260118,Identifying Risk Factors Associated With Lower Back Pain in Electronic Medical Record Free Text: Deep Learning Approach Using Clinical Note Annotations,2023,3.7100985751429025e-05,2
W4390628433,Learning dual disentangled representation with self-supervision for temporal knowledge graph reasoning,2024,3.7100985751429025e-05,2
W4287890652,Natural Language Inference with Self-Attention for Veracity Assessment of Pandemic Claims,2022,3.7100985751429025e-05,2
W4385570457,Pre-trained Language Model with Prompts for Temporal Knowledge Graph Completion,2023,3.7100985751429025e-05,2
W4367843743,Heart disease risk factors detection from electronic health records using advanced NLP and deep learning techniques,2023,3.7100985751429025e-05,2
W4385460063,The Politics of Right and Wrong: Moral Appeals in Political Communication over Six Decades in Ten Western Democracies,2023,3.7100985751429025e-05,2
W4402261986,Investigating the Robustness of Arabic Offensive Language Transformer-Based Classifiers to Adversarial Attacks,2024,3.7100985751429025e-05,2
W4385570683,Friendly Neighbors: Contextualized Sequence-to-Sequence Link Prediction,2023,3.7100985751429025e-05,2
W4205149420,Named entity disambiguation in short texts over knowledge graphs,2022,3.7100985751429025e-05,2
W4393156919,Combining Multiple Supervision for Robust Zero-Shot Dense Retrieval,2024,3.7100985751429025e-05,2
W4315781034,Natural Language Processing Applications for Computer-Aided Diagnosis in Oncology,2023,3.7100985751429025e-05,2
W4288741487,A hybrid CNN + BILSTM deep learning-based DSS for efficient prediction of judicial case decisions,2022,3.7100985751429025e-05,2
W4391511770,Transformers in health: a systematic review on architectures for longitudinal data analysis,2024,3.7100985751429025e-05,2
W3158209167,Paraphrastic Representations at Scale,2022,3.7100985751429025e-05,2
W4396722687,Back to the Future: Towards Explainable Temporal Reasoning with Large Language Models,2024,3.7100985751429025e-05,2
W4400529431,Preventing and Detecting Misinformation Generated by Large Language Models,2024,3.7100985751429025e-05,2
W4384345672,Log Parsing with Prompt-based Few-shot Learning,2023,3.7100985751429025e-05,2
W4380359954,A Data Fusion Framework for Multi-Domain Morality Learning,2023,3.7100985751429025e-05,2
W4385571334,SemEval-2023 Task 5: Clickbait Spoiling,2023,3.7100985751429025e-05,2
W4205184268,Machine Learning and Hebrew NLP for Automated Assessment of Open-Ended Questions in Biology,2022,3.7100985751429025e-05,2
W4402352366,Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated Text Detection,2024,3.7100985751429025e-05,2
W4385571206,Learning Joint Structural and Temporal Contextualized Knowledge Embeddings for Temporal Knowledge Graph Completion,2023,3.7100985751429025e-05,2
W4405107520,Trustworthy AI: Securing Sensitive Data in Large Language Models,2024,3.7100985751429025e-05,2
W4407542088,Towards Lifelong Learning of Large Language Models: A Survey,2025,3.7100985751429025e-05,2
W4386566702,Evaluating the Robustness of Discrete Prompts,2023,3.7100985751429025e-05,2
W4387074826,A Practical Survey on Zero-shot Prompt Design for In-context Learning,2023,3.7100985751429025e-05,2
W4389519061,Goal-Driven Explainable Clustering via Language Descriptions,2023,3.7100985751429025e-05,2
W4390660356,Enhancing Zero-Shot Crypto Sentiment With Fine-Tuned Language Model and Prompt Engineering,2024,3.7100985751429025e-05,2
W4389486944,An in-depth analysis of passage-level label transfer for contextual document ranking,2023,3.7096378526016967e-05,2
W3021524072,Birds have four legs?! NumerSense: Probing Numerical Commonsense Knowledge of Pre-trained Language Models,2020,3.708937276015229e-05,2
W4394895012,Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction (Preprint),2024,3.7084400720348586e-05,2
W4396767636,From explainable to interpretable deep learning for natural language processing in healthcare: How far from reality?,2024,3.7084400720348586e-05,2
W4220902914,Towards Textual Out-of-Domain Detection Without In-Domain Labels,2022,3.708418116172279e-05,2
W4287888693,BLINK with Elasticsearch for Efficient Entity Linking in Business Conversations,2022,3.708307673314284e-05,2
W3094300879,Customizing Triggers with Concealed Data Poisoning.,2020,3.708196065120694e-05,2
W3116510459,SG-Net: Syntax Guided Transformer for Language Representation,2020,3.7079035805472785e-05,2
W4385718025,Arithmetic-Based Pretraining Improving Numeracy of Pretrained Language Models,2023,3.707661991775342e-05,2
W4403577485,Aligning Large Language Models to a Domain-specific Graph Database for NL2GQL,2024,3.707367963080236e-05,2
W4385571145,LeXFiles and LegalLAMA: Facilitating English Multinational Legal Language Model Development,2023,3.707335998767174e-05,2
W4385572004,U-CREAT: Unsupervised Case Retrieval using Events extrAcTion,2023,3.707335998767174e-05,2
W4313476629,Extractive Explanations for Interpretable Text Ranking,2022,3.707289632807329e-05,2
W3105886116,HoVer: A Dataset for Many-Hop Fact Extraction And Claim Verification,2020,3.7066432192963506e-05,2
W3111289154,Reference Knowledgeable Network for Machine Reading Comprehension,2022,3.704950859305473e-05,2
W3188892795,Is My Model Using the Right Evidence? Systematic Probes for Examining Evidence-Based Tabular Reasoning,2022,3.7041850037082023e-05,2
W4385571479,SemEval-2023 Task 7: Multi-Evidence Natural Language Inference for Clinical Trial Data,2023,3.7033633758371604e-05,2
W3111711122,Generate Your Counterfactuals: Towards Controlled Counterfactual Generation for Text,2021,3.702953273080227e-05,2
W3153080312,UHD-BERT: Bucketed Ultra-High Dimensional Sparse Representations for Full Ranking.,2021,3.702744654623197e-05,2
W3102933348,What do we expect from Multiple-choice QA Systems?,2020,3.7027243132745175e-05,2
W3142036593,Transformers aftermath,2021,3.7019467960572235e-05,2
W4297459110,Visual Comparison of Language Model Adaptation,2022,3.6998098258077355e-05,2
W4312791030,VL-InterpreT: An Interactive Visualization Tool for Interpreting Vision-Language Transformers,2022,3.6998098258077355e-05,2
W3186289945,"<i>Break, Perturb, Build</i>: Automatic Perturbation of Reasoning Paths Through Question Decomposition",2022,3.698364419583297e-05,2
W3023160663,Connecting the Dots: A Knowledgeable Path Generator for Commonsense Question Answering,2020,3.697262495854784e-05,2
W4285162225,Your fairness may vary: Pretrained language model fairness in toxic text classification,2022,3.6971665311207475e-05,2
W3097547734,Differentiable Open-Ended Commonsense Reasoning,2020,3.695350260760709e-05,2
W3152711910,Hierarchical Multi-head Attentive Network for Evidence-aware Fake News Detection,2021,3.694494751590863e-05,2
W2998259147,ReCO: A Large Scale Chinese Reading Comprehension Dataset on Opinion,2020,3.6937974399897305e-05,2
W2981573048,A Unified MRC Framework for Named Entity Recognition,2019,3.693714185239307e-05,2
W3127302468,Memory Augmented Sequential Paragraph Retrieval for Multi-hop Question Answering,2021,3.692983085450862e-05,2
W4205933428,Project Debater APIs: Decomposing the AI Grand Challenge,2021,3.6929551144774186e-05,2
W4285302754,Metaphors in Pre-Trained Language Models: Probing and Generalization Across Datasets and Languages,2022,3.6929551144774186e-05,2
W4285263440,Probing as Quantifying Inductive Bias,2022,3.6929551144774186e-05,2
W4320463733,Acquiring and Modelling Abstract Commonsense Knowledge via Conceptualization,2022,3.69277016905887e-05,2
W4221151629,Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs,2022,3.692617949212583e-05,2
W4393147125,PMET: Precise Model Editing in a Transformer,2024,3.691642049460953e-05,2
W4391229250,Identifying Mentions of Pain in Mental Health Records Text: A Natural Language Processing Approach,2024,3.691178610115752e-05,2
W4220808153,MKGN: A Multi-Dimensional Knowledge Enhanced Graph Network for Multi-Hop Question and Answering,2022,3.691178610115752e-05,2
W4323519786,Chemical identification and indexing in full-text articles: an overview of the NLM-Chem track at BioCreative VII,2023,3.691178610115752e-05,2
W2561975083,Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics,2017,3.691178610115752e-05,2
W4283798762,Flexible Instance-Specific Rationalization of NLP Models,2022,3.691178610115752e-05,2
W3147450229,Question Answering Systems: A Systematic Literature Review,2021,3.691178610115752e-05,2
W4384705126,BLADE: Combining Vocabulary Pruning and Intermediate Pretraining for Scaleable Neural CLIR,2023,3.691178610115752e-05,2
W2970868452,Improving classification of Adverse Drug Reactions through Using Sentiment Analysis and Transfer Learning,2019,3.691178610115752e-05,2
W3189818462,Information Retrieval in an Infodemic: The Case of COVID-19 Publications,2021,3.691178610115752e-05,2
W4381573351,Representation Sparsification with Hybrid Thresholding for Fast SPLADE-based Document Retrieval,2023,3.691178610115752e-05,2
W4401536723,FLAT: Fusing layer representations for more efficient transfer learning in NLP,2024,3.691178610115752e-05,2
W4385570296,RetroMAE-2: Duplex Masked Auto-Encoder For Pre-Training Retrieval-Oriented Language Models,2023,3.691178610115752e-05,2
W4402980267,MoCoSA: Momentum Contrast for Knowledge Graph Completion with Structure-Augmented Pre-trained Language Models,2024,3.691178610115752e-05,2
W4399286424,Extracting patient lifestyle characteristics from Dutch clinical text with BERT models,2024,3.691178610115752e-05,2
W4386365737,LMGFuse: Language Models and Graph reasoning Fuse deeply for question answering,2023,3.691178610115752e-05,2
W4389683743,A survey of inductive knowledge graph completion,2023,3.691178610115752e-05,2
W4389524352,COMET-M: Reasoning about Multiple Events in Complex Sentences,2023,3.691178610115752e-05,2
W4404132457,"Characterizing Learning Curves During Language Model Pre-Training: Learning, Forgetting, and Stability",2024,3.691178610115752e-05,2
W4327928001,Deep Learning Mental Health Dialogue System,2023,3.691178610115752e-05,2
W4385278011,Retrieval-Augmented Knowledge Graph Reasoning for Commonsense Question Answering,2023,3.691178610115752e-05,2
W4294791148,Low-Resource Similar Case Matching in Legal Domain,2022,3.691178610115752e-05,2
W3207867270,Embedding Electronic Health Records to Learn BERT-based Models for Diagnostic Decision Support,2021,3.691178610115752e-05,2
W4317935084,The Choice of Textual Knowledge Base in Automated Claim Checking,2023,3.691178610115752e-05,2
W4293581639,Beyond word embeddings: A survey,2022,3.691178610115752e-05,2
W3212805424,Graph-Based Tri-Attention Network for Answer Ranking in CQA,2021,3.691178610115752e-05,2
W4285200900,Predicate-Argument Based Bi-Encoder for Paraphrase Identification,2022,3.691178610115752e-05,2
W4385562652,Contrastive Learning of Stress-specific Word Embedding for Social Media based Stress Detection,2023,3.691178610115752e-05,2
W4407194361,Attention heads of large language models,2025,3.691178610115752e-05,2
W3125292083,Weakly Supervised Neuro-Symbolic Module Networks for Numerical Reasoning,2021,3.690813250002207e-05,2
W3217331066,Data science approaches to confronting the COVID-19 pandemic: a narrative review,2021,3.6888967373377715e-05,2
W3152801999,QA-GNN: Reasoning with Language Models and Knowledge Graphs for Question Answering,2021,3.6886465460887436e-05,2
W4385569686,ConvGQR: Generative Query Reformulation for Conversational Search,2023,3.688534400125303e-05,2
W4385571112,Search-Oriented Conversational Query Editing,2023,3.688534400125303e-05,2
W3125591643,Learning to Deceive Knowledge Graph Augmented Models via Targeted Perturbation,2021,3.688403869303861e-05,2
W3114219454,ERICA: Improving Entity and Relation Understanding for Pre-trained Language Models via Contrastive Learning,2020,3.687917143733709e-05,2
W3172871932,Multi-Grained Knowledge Distillation for Named Entity Recognition,2021,3.687576465111344e-05,2
W3034395406,Fluent Response Generation for Conversational Question Answering,2020,3.687442079682325e-05,2
W4285269381,Multi-Granularity Structural Knowledge Distillation for Language Model Compression,2022,3.6858586965064855e-05,2
W3117660267,Picking BERT’s Brain: Probing for Linguistic Dependencies in Contextualized Embeddings Using Representational Similarity Analysis,2020,3.685494784539794e-05,2
W4372348172,Coarse-To-Fine Knowledge Selection for Document Grounded Dialogs,2023,3.684871955106702e-05,2
W3153594491,A Linguistic Study on Relevance Modeling in Information Retrieval,2021,3.684700578611891e-05,2
W2970169521,Learning with Limited Data for Multilingual Reading Comprehension,2019,3.6842663490842546e-05,2
W4379740528,Integrating domain knowledge for biomedical text analysis into deep learning: A survey,2023,3.6835399339726985e-05,2
W3090640022,Explaining Text Matching on Neural Natural Language Inference,2020,3.683377985515494e-05,2
W4385573679,"Don’t Prompt, Search! Mining-based Zero-Shot Learning with Language Models",2022,3.6830252802996085e-05,2
W4386324533,Grouped Contrastive Learning of Self-Supervised Sentence Representation,2023,3.682784809079721e-05,2
W3021606318,Towards the necessity for debiasing natural language inference datasets,2020,3.6825233478931474e-05,2
W3153592532,NoiseQA: Challenge Set Evaluation for User-Centric Question Answering,2021,3.6819055837783346e-05,2
W4382202515,Real or Fake Text?: Investigating Human Ability to Detect Boundaries between Human-Written and Machine-Generated Text,2023,3.681610462914298e-05,2
W3204342617,EntQA: Entity Linking as Question Answering,2021,3.6810429145654934e-05,2
W3099954076,Interactive Fiction Game Playing as Multi-Paragraph Reading Comprehension with Reinforcement Learning,2020,3.679762549325251e-05,2
W4389520333,LM vs LM: Detecting Factual Errors via Cross Examination,2023,3.6792750004055764e-05,2
W2969219365,The compositionality of neural networks: integrating symbolism and connectionism.,2019,3.6787872520013636e-05,2
W3189197390,From LSAT: The Progress and Challenges of Complex Reasoning,2022,3.677719090601939e-05,2
W3205301323,Misinfo Reaction Frames: Reasoning about Readers’ Reactions to News Headlines,2022,3.677527696747143e-05,2
W3213002786,Assessing the Generalization Capacity of Pre-trained Language Models through Japanese Adversarial Natural Language Inference,2021,3.6772517508927414e-05,2
W4389891246,E2S2: Encoding-Enhanced Sequence-to-Sequence Pretraining for Language Understanding and Generation,2023,3.67594274277484e-05,2
W4385573694,Finding Skill Neurons in Pre-trained Transformer-based Language Models,2022,3.674961497235338e-05,2
W4385571803,Check-COVID: Fact-Checking COVID-19 News Claims with Scientific Evidence,2023,3.674961497235338e-05,2
W4385570396,Can NLI Provide Proper Indirect Supervision for Low-resource Biomedical Relation Extraction?,2023,3.674961497235338e-05,2
W4283172096,"Can Machines Help Us Answering Question 16 in Datasheets, and In Turn Reflecting on Inappropriate Content?",2022,3.674961497235338e-05,2
W4385572276,Efficient Document Embeddings via Self-Contrastive Bregman Divergence Learning,2023,3.674961497235338e-05,2
W4386566613,Fine-Tuning Deteriorates General Textual Out-of-Distribution Detection by Distorting Task-Agnostic Features,2023,3.674961497235338e-05,2
W4388743339,STMAP: A novel semantic text matching model augmented with embedding perturbations,2023,3.674961497235338e-05,2
W4307821210,Exploring Dimensionality Reduction Techniques in Multilingual Transformers,2022,3.674961497235338e-05,2
W4393146982,DenoSent: A Denoising Objective for Self-Supervised Sentence Representation Learning,2024,3.674961497235338e-05,2
W4399366010,A Survey of Text-Matching Techniques,2024,3.674961497235338e-05,2
W3154075676,Wiki2Prop: A Multimodal Approach for Predicting Wikidata Properties from Wikipedia,2021,3.674961497235338e-05,2
W3205192296,Energon: Toward Efficient Acceleration of Transformers Using Dynamic Sparse Attention,2022,3.674961497235338e-05,2
W4385574161,Generative Prompt Tuning for Relation Classification,2022,3.674961497235338e-05,2
W4381799451,Politically-oriented information inference from text,2023,3.674961497235338e-05,2
W4285126771,Knowledge-Augmented Methods for Natural Language Processing,2022,3.674762178801018e-05,2
W4287855005,Multi-Hop Open-Domain Question Answering over Structured and Unstructured Knowledge,2022,3.67452701554338e-05,2
W2794609696,AI2: Safety and Robustness Certification of Neural Networks with Abstract Interpretation,2018,3.6738836295508985e-05,2
W3022402349,A Review of Winograd Schema Challenge Datasets and Approaches,2020,3.673403150842906e-05,2
W3176756782,REPT: Bridging Language Models and Machine Reading Comprehension via Retrieval-Based Pre-training,2021,3.6710830567116134e-05,2
W3175802991,Dialogue Graph Modeling for Conversational Machine Reading,2021,3.670739087882348e-05,2
W3125701197,Towards Rare Disease Knowledge Graph Learning from Social Posts of Patients,2021,3.670678640532756e-05,2
W4385574011,Processing Long Legal Documents with Pre-trained Transformers: Modding LegalBERT and Longformer,2022,3.668474652083173e-05,2
W3123161422,HyperGrid Transformers: Towards A Single Model for Multiple Tasks,2021,3.6666921348524185e-05,2
W3174881085,Structural Pre-training for Dialogue Comprehension,2021,3.66664362309259e-05,2
W3015297483,DialBERT: A Hierarchical Pre-Trained Model for Conversation Disentanglement,2020,3.66664362309259e-05,2
W3137280539,A Hybrid Siamese Neural Network for Natural Language Inference in Cyber-Physical Systems,2021,3.666092396497003e-05,2
W4313187582,Mr.BiQ: Post-Training Non-Uniform Quantization based on Minimizing the Reconstruction Error,2022,3.6643531038914856e-05,2
W4229440380,Necessity and Sufficiency for Explaining Text Classifiers: A Case Study in Hate Speech Detection,2022,3.6630639842805014e-05,2
W4385573098,Word Order Matters When You Increase Masking,2022,3.662756507693944e-05,2
W4385573677,An Efficient Active Learning Pipeline for Legal Text Classification,2022,3.6609066660723126e-05,2
W4225891344,Word2Vec: Optimal hyperparameters and their impact on natural language processing downstream tasks,2022,3.6609066660723126e-05,2
W3205816523,Sparse Progressive Distillation: Resolving Overfitting under Pretrain-and-Finetune Paradigm,2022,3.6609066660723126e-05,2
W4384644539,Distilling Semantic Concept Embeddings from Contrastively Fine-Tuned Language Models,2023,3.6609066660723126e-05,2
W4362499835,Transformers in Natural Language Processing,2023,3.6609066660723126e-05,2
W4286544524,Bert-Based Feature Extraction for Long-Lived Bug Prediction in Floss: A Comparative Study,2022,3.6609066660723126e-05,2
W4385574376,Data-Efficient Concept Extraction from Pre-trained Language Models for Commonsense Explanation Generation,2022,3.6609066660723126e-05,2
W4401305431,Providing Citations to Support Fact-Checking: Contextualizing Detection of Sentences Needing Citation on Small Wikipedias,2024,3.6609066660723126e-05,2
W4387848863,NOVO: Learnable and Interpretable Document Identifiers for Model-Based IR,2023,3.6609066660723126e-05,2
W3172352177,Extreme Multi-label Learning for Semantic Matching in Product Search,2021,3.6609066660723126e-05,2
W4386616609,Prediction during language comprehension: what is next?,2023,3.6609066660723126e-05,2
W4385571810,"Unified Language Representation for Question Answering over Text, Tables, and Images",2023,3.6609066660723126e-05,2
W4377232895,Relation-attention semantic-correlative knowledge graph embedding for inductive link prediction,2023,3.6609066660723126e-05,2
W4385574101,Contrastive Demonstration Tuning for Pre-trained Language Models,2022,3.6609066660723126e-05,2
W3198802556,On the Transferability of Pre-trained Language Models: A Study from Artificial Datasets,2022,3.6609066660723126e-05,2
W3213963881,Improving Unsupervised Commonsense Reasoning Using Knowledge-Enabled Natural Language Inference,2021,3.6599048141066586e-05,2
W3213458975,<scp>ParsiNLU</scp>: A Suite of Language Understanding Challenges for Persian,2021,3.6595808785143145e-05,2
W3155762665,EmpathBERT: A BERT-based Framework for Demographic-aware Empathy Prediction,2021,3.659554632663152e-05,2
W3033057983,Assessing the accuracy of automatic speech recognition for psychotherapy,2020,3.659554632663152e-05,2
W3120772090,Multi-task Retrieval for Knowledge-Intensive Tasks,2021,3.6589281548708486e-05,2
W3086963535,Can Machines Tell Stories? A Comparative Study of Deep Neural Language Models and Metrics,2020,3.6573156153399216e-05,2
W3174281149,Structural Guidance for Transformer Language Models,2021,3.656755122113329e-05,2
W4287887161,Quantifying Adaptability in Pre-trained Language Models with 500 Tasks,2022,3.656755122113329e-05,2
W3175366715,Bird’s Eye: Probing for Linguistic Graph Structures with a Simple Information-Theoretic Approach,2021,3.6560631206067946e-05,2
W3034838723,Commonsense Evidence Generation and Injection in Reading Comprehension,2020,3.654367569648365e-05,2
W3081031588,AMBERT: A Pre-trained Language Model with Multi-Grained Tokenization,2020,3.654045437710048e-05,2
W4392904185,One-Shot Sensitivity-Aware Mixed Sparsity Pruning for Large Language Models,2024,3.654040357798471e-05,2
W4393147284,OWQ: Outlier-Aware Weight Quantization for Efficient Fine-Tuning and Inference of Large Language Models,2024,3.654040357798471e-05,2
W4389524393,Outlier Suppression+: Accurate quantization of large language models by equivalent and effective shifting and scaling,2023,3.654040357798471e-05,2
W4391876565,Red Teaming Language Model Detectors with Language Models,2024,3.652883245669049e-05,2
W4385572582,FMI-SU at SemEval-2023 Task 7: Two-level Entailment Classification of Clinical Trials Enhanced by Contextual Data Augmentation,2023,3.6497660391119745e-05,2
W4385573597,Textual Manifold-based Defense Against Natural Language Adversarial Examples,2022,3.6486086888046646e-05,2
W4385571512,Decouple knowledge from paramters for plug-and-play language modeling,2023,3.6486086888046646e-05,2
W4387627515,EHR-KnowGen: Knowledge-enhanced multimodal learning for disease diagnosis generation,2023,3.6486086888046646e-05,2
W4285135170,Pre-training and Fine-tuning Neural Topic Model: A Simple yet Effective Approach to Incorporating External Knowledge,2022,3.6486086888046646e-05,2
W4377101293,Retrieve and rerank for automated ICD coding via Contrastive Learning,2023,3.6486086888046646e-05,2
W3174173633,ROSITA: Refined BERT cOmpreSsion with InTegrAted techniques,2021,3.6486086888046646e-05,2
W4382010844,Finding Structure in One Child's Linguistic Experience,2023,3.6486086888046646e-05,2
W4378009677,TextCNN-based ensemble learning model for Japanese Text Multi-classification,2023,3.6486086888046646e-05,2
W4385573422,BERT for Long Documents: A Case Study of Automated ICD Coding,2022,3.6486086888046646e-05,2
W3136270197,Is BERT a Cross-Disciplinary Knowledge Learner? A Surprising Finding of Pre-trained Models’ Transferability,2021,3.6486086888046646e-05,2
W4289868412,Improving the robustness of machine reading comprehension via contrastive learning,2022,3.6486086888046646e-05,2
W4386566763,Don’t Blame the Annotator: Bias Already Starts in the Annotation Instructions,2023,3.648067559431743e-05,2
W3159622706,ZEN 2.0: Continue Training and Adaption for N-gram Enhanced Text Encoders,2021,3.6465664661499535e-05,2
W3170644058,"“Call me sexist, but...” : Revisiting Sexism Detection Using Psychological Scales and Adversarial Samples",2021,3.645755619355184e-05,2
W4385574176,DuQM: A Chinese Dataset of Linguistically Perturbed Natural Questions for Evaluating the Robustness of Question Matching Models,2022,3.6446029051350304e-05,2
W3010763821,Enhanced attentive convolutional neural networks for sentence pair modeling,2020,3.644403287285073e-05,2
W3011150943,Coarse and Fine Granularity Graph Reasoning for Interpretable Multi-Hop Question Answering,2020,3.6441707272791283e-05,2
W3091759883,A university map of course knowledge,2020,3.6435356195583424e-05,2
W3111514949,Traditional IR rivals neural models on the MS~MARCO Document Ranking Leaderboard.,2020,3.6434415821455404e-05,2
W3180942591,AutoBERT-Zero: Evolving BERT Backbone from Scratch,2022,3.6430186991375524e-05,2
W4385570181,Prompt Discriminative Language Models for Domain Adaptation,2023,3.640283888698841e-05,2
W4388486466,BioPRO: Context-Infused Prompt Learning for Biomedical Entity Linking,2023,3.640283888698841e-05,2
W4393160078,Large Language Models Are Clinical Reasoners: Reasoning-Aware Diagnosis Framework with Prompt-Generated Rationales,2024,3.640283888698841e-05,2
W4391093854,Autocompletion of Chief Complaints in the Electronic Health Records using Large Language Models,2023,3.640283888698841e-05,2
W3100507548,"BERT Knows Punta Cana is not just beautiful, it’s gorgeous: Ranking Scalar Adjectives with Contextualised Representations",2020,3.639814277189527e-05,2
W4386566755,What happens before and after: Multi-Event Commonsense in Event Coreference Resolution,2023,3.638877472050429e-05,2
W3214405796,Multi-Vector Models with Textual Guidance for Fine-Grained Scientific Document Similarity,2022,3.6381085140486305e-05,2
W4389519087,Make Every Example Count: On the Stability and Utility of Self-Influence for Learning from Noisy NLP Datasets,2023,3.6381085140486305e-05,2
W4385570989,Unsupervised Melody-to-Lyrics Generation,2023,3.637757532392035e-05,2
W4401847921,A scoping review of large language model based approaches for information extraction from radiology reports,2024,3.637757532392035e-05,2
W4392384650,Let the LLMs Talk: Simulating Human-to-Human Conversational QA via Zero-Shot LLM-to-LLM Interactions,2024,3.637757532392035e-05,2
W4281673407,TM-BERT: A Twitter Modified BERT for Sentiment Analysis on Covid-19 Vaccination Tweets,2022,3.637757532392035e-05,2
W4378635602,Generating risk response measures for subway construction by fusion of knowledge and deep learning,2023,3.637757532392035e-05,2
W4399476954,Automatic question-answer pairs generation using pre-trained large language models in higher education,2024,3.637757532392035e-05,2
W4366439832,A novel self-attention enriching mechanism for biomedical question answering,2023,3.637757532392035e-05,2
W4404555905,AECR: Automatic attack technique intelligence extraction based on fine-tuned large language model,2024,3.637757532392035e-05,2
W4292939148,Data-Centric and Model-Centric Approaches for Biomedical Question Answering,2022,3.637757532392035e-05,2
W4393342165,A Survey on Automatic Generation of Figurative Language: From Rule-based Systems to Large Language Models,2024,3.637757532392035e-05,2
W4403909032,Quo Vadis ChatGPT? From large language models to Large Knowledge Models,2024,3.637757532392035e-05,2
W4400724805,"The potential and pitfalls of using a large language model such as ChatGPT, GPT-4, or LLaMA as a clinical assistant",2024,3.637757532392035e-05,2
W4389523811,Look-back Decoding for Open-Ended Text Generation,2023,3.637757532392035e-05,2
W4386847924,Rethinking Label Smoothing on Multi-Hop Question Answering,2023,3.637757532392035e-05,2
W4392902780,Forgetting Private Textual Sequences in Language Models Via Leave-One-Out Ensemble,2024,3.637757532392035e-05,2
W4385573179,Forging Multiple Training Objectives for Pre-trained Language Models via Meta-Learning,2022,3.637757532392035e-05,2
W4389519117,Don’t Trust ChatGPT when your Question is not in English: A Study of Multilingual Abilities and Types of LLMs,2023,3.637757532392035e-05,2
W4319986894,Dialogue Logic Aware and Key Utterance Decoupling Model for Multi-Party Dialogue Reading Comprehension,2023,3.637757532392035e-05,2
W4313563595,Data Augmentation for Improving Emotion Recognition in Software Engineering Communication,2022,3.637757532392035e-05,2
W4387143043,Zero-shot Learning for Named Entity Recognition in Software Specification Documents,2023,3.637757532392035e-05,2
W4385571674,Do Models Really Learn to Follow Instructions? An Empirical Study of Instruction Tuning,2023,3.637757532392035e-05,2
W3134687547,Information to Wisdom: Commonsense Knowledge Extraction and Compilation,2021,3.636944147790606e-05,2
W3211641885,HypoGen: Hyperbole Generation with Commonsense and Counterfactual Knowledge,2021,3.6363444339268576e-05,2
W4281660701,Mokey,2022,3.636289024368396e-05,2
W4320024180,Large-Scale Knowledge Synthesis and Complex Information Retrieval from Biomedical Documents,2022,3.636272940706913e-05,2
W4389523933,CAR: Conceptualization-Augmented Reasoner for Zero-Shot Commonsense Question Answering,2023,3.635532314079351e-05,2
W4285252640,On the Calibration of Pre-trained Language Models using Mixup Guided by Area Under the Margin and Saliency,2022,3.635182829738008e-05,2
W2952744660,Theoretical Limitations of Self-Attention in Neural Sequence Models,2020,3.6346932241930536e-05,2
W3116152597,Classifier Probes May Just Learn from Linear Context Features,2020,3.6315974081188655e-05,2
W4389524581,Can Retriever-Augmented Language Models Reason? The Blame Game Between the Retriever and the Language Model,2023,3.631344552149218e-05,2
W3214374241,The Power of Selecting Key Blocks with Local Pre-ranking for Long Document Information Retrieval,2022,3.631344552149218e-05,2
W3035487250,"“Who said it, and Why?” Provenance for Natural Language Claims",2020,3.630819546711278e-05,2
W3160106041,Elbert: Fast Albert with Confidence-Window Based Early Exit,2021,3.630076269434536e-05,2
W4285606364,Interpretable AMR-Based Question Decomposition for Multi-hop Question Answering,2022,3.628112060025252e-05,2
W4385488681,GLQA: A Generation-based Method for Legal Question Answering,2023,3.628112060025252e-05,2
W4389519321,Empower Large Language Model to Perform Better on Industrial Domain-Specific Question Answering,2023,3.628112060025252e-05,2
W4308366892,Improving Biomedical ReQA With Consistent NLI-Transfer and Post-Whitening,2022,3.628112060025252e-05,2
W4385570732,Improved Logical Reasoning of Language Models via Differentiable Symbolic Programming,2023,3.628112060025252e-05,2
W3120588017,Reddit entity linking dataset,2021,3.628112060025252e-05,2
W3182653761,Mining Numbers in Text: A Survey,2021,3.628112060025252e-05,2
W3212187545,Does BERT Understand Idioms? A Probing-Based Empirical Study of BERT Encodings of Idioms,2021,3.628112060025252e-05,2
W4226150360,ALP: Data Augmentation Using Lexicalized PCFGs for Few-Shot Text Classification,2022,3.628112060025252e-05,2
W4390916709,BERT-CNN based evidence retrieval and aggregation for Chinese legal multi-choice question answering,2024,3.628112060025252e-05,2
W4392956390,Supervised Contrast Learning Text Classification Model Based on Data Quality Augmentation,2024,3.628112060025252e-05,2
W4393864958,Evaluation and Analysis of Large Language Models for Clinical Text Augmentation and Generation,2024,3.628112060025252e-05,2
W4385573520,SparseAdapter: An Easy Approach for Improving the Parameter-Efficiency of Adapters,2022,3.628112060025252e-05,2
W4399353257,Pre-trained language models in medicine: A survey,2024,3.628112060025252e-05,2
W4288781262,Adversarial Training for Fake News Classification,2022,3.628112060025252e-05,2
W4390403247,Fine-tuning Large Language Models for Rare Disease Concept Normalization,2023,3.628112060025252e-05,2
W3176899693,Effective Batching for Recurrent Neural Network Grammars,2021,3.628112060025252e-05,2
W4386566516,How Many Data Samples is an Additional Instruction Worth?,2023,3.628064168725468e-05,2
W3034751553,Encoding History with Context-aware Representation Learning for Personalized Search,2020,3.627735919317771e-05,2
W4285171787,Right for the Right Reason: Evidence Extraction for Trustworthy Tabular Reasoning,2022,3.626924991049417e-05,2
W4409385489,A comprehensive survey on integrating large language models with knowledge-based methods,2025,3.6267872805440345e-05,2
W4285270385,Sentence-aware Contrastive Learning for Open-Domain Passage Retrieval,2022,3.6244342365200535e-05,2
W3022518881,Probing the Probing Paradigm: Does Probing Accuracy Entail Task Relevance?,2020,3.62381987742435e-05,2
W2945972899,Fixed That for You: Generating Contrastive Claims with Semantic Edits,2019,3.622892217189612e-05,2
W4285308960,DuReadervis: A : A Chinese Dataset for Open-domain Document Visual Question Answering,2022,3.622675288465726e-05,2
W3157428592,Rethinking Search: Making Experts out of Dilettantes,2021,3.621688046356069e-05,2
W3111005895,Addressing machine learning concept drift reveals declining vaccine sentiment during the COVID-19 pandemic,2020,3.620283072159948e-05,2
W4385573400,Inferring Implicit Relations in Complex Questions with Language Models,2022,3.6201449259748734e-05,2
W4385284874,Data Ambiguity Profiling for the Generation of Training Examples,2023,3.619801374438004e-05,2
W4285121883,FORTAP: Using Formulas for Numerical-Reasoning-Aware Table Pretraining,2022,3.619801374438004e-05,2
W4312905556,Transformers for tabular data representation,2022,3.619801374438004e-05,2
W4321242712,Evaluating Deep Learning Techniques for Natural Language Inference,2023,3.619481900539184e-05,2
W4392909875,BDMMT: Backdoor Sample Detection for Language Models Through Model Mutation Testing,2024,3.619481900539184e-05,2
W4285254085,Improving the Adversarial Robustness of NLP Models by Information Bottleneck,2022,3.619481900539184e-05,2
W3113677131,A Graph Reasoning Network for Multi-turn Response Selection via Customized Pre-training,2021,3.619481900539184e-05,2
W4385574083,Expose Backdoors on the Way: A Feature-Based Efficient Defense against Textual Backdoor Attacks,2022,3.619481900539184e-05,2
W4400587428,CBAs: Character-level Backdoor Attacks against Chinese Pre-trained Language Models,2024,3.619481900539184e-05,2
W4385567096,Does Your Model Classify Entities Reasonably? Diagnosing and Mitigating Spurious Correlations in Entity Typing,2022,3.619481900539184e-05,2
W4317738119,A Textual Backdoor Defense Method Based on Deep Feature Classification,2023,3.619481900539184e-05,2
W4393325714,Leverage NLP Models Against Other NLP Models: Two Invisible Feature Space Backdoor Attacks,2024,3.619481900539184e-05,2
W4402034088,Backdoor Attacks with Input-Unique Triggers in NLP,2024,3.619481900539184e-05,2
W4392904068,NWS: Natural Textual Backdoor Attacks Via Word Substitution,2024,3.619481900539184e-05,2
W3041304706,ProtTrans: Towards Cracking the Language of Life's Code Through Self-Supervised Deep Learning and High Performance Computing.,2021,3.618832172060183e-05,2
W4385265580,Grouped Contrastive Learning of Self-supervised Sentence Representation,2023,3.618292450393234e-05,2
W3118184560,Learning Dense Representations of Phrases at Scale,2020,3.6171878733846846e-05,2
W4285227756,Proceedings of the 1st Workshop on Semiparametric Methods in NLP: Decoupling Logic from Knowledge,2022,3.616147684588551e-05,2
W2979300423,Real Life Application of a Question Answering System Using BERT Language Model,2019,3.613537956840117e-05,2
W3119821914,Improving Sequence-to-Sequence Pre-training via Sequence Span Rewriting,2021,3.6132932813769396e-05,2
W4385570901,Self-Evolution Learning for Discriminative Language Model Pretraining,2023,3.6132932813769396e-05,2
W3215639742,Learning Fine-Grained Fact-Article Correspondence in Legal Cases,2021,3.612194263452303e-05,2
W4385330715,Information extraction from weakly structured radiological reports with natural language queries,2023,3.6117436619073e-05,2
W4391352835,Bidirectional Encoder Representations from Transformers in Radiology: A Systematic Review of Natural Language Processing Applications,2024,3.6117436619073e-05,2
W4385574068,Facilitating Contrastive Learning of Discourse Relational Senses by Exploiting the Hierarchy of Sense Relations,2022,3.611714757001722e-05,2
W4385570119,WhitenedCSE: Whitening-based Contrastive Learning of Sentence Embeddings,2023,3.611714757001722e-05,2
W4285134704,Model Distillation for Faithful Explanations of Medical Code Predictions,2022,3.611714757001722e-05,2
W4389520739,QA-NatVer: Question Answering for Natural Logic-based Fact Verification,2023,3.611714757001722e-05,2
W4385572096,BOLT: Fast Energy-based Controlled Text Generation with Tunable Biases,2023,3.611714757001722e-05,2
W4287887329,Contrastive Data and Learning for Natural Language Processing,2022,3.611714757001722e-05,2
W4389519126,OssCSE: Overcoming Surface Structure Bias in Contrastive Learning for Unsupervised Sentence Embedding,2023,3.611714757001722e-05,2
W4385571485,Composition-contrastive Learning for Sentence Embeddings,2023,3.611714757001722e-05,2
W4285202171,Rare Tokens Degenerate All Tokens: Improving Neural Text Generation via Adaptive Gradient Gating for Rare Token Embeddings,2022,3.611714757001722e-05,2
W4389524150,Ditto: A Simple and Efficient Approach to Improve Sentence Embeddings,2023,3.611714757001722e-05,2
W4365514966,A distributable German clinical corpus containing cardiovascular clinical routine doctor’s letters,2023,3.6100180513194964e-05,2
W4383678258,Efficient Domain Adaptation of Sentence Embeddings Using Adapters,2023,3.609895659264245e-05,2
W4281650060,Specialized document embeddings for aspect-based similarity of research papers,2022,3.609895659264245e-05,2
W4282967944,Prediction as a basis for skilled reading: insights from modern language models,2022,3.609749265500158e-05,2
W3153233475,Data-Efficient Pretraining via Contrastive Self-Supervision,2020,3.6092955536121215e-05,2
W4200313831,"Question Answering Survey: Directions, Challenges, Datasets, Evaluation Matrices",2021,3.607853632912145e-05,2
W3115393336,I Know What You Asked: Graph Path Learning using AMR for Commonsense Reasoning,2020,3.607455792872772e-05,2
W2971569798,"How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings",2019,3.607096385883022e-05,2
W3176807265,Inspecting the concept knowledge graph encoded by modern language models,2021,3.605011033414132e-05,2
W3203869270,Narrative Question Answering with Cutting-Edge Open-Domain QA Techniques: A Comprehensive Study,2021,3.6046873414202094e-05,2
W4403603005,Health Care Language Models and Their Fine-Tuning for Information Extraction: Scoping Review,2024,3.6046873414202094e-05,2
W4389518770,Discovering Universal Geometry in Embeddings with ICA,2023,3.6046873414202094e-05,2
W4386566646,Investigating Multi-source Active Learning for Natural Language Inference,2023,3.6046873414202094e-05,2
W4285146641,Towards Improving Selective Prediction Ability of NLP Systems,2022,3.6046873414202094e-05,2
W4405105409,CPLLM: Clinical prediction with large language models,2024,3.6046873414202094e-05,2
W4403968649,Developing healthcare language model embedding spaces,2024,3.6046873414202094e-05,2
W4389518681,Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation,2023,3.6046873414202094e-05,2
W4394824046,Triple alignment-enhanced complex question answering over knowledge bases,2024,3.6046873414202094e-05,2
W4223549958,The HoPE Model Architecture: a Novel Approach to Pregnancy Information Retrieval Based on Conversational Agents,2022,3.6046873414202094e-05,2
W4386390787,A template-based approach for question answering over knowledge bases,2023,3.6046873414202094e-05,2
W3174099131,Learning to Generate Questions by Learning to Recover Answer-containing Sentences,2021,3.6024835863110205e-05,2
W3120355935,Baleen: Robust Multi-Hop Reasoning at Scale via Condensed Retrieval,2021,3.602260772055666e-05,2
W3153069173,A Graph-guided Multi-round Retrieval Method for Conversational Open-domain Question Answering,2021,3.5992871785513865e-05,2
W4385565143,XMD: An End-to-End Framework for Interactive Explanation-Based Debugging of NLP Models,2023,3.598298781800652e-05,2
W3176703834,Reliability Testing for Natural Language Processing Systems,2021,3.598298781800652e-05,2
W4282916217,JiuZhang: A Chinese Pre-trained Language Model for Mathematical Problem Understanding,2022,3.598298781800652e-05,2
W3195729941,"Accurate, yet inconsistent? Consistency Analysis on Language Understanding Models",2021,3.598298781800652e-05,2
W4385569878,DISCO: Distilling Counterfactuals with Large Language Models,2023,3.598298781800652e-05,2
W4365802824,L2QA: Long Legal Article Question Answering with Cascaded Key Segment Learning,2023,3.598298781800652e-05,2
W4396654496,Oversampling effect in pretraining for bidirectional encoder representations from transformers (BERT) to localize medical BERT and enhance biomedical BERT,2024,3.598298781800652e-05,2
W3172076499,Automatic Construction of Evaluation Suites for Natural Language Generation Datasets,2021,3.598298781800652e-05,2
W4285123797,Tracing Origins: Coreference-aware Machine Reading Comprehension,2022,3.598298781800652e-05,2
W3185329530,Information asymmetry in Wikipedia across different languages: A statistical analysis,2021,3.598298781800652e-05,2
W4287854320,KroneckerBERT: Significant Compression of Pre-trained Language Models Through Kronecker Decomposition and Knowledge Distillation,2022,3.598298781800652e-05,2
W4368353189,Towards Practical Few-shot Federated NLP,2023,3.598298781800652e-05,2
W4288051127,A knowledge inference model for question answering on an incomplete knowledge graph,2022,3.598298781800652e-05,2
W4287887774,ZusammenQA: Data Augmentation with Specialized Models for Cross-lingual Open-retrieval Question Answering System,2022,3.598298781800652e-05,2
W3121735664,Detecting Stance in Media on Global Warming,2020,3.598298781800652e-05,2
W4206962558,Question answering with deep neural networks for semi-structured heterogeneous genealogical knowledge graphs,2022,3.598298781800652e-05,2
W4389524398,Tree of Clarifications: Answering Ambiguous Questions with Retrieval-Augmented Large Language Models,2023,3.595865699736883e-05,2
W4385679821,Analyzing Leakage of Personally Identifiable Information in Language Models,2023,3.5938069379906165e-05,2
W3206379359,Improving Multi-Party Dialogue Discourse Parsing via Domain Integration,2021,3.593657343721098e-05,2
W4220998098,Multilingual multi-aspect explainability analyses on machine reading comprehension models,2022,3.5932930828926315e-05,2
W4385573998,MICO: A Multi-alternative Contrastive Learning Framework for Commonsense Knowledge Representation,2022,3.593027596095433e-05,2
W4385571204,FolkScope: Intention Knowledge Graph Construction for E-commerce Commonsense Discovery,2023,3.593027596095433e-05,2
W4392745350,Question-Directed Reasoning With Relation-Aware Graph Attention Network for Complex Question Answering Over Knowledge Graph,2024,3.5925959237436816e-05,2
W4389520167,RobustEmbed: Robust Sentence Embeddings Using Self-Supervised Contrastive Pre-Training,2023,3.592465749104535e-05,2
W4389747880,Zero-Shot Learners for Natural Language Understanding via a Unified Multiple-Choice Perspective,2023,3.592465749104535e-05,2
W4385571301,Mind the Biases: Quantifying Cognitive Biases in Language Model Prompting,2023,3.592465749104535e-05,2
W4287854436,LMTurk: Few-Shot Learners as Crowdsourcing Workers in a Language-Model-as-a-Service Framework,2022,3.592465749104535e-05,2
W4394009970,SEBGM: Sentence Embedding Based on Generation Model with multi-task learning,2024,3.592465749104535e-05,2
W4389001184,A survey of the recent trends in deep learning for literature based discovery in the biomedical domain,2023,3.592465749104535e-05,2
W4385573071,Balanced Adversarial Training: Balancing Tradeoffs between Fickleness and Obstinacy in NLP Models,2022,3.592465749104535e-05,2
W4290599668,Comparison of Pretraining Models and Strategies for Health-Related Social Media Text Classification,2022,3.592465749104535e-05,2
W4221166604,UCTopic: Unsupervised Contrastive Learning for Phrase Representations and Topic Mining,2022,3.592465749104535e-05,2
W4385572248,RL4F: Generating Natural Language Feedback with Reinforcement Learning for Repairing Model Outputs,2023,3.592465749104535e-05,2
W4394911776,Fine-Tuning GPT on Biomedical NLP Tasks: An Empirical Evaluation,2024,3.592465749104535e-05,2
W3105313172,Adapting Open Domain Fact Extraction and Verification to COVID-FACT through In-Domain Language Modeling,2020,3.592465749104535e-05,2
W4385567664,UnifieR: A Unified Retriever for Large-Scale Retrieval,2023,3.592465749104535e-05,2
W4285744810,A BERT-based ensemble learning approach for the BioCreative VII challenges: full-text chemical identification and multi-label classification in PubMed articles,2022,3.592465749104535e-05,2
W4386566791,PECO: Examining Single Sentence Label Leakage in Natural Language Inference Datasets through Progressive Evaluation of Cluster Outliers,2023,3.592465749104535e-05,2
W4384643961,AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity Using Contrastive Learning and Structured Knowledge,2023,3.59230174662756e-05,2
W4385570645,A Length-Extrapolatable Transformer,2023,3.591282707924887e-05,2
W4385570359,Towards Robust Ranker for Text Retrieval,2023,3.591282707924887e-05,2
W4284691483,ArchivalQA,2022,3.591282707924887e-05,2
W4385573063,Tiny-NewsRec: Effective and Efficient PLM-based News Recommendation,2022,3.5898371849130305e-05,2
W4383875393,The defeat of the Winograd Schema Challenge,2023,3.5898150090681895e-05,2
W4386566918,"“John is 50 years old, can his son be 65?” Evaluating NLP Models’ Understanding of Feasibility",2023,3.5898150090681895e-05,2
W3173482217,LRC-BERT: Latent-representation Contrastive Knowledge Distillation for Natural Language Understanding,2021,3.589766392930976e-05,2
W4385572787,EasyNLP: A Comprehensive and Easy-to-use Toolkit for Natural Language Processing,2022,3.5896984286449685e-05,2
W4386374572,Improving task generalization via unified schema prompt,2023,3.587118802466427e-05,2
W4285819142,A Survey of Pretrained Language Models,2022,3.587118802466427e-05,2
W4386566474,A Survey on Dynamic Neural Networks for Natural Language Processing,2023,3.587118802466427e-05,2
W4287888019,Probing via Prompting,2022,3.586877490781966e-05,2
W3154790171,Measuring and Improving Faithfulness of Attention in Neural Machine Translation,2021,3.586877490781966e-05,2
W2887386650,Read + Verify: Machine Reading Comprehension with Unanswerable Questions,2018,3.586434324503438e-05,2
W2994846609,Curriculum Learning Strategies for IR,2020,3.5836952704919993e-05,2
W4391644728,Investigating the Impact of Prompt Engineering on the Performance of Large Language Models for Standardizing Obstetric Diagnosis Text: Comparative Study,2024,3.582199611559368e-05,2
W4382239863,Visually Grounded Commonsense Knowledge Acquisition,2023,3.582199611559368e-05,2
W4389523929,Vera: A General-Purpose Plausibility Estimation Model for Commonsense Statements,2023,3.582199611559368e-05,2
W4361008252,Accurate and Reliable Classification of Unstructured Reports on Their Diagnostic Goal Using BERT Models,2023,3.581779564257651e-05,2
W4385570792,MVP: Multi-task Supervised Pre-training for Natural Language Generation,2023,3.581779564257651e-05,2
W4287888899,LM-CORE: Language Models with Contextually Relevant External Knowledge,2022,3.58174217575473e-05,2
W3177101259,Empowering Language Understanding with Counterfactual Reasoning,2021,3.581372545486886e-05,2
W3175160511,SKR-QA: Semantic ranking and knowledge revise for multi-choice question answering,2021,3.579522064341825e-05,2
W4385570124,"On Isotropy, Contextualization and Learning Dynamics of Contrastive-based Sentence Representation Learning",2023,3.578119395157729e-05,2
W4385571490,Are Synonym Substitution Attacks Really Synonym Substitution Attacks?,2023,3.577658819952852e-05,2
W3135857201,PharmKE: Knowledge Extraction Platform for Pharmaceutical Texts Using Transfer Learning,2023,3.577658819952852e-05,2
W3173032467,Unsupervised Document Expansion for Information Retrieval with Stochastic Text Generation,2021,3.577658819952852e-05,2
W4385570914,Modeling Adversarial Attack on Pre-trained Language Models as Sequential Decision Making,2023,3.577658819952852e-05,2
W4386576644,Using Punctuation as an Adversarial Attack on Deep Learning-Based NLP Systems: An Empirical Study,2023,3.577658819952852e-05,2
W3209492300,Bridge the Gap Between CV and NLP! A Gradient-based Textual Adversarial Attack Framework,2023,3.577658819952852e-05,2
W4386566751,Step by Step Loss Goes Very Far: Multi-Step Quantization for Adversarial Text Attacks,2023,3.577658819952852e-05,2
W4385573938,Two is Better than Many? Binary Classification as an Effective Approach to Multi-Choice Question Answering,2022,3.5771054504978574e-05,2
W3186727973,"AStarTwice at SemEval-2021 Task 5: Toxic Span Detection Using RoBERTa-CRF, Domain Specific Pre-Training and Self-Training",2021,3.574917280960215e-05,2
W3173556213,Style is NOT a single variable: Case Studies for Cross-Stylistic Language Understanding,2021,3.574917280960215e-05,2
W3203138619,Exploring Data and Model Poisoning Attacks to Deep Learning-Based NLP Systems,2021,3.574230233508511e-05,2
W4224313980,EvidenceNet: Evidence Fusion Network for Fact Verification,2022,3.573454383280152e-05,2
W3175870271,A Closer Look at How Fine-tuning Changes BERT,2022,3.573454383280152e-05,2
W4381715962,A Transformer-Based Model Trained on Large Scale Claims Data for Prediction of Severe COVID-19 Disease Progression,2023,3.573454383280152e-05,2
W4382541143,A shared linguistic space for transmitting our thoughts from brain to brain in natural conversations,2023,3.572907888415807e-05,2
W4386796175,Grammatical cues to subjecthood are redundant in a majority of simple clauses across languages,2023,3.571430784055333e-05,2
W3020482686,Self-Attention Attribution: Interpreting Information Interactions Inside Transformer,2020,3.570052371306978e-05,2
W4389520067,DistillCSE: Distilled Contrastive Learning for Sentence Embeddings,2023,3.5696168832346194e-05,2
W4385570610,MVP-Tuning: Multi-View Knowledge Retrieval with Prompt Tuning for Commonsense Reasoning,2023,3.569550263512645e-05,2
W4327644099,CoSPLADE: Contextualizing SPLADE for Conversational Information Retrieval,2023,3.569550263512645e-05,2
W3204846429,Revisiting Self-training for Few-shot Learning of Language Model,2021,3.569550263512645e-05,2
W4397001891,Acquiring and modeling abstract commonsense knowledge via conceptualization,2024,3.569550263512645e-05,2
W4384828687,SPRINT: A Unified Toolkit for Evaluating and Demystifying Zero-shot Neural Sparse Retrieval,2023,3.569550263512645e-05,2
W3199359833,Efficient Domain Adaptation of Language Models via Adaptive Tokenization,2021,3.569550263512645e-05,2
W3120014137,Reader-Guided Passage Reranking for Open-Domain Question Answering,2021,3.568558361625902e-05,2
W2985638129,Book QA: Stories of Challenges and Opportunities,2019,3.56838059861582e-05,2
W3115231918,Cross-lingual Machine Reading Comprehension with Language Branch Knowledge Distillation,2020,3.5668255746694694e-05,2
W4393161039,SciEval: A Multi-Level Large Language Model Evaluation Benchmark for Scientific Research,2024,3.566073994368007e-05,2
W4386566629,On Robustness of Prompt-based Semantic Parsing with Large Pre-trained Language Model: An Empirical Study on Codex,2023,3.566073994368007e-05,2
W4372219079,Sentiment spin: Attacking financial sentiment with GPT-3,2023,3.566073994368007e-05,2
W4389521054,Batch Prompting: Efficient Inference with Large Language Model APIs,2023,3.566073994368007e-05,2
W4404918643,A Survey on Model Compression for Large Language Models,2024,3.566073994368007e-05,2
W3102589552,Detecting Media Bias in News Articles using Gaussian Bias Distributions,2020,3.565915393384276e-05,2
W4320002848,Electric Power Audit Text Classification With Multi-Grained Pre-Trained Language Model,2023,3.565915393384276e-05,2
W3117745048,FACE-KEG: Fact Checking Explained using KnowledgE Graphs,2021,3.565915393384276e-05,2
W4313591157,LiDA: Language-Independent Data Augmentation for Text Classification,2023,3.565915393384276e-05,2
W4389519518,Aligning Large Language Models through Synthetic Feedback,2023,3.565915393384276e-05,2
W4387809898,Benchmarking the Generation of Fact Checking Explanations,2023,3.565915393384276e-05,2
W4385571813,Prompt to be Consistent is Better than Self-Consistent? Few-Shot and Zero-Shot Fact Verification with Pre-trained Language Models,2023,3.565915393384276e-05,2
W3172931322,TuringAdvice: A Generative and Dynamic Evaluation of Language Use,2021,3.5657223607805524e-05,2
W4285278721,Structural Characterization for Dialogue Disentanglement,2022,3.565014281633022e-05,2
W3154165903,On the evolution of syntactic information encoded by BERT’s contextualized representations,2021,3.5638647762620656e-05,2
W3183866186,A Collaborative AI-Enabled Pretrained Language Model for AIoT Domain Question Answering,2021,3.5625228479311315e-05,2
W4385570071,Better Zero-Shot Reasoning with Self-Adaptive Prompting,2023,3.5625228479311315e-05,2
W4285288514,Can Pre-trained Language Models Interpret Similes as Smart as Human?,2022,3.561324662832197e-05,2
W3088056511,What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams,2020,3.560061509176372e-05,2
W4313420283,Generating knowledge aware explanation for natural language inference,2022,3.559349176378191e-05,2
W4385572466,Masked Latent Semantic Modeling: an Efficient Pre-training Alternative to Masked Language Modeling,2023,3.5574979259938176e-05,2
W4389523748,A surprisal oracle for active curriculum language modeling,2023,3.5574979259938176e-05,2
W4385571531,How to Plant Trees in Language Models: Data and Architectural Effects on the Emergence of Syntactic Inductive Biases,2023,3.5574979259938176e-05,2
W4385570848,How poor is the stimulus? Evaluating hierarchical generalization in neural networks trained on child-directed speech,2023,3.5574979259938176e-05,2
W3110453189,Cross-Lingual Passage Re-Ranking With Alignment Augmented Multilingual BERT,2020,3.556373859297308e-05,2
W3204993626,Automated quality assessment of cognitive behavioral therapy sessions through highly contextualized language representations,2021,3.555642002953376e-05,2
W4205105574,Distilling Knowledge for Empathy Detection,2021,3.555642002953376e-05,2
W3210661875,Exploring Generalization Ability of Pretrained Language Models on Arithmetic and Logical Reasoning,2021,3.555597033606334e-05,2
W4385573301,Reduce Catastrophic Forgetting of Dense Retrieval Training with Teleportation Negatives,2022,3.5548882728746265e-05,2
W4385573188,ReSel: N-ary Relation Extraction from Scientific Text and Tables by Learning to Retrieve and Select,2022,3.5548882728746265e-05,2
W4287075683,Self-Supervised Contrastive Learning with Adversarial Perturbations for Defending Word Substitution-based Attacks,2022,3.5541696447916214e-05,2
W4372260073,Bert is Robust! A Case Against Word Substitution-Based Adversarial Attacks,2023,3.5541696447916214e-05,2
W4385573514,Natural Language Deduction with Incomplete Information,2022,3.553911935695571e-05,2
W3171010408,A Proposed Chatbot Framework for COVID-19,2021,3.5538411990632884e-05,2
W4283798026,Weakly Supervised Neuro-Symbolic Module Networks for Numerical Reasoning over Text,2022,3.553578864463752e-05,2
W4296143727,Heterogeneous deep graph convolutional network with citation relational BERT for COVID-19 inline citation recommendation,2022,3.553578864463752e-05,2
W3205668414,Distilling Relation Embeddings from Pretrained Language Models,2021,3.553578864463752e-05,2
W4391404146,Sentiment Analysis in Portuguese Restaurant Reviews: Application of Transformer Models in Edge Computing,2024,3.553578864463752e-05,2
W4317651364,aeroBERT-NER: Named-Entity Recognition for Aerospace Requirements Engineering using BERT,2023,3.553578864463752e-05,2
W4385573733,DEER: Descriptive Knowledge Graph for Explaining Entity Relationships,2022,3.553578864463752e-05,2
W3099976981,Don’t Read Too Much Into It: Adaptive Computation for Open-Domain Question Answering,2020,3.551954596113535e-05,2
W4389523924,CoLLiE: Collaborative Training of Large Language Models in an Efficient Way,2023,3.550948281090993e-05,2
W4391277633,Evaluation of Medium-large Language Models at Zero-shot Closed Book Generative Question Answering,2024,3.550948281090993e-05,2
W4389524379,"The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations",2023,3.550948281090993e-05,2
W3175621180,Bi-Granularity Contrastive Learning for Post-Training in Few-Shot Scene,2021,3.549624303815784e-05,2
W4385572482,Evaluation of ChatGPT on Biomedical Tasks: A Zero-Shot Comparison with Fine-Tuned Generative Transformers,2023,3.5491477500056615e-05,2
W4212867238,Beyond NED,2022,3.5485548433022686e-05,2
W4310130650,Answering Count Questions with Structured Answers from Text,2022,3.5485548433022686e-05,2
W4385572862,Finding Dataset Shortcuts with Grammar Induction,2022,3.548468016768106e-05,2
W4385572608,Plug-and-Play Knowledge Injection for Pre-trained Language Models,2023,3.548468016768106e-05,2
W4385573497,Looking at the Overlooked: An Analysis on the Word-Overlap Bias in Natural Language Inference,2022,3.548468016768106e-05,2
W4385574074,Debiasing Masks: A New Framework for Shortcut Mitigation in NLU,2022,3.548468016768106e-05,2
W3115049126,Intermediate Self-supervised Learning for Machine Translation Quality Estimation,2020,3.546097354166269e-05,2
W4385573185,ConvFinQA: Exploring the Chain of Numerical Reasoning in Conversational Finance Question Answering,2022,3.5449091940087e-05,2
W4281656839,MultiHiertt: Numerical Reasoning over Multi Hierarchical Tabular and Textual Data,2022,3.5449091940087e-05,2
W4385573449,NeuroCounterfactuals: Beyond Minimal-Edit Counterfactuals for Richer Data Augmentation,2022,3.54391740769853e-05,2
W3203595782,Encoder Adaptation of Dense Passage Retrieval for Open-Domain Question Answering,2021,3.54354338008728e-05,2
W4385567371,Open-domain Question Answering via Chain of Reasoning over Heterogeneous Knowledge,2022,3.541810465164568e-05,2
W4385573853,Mixed-modality Representation Learning and Pre-training for Joint Table-and-Text Retrieval in OpenQA,2022,3.541810465164568e-05,2
W4385572733,Retrieval Augmentation for Commonsense Reasoning: A Unified Approach,2022,3.5412931728876804e-05,2
W3198510419,Diagnostics-Guided Explanation Generation,2022,3.5412931728876804e-05,2
W4385567084,Continual Training of Language Models for Few-Shot Learning,2022,3.539655023681205e-05,2
W3173765306,DuReader_robust: A Chinese Dataset Towards Evaluating Robustness and Generalization of Machine Reading Comprehension in Real-World Applications,2021,3.5390862152124064e-05,2
W2988152053,Dice Loss for Data-imbalanced NLP Tasks,2019,3.537657546317445e-05,2
W4385573364,Mask-then-Fill: A Flexible and Effective Data Augmentation Framework for Event Extraction,2022,3.537657546317445e-05,2
W4385573612,Proceedings of the 5th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE),2022,3.537657546317445e-05,2
W4385572343,Exploring the Curious Case of Code Prompts,2023,3.534413185605081e-05,2
W3199051766,A Simple Approach to Jointly Rank Passages and Select Relevant Sentences in the OBQA Context,2022,3.5269512883316096e-05,2
W3167021021,KPQA: A Metric for Generative Question Answering Using Keyphrase Weights,2021,3.5269372115821945e-05,2
W4223569930,Using Interactive Feedback to Improve the Accuracy and Explainability of Question Answering Systems Post-Deployment,2022,3.522812587478298e-05,2
W3216092102,Class imbalance in out-of-distribution datasets: Improving the robustness of the TextCNN for the classification of rare cancer types,2021,3.5222628095124226e-05,2
W4385573338,BioReader: a Retrieval-Enhanced Text-to-Text Transformer for Biomedical Literature,2022,3.5222628095124226e-05,2
W4385565410,CREPE: Open-Domain Question Answering with False Presuppositions,2023,3.522011863990646e-05,2
W4285116311,On the Effectiveness of Pre-Trained Language Models for Legal Natural Language Processing: An Empirical Study,2022,3.520898924871402e-05,2
W3213325056,Distantly-Supervised Dense Retrieval Enables Open-Domain Question Answering without Evidence Annotation,2021,3.520898924871402e-05,2
W3212786531,A Model of Cross-Lingual Knowledge-Grounded Response Generation for Open-Domain Dialogue Systems,2021,3.520898924871402e-05,2
W3175910938,Few-Shot Text Ranking with Meta Adapted Synthetic Weak Supervision,2021,3.520898924871402e-05,2
W3171388604,An Empirical Survey of Data Augmentation for Limited Data Learning in NLP,2021,3.518214942225588e-05,2
W3173937547,Modeling Event-Pair Relations in External Knowledge Graphs for Script Reasoning,2021,3.517471732309934e-05,2
W3106346472,Language Through a Prism: A Spectral Approach for Multiscale Language Representations,2020,3.5168446466512984e-05,2
W3206945533,The Irrationality of Neural Rationale Models,2022,3.514023459818888e-05,2
W4285163271,Do Transformer Models Show Similar Attention Patterns to Task-Specific Human Gaze?,2022,3.514023459818888e-05,2
W3102127365,Domain Adversarial Fine-Tuning as an Effective Regularizer,2020,3.511744103084071e-05,2
W3095594087,Effective Unsupervised Domain Adaptation with Adversarially Trained Language Models,2020,3.511744103084071e-05,2
W4283329669,Synwmd: Syntax-Aware Word Mover's Distance for Sentence Similarity Evaluation,2022,3.511659842391275e-05,2
W4385571824,Relational Sentence Embedding for Flexible Semantic Matching,2023,3.511659842391275e-05,2
W3091534907,Interpreting Graph Neural Networks for NLP With Differentiable Edge Masking,2020,3.5108065902981135e-05,2
W4389519287,CLEVA: Chinese Language Models EVAluation Platform,2023,3.5104431531243296e-05,2
W4389518761,Dynosaur: A Dynamic Growth Paradigm for Instruction-Tuning Data Curation,2023,3.5104431531243296e-05,2
W4385571633,LMentry: A Language Model Benchmark of Elementary Language Tasks,2023,3.5104431531243296e-05,2
W4389519042,Do LLMs Understand Social Knowledge? Evaluating the Sociability of Large Language Models with SocKET Benchmark,2023,3.5104431531243296e-05,2
W4385570095,What’s the Meaning of Superhuman Performance in Today’s NLU?,2023,3.5088589471268516e-05,2
W4386576819,Interventional Probing in High Dimensions: An NLI Case Study,2023,3.5088589471268516e-05,2
W4385573517,Collateral facilitation in humans and language models,2022,3.507991960312215e-05,2
W3200092677,How Can the [MASK] Know? The Sources and Limitations of Knowledge in BERT,2021,3.507991960312215e-05,2
W3167831019,Probing for Bridging Inference in Transformer Language Models,2021,3.507991960312215e-05,2
W3103410128,"What does BERT know about books, movies and music? Probing BERT for Conversational Recommendation",2020,3.507991960312215e-05,2
W3004280374,Vec2graph: A Python Library for Visualizing Word Embeddings as Graphs,2020,3.5075436554404726e-05,2
W2909672886,Multi-style Generative Reading Comprehension,2019,3.5059812974669454e-05,2
W3089271032,TernaryBERT: Distillation-aware Ultra-low Bit BERT,2020,3.5052025580852184e-05,2
W3123330721,BERTology Meets Biology: Interpreting Attention in Protein Language Models,2021,3.5052025580852184e-05,2
W3092171032,"Infusing Disease Knowledge into BERT for Health Question Answering, Medical Inference and Disease Name Recognition",2020,3.5052025580852184e-05,2
W3023124213,SegaBERT: Pre-training of Segment-aware BERT for Language Understanding,2020,3.504730300062051e-05,2
W4385572836,Learning to Decompose: Hypothetical Question Decomposition Based on Comparable Texts,2022,3.4965732555507806e-05,2
W4287887938,Generalized Quantifiers as a Source of Error in Multilingual NLU Benchmarks,2022,3.492782091878028e-05,2
W4285161221,Can Unsupervised Knowledge Transfer from Social Discussions Help Argument Mining?,2022,3.492782091878028e-05,2
W4285206788,Knowledge Distillation Meets Few-Shot Learning: An Approach for Few-Shot Intent Classification Within and Across Domains,2022,3.492782091878028e-05,2
W4226003933,Better Language Model with Hypernym Class Prediction,2022,3.492782091878028e-05,2
W3214133644,"Generalising to German Plural Noun Classes, from the Perspective of a Recurrent Neural Network",2021,3.492782091878028e-05,2
W3093681547,XOR QA: Cross-lingual Open-Retrieval Question Answering,2020,3.490258627526548e-05,2
W4386932193,Fake Review Detection via Heterogeneous Graph Attention Network,2023,3.464139029789952e-05,2
W4297678984,Towards Complex Document Understanding By Discrete Reasoning,2022,3.464139029789952e-05,2
W4391520039,Survey of transformers and towards ensemble learning using transformers for natural language processing,2024,3.464139029789952e-05,2
W4285601829,Heterogeneous Ensemble Knowledge Transfer for Training Large Models in Federated Learning,2022,3.464139029789952e-05,2
W4400525285,Combining Large Language Models and Crowdsourcing for Hybrid Human-AI Misinformation Detection,2024,3.464139029789952e-05,2
W4385571310,DSP: Discriminative Soft Prompts for Zero-Shot Entity and Relation Extraction,2023,3.464139029789952e-05,2
W4327571437,Topic-aware multi-hop machine reading comprehension using weighted graphs,2023,3.464139029789952e-05,2
W4378512336,MGeo: Multi-Modal Geographic Language Model Pre-Training,2023,3.464139029789952e-05,2
W4385571407,DMLM: Descriptive Masked Language Modeling,2023,3.464139029789952e-05,2
W4393932132,Adapting transformer-based language models for heart disease detection and risk factors extraction,2024,3.464139029789952e-05,2
W4389520682,DUMB: A Dutch Model Benchmark,2023,3.464139029789952e-05,2
W4410176770,Semantic Processing of Argument Structure during Naturalistic Story Listening: Evidence from Computational Modeling on fMRI,2025,3.464139029789952e-05,2
W4401852331,Enhancing performance of transformer-based models in natural language understanding through word importance embedding,2024,3.464139029789952e-05,2
W4408804730,Context Matters: Understanding Socially Appropriate Affective Responses Via Sentence Embeddings,2025,3.464139029789952e-05,2
W4393200435,Data Augmentation and Large Language Model for Legal Case Retrieval and Entailment,2024,3.464139029789952e-05,2
W4408242371,On the Gap Between AI-Generated and Human-Written Patent Texts,2025,3.464139029789952e-05,2
W4385571498,Generating Better Items for Cognitive Assessments Using Large Language Models,2023,3.464139029789952e-05,2
W3035475567,Simulating a Primary Visual Cortex at the Front of CNNs Improves Robustness to Image Perturbations,2020,3.464139029789952e-05,2
W4396218105,Does More Advice Help? The Effects of Second Opinions in AI-Assisted Decision Making,2024,3.464139029789952e-05,2
W4400869738,A Survey of LLM Datasets: From Autoregressive Model to AI Chatbot,2024,3.464139029789952e-05,2
W4221166361,TrustAL: Trustworthy Active Learning Using Knowledge Distillation,2022,3.464139029789952e-05,2
W4408688975,DAFE: LLM-Based Evaluation Through Dynamic Arbitration for Free-Form Question-Answering,2025,3.464139029789952e-05,2
W4389523793,Navigating the Grey Area: How Expressions of Uncertainty and Overconfidence Affect Language Models,2023,3.464139029789952e-05,2
W4407634256,Teaching a Conversational Agent using Natural Language: Effect on Learning and Engagement,2025,3.464139029789952e-05,2
W4406603177,CARDBiomedBench: A Benchmark for Evaluating Large Language Model Performance in Biomedical Research,2025,3.464139029789952e-05,2
W3183820005,BERT Goes Shopping: Comparing Distributional Models for Product Representations,2021,3.464139029789952e-05,2
W3137983801,Making costly manufacturing smart with transfer learning under limited data: A case study on composites autoclave processing,2021,3.464139029789952e-05,2
W4287855004,Fine-tuning Transformers with Additional Context to Classify Discursive Moves in Mathematics Classrooms,2022,3.464139029789952e-05,2
W4225624948,LPViT: A Transformer Based Model for PCB Image Classification and Defect Detection,2022,3.464139029789952e-05,2
W4385626383,Duplicate Quora Questions Pair Detection using Siamese Bert and Ma-LSTM,2023,3.464139029789952e-05,2
W4407415852,OWL2Vec4OA: Tailoring Knowledge Graph Embeddings for Ontology Alignment,2025,3.464139029789952e-05,2
W4408147356,Detecting AI-Generated Text Using Fine-Tuned Transformers: A Study on Academic Integrity,2025,3.464139029789952e-05,2
W4213243595,A Multi-task Learning Framework for Product Ranking with BERT,2022,3.464139029789952e-05,2
W3155287831,Identifying the Limits of Cross-Domain Knowledge Transfer for Pretrained Models,2022,3.464139029789952e-05,2
W4394828474,"AHAM: Adapt, Help, Ask, Model Harvesting LLMs for Literature Mining",2024,3.464139029789952e-05,2
W4288384170,Learning representations for gene ontology terms by jointly encoding graph structure and textual node descriptors,2022,3.464139029789952e-05,2
W4360765003,Zero-Shot Text Matching for Automated Auditing using Sentence Transformers,2022,3.464139029789952e-05,2
W4406010253,Generative Artificial Intelligence-Based Medical Entity Data Extractor Using Large Language Models,2025,3.464139029789952e-05,2
W4394951779,"Optimclm: Optimizing Clinical Language Models for Predicting Patient Outcomes Via Knowledge Distillation, Pruning and Quantization",2024,3.464139029789952e-05,2
W4391903691,"Introduction to the Minitrack on Diversity, Equity, and Inclusion in Digital Government: Narrowing the Divides",2023,3.464139029789952e-05,2
W4408864216,Using Large Language Models for Natural Language Processing Tasks in Requirements Engineering: A Systematic Guideline,2025,3.464139029789952e-05,2
W4310854123,Transformer Grammars: Augmenting Transformer Language Models with Syntactic Inductive Biases at Scale,2022,3.464139029789952e-05,2
W4312531598,Computational Understanding of Narratives: A Survey,2022,3.464139029789952e-05,2
W4388751616,Fictionalism about Chatbots,2023,3.464139029789952e-05,2
W3167262725,Pre-trained Language Model for Web-scale Retrieval in Baidu Search,2021,3.464139029789952e-05,2
W4389518653,Tunable Soft Prompts are Messengers in Federated Learning,2023,3.464139029789952e-05,2
W4400927874,DPAL-BERT: A Faster and Lighter Question Answering Model,2024,3.464139029789952e-05,2
W4385312233,Biglog: Unsupervised Large-scale Pre-training for a Unified Log Representation,2023,3.464139029789952e-05,2
W4403181807,The Synergy of Clinical Psychology and Affective Computing: Advancements in Emotion Recognition and Therapy,2024,3.464139029789952e-05,2
W4407991112,BERT Mutation: Deep Transformer Model for Masked Uniform Mutation in Genetic Programming,2025,3.464139029789952e-05,2
W4408542627,Structure-Aware Transformer for hyper-relational knowledge graph completion,2025,3.464139029789952e-05,2
W4403048625,Extracting Sentence Embeddings from Pretrained Transformer Models,2024,3.464139029789952e-05,2
W4407943414,Attention-based backdoor attacks against natural language processing models,2025,3.464139029789952e-05,2
W4405075726,A Systematic Comparison Between Open- and Closed-Source Large Language Models in the Context of Generating GDPR-Compliant Data Categories for Processing Activity Records,2024,3.464139029789952e-05,2
W4393156784,STAR: Boosting Low-Resource Information Extraction by Structure-to-Text Data Generation with Large Language Models,2024,3.464139029789952e-05,2
W3105183573,Adversarial Self-Supervised Data-Free Distillation for Text Classification,2020,3.464139029789952e-05,2
W4402034408,Attention-Driven Dropout: A Simple Method to Improve Self-supervised Contrastive Sentence Embeddings,2024,3.464139029789952e-05,2
W4380434506,A Few-Shot Approach to Resume Information Extraction via Prompts,2023,3.464139029789952e-05,2
W4401042387,Assessing Logical Puzzle Solving in Large Language Models: Insights from a Minesweeper Case Study,2024,3.464139029789952e-05,2
W4385363516,Large language models as models of human cognition,2023,3.464139029789952e-05,2
W4393061348,Unlocking maintenance insights in industrial text through semantic search,2024,3.464139029789952e-05,2
W4409825362,Large language models for intelligent RDF knowledge graph construction: results from medical ontology mapping,2025,3.464139029789952e-05,2
W4385573418,Teaching Broad Reasoning Skills for Multi-Step QA by Generating Hard Contexts,2022,3.464139029789952e-05,2
W4388825438,Reinforcement learning from constraints and focal entity shifting in conversational KGQA,2023,3.464139029789952e-05,2
W4389109049,Knowledge-enhanced Agents for Interactive Text Games,2023,3.464139029789952e-05,2
W4407268941,"Enhancing Knowledge Graph Construction: Evaluating with Emphasis on Hallucination, Omission, and Graph Similarity Metrics",2025,3.464139029789952e-05,2
W4387951242,Tale of Two Cs: Computation vs. Communication Scaling for Future Transformers on Future Hardware,2023,3.464139029789952e-05,2
W4394789132,Advancing NLP models with strategic text augmentation: A comprehensive study of augmentation methods and curriculum strategies,2024,3.464139029789952e-05,2
W4385567170,Knowledge Graph Generation From Text,2022,3.464139029789952e-05,2
W4407841165,Sentiment Analysis with Large Language Models Applied to the Federal Reserve Beige Book,2025,3.464139029789952e-05,2
W4385570675,Compounding Geometric Operations for Knowledge Graph Completion,2023,3.464139029789952e-05,2
W4283835457,MIA 2022 Shared Task: Evaluating Cross-lingual Open-Retrieval Question Answering for 16 Diverse Languages,2022,3.464139029789952e-05,2
W4317772742,Handbook of Computational Social Science for Policy,2023,3.464139029789952e-05,2
W4399914009,Fine-grained and coarse-grained contrastive learning for text classification,2024,3.464139029789952e-05,2
W3016564562,Privacy-Preserving Deep Learning NLP Models for Cancer Registries,2020,3.464139029789952e-05,2
W4388676985,Enhancing Medical Text Representation for Lung Diagnosis Prediction Via Knowledge Infusion,2023,3.464139029789952e-05,2
W4385569796,Randomized Smoothing with Masked Inference for Adversarially Robust Text Classifications,2023,3.464139029789952e-05,2
W4390684394,Topics in the Haystack: Enhancing Topic Quality through Corpus Expansion,2024,3.464139029789952e-05,2
W4283815817,Go Wider Instead of Deeper,2022,3.464139029789952e-05,2
W4406460250,SR2ACM: A Methodical Approach for Translating Natural Language Security Requirements to Access Control Model,2024,3.464139029789952e-05,2
W4395469233,Exploring diverse interests of collaborators in smart cities: A topic analysis using LDA and BERT,2024,3.464139029789952e-05,2
W3088199239,Chart-based Zero-shot Constituency Parsing on Multiple Languages,2020,3.464139029789952e-05,2
W4399897292,Privileged representational axes in biological and artificial neural networks,2024,3.464139029789952e-05,2
W4319025279,SelfCCL: Curriculum Contrastive Learning by Transferring Self-Taught Knowledge for Fine-Tuning BERT,2023,3.464139029789952e-05,2
W4407059178,Opportunities to Use Arabic YouTube Comments in Text Mining and Masked Language Modeling,2025,3.464139029789952e-05,2
W4385488503,HSimCSE: Improving Contrastive Learning of Unsupervised Sentence Representation with Adversarial Hard Positives and Dual Hard Negatives,2023,3.464139029789952e-05,2
W4383665117,Resume Shortlisting and Ranking with Transformers,2023,3.464139029789952e-05,2
W4388714782,"The good, the bad, and the ambivalent: Extrapolating affective values for 38,000+ Chinese words via a computational model",2023,3.464139029789952e-05,2
W4391108544,A novel technique using graph neural networks and relevance scoring to improve the performance of knowledge graph-based question answering systems,2024,3.464139029789952e-05,2
W4409626943,Industrial applications of large language models,2025,3.464139029789952e-05,2
W4410215381,Transforming education: tackling the two sigma problem with AI in journal clubs – a proof of concept,2025,3.464139029789952e-05,2
W4385570289,Boosting Text Augmentation via Hybrid Instance Filtering Framework,2023,3.464139029789952e-05,2
W4389524397,Increasing Coverage and Precision of Textual Information in Multilingual Knowledge Graphs,2023,3.464139029789952e-05,2
W4389518889,Conic10K: A Challenging Math Problem Understanding and Reasoning Dataset,2023,3.464139029789952e-05,2
W4399426475,Scope Ambiguities in Large Language Models,2024,3.464139029789952e-05,2
W4313007581,Contrastive Multi-Modal Knowledge Graph Representation Learning,2022,3.464139029789952e-05,2
W4389520046,Elevating Code-mixed Text Handling through Auditory Information of Words,2023,3.464139029789952e-05,2
W4408838056,Large scale summarization using ensemble prompts and in context learning approaches,2025,3.464139029789952e-05,2
W4390754775,Input-oriented demonstration learning for hybrid evidence fact verification,2024,3.464139029789952e-05,2
W4318464561,LAD: Layer-Wise Adaptive Distillation for BERT Model Compression,2023,3.464139029789952e-05,2
W4407045844,Analysis of argument structure constructions in the large language model BERT,2025,3.464139029789952e-05,2
W4408614598,Conversational Explanations: Discussing Explainable AI with Non-AI Experts,2025,3.464139029789952e-05,2
W4408362299,AI Computing Systems for Large Language Models Training,2025,3.464139029789952e-05,2
W4410129427,fastText-Based Siamese Network for Hindi Semantic Textual Similarity,2025,3.464139029789952e-05,2
W4385571760,RQUGE: Reference-Free Metric for Evaluating Question Generation by Answering the Question,2023,3.464139029789952e-05,2
W4399891105,Adaption BERT for Medical Information Processing with ChatGPT and Contrastive Learning,2024,3.464139029789952e-05,2
W4393159663,Contributing Dimension Structure of Deep Feature for Coreset Selection,2024,3.464139029789952e-05,2
W4407268166,K-Bloom: unleashing the power of pre-trained language models in extracting knowledge graph with predefined relations,2025,3.464139029789952e-05,2
W4396577390,MetaMate: Large Language Model to the Rescue of Automated Data Extraction for Educational Systematic Reviews and Meta-analyses,2024,3.464139029789952e-05,2
W4399184154,Optimization techniques for sentiment analysis based on LLM (GPT-3),2024,3.464139029789952e-05,2
W3173134000,Reconstructing Implicit Knowledge with Language Models,2021,3.464139029789952e-05,2
W4389518735,From Words to Wires: Generating Functioning Electronic Devices from Natural Language Descriptions,2023,3.464139029789952e-05,2
W4400928211,MedT2T: An adaptive pointer constrain generating method for a new medical text-to-table task,2024,3.464139029789952e-05,2
W4285279063,CAISA at WASSA 2022: Adapter-Tuning for Empathy Prediction,2022,3.464139029789952e-05,2
W4389520075,From Relevance to Utility: Evidence Retrieval with Feedback for Fact Verification,2023,3.464139029789952e-05,2
W3204121251,ODIST: Open World Classification via Distributionally Shifted Instances,2021,3.464139029789952e-05,2
W4385572478,The Diminishing Returns of Masked Language Models to Science,2023,3.464139029789952e-05,2
W4410486525,Emails by LLMs: A Comparison of Language in AI-Generated and Human-Written Emails,2025,3.464139029789952e-05,2
W4365813230,Siamese Interaction and Fine-Tuning Representation of Chinese Semantic Matching Algorithm Based on RoBERTa-wwm-ext,2023,3.464139029789952e-05,2
W4389519941,Comparing Prompt-Based and Standard Fine-Tuning for Urdu Text Classification,2023,3.464139029789952e-05,2
W3093681740,DeText,2020,3.464139029789952e-05,2
W4400127166,Improving Text Classification with Large Language Model-Based Data Augmentation,2024,3.464139029789952e-05,2
W4410120115,Cross-lingual prompt and knowledge enhancement-based named entity recognition for low-resource electronic medical records,2025,3.464139029789952e-05,2
W4385570771,Lauri Ingman at SemEval-2023 Task 4: A Chain Classifier for Identifying Human Values behind Arguments,2023,3.464139029789952e-05,2
W4392370696,Structural complexity predicts consensus readability in online discussions,2024,3.464139029789952e-05,2
W4224541024,Hierarchical label-wise attention transformer model for explainable ICD coding,2022,3.464139029789952e-05,2
W4385574137,Knowledge informed sustainability detection from short financial texts,2022,3.464139029789952e-05,2
W4404931769,Cluster-Mined Negative Samples for Enhanced Unsupervised Sentence Representation Learning,2024,3.464139029789952e-05,2
W3089073032,Exploring the relationship between social presence and learners’ prestige in MOOC discussion forums using automated content analysis and social network analysis,2020,3.464139029789952e-05,2
W4386892339,Exploring new depths: Applying machine learning for the analysis of student argumentation in chemistry,2023,3.464139029789952e-05,2
W4382119231,Uncertainty-Driven Knowledge Distillation for Language Model Compression,2023,3.464139029789952e-05,2
W4389988752,Zero-shot Bilingual App Reviews Mining with Large Language Models,2023,3.464139029789952e-05,2
W4402265970,FIN2SUM: Advancing AI-Driven Financial Text Summarization with LLMs,2024,3.464139029789952e-05,2
W4401684295,Symbol ungrounding: what the successes (and failures) of large language models reveal about human cognition,2024,3.464139029789952e-05,2
W4313479714,Extraction of knowledge graph of Covid-19 through mining of unstructured biomedical corpora,2023,3.464139029789952e-05,2
W4405745605,Transformer-Based Tool for Automated Fact-Checking: A Pilot Study on Online Health Information (Preprint),2024,3.464139029789952e-05,2
W4375869395,NCL: Textual Backdoor Defense Using Noise-Augmented Contrastive Learning,2023,3.464139029789952e-05,2
W4385571746,DiSCoMaT: Distantly Supervised Composition Extraction from Tables in Materials Science Articles,2023,3.464139029789952e-05,2
W4389829637,A Relation Embedding Assistance Networks for Multi-hop Question Answering,2023,3.464139029789952e-05,2
W4389949263,BioEGRE: a linguistic topology enhanced method for biomedical relation extraction based on BioELECTRA and graph pointer neural network,2023,3.464139029789952e-05,2
W4389519983,Impact of Co-occurrence on Factual Knowledge of Large Language Models,2023,3.464139029789952e-05,2
W3169737649,Clusformer: A Transformer based Clustering Approach to Unsupervised Large-scale Face and Visual Landmark Recognition,2021,3.464139029789952e-05,2
W4408042595,Data transformation of unstructured electroencephalography reports by natural language processing: improving data usability for large-scale epilepsy studies,2025,3.464139029789952e-05,2
W3191132518,Gender Bias and Under-Representation in Natural Language Processing Across Human Languages,2021,3.464139029789952e-05,2
W4391097066,Efficient Classification of Malicious URLs: M-BERT—A Modified BERT Variant for Enhanced Semantic Understanding,2024,3.464139029789952e-05,2
W4378421851,Discourse-Aware Graph Networks for Textual Logical Reasoning,2023,3.464139029789952e-05,2
W4387846571,"Spans, Not Tokens: A Span-Centric Model for Multi-Span Reading Comprehension",2023,3.464139029789952e-05,2
W4205927329,What’s in Your Head? Emergent Behaviour in Multi-Task Transformer Models,2021,3.464139029789952e-05,2
W4407682194,Efficiency and Performance Optimization in Large Language Models through IB Fine-Tuning,2025,3.464139029789952e-05,2
W4287271794,Cooperative Self-training of Machine Reading Comprehension,2022,3.464139029789952e-05,2
W3034257506,An Iterative Multi-Source Mutual Knowledge Transfer Framework for Machine Reading Comprehension,2020,3.464139029789952e-05,2
W4391385091,A knowledge graph-based bio-inspired design approach for knowledge retrieval and reasoning,2024,3.464139029789952e-05,2
W4408925102,Prediction of Chromatographic Retention Time of a Small Molecule from SMILES Representation Using a Hybrid Transformer-LSTM Model,2025,3.464139029789952e-05,2
W4386847948,Ask to Understand: Question Generation for Multi-hop Question Answering,2023,3.464139029789952e-05,2
W4393684362,Understanding Large Language Models : Towards Rigorous and Targeted Interpretability Using Probing Classifiers and Self-Rationalisation,2024,3.464139029789952e-05,2
W4220785642,Greedy-layer pruning: Speeding up transformer models for natural language processing,2022,3.464139029789952e-05,2
W4385571405,Question-Interlocutor Scope Realized Graph Modeling over Key Utterances for Dialogue Reading Comprehension,2023,3.464139029789952e-05,2
W4221081166,Darling: A Web Application for Detecting Disease-Related Biomedical Entity Associations with Literature Mining,2022,3.464139029789952e-05,2
W4406947254,Toward cultural interpretability: A linguistic anthropological framework for describing and evaluating large language models,2025,3.464139029789952e-05,2
W4407079550,Deep Learning-Driven Ontology Learning: A Systematic Mapping Study,2025,3.464139029789952e-05,2
W4306770848,Differentiation in microenterprises,2022,3.464139029789952e-05,2
W4385571952,Enhancing Neural Topic Model with Multi-Level Supervisions from Seed Words,2023,3.464139029789952e-05,2
W4393853326,Generative AI-Based Text Generation Methods Using Pre-Trained GPT 2 Model,2024,3.464139029789952e-05,2
W4393048251,Inclusion in Linguistics,2024,3.464139029789952e-05,2
W4409202420,The BERT Model Family and Encoder-Only Transformers,2025,3.464139029789952e-05,2
W4409019114,Enhancing Language Models via HTML DOM Tree for Text Structure Understanding,2025,3.464139029789952e-05,2
W4410345129,U-Net Encapsulated Transformer for Reducing Dimensionality in Training Large Language Models,2025,3.464139029789952e-05,2
W4225658316,CVSS-BERT: Explainable Natural Language Processing to Determine the Severity of a Computer Security Vulnerability from its Description,2021,3.464139029789952e-05,2
W4409404441,Medical short text classification via Soft Prompt-tuning,2025,3.464139029789952e-05,2
W4382240599,"Relief in Sight? Chatbots, In-baskets, and the Overwhelmed Primary Care Clinician",2023,3.464139029789952e-05,2
W4386566659,DyLoRA: Parameter-Efficient Tuning of Pre-trained Models using Dynamic Search-Free Low-Rank Adaptation,2023,3.464139029789952e-05,2
W4407316294,Linguistic changes in spontaneous speech for detecting Parkinson’s disease using large language models,2025,3.464139029789952e-05,2
W4403865042,Detecting Bias in LLMs' Natural Language Inference Using Metamorphic Testing,2024,3.464139029789952e-05,2
W2984060780,Contextual Text Denoising with Masked Language Model,2019,3.464139029789952e-05,2
W4406776968,The role of meaning in the rivalry of <i>-ity</i> and <i>-ness</i>: evidence from distributional semantics,2025,3.464139029789952e-05,2
W3122244192,Building Interpretable Interaction Trees for Deep NLP Models,2021,3.464139029789952e-05,2
W4407389405,"A Dynamic-Selection-Based, Retrieval-Augmented Generation Framework: Enhancing Multi-Document Question-Answering for Commercial Applications",2025,3.464139029789952e-05,2
W4392895803,Extending the Architecture of Language From a Multimodal Perspective,2024,3.464139029789952e-05,2
W4410506857,Aligning Emotions: A Comparative Analysis of Text and Imagery by European Party Leaders on Instagram,2025,3.464139029789952e-05,2
W4386826892,Semantic-enhanced Contrastive Learning for Session-based Recommendation,2023,3.464139029789952e-05,2
W4406940831,Evaluating Large Language Models for Tax Law Reasoning,2025,3.464139029789952e-05,2
W4400651718,Simple Data Transformations for Mitigating the Syntactic Similarity to Improve Sentence Embeddings at Supervised Contrastive Learning,2024,3.464139029789952e-05,2
W4408519190,Oil Price Volatility Classification and Prediction with Sentiment Analysis: Machine Learning Approach,2025,3.464139029789952e-05,2
W4385571098,Data Curation Alone Can Stabilize In-context Learning,2023,3.464139029789952e-05,2
W4385825586,Fly-Swat or Cannon? Cost-Effective Language Model Choice via Meta-Modeling,2024,3.464139029789952e-05,2
W4205434581,AnomalyAdapters: Parameter-Efficient Multi-Anomaly Task Detection,2022,3.464139029789952e-05,2
W3201012227,Graph-based Retrieval for Claim Verification over Cross-document Evidence,2022,3.464139029789952e-05,2
W4298144575,Semantic reconstruction of continuous language from non-invasive brain recordings,2022,3.464139029789952e-05,2
W4320854797,Mixed Multi-Model Semantic Interaction for Graph-based Narrative Visualizations,2023,3.464139029789952e-05,2
W4402722849,SpikingMiniLM: energy-efficient spiking transformer for natural language understanding,2024,3.464139029789952e-05,2
W4389519950,MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic,2023,3.464139029789952e-05,2
W4393347796,Uncovering Flat and Hierarchical Topics by Community Discovery on Word Co-occurrence Network,2024,3.464139029789952e-05,2
W4408717853,Multi-TuneV: Fine-tuning the fusion of multiple modules for video action recognition,2025,3.464139029789952e-05,2
W4360995184,Slovak Dataset for Multilingual Question Answering,2023,3.464139029789952e-05,2
W3170137791,Posthoc Verification and the Fallibility of the Ground Truth,2022,3.464139029789952e-05,2
W4378509386,WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia,2023,3.464139029789952e-05,2
W4410374560,Sentiment analysis and summarization with ChatGPT: implications for sales prediction,2025,3.464139029789952e-05,2
W4293565917,Improving text classification with transformers and layer normalization,2022,3.464139029789952e-05,2
W4408997033,Fields of the Future: Digital Transformation in Smart Agriculture with Large Language Models and Generative AI,2025,3.464139029789952e-05,2
W4393131999,Privacy-preserving data integration and sharing in multi-party IoT environments: An entity embedding perspective,2024,3.464139029789952e-05,2
W4391653102,MetRoBERTa: Leveraging Traditional Customer Relationship Management Data to Develop a Transit-Topic-Aware Language Model,2024,3.464139029789952e-05,2
W3025047062,Neural Networks-Based Aerodynamic Data Modeling: A Comprehensive Review,2020,3.464139029789952e-05,2
W4385532435,SAKP: A Korean Sentiment Analysis Model via Knowledge Base and Prompt Tuning,2023,3.464139029789952e-05,2
W4385572514,Revealing the Blind Spot of Sentence Encoder Evaluation by HEROS,2023,3.464139029789952e-05,2
W4409688433,Applications and Modeling of Keystroke Logs in Writing Assessments,2025,3.464139029789952e-05,2
W4401555054,"Correctness Comparison of <scp>ChatGPT</scp>‐4, Gemini, Claude‐3, and Copilot for Spatial Tasks",2024,3.464139029789952e-05,2
W4312426142,Context-Free Word Importance Scores for Attacking Neural Networks,2022,3.464139029789952e-05,2
W4409373574,A brief study on evaluation metrics for knowledge graph embeddings,2025,3.464139029789952e-05,2
W4389524114,CarExpert: Leveraging Large Language Models for In-Car Conversational Question Answering,2023,3.464139029789952e-05,2
W4407214653,Re-SciBERT: An Entity-Enriched Language Model to Enhance Biomedical Relation Extraction,2024,3.464139029789952e-05,2
W4409386825,Detecting emergencies in patient portal messages using large language models and knowledge graph-based retrieval-augmented generation,2025,3.464139029789952e-05,2
W4409357852,SemiRALD: A semi-supervised hybrid language model for Robust Anomalous Log Detection,2025,3.464139029789952e-05,2
W4382405173,TABASCO: A transformer based contextualization toolkit,2023,3.464139029789952e-05,2
W4406039094,Temporal knowledge graph completion based on product space and contrastive learning of commonsense,2025,3.464139029789952e-05,2
W4402351653,Anchor Your Embeddings Through the Storm: Mitigating Instance-to-Document Semantic Gap,2024,3.464139029789952e-05,2
W4393199286,Investigating machine learning and natural language processing techniques applied for detecting eating disorders: a systematic literature review,2024,3.464139029789952e-05,2
W4403768141,Multi-Hop Arabic LLM Reasoning in Complex QA,2024,3.464139029789952e-05,2
W4408228388,NLP modeling recommendations for restricted data availability in clinical settings,2025,3.464139029789952e-05,2
W4364368785,Drug–drug interaction extraction‐based system: An <scp>natural language processing</scp> approach,2023,3.464139029789952e-05,2
W4393159433,Prompting Segmentation with Sound Is Generalizable Audio-Visual Source Localizer,2024,3.464139029789952e-05,2
W4404723500,Can Language Models Trained on Written Monologue Learn to Predict Spoken Dialogue?,2024,3.464139029789952e-05,2
W4386566597,Neural Ranking with Weak Supervision for Open-Domain Question Answering : A Survey,2023,3.464139029789952e-05,2
W4409787112,Benchmarking large language models for automated labeling: The case of issue report classification,2025,3.464139029789952e-05,2
W4385570151,CodePrompt: Task-Agnostic Prefix Tuning for Program and Language Generation,2023,3.464139029789952e-05,2
W4387171262,GENEMASK: Fast Pretraining of Gene Sequences to Enable Few-Shot Learning,2023,3.464139029789952e-05,2
W4408955021,Enhancing Radiology Report Interpretation with Large-Scale Language Models: A Two-Stage Fine-Tuning Approach,2025,3.464139029789952e-05,2
W4406771743,A Flexible Knowledge Graph Error Detection Framework Combined with Semantic Information,2025,3.464139029789952e-05,2
W4407839089,stEELlm: An LLM for Generating Semantic Annotations of Tabular Data,2025,3.464139029789952e-05,2
W4367309809,Decoding Prompt Syntax: Analysing its Impact on Knowledge Retrieval in Large Language Models,2023,3.464139029789952e-05,2
W4385572043,Going Beyond Sentence Embeddings: A Token-Level Matching Algorithm for Calculating Semantic Textual Similarity,2023,3.464139029789952e-05,2
W4385532480,Misinformation Detection Using an Ensemble Method with Emphasis on Sentiment and Emotional Analyses,2023,3.464139029789952e-05,2
W4385570483,Petals: Collaborative Inference and Fine-tuning of Large Models,2023,3.464139029789952e-05,2
W4393111197,Automatic Scoring of Metaphor Creativity with Large Language Models,2024,3.464139029789952e-05,2
W4385251138,"Using ChatGPT Standard Prompt Engineering Techniques in Lesson Preparation: Role, Instructions and Seed-Word Prompts",2023,3.464139029789952e-05,2
W4408919020,The Geometry of Concepts: Sparse Autoencoder Feature Structure,2025,3.464139029789952e-05,2
W4385569949,Multilingual Conceptual Coverage in Text-to-Image Models,2023,3.464139029789952e-05,2
W4400255044,Teaching Materials for Reading in a Professional Context to Improve the Reading Skills of English Education Program Students,2024,3.464139029789952e-05,2
W4389520746,APrompt: Attention Prompt Tuning for Efficient Adaptation of Pre-trained Language Models,2023,3.464139029789952e-05,2
W4385573684,Why is Winoground Hard? Investigating Failures in Visuolinguistic Compositionality,2022,3.464139029789952e-05,2
W4379382656,Zero-Shot and Few-Shot Learning With Knowledge Graphs: A Comprehensive Survey,2023,3.464139029789952e-05,2
W4385565162,WeLT: Improving Biomedical Fine-tuned Pre-trained Language Models with Cost-sensitive Learning,2023,3.464139029789952e-05,2
W4224909334,A survey of methods for revealing and overcoming weaknesses of data-driven Natural Language Understanding,2022,3.464139029789952e-05,2
W4410555860,Innovative Techniques for Compressing Large Language Models without Performance Loss,2025,3.464139029789952e-05,2
W4399972440,End-to-end pseudonymization of fine-tuned clinical BERT models,2024,3.464139029789952e-05,2
W4408342914,Automatic evaluation and enhancement of reading strategies in English reading comprehension based on the BERT model,2025,3.464139029789952e-05,2
W4400765516,Harnessing large language models to auto-evaluate the student project reports,2024,3.464139029789952e-05,2
W4385572411,Learning by Analogy: Diverse Questions Generation in Math Word Problem,2023,3.464139029789952e-05,2
W4386798146,ActiveGLAE: A Benchmark for Deep Active Learning with Transformers,2023,3.464139029789952e-05,2
W4385565217,Targeted Data Generation: Finding and Fixing Model Weaknesses,2023,3.464139029789952e-05,2
W4385564928,OpenICL: An Open-Source Framework for In-context Learning,2023,3.464139029789952e-05,2
W4409747196,Enhancing pre-trained language model by answering natural questions for event extraction,2025,3.464139029789952e-05,2
W4407410388,Natural language processing techniques applied to the electronic health record in clinical research and practice - an introduction to methodologies,2025,3.464139029789952e-05,2
W4392637261,"MedRedQA for Medical Consumer Question Answering: Dataset, Tasks, and Neural Baselines",2023,3.464139029789952e-05,2
W4287887915,stce at SemEval-2022 Task 6: Sarcasm Detection in English Tweets,2022,3.464139029789952e-05,2
W4410446500,The “LLM World of Words” English free association norms generated by large language models,2025,3.464139029789952e-05,2
W4377289963,Drug–disease association prediction with literature based multi-feature fusion,2023,3.464139029789952e-05,2
W4406033330,Using transformer-based models and social media posts for heat stroke detection,2025,3.464139029789952e-05,2
W4391873151,Phenomics Assistant: An Interface for LLM-based Biomedical Knowledge Graph Exploration,2024,3.464139029789952e-05,2
W4385573900,monoQA: Multi-Task Learning of Reranking and Answer Extraction for Open-Retrieval Conversational Question Answering,2022,3.464139029789952e-05,2
W4407887224,The Design and Practice of an Enhanced Search for Maritime Transportation Knowledge Graph Based on Semi-Schema Constraints,2025,3.464139029789952e-05,2
W4393166638,"Quality, Accuracy, and Bias in ChatGPT-Based Summarization of Medical Abstracts",2024,3.464139029789952e-05,2
W3015378124,Adversarial Attacks on Time Series,2020,3.464139029789952e-05,2
W4389289000,Sample-based Dynamic Hierarchical Transformer with Layer and Head Flexibility via Contextual Bandit,2023,3.464139029789952e-05,2
W4408159234,Management of psychological emergency cases on social media: A hybrid approach combining knowledge graphs and graph neural networks,2025,3.464139029789952e-05,2
W4366308387,Analyzing Deceptive Opinion Spam Patterns: the Topic Modeling Approach,2022,3.464139029789952e-05,2
W4317423646,Sentence embedding and fine-tuning to automatically identify duplicate bugs,2023,3.464139029789952e-05,2
W3181074959,Effective Sparsification of Neural Networks with Global Sparsity Constraint,2021,3.464139029789952e-05,2
W4390679741,Software Vulnerability Detection with GPT and In-Context Learning,2023,3.464139029789952e-05,2
W4389040036,An In-Depth Evaluation of Federated Learning on Biomedical Natural Language Processing,2023,3.464139029789952e-05,2
W3036818742,Review of Deep Learning Techniques for Improving the Performance of Machine Reading Comprehension Problem,2020,3.464139029789952e-05,2
W4385574362,Using Roark-Hollingshead Distance to Probe BERT’s Syntactic Competence,2022,3.464139029789952e-05,2
W4406412494,LAMGCN:Traditional Chinese Medicine Herb Recommendation via LSTMs with Attention Mechanisms and Graph Convolutional Networks,2025,3.464139029789952e-05,2
W4393145366,Enhancing Essay Scoring with Adversarial Weights Perturbation and Metric-specific AttentionPooling,2023,3.464139029789952e-05,2
W3117281880,A Graph Representation of Semi-structured Data for Web Question Answering,2020,3.464139029789952e-05,2
W4406370386,GeAR: Generation Augmented Retrieval,2025,3.464139029789952e-05,2
W4387103825,Contrastive learning for unsupervised sentence embeddings using negative samples with diminished semantics,2023,3.464139029789952e-05,2
W4393146985,Liberating Seen Classes: Boosting Few-Shot and Zero-Shot Text Classification via Anchor Generation and Classification Reframing,2024,3.464139029789952e-05,2
W4385570380,AutoConv: Automatically Generating Information-seeking Conversations with Large Language Models,2023,3.464139029789952e-05,2
W4400528864,Boosting Conversational Question Answering with Fine-Grained Retrieval-Augmentation and Self-Check,2024,3.464139029789952e-05,2
W3035103838,Mining Implicit Relevance Feedback from User Behavior for Web Question Answering,2020,3.464139029789952e-05,2
W4394769991,A Heterogeneous Directed Graph Attention Network for inductive text classification using multilevel semantic embeddings,2024,3.464139029789952e-05,2
W4386356152,A comparison of large language model versus manual chart review for extraction of data elements from the electronic health record,2023,3.464139029789952e-05,2
W4398173700,Hybrid Retrieval-Augmented Generation Approach for LLMs Query Response Enhancement,2024,3.464139029789952e-05,2
W4391023916,Layer Configurations of BERT for Multitask Learning and Data Augmentation,2024,3.464139029789952e-05,2
W4387171303,Identical and Fraternal Twins: Fine-Grained Semantic Contrastive Learning of Sentence Representations,2023,3.464139029789952e-05,2
W4408725130,Robust privacy amidst innovation with large language models through a critical assessment of the risks,2025,3.464139029789952e-05,2
W4283204541,Lexical semantics enhanced neural word embeddings,2022,3.464139029789952e-05,2
W4313504207,Context-Based Interpretation of Financial Information,2023,3.464139029789952e-05,2
W4387942588,New Siamese Neural Networks for Text Classification and Ontologies Alignment,2023,3.464139029789952e-05,2
W4315777907,Image Embedding and Classification using Pre-Trained Deep Learning Architectures,2022,3.464139029789952e-05,2
W4407057467,Parallel hierarchical encoding of linguistic representations in the human auditory cortex and recurrent automatic speech recognition systems,2025,3.464139029789952e-05,2
W4385570578,DiscoPrompt: Path Prediction Prompt Tuning for Implicit Discourse Relation Recognition,2023,3.464139029789952e-05,2
W4404295456,TransGPT: Multi-modal Generative Pre-trained Transformer for Transportation,2024,3.464139029789952e-05,2
W4405284316,Classification of English Words into Grammatical Notations Using Deep Learning Technique,2024,3.464139029789952e-05,2
W4407596266,Evaluating diabetes dataset for knowledge graph embedding based link prediction,2025,3.464139029789952e-05,2
W4410371768,Continual Learning of Large Language Models: A Comprehensive Survey,2025,3.464139029789952e-05,2
W4304185307,ASRS-CMFS vs. RoBERTa: Comparing Two Pre-Trained Language Models to Predict Anomalies in Aviation Occurrence Reports with a Low Volume of In-Domain Data Available,2022,3.464139029789952e-05,2
W4406617454,Using the Retrieval-Augmented Generation to Improve the Question-Answering System in Human Health Risk Assessment: The Development and Application,2025,3.464139029789952e-05,2
W4390990543,Unraveling energy justice in NYC urban buildings through social media sentiment analysis and transformer deep learning,2024,3.464139029789952e-05,2
W4406615479,Safety analysis in the era of large language models: A case study of STPA using ChatGPT,2025,3.464139029789952e-05,2
W3129896640,A Definition and a Test for Human-Level Artificial Intelligence,2023,3.464139029789952e-05,2
W4385572138,"Ginn-Khamov at SemEval-2023 Task 6, Subtask B: Legal Named Entities Extraction for Heterogenous Documents",2023,3.464139029789952e-05,2
W3107366692,Portuguese word embeddings for the oil and gas industry: Development and evaluation,2020,3.464139029789952e-05,2
W4221058809,Towards Analyzing the Bias of News Recommender Systems Using Sentiment and Stance Detection,2022,3.464139029789952e-05,2
W3012070096,Supervised and unsupervised language modelling in Chest X-Ray radiological reports,2020,3.464139029789952e-05,2
W4386422441,SiMaLSTM-SNP: novel semantic relatedness learning model preserving both Siamese networks and membrane computing,2023,3.464139029789952e-05,2
W4384918632,Understanding Multi-Turn Toxic Behaviors in Open-Domain Chatbots,2023,3.464139029789952e-05,2
W4407254137,Contrastive Language-Entity Pre-training for Richer Knowledge Graph Embedding,2025,3.464139029789952e-05,2
W4410356867,GANDALF: A LLM-based approach to map bark beetle outbreaks in semantic stories of Sentinel-2 images,2025,3.464139029789952e-05,2
W4284899843,Towards Understanding the Skill Gap in Cybersecurity,2022,3.464139029789952e-05,2
W4385574363,It Is Not Easy To Detect Paraphrases: Analysing Semantic Similarity With Antonyms and Negation Using the New SemAntoNeg Benchmark,2022,3.464139029789952e-05,2
W4391558228,RIXA - Explaining Artificial Intelligence in Natural Language,2023,3.464139029789952e-05,2
W4386566678,Do Deep Neural Networks Capture Compositionality in Arithmetic Reasoning?,2023,3.464139029789952e-05,2
W4407100023,LLM-mediated domain-specific voice agents: <i>the case of TextileBot</i>,2025,3.464139029789952e-05,2
W4387185357,TrojBits: A Hardware Aware Inference-Time Attack on Transformer-Based Language Models,2023,3.464139029789952e-05,2
W4395112771,Implications of Minimum Description Length for Adversarial Attack in Natural Language Processing,2024,3.464139029789952e-05,2
W4403582642,Not All Negatives are Equally Negative: Soft Contrastive Learning for Unsupervised Sentence Representations,2024,3.464139029789952e-05,2
W4389518776,A Cheaper and Better Diffusion Language Model with Soft-Masked Noise,2023,3.464139029789952e-05,2
W4312398513,"Adversarial NLP for Social Network Applications: Attacks, Defenses, and Research Directions",2022,3.464139029789952e-05,2
W3094602619,Predictive Student Modeling in Game-Based Learning Environments with Word Embedding Representations of Reflection,2020,3.464139029789952e-05,2
W4406458141,Aligning the Representation of Knowledge Graph and Large Language Model for Causal Question Answering,2024,3.464139029789952e-05,2
W3194118282,Regularizing transformers with deep probabilistic layers,2023,3.464139029789952e-05,2
W4407900932,Self-supervised learning for neural topic models with variance–invariance–covariance regularization,2025,3.464139029789952e-05,2
W3026350704,Aggregating Customer Review Attributes for Online Reputation Generation,2020,3.464139029789952e-05,2
W4408529625,Large language model agents can use tools to perform clinical calculations,2025,3.464139029789952e-05,2
W4287890478,Residue-Based Natural Language Adversarial Attack Detection,2022,3.464139029789952e-05,2
W4391044610,Commonsense Reasoning and Explainable Artificial Intelligence Using Large Language Models,2024,3.464139029789952e-05,2
W4406799871,ChatGPT and L2 Chinese writing: evaluating the impact of model version and prompt language on automated corrective feedback,2025,3.464139029789952e-05,2
W4394565991,NativE: Multi-modal Knowledge Graph Completion in the Wild,2024,3.464139029789952e-05,2
W4389518835,MPrompt: Exploring Multi-level Prompt Tuning for Machine Reading Comprehension,2023,3.464139029789952e-05,2
W3084317880,The Graph Reasoning Approach Based on the Dynamic Knowledge Auxiliary for Complex Fact Verification,2020,3.464139029789952e-05,2
W4410089370,TourRank: Utilizing Large Language Models for Documents Ranking with a Tournament-Inspired Strategy,2025,3.464139029789952e-05,2
W3197004538,Multi-level retrieval with semantic Axiomatic Fuzzy Set clustering for question answering,2021,3.464139029789952e-05,2
W4392663267,Construction and analysis of uncertainty indices based on multilingual text representations,2024,3.464139029789952e-05,2
W4389519341,FACTIFY3M: A benchmark for multimodal fact verification with explainability through 5W Question-Answering,2023,3.464139029789952e-05,2
W4311970748,Indonesian Scientists’ Behavior Relative to Research Data Governance in Preventing WMD-Applicable Technology Transfer,2022,3.464139029789952e-05,2
W4401197683,Natural language processing in the intensive care unit: A scoping review,2024,3.464139029789952e-05,2
W4306873598,Pre-trained Language Model-based Retrieval and Ranking for Web Search,2022,3.464139029789952e-05,2
W4367298452,Decomposed Two-Stage Prompt Learning for Few-Shot Named Entity Recognition,2023,3.464139029789952e-05,2
W3130395060,TeraPipe: Token-Level Pipeline Parallelism for Training Large-Scale Language Models,2021,3.464139029789952e-05,2
W4323568419,A Multi-Modal Story Generation Framework with AI-Driven Storyline Guidance,2023,3.464139029789952e-05,2
W4410104073,Are transformers truly foundational for robotics?,2025,3.464139029789952e-05,2
W4385573352,Detecting Relevant Differences Between Similar Legal Texts,2022,3.464139029789952e-05,2
W4407830908,AUTOMATED DETECTION OF EMOTION IN CENTRAL BANK COMMUNICATION: A WARNING,2025,3.464139029789952e-05,2
W4392818979,Contrasting Linguistic Patterns in Human and LLM-Generated News Text,2024,3.464139029789952e-05,2
W4386791134,Cell2Sentence: Teaching Large Language Models the Language of Biology,2023,3.464139029789952e-05,2
W4387782510,A taxonomy and review of generalization research in NLP,2023,3.464139029789952e-05,2
W4401357421,"An Empirical Evaluation of the Zero-Shot, Few-Shot, and Traditional Fine-Tuning Based Pretrained Language Models for Sentiment Analysis in Software Engineering",2024,3.464139029789952e-05,2
W3175554834,Extracting Semantic Process Information from the Natural Language in Event Logs,2021,3.464139029789952e-05,2
W4287887311,SemEval-2022 Task 3: PreTENS-Evaluating Neural Networks on Presuppositional Semantic Knowledge,2022,3.464139029789952e-05,2
W4210551272,Classifying the content of social media images to support cultural ecosystem service assessments using deep learning models,2022,3.464139029789952e-05,2
W4400970942,Biulkbqa: A Joint Generate and Retrieve Efficient Dual-Stream Framework for Knowledge Base Question Answering,2024,3.464139029789952e-05,2
W4390970119,NLP-Based Recommendation Approach for Diverse Service Generation,2024,3.464139029789952e-05,2
W3202547399,"Evaluating the Cybersecurity Risk of Real-world, Machine Learning Production Systems",2022,3.464139029789952e-05,2
W4385570911,Data Selection for Fine-tuning Large Language Models Using Transferred Shapley Values,2023,3.464139029789952e-05,2
W4392056731,Using natural language processing to analyze unstructured patient-reported outcomes data derived from electronic health records for cancer populations: a systematic review,2024,3.464139029789952e-05,2
W4407241465,Out-of-distribution generalization via composition: A lens through induction heads in Transformers,2025,3.464139029789952e-05,2
W4406901061,SecLMNER: A framework for enhanced named entity recognition in multi-source cybersecurity data using large language models,2025,3.464139029789952e-05,2
W4398152371,"Comparing Fine-Tuning, Zero and Few-Shot Strategies with Large Language Models in Hate Speech Detection in English",2024,3.464139029789952e-05,2
W4391544525,ChIP-GPT: a managed large language model for robust data extraction from biomedical database records,2024,3.464139029789952e-05,2
W4391899877,Few-shot code translation via task-adapted prompt learning,2024,3.464139029789952e-05,2
W4387924881,Enforcing legal information extraction through context-aware techniques: The ASKE approach,2023,3.464139029789952e-05,2
W4409183272,Approximate Bag-of-Words Top-k Corpus Graphs,2025,3.464139029789952e-05,2
W4410202920,Ontology matching with Large Language Models and prioritized depth-first search,2025,3.464139029789952e-05,2
W4399516266,Transformer-based Language Models and Homomorphic Encryption: An Intersection with BERT-tiny,2024,3.464139029789952e-05,2
W4387645476,Fine-Tuning Large Enterprise Language Models via Ontological Reasoning,2023,3.464139029789952e-05,2
W4407855931,Osteosarcoma KGQA system: deep learning-based knowledge graph and large language model fusion,2025,3.464139029789952e-05,2
W4389524278,CASE: Commonsense-Augmented Score with an Expanded Answer Space,2023,3.464139029789952e-05,2
W4408935240,Student Enrollment Consultation Q&amp;A Robot Based on Large Language Model,2025,3.464139029789952e-05,2
W4407054226,EHR-based prediction modelling meets multimodal deep learning: A systematic review of structured and textual data fusion methods,2025,3.464139029789952e-05,2
W4318464905,Transfer learning for the efficient detection of COVID-19 from smartphone audio data,2023,3.464139029789952e-05,2
W4406320500,BiomedRAG: A retrieval augmented large language model for biomedicine,2025,3.464139029789952e-05,2
W4394742621,JustiLM: Few-shot Justification Generation for Explainable Fact-Checking of Real-world Claims,2024,3.464139029789952e-05,2
W4386780600,Open-world story generation with structured knowledge enhancement: A comprehensive survey,2023,3.464139029789952e-05,2
W4400113179,A Review on Neuro-symbolic AI Improvements to Natural Language Processing,2024,3.464139029789952e-05,2
W4409162402,Utilizing Large Language Models to Detect and Decipher Abbreviation in Clinical Notes (Preprint),2025,3.464139029789952e-05,2
W4402605383,Reinforced Multi-teacher Knowledge Distillation for Unsupervised Sentence Representation,2024,3.464139029789952e-05,2
W4408156536,Robust Infidelity: When Faithfulness Measures on Masked Language Models Are Misleading,2025,3.464139029789952e-05,2
W3094245163,Causal Effects of Linguistic Properties,2020,3.464139029789952e-05,2
W4389104898,Performance Analysis of Federated Learning Algorithms for Multilingual Protest News Detection Using Pre-Trained DistilBERT and BERT,2023,3.464139029789952e-05,2
W4386647425,ProVe: A pipeline for automated provenance verification of knowledge graphs against textual sources,2023,3.464139029789952e-05,2
W4391127883,Predictive typing method for Persian office automation,2024,3.464139029789952e-05,2
W4407340340,Abstract Operations Research Modeling Using Natural Language Inputs,2025,3.464139029789952e-05,2
W4397003497,Clinical Text Datasets for Medical Artificial Intelligence and Large Language Models — A Systematic Review,2024,3.464139029789952e-05,2
W3114204117,Connecting the Dots Between Fact Verification and Fake News Detection,2020,3.464139029789952e-05,2
W4403997208,Language as a cognitive and social tool at the time of large language models,2024,3.464139029789952e-05,2
W4396843991,"Text-Attributed Graph Representation Learning: Methods, Applications, and Challenges",2024,3.464139029789952e-05,2
W4401468394,Development of a natural language processing pipeline for assessment of cardiovascular risk in myeloproliferative neoplasms,2024,3.464139029789952e-05,2
W4392849937,Local Interpretations for Explainable Natural Language Processing: A Survey,2024,3.464139029789952e-05,2
W4388805583,The power and potentials of Flexible Query Answering Systems: A critical and comprehensive analysis,2023,3.464139029789952e-05,2
W3186134690,SemEval-2021 Task 4: Reading Comprehension of Abstract Meaning,2021,3.464139029789952e-05,2
W4385573594,Eliciting Knowledge from Large Pre-Trained Models for Unsupervised Knowledge-Grounded Conversation,2022,3.464139029789952e-05,2
W4390511900,PTCAS: Prompt tuning with continuous answer search for relation extraction,2024,3.464139029789952e-05,2
W4378515217,Biomedical Relation Extraction Using Dependency Graph and Decoder-Enhanced Transformer Model,2023,3.464139029789952e-05,2
W4408095424,Leveraging Unstructured Text Data for Federated Instruction Tuning of Large Language Models,2025,3.464139029789952e-05,2
W4384916163,HSM-QA: Question Answering System Based on Hierarchical Semantic Matching,2023,3.464139029789952e-05,2
W4404688462,"Survey on Large Language Model-Enhanced Reinforcement Learning: Concept, Taxonomy, and Methods",2024,3.464139029789952e-05,2
W4386022344,Dataset versus reality: Understanding model performance from the perspective of information need,2023,3.464139029789952e-05,2
W4399109812,DUVEL: an active-learning annotated biomedical corpus for the recognition of oligogenic combinations,2024,3.464139029789952e-05,2
W4406857279,Research on Parameter-Efficient Knowledge Graph Completion Methods and Their Performance in the Cybersecurity Field,2025,3.464139029789952e-05,2
W4388924707,Language augmentation approach for code-mixed text classification,2023,3.464139029789952e-05,2
W4407843019,Effectiveness of Transformer-Based Large Language Models in Identifying Adverse Drug Reaction Relations from Unstructured Discharge Summaries in Singapore,2025,3.464139029789952e-05,2
W4389520038,InterroLang: Exploring NLP Models and Datasets through Dialogue-based Explanations,2023,3.464139029789952e-05,2
W4287854500,A Dog Is Passing Over The Jet? A Text-Generation Dataset for Korean Commonsense Reasoning and Evaluation,2022,3.464139029789952e-05,2
W4223560628,A Comparative Study of Pre-trained Encoders for Low-Resource Named Entity Recognition,2022,3.464139029789952e-05,2
W4385570112,Sen2Pro: A Probabilistic Perspective to Sentence Embedding from Pre-trained Language Model,2023,3.464139029789952e-05,2
W4388462011,Analyzing the relation among different factors leading to Ph.D. dropout using numerical association rule mining,2023,3.464139029789952e-05,2
W4393398286,Exploiting Graph Embeddings from Knowledge Bases for Neural Biomedical Relation Extraction,2024,3.464139029789952e-05,2
W4385573593,Temporal Word Meaning Disambiguation using TimeLMs,2022,3.464139029789952e-05,2
W4391230471,Mconvkgc: a novel multi-channel convolutional model for knowledge graph completion,2024,3.464139029789952e-05,2
W4392938490,Volatility forecasting and assessing risk of financial markets using multi-transformer neural network based architecture,2024,3.464139029789952e-05,2
W4200557907,"“YOU POST, I TRAVEL.” Bloggers' credibility, digital engagement, and travelers' behavioral intention: The mediating role of hedonic and utilitarian motivations",2021,3.464139029789952e-05,2
W4390510809,Siamese capsule network with position correlation and integrating articles of law for Chinese similar case matching,2024,3.464139029789952e-05,2
W4367555203,"Comparison of pre-trained language models in terms of carbon emissions, time and accuracy in multi-label text classification using AutoML",2023,3.464139029789952e-05,2
W4391651108,Tabular reasoning via two-stage knowledge injection,2024,3.464139029789952e-05,2
W4321434205,Feature-Based Graph Backdoor Attack in the Node Classification Task,2023,3.464139029789952e-05,2
W3116010752,"Rhetoric, Logic, and Dialectic: Advancing Theory-based Argument Quality Assessment in Natural Language Processing",2020,3.464139029789952e-05,2
W4389520499,"Unifying Text, Tables, and Images for Multimodal Question Answering",2023,3.464139029789952e-05,2
W4408209324,Conversational Agents in the Legal Domain: A Systematic Review of the Literature,2025,3.464139029789952e-05,2
W4377820934,Knowledge Acquired by Foundation Models,2023,3.464139029789952e-05,2
W4405989740,Success and failure of compositional generalisation in distributional models of language,2025,3.464139029789952e-05,2
W4409626371,Optimizing Prompt Refinement: Algorithmic Strategies for Llm-Driven Text Classification Tasks,2025,3.464139029789952e-05,2
W4220798854,CEQE to SQET: A study of contextualized embeddings for query expansion,2022,3.464139029789952e-05,2
W4410068129,SensorQA: A Question Answering Benchmark for Daily-Life Monitoring,2025,3.464139029789952e-05,2
W3115271704,Towards Fast and Accurate Neural Chinese Word Segmentation with Multi-Criteria Learning,2020,3.464139029789952e-05,2
W3213549365,Theme Transformer: Symbolic Music Generation With Theme-Conditioned Transformer,2022,3.464139029789952e-05,2
W4400525421,Reciprocating Encoder Portrayal From Reliable Transformer Dependent Bidirectional Long Short-Term Memory for Question and Answering Text Classification,2024,3.464139029789952e-05,2
W4408200739,Transforming hematological research documentation with large language models: an approach to scientific writing and data analysis,2025,3.464139029789952e-05,2
W4408072827,Comparing Traditional Book Wisdom with Large Language Model’s Guidance on Time and Stress Management,2025,3.464139029789952e-05,2
W4385571038,Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 6: Tutorial Abstracts),2023,3.464139029789952e-05,2
W3022569409,Establishing Baselines for Text Classification in Low-Resource Languages,2020,3.464139029789952e-05,2
W4408925093,Specialized Large Language Model Outperforms Neurologists at Complex Diagnosis in Blinded Case-Based Evaluation,2025,3.464139029789952e-05,2
W3098771568,Constrained BERT BiLSTM CRF for understanding multi-sentence entity-seeking questions,2020,3.464139029789952e-05,2
W4293304858,Match-Prompt,2022,3.464139029789952e-05,2
W4407058961,Question Answering over the Arabic Hadith Sharif Using Transformer Models,2025,3.464139029789952e-05,2
W4401855268,Understanding Narratives of Uncertainty in Fertility Intentions of Dutch Women: A Neural Topic Modeling Approach,2024,3.464139029789952e-05,2
W4408377435,Electronic Health Record classification and analysis using NLP Techniques,2025,3.464139029789952e-05,2
W4407254385,Dynamic Layer-Wise Token Pruning for Sequence-to-Sequence Transformer Inference,2025,3.464139029789952e-05,2
W4389520111,Distilling ChatGPT for Explainable Automated Student Answer Assessment,2023,3.464139029789952e-05,2
W4403343568,Federated learning-based natural language processing: a systematic literature review,2024,3.464139029789952e-05,2
W4404823333,Mitigating the Bias of Large Language Model Evaluation,2024,3.464139029789952e-05,2
W4407394771,Text Classification by CEFR Levels Using Machine Learning Methods and the BERT Language Model,2024,3.464139029789952e-05,2
W4360850261,Enabling Early Health Care Intervention by Detecting Depression in Users of Web-Based Forums using Language Models: Longitudinal Analysis and Evaluation,2023,3.464139029789952e-05,2
W4212946592,Positional SHAP (PoSHAP) for Interpretation of machine learning models trained from biological sequences,2022,3.464139029789952e-05,2
W4389523890,MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter,2023,3.464139029789952e-05,2
W4396736493,Knowledge-Augmented Large Language Models for Personalized Contextual Query Suggestion,2024,3.464139029789952e-05,2
W4409451928,Benchmarking domain-specific pretrained language models to identify the best model for methodological rigor in clinical studies,2025,3.464139029789952e-05,2
W4389438760,Toward explainable AI (XAI) for mental health detection based on language behavior,2023,3.464139029789952e-05,2
W4406122607,Annotated corpus for traditional formula-disease relationships in biomedical articles,2025,3.464139029789952e-05,2
W4396667547,Enhancing Machine-Generated Text Detection: Adversarial Fine-Tuning of Pre-Trained Language Models,2024,3.464139029789952e-05,2
W4396833205,ARTiST: Automated Text Simplification for Task Guidance in Augmented Reality,2024,3.464139029789952e-05,2
W4409278937,Linking Symptom Inventories Using Semantic Textual Similarity,2025,3.464139029789952e-05,2
W4396760140,SIDU-TXT: An XAI algorithm for NLP with a holistic assessment approach,2024,3.464139029789952e-05,2
W3091101427,A Deep Transfer Learning Approach for Fake News Detection,2020,3.464139029789952e-05,2
W3209819950,Venomave: Targeted Poisoning Against Speech Recognition,2023,3.464139029789952e-05,2
W4392934733,A Knowledge-Injected Curriculum Pretraining Framework for Question Answering,2024,3.464139029789952e-05,2
W4385569785,Pre-Training to Learn in Context,2023,3.464139029789952e-05,2
W4398243240,Large language models: Expectations for semantics-driven systems engineering,2024,3.464139029789952e-05,2
W4407571831,Show Me the Work: Fact-Checkers' Requirements for Explainable Automated Fact-Checking,2025,3.464139029789952e-05,2
W4383368985,Enhancing multiple-choice question answering through sequential fine-tuning and Curriculum Learning strategies,2023,3.464139029789952e-05,2
W4407039591,Are Large Language Models More Honest in Their Probabilistic or Verbalized Confidence?,2025,3.464139029789952e-05,2
W4389519053,Multilingual estimation of political-party positioning: From label aggregation to long-input Transformers,2023,3.464139029789952e-05,2
W4401440681,Mapping vaccine names in clinical trials to vaccine ontology using cascaded fine-tuned domain-specific language models,2024,3.464139029789952e-05,2
W4402402588,A Dynamic Retrieval-Augmented Generation Framework for Border Inspection Legal Question Answering,2024,3.464139029789952e-05,2
W4410197203,Knowledge-enhanced Parameter-efficient Transfer Learning with METER for medical vision-language tasks,2025,3.464139029789952e-05,2
W4409775117,Construction of Journal Knowledge Graph Based on Deep Learning and LLM,2025,3.464139029789952e-05,2
W4285217916,Explanation Graph Generation via Pre-trained Language Models: An Empirical Study with Contrastive Learning,2022,3.464139029789952e-05,2
W4396831993,Human-LLM Collaborative Annotation Through Effective Verification of LLM Labels,2024,3.464139029789952e-05,2
W4398223181,Relation Extraction in Underexplored Biomedical Domains: A Diversity-optimized Sampling and Synthetic Data Generation Approach,2024,3.464139029789952e-05,2
W4410478508,Saliency Attention and Semantic Similarity-Driven Adversarial Perturbation,2025,3.464139029789952e-05,2
W4409651000,FZeroTC: fully zero-shot text classification for simultaneously discovering and labeling unseen classes,2025,3.464139029789952e-05,2
W3164024373,Embed2Detect: temporally clustered embedded words for event detection in social media,2021,3.464139029789952e-05,2
W4407134116,A comparative evaluation of the effectiveness of document splitters for large language models in legal contexts,2025,3.464139029789952e-05,2
W4399372400,COA-GPT: Generative Pre-Trained Transformers for Accelerated Course of Action Development in Military Operations,2024,3.464139029789952e-05,2
W3202627914,Towards Interpretable and Reliable Reading Comprehension: A Pipeline Model with Unanswerability Prediction,2021,3.464139029789952e-05,2
W4280605341,AEON: a method for automatic evaluation of NLP test cases,2022,3.464139029789952e-05,2
W4407746323,GenKP: generative knowledge prompts for enhancing large language models,2025,3.464139029789952e-05,2
W4389520069,"Values, Ethics, Morals? On the Use of Moral Concepts in NLP Research",2023,3.464139029789952e-05,2
W4385572148,Claim-Dissector: An Interpretable Fact-Checking System with Joint Re-ranking and Veracity Prediction,2023,3.464139029789952e-05,2
W4400156412,Contrastive learning based on linguistic knowledge and adaptive augmentation for text classification,2024,3.464139029789952e-05,2
W3208243843,Is BERT the New Silver Bullet? - An Empirical Investigation of Requirements Dependency Classification,2021,3.464139029789952e-05,2
W4385570980,CITADEL: Conditional Token Interaction via Dynamic Lexical Routing for Efficient and Effective Multi-Vector Retrieval,2023,3.464139029789952e-05,2
W4409060877,Enhancing Plant Protection Knowledge with Large Language Models: A Fine-Tuned Question-Answering System Using LoRA,2025,3.464139029789952e-05,2
W3207878700,Towards Efficient NLP: A Standard Evaluation and A Strong Baseline,2022,3.464139029789952e-05,2
W4388821834,On reading and interpreting black box deep neural networks,2023,3.464139029789952e-05,2
W4393239266,Large Language Models and the Future of Organization Theory,2024,3.464139029789952e-05,2
W4402577336,Case-Based Deduction for Entailment Tree Generation,2024,3.464139029789952e-05,2
W4385572256,Structure-Aware Language Model Pretraining Improves Dense Retrieval on Structured Data,2023,3.464139029789952e-05,2
W4312064036,Combining BERT with numerical variables to classify injury leave based on accident description,2022,3.464139029789952e-05,2
W4410344873,AEKG4APT: An AI-Enhanced Knowledge Graph for Advanced Persistent Threats with Large Language Model Analysis,2025,3.464139029789952e-05,2
W4406248884,NLP and education,2025,3.464139029789952e-05,2
W4406159163,A hybrid model for the detection of multi-agent written news articles based on linguistic features and BERT,2025,3.464139029789952e-05,2
W4404112581,Open-Ethical AI: Advancements in Open-Source Human-Centric Neural Language Models,2024,3.464139029789952e-05,2
W3122172846,Interpreting Graph Neural Networks for NLP With Differentiable Edge Masking,2021,3.464139029789952e-05,2
W4399168671,Hyperbolic Pre-Trained Language Model,2024,3.464139029789952e-05,2
W4408742984,Evaluating explainability in language classification models: A unified framework incorporating feature attribution methods and key factors affecting faithfulness,2025,3.464139029789952e-05,2
W4407930738,"Legal information extraction and classification using BERT, Bi-LSTM, and CRF models",2025,3.464139029789952e-05,2
W4409159827,CREDIFY: contextualized retrieval of evidence for open-domain fact verification,2025,3.464139029789952e-05,2
W4409277341,A Novel Retrieval-Augmented Generation Framework Using Large Language Models for Lyrics and Song Composition,2025,3.464139029789952e-05,2
W4408258137,Towards Semantic Classification: An Experimental Study on Automated Understanding of the Meaning of Verbal Utterances,2025,3.464139029789952e-05,2
W4391887109,MAEDAY: MAE for few- and zero-shot AnomalY-Detection,2024,3.464139029789952e-05,2
W3165229798,Evaluation of Federated Learning in Phishing Email Detection,2023,3.464139029789952e-05,2
W4403938784,Integrating Multi-view Analysis: Multi-view Mixture-of-Expert for Textual Personality Detection,2024,3.464139029789952e-05,2
W4389523725,"Out-of-Distribution Generalization in Natural Language Processing: Past, Present, and Future",2023,3.464139029789952e-05,2
W4407857790,"Urdu Word Sense Disambiguation: Leveraging Contextual Stacked Embedding, Siamese Transformer Encoder 1DCNN-BiLSTM, and Gloss Data Augmentation",2025,3.464139029789952e-05,2
W4285280220,Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics,2022,3.464139029789952e-05,2
W4405316960,Diff-PC: Identity-preserving and 3D-aware controllable diffusion for zero-shot portrait customization,2024,3.464139029789952e-05,2
W4405427519,MetaphorPrompt - An Analogical Reasoning Approach for Extracting Causal Links from Biological Text,2024,3.464139029789952e-05,2
W4353021271,Latent Factors of Language Disturbance and Relationships to Quantitative Speech Features,2023,3.464139029789952e-05,2
W4379467046,Enhanced bare-bones particle swarm optimization based evolving deep neural networks,2023,3.464139029789952e-05,2
W4402761916,Geometry of Textual Data Augmentation: Insights from Large Language Models,2024,3.464139029789952e-05,2
W4380085693,Retrospective Multi-granularity Fusion Network for Chinese Idiom Cloze-style Reading Comprehension,2023,3.464139029789952e-05,2
W4407088958,Integration of biomedical concepts for enhanced medical literature retrieval,2025,3.464139029789952e-05,2
W4386630107,Short Text Analytics based on BERT by using Multivariate Filter Methods for Feature Selection,2023,3.464139029789952e-05,2
W4385571997,Query Enhanced Knowledge-Intensive Conversation via Unsupervised Joint Modeling,2023,3.464139029789952e-05,2
W4406502940,Zero-Shot Dense Retrieval Based on Query Expansion,2025,3.464139029789952e-05,2
W4225783786,Counterfactual Representation Augmentation for Cross-Domain Sentiment Analysis,2022,3.464139029789952e-05,2
W4401692510,AdIn-DETR: Adapting Detection Transformer for End-to-End Real-Time Power Line Insulator Defect Detection,2024,3.464139029789952e-05,2
W4212926012,Effects of Similarity Score Functions in Attention Mechanisms on the Performance of Neural Question Answering Systems,2022,3.464139029789952e-05,2
W4365420739,Event Extraction With Dynamic Prefix Tuning and Relevance Retrieval,2023,3.464139029789952e-05,2
W4402263660,"BOLT: Privacy-Preserving, Accurate and Efficient Inference for Transformers",2024,3.464139029789952e-05,2
W4386566684,AutoTriggER: Label-Efficient and Robust Named Entity Recognition with Auxiliary Trigger Extraction,2023,3.464139029789952e-05,2
W4389520349,CoF-CoT: Enhancing Large Language Models with Coarse-to-Fine Chain-of-Thought Prompting for Multi-domain NLU Tasks,2023,3.464139029789952e-05,2
W3113524397,An Empirical Study of Contextual Data Augmentation for Japanese Zero Anaphora Resolution,2020,3.464139029789952e-05,2
W4407742619,A survey on learning with noisy labels in Natural Language Processing: How to train models with label noise,2025,3.464139029789952e-05,2
W4362632884,A Neural Topic Modeling Study Integrating SBERT and Data Augmentation,2023,3.464139029789952e-05,2
W4391839376,Analyzing public demands on China’s online government inquiry platform: A BERTopic-Based topic modeling study,2024,3.464139029789952e-05,2
W4385901301,Effectively Modeling Sentence Interactions With Factorization Machines for Fact Verification,2023,3.464139029789952e-05,2
W4394902770,Uncovering Gender Bias within Journalist-Politician Interaction in Indian Twitter,2024,3.464139029789952e-05,2
W4385319136,What does Chinese BERT learn about syntactic knowledge?,2023,3.464139029789952e-05,2
W4306249555,Enriching Biomedical Knowledge for Low-resource Language Through Translation,2022,3.464139029789952e-05,2
W4385572615,ML-LMCL: Mutual Learning and Large-Margin Contrastive Learning for Improving ASR Robustness in Spoken Language Understanding,2023,3.464139029789952e-05,2
W4380609152,Instance-Aware Prompt Learning for Language Understanding and Generation,2023,3.464139029789952e-05,2
W4410202262,Unleashing the potential of prompt engineering for large language models,2025,3.464139029789952e-05,2
W4410300584,Dataset for Legal Question Answering System in the Indian Judiciary Context,2025,3.464139029789952e-05,2
W3212837704,Low-resource Taxonomy Enrichment with Pretrained Language Models,2021,3.464139029789952e-05,2
W3098214632,BERT for Monolingual and Cross-Lingual Reverse Dictionary,2020,3.464139029789952e-05,2
W3148364056,Classifying Scientific Publications with BERT - Is Self-attention a Feature Selection Method?,2021,3.464139029789952e-05,2
W4410590444,Evaluating the Performance of Complex Text Generated by Large Language Models,2025,3.464139029789952e-05,2
W4392372817,Incorporating evidence into mental health Q&amp;A: a novel method to use generative language models for validated clinical content extraction,2024,3.464139029789952e-05,2
W4386566493,JBLiMP: Japanese Benchmark of Linguistic Minimal Pairs,2023,3.464139029789952e-05,2
W4399036027,Improving Robustness in Language Models for Legal Textual Entailment Through Artifact-Aware Training,2024,3.464139029789952e-05,2
W4407559544,Machine learning tools match physician accuracy in multilingual text annotation,2025,3.464139029789952e-05,2
W4409527720,Stimulus dependencies—rather than next-word prediction—can explain pre-onset brain encoding during natural listening,2025,3.464139029789952e-05,2
W4400259231,Unlocking the Potential: A Comprehensive Systematic Review of ChatGPT in Natural Language Processing Tasks,2024,3.464139029789952e-05,2
W4283079132,Automatic data extraction to support meta-analysis statistical analysis: a case study on breast cancer,2022,3.464139029789952e-05,2
W4409030971,Making sense of transformer success,2025,3.464139029789952e-05,2
W4403563666,E-code: Mastering efficient code generation through pretrained models and expert encoder group,2024,3.464139029789952e-05,2
W4400099044,Assessing the performance of large language models in literature screening for pharmacovigilance: a comparative study,2024,3.464139029789952e-05,2
W4375868971,Self-Supervised Adversarial Training for Contrastive Sentence Embedding,2023,3.464139029789952e-05,2
W4409011559,The cortical architecture representing the linguistic hierarchy of the conversational speech,2025,3.464139029789952e-05,2
W4392909639,Exploring Soft Prompt Initialization Strategy for Few-Shot Continual Text Classification,2024,3.464139029789952e-05,2
W4386450708,"Sentences Similarity Model Based on Fusion of Semantic, Syntactic and Word Order Multi-Features",2023,3.464139029789952e-05,2
W4312480353,Clickbait Headline Detection in Indonesian News Sites using Robustly Optimized BERT Pre-training Approach (RoBERTa),2022,3.464139029789952e-05,2
W4309652662,Active learning for transformer models in direction query tagging,2022,3.464139029789952e-05,2
W4285243012,Factual Consistency of Multilingual Pretrained Language Models,2022,3.464139029789952e-05,2
W4385572073,HyperPELT: Unified Parameter-Efficient Language Model Tuning for Both Language and Vision-and-Language Tasks,2023,3.464139029789952e-05,2
W4407196512,Accelerating knowledge graph and ontology engineering with large language models,2025,3.464139029789952e-05,2
W4391116601,Exploiting Language Models as a Source of Knowledge for Cognitive Agents,2024,3.464139029789952e-05,2
W4386566925,A Survey of Methods for Addressing Class Imbalance in Deep-Learning Based Natural Language Processing,2023,3.464139029789952e-05,2
W4410332729,Overcoming Data Shortage in Critical Domains With Data Augmentation for Natural Language Software Requirements,2025,3.464139029789952e-05,2
W4388422777,Extracting laboratory test information from paper-based reports,2023,3.464139029789952e-05,2
W4368408045,CsFEVER and CTKFacts: acquiring Czech data for fact verification,2023,3.464139029789952e-05,2
W4391286686,Zero-Shot Medical Information Retrieval via Knowledge Graph Embedding,2024,3.464139029789952e-05,2
W4386071594,Learning Federated Visual Prompt in Null Space for MRI Reconstruction,2023,3.464139029789952e-05,2
W4389523987,Support or Refute: Analyzing the Stance of Evidence to Detect Out-of-Context Mis- and Disinformation,2023,3.464139029789952e-05,2
W4410304050,Similarity Measurement Model for Standard Clauses Based on RAG,2025,3.464139029789952e-05,2
W4396735998,RulePrompt: Weakly Supervised Text Classification with Prompting PLMs and Self-Iterative Logical Rules,2024,3.464139029789952e-05,2
W4295308427,A Survey of Text Representation Methods and Their Genealogy,2022,3.464139029789952e-05,2
W4386065780,Decomposed Soft Prompt Guided Fusion Enhancing for Compositional Zero-Shot Learning,2023,3.464139029789952e-05,2
W4402352511,Option-Differentiated Clue Augmentation for Commonsense Question Answering,2024,3.464139029789952e-05,2
W4410151876,Anchored Preference Optimization and Contrastive Revisions: Addressing Underspecification in Alignment,2025,3.464139029789952e-05,2
W4404172291,Transformer-Based Quantification of the Echo Chamber Effect in Online Communities,2024,3.464139029789952e-05,2
W3013555162,Born-Again Tree Ensembles,2020,3.464139029789952e-05,2
W4398218462,GastroBot: a Chinese gastrointestinal disease chatbot based on the retrieval-augmented generation,2024,3.464139029789952e-05,2
W4387686358,Connecting AI: Merging Large Language Models and Knowledge Graph,2023,3.464139029789952e-05,2
W3126763054,Challenges in Automated Debiasing for Toxic Language Detection,2021,3.464139029789952e-05,2
W4393147000,TaskLAMA: Probing the Complex Task Understanding of Language Models,2024,3.464139029789952e-05,2
W4387185528,The Emotions of the Crowd: Learning Image Sentiment from Tweets via Cross-Modal Distillation,2023,3.464139029789952e-05,2
W4206700446,Predicting permeability from 3D rock images based on CNN with physical information,2022,3.464139029789952e-05,2
W4403780651,Bridging Gaps in Content and Knowledge for Multimodal Entity Linking,2024,3.464139029789952e-05,2
W4399107405,On knowing a gene: A distributional hypothesis of gene function,2024,3.464139029789952e-05,2
W4320501880,Intelligent Question Answering System Based on Domain Knowledge Graph,2023,3.464139029789952e-05,2
W4407042009,Event extraction based on self-data augmentation with large language models,2025,3.464139029789952e-05,2
W4410571380,ExDoRA: enhancing the transferability of large language models for depression detection using free-text explanations,2025,3.464139029789952e-05,2
W4406750975,Enhancing doctor-patient communication using large language models for pathology report interpretation,2025,3.464139029789952e-05,2
W4385768252,A Multi-Modal Neural Geometric Solver with Textual Clauses Parsed from Diagram,2023,3.464139029789952e-05,2
W4393161231,CFEVER: A Chinese Fact Extraction and VERification Dataset,2024,3.464139029789952e-05,2
W4385324506,Deciphering “the language of nature”: A transformer-based language model for deleterious mutations in proteins,2023,3.464139029789952e-05,2
W4389165057,Augmenting interpretable models with large language models during training,2023,3.464139029789952e-05,2
W4410540745,Detection of Duplicate Questions Using Universal Sentence Encoder with Learning,2025,3.464139029789952e-05,2
W4396819963,Ranked List Truncation for Large Language Model-based Re-Ranking,2024,3.464139029789952e-05,2
W4323354733,AI chatbots not yet ready for clinical use,2023,3.464139029789952e-05,2
W4385570304,Causality-aware Concept Extraction based on Knowledge-guided Prompting,2023,3.464139029789952e-05,2
W4408420741,A Pilot Study Using Natural Language Processing to Explore Textual Electronic Mental Healthcare Data,2025,3.464139029789952e-05,2
W4392903658,Interpretable Multimodal Out-of-Context Detection with Soft Logic Regularization,2024,3.464139029789952e-05,2
W4407264142,KG-prompt: Interpretable knowledge graph prompt for pre-trained language models,2025,3.464139029789952e-05,2
W4394773691,Retrieve What You Need: A Mutual Learning Framework for Open-domain Question Answering,2024,3.464139029789952e-05,2
W4403768714,Semantic-Driven Topic Modeling Using Transformer-Based Embeddings and Clustering Algorithms,2024,3.464139029789952e-05,2
W4406703812,Exploring the Behavior and Performance of Large Language Models: Can LLMs Infer Answers to Questions Involving Restricted Information?,2025,3.464139029789952e-05,2
W4410015771,Test-driving information Theory-based Compositional Distributional Semantics: A case study on Spanish song lyrics,2025,3.464139029789952e-05,2
W4319302991,Buried Object Characterization Using Ground Penetrating Radar Assisted by Data-Driven Surrogate-Models,2023,3.464139029789952e-05,2
W4385570547,An Exploration of Encoder-Decoder Approaches to Multi-Label Classification for Legal and Biomedical Text,2023,3.464139029789952e-05,2
W4388551933,Unsupervised Contrastive Learning of Sentence Embeddings Through Optimized Sample Construction and Knowledge Distillation,2023,3.464139029789952e-05,2
W4389519850,GROVE: A Retrieval-augmented Complex Story Generation Framework with A Forest of Evidence,2023,3.464139029789952e-05,2
W4385572255,KInITVeraAI at SemEval-2023 Task 3: Simple yet Powerful Multilingual Fine-Tuning for Persuasion Techniques Detection,2023,3.464139029789952e-05,2
W4391109462,Extracting Patient Lifestyle Characteristics from Dutch Clinical Text with BERT Models,2024,3.464139029789952e-05,2
W2810150893,Beyond Precision: A Study on Recall of Initial Retrieval with Neural Representations,2023,3.464139029789952e-05,2
W4408854660,Dual-view cross attention enhanced semi-supervised learning method for discourse cognitive engagement classification in online course discussions,2025,3.464139029789952e-05,2
W4406711870,Unlocking wisdom: enhancing biomedical question answering with domain knowledge,2025,3.464139029789952e-05,2
W4393160377,A Learnable Discrete-Prior Fusion Autoencoder with Contrastive Learning for Tabular Data Synthesis,2024,3.464139029789952e-05,2
W4406917752,Evolving Chain-of-Thought and automatic text annotation based intent classification method for wireless network,2025,3.464139029789952e-05,2
W4405491233,Extraction of patients subpopulations with psychiatric symptoms using a transformer architecture,2024,3.464139029789952e-05,2
W4407554043,Event Log Extraction for Process Mining Using Large Language Models,2025,3.464139029789952e-05,2
W4396873766,A head-to-head attention with prompt text augmentation for text classification,2024,3.464139029789952e-05,2
W4408029418,Mario: Near Zero-cost Activation Checkpointing in Pipeline Parallelism,2025,3.464139029789952e-05,2
W4409720324,Quantifying Divergence for Human-AI Collaboration and Cognitive Trust,2025,3.464139029789952e-05,2
W4408366965,Exploring the potential of Claude 2 for risk of bias assessment: Using a large language model to assess randomized controlled trials with RoB 2,2025,3.464139029789952e-05,2
W4406695259,Subreddit to Symptomatology: A Lexicon-based Approach to Extract Symptoms of Complex Conditions from Online Discourse (Preprint),2025,3.464139029789952e-05,2
W4285160596,Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts,2022,3.464139029789952e-05,2
W4393147190,Labels Need Prompts Too: Mask Matching for Natural Language Understanding Tasks,2024,3.464139029789952e-05,2
W4403943146,Multi-hop Reading Comprehension Model Based on Abstract Meaning Representation and Multi-task Joint Learning,2024,3.464139029789952e-05,2
W4409767054,Emerging Data Practices: Data Work in the Era of Large Language Models,2025,3.464139029789952e-05,2
W4319597833,A Comparison of Different Topic Modeling Methods through a Real Case Study of Italian Customer Care,2023,3.464139029789952e-05,2
W4385571840,Robust Natural Language Understanding with Residual Attention Debiasing,2023,3.464139029789952e-05,2
W4407482948,Prompts to Table: Specification and Iterative Refinement for Clinical Information Extraction with Large Language Models,2025,3.464139029789952e-05,2
W4392267027,Large-scale benchmark yields no evidence that language model surprisal explains syntactic disambiguation difficulty,2024,3.464139029789952e-05,2
W4400528385,LeCaRDv2: A Large-Scale Chinese Legal Case Retrieval Dataset,2024,3.464139029789952e-05,2
W4407888437,A Maritime Document Knowledge Graph Construction Method Based on Conceptual Proximity Relations,2025,3.464139029789952e-05,2
W4385505449,Analysis of the evolution of advanced transformer-based language models: experiments on opinion mining,2023,3.464139029789952e-05,2
W4409737518,Patient-Centered Research Through Artificial Intelligence to Identify Priorities in Cancer Care,2025,3.464139029789952e-05,2
W4407410901,Are Natural Language Processing methods applicable to EPS forecasting in Poland?,2025,3.464139029789952e-05,2
W4396698999,"Benchmarking of Commercial Large Language Models: ChatGPT, Mistral, and Llama",2024,3.464139029789952e-05,2
W4387171991,Revision Transformers: Instructing Language Models to Change Their Values,2023,3.464139029789952e-05,2
W4389518789,A Causal View of Entity Bias in (Large) Language Models,2023,3.464139029789952e-05,2
W4384298419,A transformer framework for generating context-aware knowledge graph paths,2023,3.464139029789952e-05,2
W4409657110,Mitigating Forgetting in Adapting Pre-trained Language Models to Text Processing Tasks via Consistency Alignment,2025,3.464139029789952e-05,2
W4410056248,Exploring formal defeasible reasoning of large language models: A Chain-of-Thought approach,2025,3.464139029789952e-05,2
W4393074274,ELOQUENT CLEF Shared Tasks for Evaluation of Generative Language Model Quality,2024,3.464139029789952e-05,2
W4394789579,Surveying biomedical relation extraction: a critical examination of current datasets and the proposal of a new resource,2024,3.464139029789952e-05,2
W4385567248,Visual Named Entity Linking: A New Dataset and A Baseline,2022,3.464139029789952e-05,2
W4400482513,Ontology matching and repair based on semantic association and probabilistic logic,2024,3.464139029789952e-05,2
W4409253829,Enhancing Vietnamese Mental Health Question-Answering Systems: Adaptive Retrieval Augmented Generation Pipeline and Data Augmentation for Large Language Models,2025,3.464139029789952e-05,2
W4410314721,VIKCSE: Visual-knowledge enhanced contrastive learning with prompts for sentence embedding,2025,3.464139029789952e-05,2
W4409759796,Understanding the Student Confidence in Viva Responses Through Audio Analysis,2025,3.464139029789952e-05,2
W4388209043,Advanced sentence-embedding method considering token importance based on explainable artificial intelligence and text summarization model,2023,3.464139029789952e-05,2
W4235453268,Effects of Language on Visual Perception,2020,3.464139029789952e-05,2
W4406475488,A dataset for evaluating clinical research claims in large language models,2025,3.464139029789952e-05,2
W4408411093,Enhancing diagnostic capability with multi-agents conversational large language models,2025,3.464139029789952e-05,2
W4400525136,BERT-based Global Semantic Refinement and Local Semantic Extraction for Distinguishing Urgent Posts in MOOC Forums,2024,3.464139029789952e-05,2
W3162022378,The text-package: An R-package for Analyzing and Visualizing Human Language Using Natural Language Processing and Deep Learning,2021,3.464139029789952e-05,2
W4401778192,IMPLEMENTING RETRIEVAL-AUGMENTED GENERATION AND VECTOR DATABASES FOR CHATBOTS IN PUBLIC SERVICES AGENCIES CONTEXT,2024,3.464139029789952e-05,2
W4378227416,Morphosyntactic probing of multilingual BERT models,2023,3.464139029789952e-05,2
W4410373085,Specialized or general AI? a comparative evaluation of LLMs’ performance in legal tasks,2025,3.464139029789952e-05,2
W4409002188,Leveraging large language models to mimic domain expert labeling in unstructured text-based electronic healthcare records in non-english languages,2025,3.464139029789952e-05,2
W4409877648,Autonomous embodied navigation task generation from natural language dialogues,2025,3.464139029789952e-05,2
W4406477144,Enhancing textual textbook question answering with large language models and retrieval augmented generation,2025,3.464139029789952e-05,2
W4385572389,TüReuth Legal at SemEval-2023 Task 6: Modelling Local and Global Structure of Judgements for Rhetorical Role Prediction,2023,3.464139029789952e-05,2
W4403989939,NSSC: a neuro-symbolic AI system for enhancing accuracy of named entity recognition and linking from oncologic clinical notes,2024,3.464139029789952e-05,2
W4408095213,FedHLT: Efficient Federated Low-Rank Adaption with Hierarchical Language Tree for Multilingual Modeling,2025,3.464139029789952e-05,2
W4393218806,Bayesian-knowledge driven ontologies: A framework for fusion of semantic knowledge under uncertainty and incompleteness,2024,3.464139029789952e-05,2
W4402727267,Language Models as Black-Box Optimizers for Vision-Language Models,2024,3.464139029789952e-05,2
W4385488817,Defending Machine Reading Comprehension against Question-Targeted Attacks,2023,3.464139029789952e-05,2
W4408112574,Domain-Specific Question-Answering Systems: A Case Study of a Carbon Neutrality Knowledge Base,2025,3.464139029789952e-05,2
W3196778134,Transformer models for enhancing AttnGAN based text to image generation,2021,3.464139029789952e-05,2
W4385807433,Artificial Intelligence’s new clothes? A system technology perspective,2023,3.464139029789952e-05,2
W4409108674,Who Is Leading in Communication Tone? Wavelet Analysis of the Fed and the ECB,2025,3.464139029789952e-05,2
W4391841474,Combining prompt-based language models and weak supervision for labeling named entity recognition on legal documents,2024,3.464139029789952e-05,2
W4386392742,Contrastive Graph Prompt-tuning for Cross-domain Recommendation,2023,3.464139029789952e-05,2
W4407773580,NNBSVR: Neural Network-Based Semantic Vector Representations of ICD-10 codes,2025,3.464139029789952e-05,2
W4394719810,Knowledge Graph Multi-Hop Question Answering Based on Dependent Syntactic Semantic Augmented Graph Networks,2024,3.464139029789952e-05,2
W4387781773,Schema matching based on energy domain pre-trained language model,2023,3.464139029789952e-05,2
W4287890938,Pragmatic and Logical Inferences in NLI Systems: The Case of Conjunction Buttressing,2022,3.464139029789952e-05,2
W4393154423,SAM-PARSER: Fine-Tuning SAM Efficiently by Parameter Space Reconstruction,2024,3.464139029789952e-05,2
W4396843973,NoteLLM: A Retrievable Large Language Model for Note Recommendation,2024,3.464139029789952e-05,2
W4382468457,Fine-Grained Retrieval Prompt Tuning,2023,3.464139029789952e-05,2
W4407442143,A knowledge graph attention network for the cold‐start problem in intelligent manufacturing: Interpretability and accuracy improvement,2025,3.464139029789952e-05,2
W3165643650,Technological progress in electronic health record system optimization: Systematic review of systematic literature reviews,2021,3.464139029789952e-05,2
W4290989514,Improving Prediction of Arabic Fake News Using Fuzzy Logic and Modified Random Forest Model,2022,3.464139029789952e-05,2
W4408466330,Negation Scope Conversion for Unifying Negation-Annotated Datasets,2025,3.464139029789952e-05,2
W3196359847,Application of natural language processing in HAZOP reports,2021,3.464139029789952e-05,2
W2983771403,Memory Graph Networks for Explainable Memory-grounded Question Answering,2019,3.464139029789952e-05,2
W4312385228,Tiny RNN Model with Certified Robustness for Text Classification,2022,3.464139029789952e-05,2
W4410104494,"Dual‐stream algorithms for dementia detection: Harnessing structured and unstructured electronic health record data, a novel approach to prevalence estimation",2025,3.464139029789952e-05,2
W4398250357,Predicting the next sentence (not word) in large language models: What model-brain alignment tells us about discourse comprehension,2024,3.464139029789952e-05,2
W4403063412,Adaptive Bi-Encoder Model Selection and Ensemble for Text Classification,2024,3.464139029789952e-05,2
W4389519823,Detecting Syntactic Change with Pre-trained Transformer Models,2023,3.464139029789952e-05,2
W4389822970,Incivility detection in open source code review and issue discussions,2023,3.464139029789952e-05,2
W4317879851,Assessing the Capacity of Transformer to Abstract Syntactic Representations: A Contrastive Analysis Based on Long-distance Agreement,2023,3.464139029789952e-05,2
W4389520744,Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text,2023,3.464139029789952e-05,2
W4300797895,Learning Entity Linking Features for Emerging Entities,2022,3.464139029789952e-05,2
W4407914295,Assessing Generalization Capability of Text Ranking Models in Polish,2025,3.464139029789952e-05,2
W4385571787,Contrastive Learning of Sociopragmatic Meaning in Social Media,2023,3.464139029789952e-05,2
W3100144085,Adversarial Examples for CNN-Based SAR Image Classification: An Experience Study,2020,3.464139029789952e-05,2
W4315778472,ShortcutLens: A Visual Analytics Approach for Exploring Shortcuts in Natural Language Understanding Dataset,2023,3.464139029789952e-05,2
W4405576517,"Large language models to process, analyze, and synthesize biomedical texts: a scoping review",2024,3.464139029789952e-05,2
W4224920338,Bytecover2: Towards Dimensionality Reduction of Latent Embedding for Efficient Cover Song Identification,2022,3.464139029789952e-05,2
W4387171349,Language Models as Controlled Natural Language Semantic Parsers for Knowledge Graph Question Answering,2023,3.464139029789952e-05,2
W4406870107,From Liberating to Questioning Tabular Data in Documents Using Knowledge Graphs,2025,3.464139029789952e-05,2
W4394574605,Discovering Personally Identifiable Information in Textual Data - A Case Study with Automated Concatenation of Embeddings,2024,3.464139029789952e-05,2
W4396927733,Scoring Multi-hop Question Decomposition Using Masked Language Models,2024,3.464139029789952e-05,2
W4410453176,Implementation and Performance Comparison Study of a Retrieval-Augmented Generation (RAG)-based Chatbot for Korean Medical Consultation (Preprint),2025,3.464139029789952e-05,2
W3199757199,The Language of Dreams: Application of Linguistics-Based Approaches for the Automated Analysis of Dream Experiences,2021,3.464139029789952e-05,2
W4396661911,Semantic- and relation-based graph neural network for knowledge graph completion,2024,3.464139029789952e-05,2
W4400580071,Beyond algorithms: The human touch machine-generated titles for enhancing click-through rates on social media,2024,3.464139029789952e-05,2
W4409778058,Enhancing Accuracy and Explainability in Anomaly Classification with Large Language Models,2025,3.464139029789952e-05,2
W3189998517,Self-Supervised Adversarial Distribution Regularization for Medication Recommendation,2021,3.464139029789952e-05,2
W4311431702,Federated Few-Shot Learning for Mobile NLP,2023,3.464139029789952e-05,2
W4409852358,Exploring Prompt Injection: Methodologies and Risks with an Interactive Chatbot Demonstration,2025,3.464139029789952e-05,2
W4391066510,Principles and applications of convolutional neural network for spectral analysis in food quality evaluation: A review,2024,3.464139029789952e-05,2
W4386826409,A survey of techniques for optimizing transformer inference,2023,3.464139029789952e-05,2
W4405025923,Investigating OCR-Sensitive Neurons to Improve Entity Recognition in Historical Documents,2024,3.464139029789952e-05,2
W3098284381,Unsupervised Parsing with S-DIORA: Single Tree Encoding for Deep Inside-Outside Recursive Autoencoders,2020,3.464139029789952e-05,2
W4398774699,Nonet at SemEval-2023 Task 6: Methodologies for Legal Evaluation,2024,3.464139029789952e-05,2
W4409806408,Addressing Asymmetry in Contrastive Learning: LLM-Driven Sentence Embeddings with Ranking and Label Smoothing,2025,3.464139029789952e-05,2
W4382203222,Multi-perspective contrastive learning framework guided by sememe knowledge and label information for sarcasm detection,2023,3.464139029789952e-05,2
W4410486481,A Discourse Analysis Framework for Legislative and Social Media Debates,2025,3.464139029789952e-05,2
W4400353916,How to classify domain entities into top-level ontology concepts using large language models,2024,3.464139029789952e-05,2
W3010714856,TRANS-BLSTM: Transformer with Bidirectional LSTM for Language Understanding,2020,3.464139029789952e-05,2
W4376485639,CoSBERT: A Cosine-Based Siamese BERT-Networks Using for Semantic Textual Similarity,2023,3.464139029789952e-05,2
W4283768917,CBR-Based Decision Support System for Maintenance Text Using NLP for an Aviation Case Study,2022,3.464139029789952e-05,2
W4407743121,Can ChatGPT recognize impoliteness? An exploratory study of the pragmatic awareness of a large language model,2025,3.464139029789952e-05,2
W4392240059,H3D-Transformer: A Heterogeneous 3D (H3D) Computing Platform for Transformer Model Acceleration on Edge Devices,2024,3.464139029789952e-05,2
W4390823535,Explainable text-based features in predictive models of crowdfunding campaigns,2024,3.464139029789952e-05,2
W4319587062,BERT-based Chinese Medicine Named Entity Recognition Model Applied to Medication Reminder Dialogue System,2022,3.464139029789952e-05,2
W4386566605,AdapterSoup: Weight Averaging to Improve Generalization of Pretrained Language Models,2023,3.464139029789952e-05,2
W4409880148,Natural Language Processing Methods for Assessing Social Determinants of Health in the Electronic Health Records: A Narrative Review,2025,3.464139029789952e-05,2
W4396677700,‘cito': an R package for training neural networks using ‘torch',2024,3.464139029789952e-05,2
W4394958222,Evaluating the language abilities of Large Language Models vs. humans: Three caveats,2024,3.464139029789952e-05,2
W4389523773,C-STS: Conditional Semantic Textual Similarity,2023,3.464139029789952e-05,2
W4400527438,Weighted KL-Divergence for Document Ranking Model Refinement,2024,3.464139029789952e-05,2
W2990591037,ToNy: Contextual embeddings for accurate multilingual discourse segmentation of full documents,2019,3.464139029789952e-05,2
W4327644612,Improving Neural Topic Models with Wasserstein Knowledge Distillation,2023,3.464139029789952e-05,2
W4395688865,Answering Spatial Commonsense Questions by Learning Domain-Invariant Generalization Knowledge,2024,3.464139029789952e-05,2
W4389519996,Culturally Aware Natural Language Inference,2023,3.464139029789952e-05,2
W4389518708,"Towards Reliable Misinformation Mitigation: Generalization, Uncertainty, and GPT-4",2023,3.464139029789952e-05,2
W4362720788,NL-Augmenter 🦎 → 🐍 A Framework for Task-Sensitive Natural Language Augmentation,2023,3.464139029789952e-05,2
W4398150831,ChatGPT Label: Comparing the Quality of Human-Generated and LLM-Generated Annotations in Low-Resource Language NLP Tasks,2024,3.464139029789952e-05,2
W4406459274,LLM Augmentations to support Analytical Reasoning over Multiple Documents,2024,3.464139029789952e-05,2
W4386566688,MetaQA: Combining Expert Agents for Multi-Skill Question Answering,2023,3.464139029789952e-05,2
W4408250731,TCM-KLLaMA: Intelligent generation model for Traditional Chinese Medicine Prescriptions based on knowledge graph and large language model,2025,3.464139029789952e-05,2
W4396871174,Non-Alpha-Num: a novel architecture for generating adversarial examples for bypassing NLP-based clickbait detection mechanisms,2024,3.464139029789952e-05,2
W4406844948,AutoML-Guided Fusion of Entity and LLM-Based Representations for Document Classification,2025,3.464139029789952e-05,2
W4409120200,DALL-M: Context-aware clinical data augmentation with large language models,2025,3.464139029789952e-05,2
W4407034894,"Advanced Text Analysis, Simplification, Classification, and Synthesis Techniques",2025,3.464139029789952e-05,2
W4402351271,Unlocking Chain of Thought in Base Language Models by Heuristic Instruction,2024,3.464139029789952e-05,2
W4382133580,Deep learning prediction models based on EHR trajectories: A systematic review,2023,3.464139029789952e-05,2
W4388709718,WebUltron: An Ultimate Retriever on Webpages Under the Model-Centric Paradigm,2023,3.464139029789952e-05,2
W4392207929,Legal Document Similarity Matching Based on Ensemble Learning,2024,3.464139029789952e-05,2
W3199912364,Box Embeddings: An open-source library for representation learning using geometric structures,2021,3.464139029789952e-05,2
W4295936540,Evaluating Attribution Methods for Explainable NLP with Transformers,2022,3.464139029789952e-05,2
W4386005268,L3Cube-MahaSBERT and HindSBERT: Sentence BERT Models and Benchmarking BERT Sentence Representations for Hindi and Marathi,2023,3.464139029789952e-05,2
W4409968028,Knowledge-Guided Reasoning Chain of Pre-trained LLM in Industrial Domain,2025,3.464139029789952e-05,2
W4388593316,Assessing the Strengths and Weaknesses of Large Language Models,2023,3.464139029789952e-05,2
W4376279187,Dynamic Topic Modelling for Exploring the Scientific Literature on Coronavirus: An Unsupervised Labelling Technique,2023,3.464139029789952e-05,2
W4410096736,Evaluation of Effectiveness of Large Language Models in Ontology and Knowledge Graph Creation,2025,3.464139029789952e-05,2
W4410173160,Linear self-attention with multi-relational graph for knowledge graph completion,2025,3.464139029789952e-05,2
W4386967736,Asking Questions about Scientific Articles—Identifying Large N Studies with LLMs,2023,3.464139029789952e-05,2
W4372341200,Studying the Influence of Toxicity and Emotion Features for Stress Detection on Social Media,2023,3.464139029789952e-05,2
W4406772193,CoLE: A collaborative legal expert prompting framework for large language models in law,2025,3.464139029789952e-05,2
W4409160182,Graph-Convolutional Networks: Named Entity Recognition and Large Language Model Embedding in Document Clustering,2025,3.464139029789952e-05,2
W4378364109,FineEHR: Refine Clinical Note Representations to Improve Mortality Prediction,2023,3.464139029789952e-05,2
W4385516995,Pre-Trained Model-Based NFR Classification: Overcoming Limited Data Challenges,2023,3.464139029789952e-05,2
W4252760000,Proceedings of the 1st Workshop on NLP for Positive Impact,2021,3.464139029789952e-05,2
W4409387699,A TCM Syndrome Differentiation Thinking Method Based on Chain of Thought and Knowledge Retrieval Augmentation,2025,3.464139029789952e-05,2
W4394569842,Let's Speak Trajectories: A Vision to Use NLP Models for Trajectory Analysis Tasks,2024,3.464139029789952e-05,2
W4408546772,Prompt Framework for Extracting Scale-Related Knowledge Entities from Chinese Medical Literature: Development and Evaluation Study,2025,3.464139029789952e-05,2
W4401608846,Enhancing Cyberbullying Detection on Social Media Using Transformer Models,2024,3.464139029789952e-05,2
W4409800684,Knowledge Graph-Based Legal Query System with LLM and Retrieval Augmented Generation,2025,3.464139029789952e-05,2
W4392869958,Translate-Distill: Learning Cross-Language Dense Retrieval by Translation and Distillation,2024,3.464139029789952e-05,2
W4409599055,Research on the discrimination of translation difficulty level based on spoken language signal processing technology,2025,3.464139029789952e-05,2
W4385573387,Fine-Grained Extraction and Classification of Skill Requirements in German-Speaking Job Ads,2022,3.464139029789952e-05,2
W4386276891,Dynamic prompt-based virtual assistant framework for BIM information search,2023,3.464139029789952e-05,2
W4385483069,CAKT: Coupling contrastive learning with attention networks for interpretable knowledge tracing,2023,3.464139029789952e-05,2
W4410253067,A Rhetorical Role Relatedness (RRR) framework for Legal Case Brief Generation,2025,3.464139029789952e-05,2
W4409341352,Integrating TCM’s “One Root of Medicine and Food” Principle Into Dietary Recommendations with Retrieval-Augmented LLMs,2025,3.464139029789952e-05,2
W3008424731,KEML: A Knowledge-Enriched Meta-Learning Framework for Lexical Relation Classification,2021,3.464139029789952e-05,2
W4394999741,Scaling Implicit Bias Analysis across Transformer-Based Language Models through Embedding Association Test and Prompt Engineering,2024,3.464139029789952e-05,2
W4389519036,Improving Language Models’ Meaning Understanding and Consistency by Learning Conceptual Roles from Dictionary,2023,3.464139029789952e-05,2
W4394805543,Research on Long Text Similarity Calculation Method Based on TextRank and BERT,2024,3.464139029789952e-05,2
W4408071852,Pretrained transformers applied to clinical studies improve predictions of treatment efficacy and associated biomarkers,2025,3.464139029789952e-05,2
W4410533142,Diacritical Manipulations as Adversarial Attacks in Arabic NLP Systems,2025,3.464139029789952e-05,2
W4403462579,Bridge to better understanding: Syntax extension with virtual linking-phrase for natural language inference,2024,3.464139029789952e-05,2
W4399487368,ARG-Net: Adversarial Robust Generalized Network to Defend Against Word-Level Textual Adversarial Attacks,2024,3.464139029789952e-05,2
W4386394330,Deep Learning-based Sentence Embeddings using BERT for Textual Entailment,2023,3.464139029789952e-05,2
W3200593933,Comprehensive analysis of embeddings and pre-training in NLP,2021,3.464139029789952e-05,2
W4391402460,An Analysis on Matching Mechanisms and Token Pruning for Late-interaction Models,2024,3.464139029789952e-05,2
W4408165783,Medical foundation large language models for comprehensive text analysis and beyond,2025,3.464139029789952e-05,2
W4399391277,RA-CFGPT: Chinese financial assistant with retrieval-augmented large language model,2024,3.464139029789952e-05,2
W4400200617,Effectiveness of large language models in automated evaluation of argumentative essays: finetuning vs. zero-shot prompting,2024,3.464139029789952e-05,2
W4409281855,Elevating large language model reasoning ability with auto-enhanced zero-shot prompts,2025,3.464139029789952e-05,2
W4401656847,AgXQA: A benchmark for advanced Agricultural Extension question answering,2024,3.464139029789952e-05,2
W4388802931,AI direct tests: LNE and NIST evaluations,2023,3.464139029789952e-05,2
W4388184878,LLMs may Dominate Information Access: Neural Retrievers are Biased Towards LLM-Generated Texts,2023,3.464139029789952e-05,2
W3199348444,Fine-Tuned Transformers Show Clusters of Similar Representations Across Layers,2021,3.464139029789952e-05,2
W4385570698,RMLM: A Flexible Defense Framework for Proactively Mitigating Word-level Adversarial Attacks,2023,3.464139029789952e-05,2
W4403211586,Comprehensive Modeling and Question Answering of Cancer Clinical Practice Guidelines using LLMs,2024,3.464139029789952e-05,2
W4319042407,A study on surprisal and semantic relatedness for eye-tracking data prediction,2023,3.464139029789952e-05,2
W4388537645,Poisoning scientific knowledge using large language models,2023,3.464139029789952e-05,2
W4408366404,Generalizable and scalable multistage biomedical concept normalization leveraging large language models,2025,3.464139029789952e-05,2
W4384890771,SparseEmbed: Learning Sparse Lexical Representations with Contextual Embeddings for Retrieval,2023,3.464139029789952e-05,2
W4406240777,What is creative in childhood writing? Computationally measured linguistic characteristics explain much of the variance in subjective human-rated creativity scores,2025,3.464139029789952e-05,2
W3135098861,Does the Magic of BERT Apply to Medical Code Assignment? A Quantitative Study,2021,3.464139029789952e-05,2
W4323896847,Prompt Consistency for Multi-Label Textual Emotion Detection,2023,3.464139029789952e-05,2
W4407187061,Targeted generative data augmentation for automatic metastases detection from free-text radiology reports,2025,3.464139029789952e-05,2
W4385573481,Enhancing Out-of-Distribution Detection in Natural Language Understanding via Implicit Layer Ensemble,2022,3.464139029789952e-05,2
W4385572505,Commonsense Knowledge Graph Completion Via Contrastive Pretraining and Node Clustering,2023,3.464139029789952e-05,2
W4389519078,Linking Surface Facts to Large-Scale Knowledge Graphs,2023,3.464139029789952e-05,2
W4406163678,The Frontier of Data Erasure: A Survey on Machine Unlearning for Large Language Models,2025,3.464139029789952e-05,2
W4408400712,Dynamically Contrastive Clustering For Sentence Embedding,2024,3.464139029789952e-05,2
W4393152852,Fact-Driven Logical Reasoning for Machine Reading Comprehension,2024,3.464139029789952e-05,2
W3174693043,Reasoning over Entity-Action-Location Graph for Procedural Text Understanding,2021,3.464139029789952e-05,2
W4385565595,How do humans perceive adversarial text? A reality check on the validity and naturalness of word-based adversarial attacks,2023,3.464139029789952e-05,2
W4389519806,BERT Has More to Offer: BERT Layers Combination Yields Better Sentence Embeddings,2023,3.464139029789952e-05,2
W4406783181,Context Is King: Large Language Models’ Interpretability in Divergent Knowledge Scenarios,2025,3.464139029789952e-05,2
W4406297511,Tool learning with large language models: a survey,2025,3.464139029789952e-05,2
W4390426502,The role of large language models in medical image processing: a narrative review,2023,3.464139029789952e-05,2
W4367551721,Mapping Relationship Discovery of Multidimensional Architectures in Autonomous Transportation System Based on Text-Matching Model,2023,3.464139029789952e-05,2
W4401824351,Zero‐ and few‐shot prompting of generative large language models provides weak assessment of risk of bias in clinical trials,2024,3.464139029789952e-05,2
W4390805651,Hevenli: A Large Dataset for English-Vietnamese Cross-Lingual Natural Language Inference in Healthcare,2024,3.464139029789952e-05,2
W4376464559,Automatic Context Pattern Generation for Entity Set Expansion,2023,3.464139029789952e-05,2
W4396506940,Challenges and opportunities of using transformer-based multi-task learning in NLP through ML lifecycle: A position paper,2024,3.464139029789952e-05,2
W4389524345,FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions,2023,3.464139029789952e-05,2
W4387250954,A Theoretical Framework for AI Models Explainability with Application in Biomedicine,2023,3.464139029789952e-05,2
W4392763134,Large language models are able to downplay their cognitive abilities to fit the persona they simulate,2024,3.464139029789952e-05,2
W4407315605,Metacognitive symbolic distillation framework for multi-choice machine reading comprehension,2025,3.464139029789952e-05,2
W4391994107,A Systematic Review of NLP Applications in Clinical Healthcare: Advancement and Challenges,2024,3.464139029789952e-05,2
W4385488736,"AfriWOZ: Corpus for Exploiting Cross-Lingual Transfer for Dialogue Generation in Low-Resource, African Languages",2023,3.464139029789952e-05,2
W4398764576,Natural language processing systems for extracting information from electronic health records about activities of daily living. A systematic review,2024,3.464139029789952e-05,2
W4407194866,CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare,2025,3.464139029789952e-05,2
W4407827488,A systematic review of automated hyperpartisan news detection,2025,3.464139029789952e-05,2
W4392951803,Chinese Diabetes Question Classification Using Large Language Models and Transfer Learning,2024,3.464139029789952e-05,2
W4220771481,TaxoCom: Topic Taxonomy Completion with Hierarchical Discovery of Novel Topic Clusters,2022,3.464139029789952e-05,2
W4404818016,Concepts and Relations Features Are All You Need for Embedding-Based Ontology Matching,2024,3.464139029789952e-05,2
W4400264092,Mlke: A Benchmark for Multilingual Knowledge Editing on Large Language Model,2024,3.464139029789952e-05,2
W4409957554,AdaFT: An efficient domain-adaptive fine-tuning framework for sentiment analysis in chinese financial texts,2025,3.464139029789952e-05,2
W4393187322,Automatic categorization of self-acknowledged limitations in randomized controlled trial publications,2024,3.464139029789952e-05,2
W4389520137,Disentangling Structure and Style: Political Bias Detection in News by Inducing Document Hierarchy,2023,3.464139029789952e-05,2
W4410308771,Search method for ship regulations based on semantic similarity using natural language processing,2025,3.464139029789952e-05,2
W4390098899,Pre-Trained Models for Intent Classification in Chatbot: Comparative Study and Critical Analysis,2023,3.464139029789952e-05,2
W4409019555,Efficient Fine-Tuning of Small-Parameter Large Language Models for Biomedical Bilingual Multi-Task Applications,2025,3.464139029789952e-05,2
W4393158050,Verbal Reports as Data Revisited: Using Natural Language Models to Validate Cognitive Models,2024,3.464139029789952e-05,2
W4407079389,Multilingual Computational Models Reveal Shared Brain Responses to 21 Languages,2025,3.464139029789952e-05,2
W4408741271,Exploring Classification Consistency of Natural Language Requirements Using GPT-4o,2025,3.464139029789952e-05,2
W4399485854,Evaluating Generative Language Models with Prompt Engineering for Categorizing User Stories to its Sector Domains,2024,3.464139029789952e-05,2
W4409094772,Snort Meets Transformers: Accelerating Transformer-Based Network Traffic Classification for Real-Time Performance,2025,3.464139029789952e-05,2
W4382245789,Retrieval-Based Diagnostic Decision Support: Mixed Methods Study (Preprint),2023,3.464139029789952e-05,2
W4408164385,Sentential Cross-lingual Paraphrase Detection for English-Urdu Language Pair,2025,3.464139029789952e-05,2
W4401414182,FLTRNN: Faithful Long-Horizon Task Planning for Robotics with Large Language Models,2024,3.464139029789952e-05,2
W4400527956,A Setwise Approach for Effective and Highly Efficient Zero-shot Ranking with Large Language Models,2024,3.464139029789952e-05,2
W4409785640,"Improving Text Classification on Small-Sized, Imbalanced Datasets with Selective Few-Random-Shot Augmentation",2025,3.464139029789952e-05,2
W4409068762,Optimising Contract Interpretations with Large Language Models: A Comparative Evaluation of a Vector Database-Powered Chatbot vs. ChatGPT,2025,3.464139029789952e-05,2
W4382317573,CodeAttack: Code-Based Adversarial Attacks for Pre-trained Programming Language Models,2023,3.464139029789952e-05,2
W4406940792,ERASMO: Leveraging Large Language Models for Enhanced Clustering Segmentation,2025,3.464139029789952e-05,2
W4393146990,"Translate Meanings, Not Just Words: IdiomKB’s Role in Optimizing Idiomatic Translation with Language Models",2024,3.464139029789952e-05,2
W4409663470,Qibo: A Large Language Model for traditional Chinese medicine,2025,3.464139029789952e-05,2
W4292676168,Automated diagnosing primary open-angle glaucoma from fundus image by simulating human’s grading with deep learning,2022,3.464139029789952e-05,2
W4409166199,Verifying Cross-Modal Entity Consistency in News Using Vision-Language Models,2025,3.464139029789952e-05,2
W4391114242,Towards Generative Search and Recommendation: A keynote at RecSys 2023,2023,3.464139029789952e-05,2
W4409183263,Large Language Model Can Be a Foundation for Hidden Rationale-Based Retrieval,2025,3.464139029789952e-05,2
W4385574304,Retrofitting Multilingual Sentence Embeddings with Abstract Meaning Representation,2022,3.464139029789952e-05,2
W4396982340,CoSENT: Consistent Sentence Embedding via Similarity Ranking,2024,3.464139029789952e-05,2
W4315436249,Negation detection in Dutch clinical texts: an evaluation of rule-based and machine learning methods,2023,3.464139029789952e-05,2
W4327644053,Parameter-Efficient Sparse Retrievers and Rerankers Using Adapters,2023,3.464139029789952e-05,2
W4408559683,Towards Building Urdu Language Document Retrieval Framework,2025,3.464139029789952e-05,2
W4410429768,Generating Clarifying Questions for Conversational Legal Case Retrieval without External Knowledge,2025,3.464139029789952e-05,2
W3012625840,The value of text for small business default prediction: A Deep Learning approach,2021,3.464139029789952e-05,2
W4323055192,Controllable Text Generation Using Semantic Control Grammar,2023,3.464139029789952e-05,2
W4391678886,Federated Freeze BERT for text classification,2024,3.464139029789952e-05,2
W4228996479,Effective use of BERT in graph embeddings for sparse knowledge graph completion,2022,3.464139029789952e-05,2
W4406371523,COTR: Efficient Job Task Recognition for Occupational Information Systems with Class-Incremental Learning,2025,3.464139029789952e-05,2
W4410441532,Intelligent Question-Answering on Geomorphology Knowledge Based on Knowledge Graph Retrieval-Augmented Generation Technology,2025,3.464139029789952e-05,2
W4408089088,Fixer-level supervised contrastive learning for bug assignment,2025,3.464139029789952e-05,2
W4317829471,PLM-AS: Pre-trained Language Models Augmented with Scanpaths for Sentiment Classification,2023,3.464139029789952e-05,2
W4381713888,University Student Dropout Prediction Using Pretrained Language Models,2023,3.464139029789952e-05,2
W4402352514,Defect Correction Method for Software Requirements Text Using Large Language Models,2024,3.464139029789952e-05,2
W4394717739,Interactive Question Answering Systems: Literature Review,2024,3.464139029789952e-05,2
W3207160263,Deep Learning Methods for Vessel Trajectory Prediction Based on Recurrent Neural Networks,2021,3.464139029789952e-05,2
W4389109075,NLFOA: Natural Language Focused Ontology Alignment,2023,3.464139029789952e-05,2
W4401664886,PMANet: Malicious URL detection via post-trained language model guided multi-level feature attention network,2024,3.464139029789952e-05,2
W4388288227,Comparing neural sentence encoders for topic segmentation across domains: not your typical text similarity task,2023,3.464139029789952e-05,2
W4402727837,LLaMA-Excitor: General Instruction Tuning via Indirect Feature Interaction,2024,3.464139029789952e-05,2
W4385570924,Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text,2023,3.464139029789952e-05,2
W4393159548,Narrowing the Gap between Supervised and Unsupervised Sentence Representation Learning with Large Language Model,2024,3.464139029789952e-05,2
W4362640873,SEARCHFORMER: Semantic patent embeddings by siamese transformers for prior art search,2023,3.464139029789952e-05,2
W4313260873,Stock Price Prediction Using a Frequency Decomposition Based GRU Transformer Neural Network,2022,3.464139029789952e-05,2
W4389518740,Can You Follow Me? Testing Situational Understanding for ChatGPT,2023,3.464139029789952e-05,2
W4410392558,Cross-Lingual Entity Linking Using GPT Models in Radiology Abstracts,2025,3.464139029789952e-05,2
W4406407909,Large Language Models Struggle to Encode Medical Concepts - A Multilingual Benchmarking and Comparative Analysis,2025,3.464139029789952e-05,2
W4405979169,Enhancing Text-to-Image Retrieval by Addressing Parts-of-Speech Imbalance in Vision-Language Models,2025,3.464139029789952e-05,2
W4389520008,Detecting Propaganda Techniques in Code-Switched Social Media Text,2023,3.464139029789952e-05,2
W4407695356,Do LLMs write like humans? Variation in grammatical and rhetorical styles,2025,3.464139029789952e-05,2
W4367671721,FeQA: Fusion and enhancement of multi-source knowledge on question answering,2023,3.464139029789952e-05,2
W4382239759,Analogical Inference Enhanced Knowledge Graph Embedding,2023,3.464139029789952e-05,2
W4407598256,ChatCNC: Conversational machine monitoring via large language model and real-time data retrieval augmented generation,2025,3.464139029789952e-05,2
W4360993130,Enhancing Biomedical ReQA With Adversarial Hard In-Batch Negative Samples,2023,3.464139029789952e-05,2
W4400142326,Knowledge-injected prompt learning for actionable information extraction from crisis-related tweets,2024,3.464139029789952e-05,2
W4392546128,Systematic evaluation of common natural language processing techniques to codify clinical notes,2024,3.464139029789952e-05,2
W2976258142,10 years of health-care reform in China: progress and gaps in Universal Health Coverage,2019,3.464139029789952e-05,2
W4387316165,CitePrompt: Using Prompts to Identify Citation Intent in Scientific Papers,2023,3.464139029789952e-05,2
W4322505467,Automated ICD coding for coronary heart diseases by a deep learning method,2023,3.464139029789952e-05,2
W4402604910,CoT-BERT: Enhancing Unsupervised Sentence Representation Through Chain-of-Thought,2024,3.464139029789952e-05,2
W4406424553,COMCARE: A Collaborative Ensemble Framework for Context-Aware Medical Named Entity Recognition and Relation Extraction,2025,3.464139029789952e-05,2
W4393333899,Automatic information extraction from Employment Tribunal judgements using large language models,2024,3.464139029789952e-05,2
W4408769333,An automated classification pipeline for tables in pharmacokinetic literature,2025,3.464139029789952e-05,2
W4399920053,LMCK: pre-trained language models enhanced with contextual knowledge for Vietnamese natural language inference,2024,3.464139029789952e-05,2
W4410092719,The bewitching AI: The Illusion of Communication with Large Language Models,2025,3.464139029789952e-05,2
W4409254893,Detecting Persuasion in Financial Short Texts: A Computational Approach,2025,3.464139029789952e-05,2
W4409166643,Jina Embeddings V3: Multilingual Text Encoder with Low-Rank Adaptations,2025,3.464139029789952e-05,2
W3141235929,Natural language processing,2021,3.464139029789952e-05,2
W4408135179,A simplified retriever to improve accuracy of phenotype normalizations by large language models,2025,3.464139029789952e-05,2
W4392384310,LEAD: Liberal Feature-based Distillation for Dense Retrieval,2024,3.464139029789952e-05,2
W4381827011,Identifying and Extracting Rare Disease Phenotypes with Large Language Models,2023,3.464139029789952e-05,2
W4385574319,How Long Is Enough? Exploring the Optimal Intervals of Long-Range Clinical Note Language Modeling,2022,3.464139029789952e-05,2
W4229036562,RLAS-BIABC: A Reinforcement Learning-Based Answer Selection Using the BERT Model Boosted by an Improved ABC Algorithm,2022,3.464139029789952e-05,2
W4397010262,Few-shot biomedical relation extraction using data augmentation and domain information,2024,3.464139029789952e-05,2
W4395112660,SpecInfer: Accelerating Large Language Model Serving with Tree-based Speculative Inference and Verification,2024,3.464139029789952e-05,2
W4206254927,On the relationship between similar requirements and similar software,2022,3.464139029789952e-05,2
W4408210925,A Multi-Attribute Mixture Expert Reasoning Approach Based on Large Language Models,2025,3.464139029789952e-05,2
W4390497390,Adversarial machine learning :,2024,3.464139029789952e-05,2
W4319934130,Memory-Aware Attentive Control for Community Question Answering With Knowledge-Based Dual Refinement,2023,3.464139029789952e-05,2
W4399632250,CAREER: Context-Aware API Recognition with Data Augmentation for API Knowledge Extraction,2024,3.464139029789952e-05,2
W4409214646,The News in Earnings Announcement Disclosures: Capturing Word Context Using LLM Methods,2025,3.464139029789952e-05,2
W3120519792,EarlyBERT: Efficient BERT Training via Early-bird Lottery Tickets,2021,3.464139029789952e-05,2
W3165244476,Unsupervised multi-sense language models for natural language processing tasks,2021,3.464139029789952e-05,2
W4387968110,ECENet: Explainable and Context-Enhanced Network for Muti-modal Fact verification,2023,3.464139029789952e-05,2
W3116179800,Incorporating Syntax and Frame Semantics in Neural Network for Machine Reading Comprehension,2020,3.464139029789952e-05,2
W4396900090,Introduction to Large Language Models (LLMs) for dementia care and research,2024,3.464139029789952e-05,2
W4281737296,NuPS: A Parameter Server for Machine Learning with Non-Uniform Parameter Access,2022,3.464139029789952e-05,2
W4407719186,Extend Adversarial Policy Against Neural Machine Translation via Unknown Token,2025,3.464139029789952e-05,2
W4403010755,"ChatGeoAI: Enabling Geospatial Analysis for Public through Natural Language, with Large Language Models",2024,3.464139029789952e-05,2
W4400426842,Intent aware data augmentation by leveraging generative AI for stress detection in social media texts,2024,3.464139029789952e-05,2
W4389519029,Universal Self-Adaptive Prompting,2023,3.464139029789952e-05,2
W4408204750,Towards semantic versioning of open pre-trained language model releases on hugging face,2025,3.464139029789952e-05,2
W4394822252,Floating-Point Embedding: Enhancing the Mathematical Comprehension of Large Language Models,2024,3.464139029789952e-05,2
W4409705281,Exploring the Green AI Potential of Adapter Tuning for Language Models,2025,3.464139029789952e-05,2
W4406609894,Amplifying commonsense knowledge via bi-directional relation integrated graph-based contrastive pre-training from large language models,2025,3.464139029789952e-05,2
W4385574114,Metric-guided Distillation: Distilling Knowledge from the Metric to Ranker and Retriever for Generative Commonsense Reasoning,2022,3.464139029789952e-05,2
W4362650778,Less is Better: Constructing Legal Question Answering System by Weighing Longest Common Subsequence of Disjunctive Union Text,2023,3.464139029789952e-05,2
W4385571153,"Expand, Rerank, and Retrieve: Query Reranking for Open-Domain Question Answering",2023,3.464139029789952e-05,2
W3091864705,Fact Extraction and VERification -- The FEVER case: An Overview,2020,3.464139029789952e-05,2
W4399730482,A criteria-based classification model using augmentation and contrastive learning for analyzing imbalanced statement data,2024,3.464139029789952e-05,2
W4409989924,A disambiguation method for potential ambiguities in Chinese based on knowledge graphs and large language model,2025,3.464139029789952e-05,2
W4389520486,Open-source Large Language Models are Strong Zero-shot Query Likelihood Models for Document Ranking,2023,3.464139029789952e-05,2
W4393308651,Prefix Data Augmentation for Contrastive Learning of Unsupervised Sentence Embedding,2024,3.464139029789952e-05,2
W4406846967,SPIRIT: Structural Entropy Guided Prefix Tuning for Hierarchical Text Classification,2025,3.464139029789952e-05,2
W4401068660,"Prompts and Large Language Models: A New Tool for Drafting, Reviewing and Interpreting Contracts?",2024,3.464139029789952e-05,2
W4389724194,Back Translation-EDA and Transformer for Hate Speech Classification in Indonesian,2023,3.464139029789952e-05,2
W4389518213,Explaining Data Patterns in Natural Language with Language Models,2023,3.464139029789952e-05,2
W4406016552,Brain-model neural similarity reveals abstractive summarization performance,2025,3.464139029789952e-05,2
W4313315719,Deep learning-based question answering: a survey,2022,3.464139029789952e-05,2
W4402101192,LLMs in the Loop: Leveraging Large Language Model Annotations for Active Learning in Low-Resource Languages,2024,3.464139029789952e-05,2
W4402654757,Improved Models for Media Bias Detection and Subcategorization,2024,3.464139029789952e-05,2
W4406152280,A generalist medical language model for disease diagnosis assistance,2025,3.464139029789952e-05,2
W4408235728,"From Pure Language to Word Embeddings: Benjamin, Metaphysics, and Machine Translation",2025,3.464139029789952e-05,2
W4383999518,A benchmark for evaluating Arabic contextualized word embedding models,2023,3.464139029789952e-05,2
W4396225444,Cross-Domain Knowledge Transfer without Retraining to Facilitating Seamless Knowledge Application in Large Language Models,2024,3.464139029789952e-05,2
W3169461013,Claim Detection in Biomedical Twitter Posts,2021,3.464139029789952e-05,2
W4406354428,The Impact of Linguistic Signals on Cognitive Change in Support Seekers in Online Mental Health Communities: Text Analysis and Empirical Study,2025,3.464139029789952e-05,2
W4380358240,"""This Is Fake News"": Characterizing the Spontaneous Debunking from Twitter Users to COVID-19 False Information",2023,3.464139029789952e-05,2
W4394796464,A noise audit of human-labeled benchmarks for machine commonsense reasoning,2024,3.464139029789952e-05,2
W4389520015,Inductive Relation Inference of Knowledge Graph Enhanced by Ontology Information,2023,3.464139029789952e-05,2
W4406276517,Knowledge Enhanced Language Model for Biomedical Natural Language Processing: Introducing a New Language Model for BioNLP,2025,3.464139029789952e-05,2
W4377197291,Counterfactual can be strong in medical question and answering,2023,3.464139029789952e-05,2
W4287855087,TCU at SemEval-2022 Task 8: A Stacking Ensemble Transformer Model for Multilingual News Article Similarity,2022,3.464139029789952e-05,2
W4212830955,Doc2KG,2022,3.464139029789952e-05,2
W4396901469,Efficient Compression of Large Language Models: A Case Study on Llama 2 with 13B Parameters,2024,3.464139029789952e-05,2
W4408999580,Named entity recognition for construction documents based on fine-tuning of large language models with low-quality datasets,2025,3.464139029789952e-05,2
W4409651300,Event Detection and Analysis from Social Media Data Using N-gram and Distil-BERT Model,2025,3.464139029789952e-05,2
W4408599531,Case ID Revealed HERE: Hybrid Elusive Case Repair Method for Transformer-Driven Business Process Event Log Enhancement,2025,3.464139029789952e-05,2
W3159119521,Human-Model Divergence in the Handling of Vagueness,2021,3.464139029789952e-05,2
W4409972601,A Few‐Shot Learning Approach for a Multilingual Agro‐Information Question Answering System,2025,3.464139029789952e-05,2
W4401039927,The Role of Information Technology in Combating Hoaxes and Misinformation,2024,3.464139029789952e-05,2
W4385570233,Dataset Distillation with Attention Labels for Fine-tuning BERT,2023,3.464139029789952e-05,2
W4410412168,Ontology-Based Learning Assistant Chatbot: Enhancing Accurate and Explanatory Knowledge Provision in Myanmar’s Primary Education,2025,3.464139029789952e-05,2
W4392712776,DAEPK:Domain-Adaptive Text Feature Enhancement Technology Integrating Prior Knowledge Domain In Text Classification,2024,3.464139029789952e-05,2
W4406628184,Large language models for data extraction from unstructured and semi-structured electronic health records: a multiple model performance evaluation,2025,3.464139029789952e-05,2
W4408853582,RECoT: Relation-enhanced Chains-of-Thoughts for knowledge-intensive multi-hop questions answering,2025,3.464139029789952e-05,2
W4406737213,Has machine paraphrasing skills approached humans? Detecting automatically and manually generated paraphrased cases,2025,3.464139029789952e-05,2
W3211152275,AVocaDo: Strategy for Adapting Vocabulary to Downstream Domain,2021,3.464139029789952e-05,2
W4409079480,NLP verification: towards a general methodology for certifying robustness,2025,3.464139029789952e-05,2
W4394000434,Interpretable answer retrieval based on heterogeneous network embedding,2024,3.464139029789952e-05,2
W4409172641,Legal Literacy in Indonesia: Leveraging Semantic-Based AI and NLP for Enhanced Civil Law Access,2025,3.464139029789952e-05,2
W4385571401,BIC: Twitter Bot Detection with Text-Graph Interaction and Semantic Consistency,2023,3.464139029789952e-05,2
W4406828411,Inflect-text: a novel mechanism to evade neural text classifiers by leveraging word inflectional perturbations,2025,3.464139029789952e-05,2
W4391609107,"Embodied human language models vs. Large Language Models, or why Artificial Intelligence cannot explain the modal be able to",2024,3.464139029789952e-05,2
W4408044443,Generalizable and Robust Log Anomaly Detection Based on Transformer,2025,3.464139029789952e-05,2
W4408569861,Contrastive learning with large language models for medical code prediction,2025,3.464139029789952e-05,2
W4312092237,Classifying Customers’ Journey from Online Reviews of Amazon Fresh via Sentiment Analysis and Topic Modelling,2022,3.464139029789952e-05,2
W4406313140,"Fine-Tuning PHI-3 for Multiple-Choice Question Answering: Methodology, Results, and Challenges",2025,3.464139029789952e-05,2
W4408080196,Text Summarization Using the T5 Transformer with Rouge Score,2025,3.464139029789952e-05,2
W4313591059,Knowledge Adaptive Multi-Way Matching Network for Biomedical Named Entity Recognition via Machine Reading Comprehension,2023,3.464139029789952e-05,2
W4401208806,Exploring Continual Learning of Compositional Generalization in NLI,2024,3.464139029789952e-05,2
W4389288957,Sample-based Dynamic Hierarchical Transformer with Layer and Head Flexibility via Contextual Bandit,2023,3.464139029789952e-05,2
W4406640860,Human-interpretable clustering of short text using large language models,2025,3.464139029789952e-05,2
W4391070609,Semantics-enabled biomedical literature analytics,2024,3.464139029789952e-05,2
W3209080096,MOOCCubeX: A Large Knowledge-centered Repository for Adaptive Learning in MOOCs,2021,3.464139029789952e-05,2
W4407567330,Optimizing Tumor Information Extraction from Pathology Reports Using Large Language Models: The Advantage of Few-Shot Learning,2025,3.464139029789952e-05,2
W4409098905,Mental Health in the Digital Era-NLP Models for Depression and Suicidal Tendency Detection,2025,3.464139029789952e-05,2
W4393039272,Automatic Coding of Contingency in Child-Caregiver Conversations,2024,3.464139029789952e-05,2
W4402352134,SEVEN: Pruning Transformer Model by Reserving Sentinels,2024,3.464139029789952e-05,2
W4407596815,Large language models can better understand knowledge graphs than we thought,2025,3.464139029789952e-05,2
W4406174106,Leveraging Retrieval-Augmented Generation for Swahili Language Conversation Systems,2025,3.464139029789952e-05,2
W4382239991,Multi-Label Few-Shot ICD Coding as Autoregressive Generation with Prompt,2023,3.464139029789952e-05,2
W4389524005,Improving Bias Mitigation through Bias Experts in Natural Language Understanding,2023,3.464139029789952e-05,2
W4401094131,Show Criminals’ True Color: Chinese Variant Toxic Text Restoration Based on Pointer-Generator Network,2024,3.464139029789952e-05,2
W4409202736,Improving zero-shot cross-domain slot filling via machine reading comprehension prompt template,2025,3.464139029789952e-05,2
W4389520408,What do Deck Chairs and Sun Hats Have in Common? Uncovering Shared Properties in Large Concept Vocabularies,2023,3.464139029789952e-05,2
W4389519826,FinePrompt: Unveiling the Role of Finetuned Inductive Bias on Compositional Reasoning in GPT-4,2023,3.464139029789952e-05,2
W4408345962,LLM-IE: a python package for biomedical generative information extraction with large language models,2025,3.464139029789952e-05,2
W4405127520,Enhanced question understanding for multi-type legal question answering,2024,3.464139029789952e-05,2
W4389524356,FLEEK: Factual Error Detection and Correction with Evidence Retrieved from External Knowledge,2023,3.464139029789952e-05,2
W4367556316,Explainable Natural Language Inference in the Legal Domain via Text Generation,2023,3.464139029789952e-05,2
W4407214475,Evaluation and Analysis of Large Language Models Performance in English Exam,2024,3.464139029789952e-05,2
W4229029358,XLTime: A Cross-Lingual Knowledge Transfer Framework for Temporal Expression Extraction,2022,3.464139029789952e-05,2
W4399513151,Towards knowledge-infused automated disease diagnosis assistant,2024,3.464139029789952e-05,2
W4399116719,An Efficient Corpus Indexer for dynamic corpora retrieval,2024,3.464139029789952e-05,2
W4408529278,"Lost in translation: using global fact-checks to measure multilingual misinformation prevalence, spread, and evolution",2025,3.464139029789952e-05,2
W4210550054,KerasBERT: Modeling the Keras Language,2021,3.464139029789952e-05,2
W4409991618,Research on Automatic Question Generation Methods for Niche Subjects Based on Large Language Models,2025,3.464139029789952e-05,2
W4406941547,GovBERT-BR: A BERT-Based Language Model for Brazilian Portuguese Governmental Data,2025,3.464139029789952e-05,2
W4323341588,Long Short-Term Memory for Non-Factoid Answer Selection in Indonesian Question Answering System for Health Information,2023,3.464139029789952e-05,2
W4409810916,Improving Vietnamese Legal Document Retrieval Using Synthetic Data,2025,3.464139029789952e-05,2
W4385828568,Unsupervised techniques for generating a standard sample self-explanation answer with knowledge components in a math quiz,2023,3.464139029789952e-05,2
W4322008875,Contextualized Construct Representation: Leveraging Psychometric Scales to Advance Theory-Driven Text Analysis,2023,3.464139029789952e-05,2
W4392632244,Rag-Fusion: A New Take on Retrieval Augmented Generation,2024,3.464139029789952e-05,2
W3202780679,Pushing on Text Readability Assessment: A Transformer Meets Handcrafted Linguistic Features,2021,3.464139029789952e-05,2
W4407843264,Geographic Named Entity Matching and Evaluation Recommendation Using Multi-Objective Tasks: A Study Integrating a Large Language Model (LLM) and Retrieval-Augmented Generation (RAG),2025,3.464139029789952e-05,2
W4242952243,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations,2021,3.464139029789952e-05,2
W4327644068,Probing BERT for Ranking Abilities,2023,3.464139029789952e-05,2
W4405185737,KG-EGV: A Framework for Question Answering with Integrated Knowledge Graphs and Large Language Models,2024,3.464139029789952e-05,2
W4389519877,NERetrieve: Dataset for Next Generation Named Entity Recognition and Retrieval,2023,3.464139029789952e-05,2
W4391579685,KnowLog: Knowledge Enhanced Pre-trained Language Model for Log Understanding,2024,3.464139029789952e-05,2
W3199225381,Explainable Identification of Dementia From Transcripts Using Transformer Networks,2022,3.464139029789952e-05,2
W4406731238,Towards normalized clinical information extraction in Chinese radiology report with large language models,2025,3.464139029789952e-05,2
W4388937418,Transformer-Based Models for Named Entity Recognition: A Comparative Study,2023,3.464139029789952e-05,2
W4385573195,RuCoLA: Russian Corpus of Linguistic Acceptability,2022,3.464139029789952e-05,2
W4409951379,Detoxifying language model outputs: combining multi-agent debates and reinforcement learning for improved summarization,2025,3.464139029789952e-05,2
W4220924176,A Deep Fusion Matching Network Semantic Reasoning Model,2022,3.464139029789952e-05,2
W4393160541,Mitigating the Impact of False Negative in Dense Retrieval with Contrastive Confidence Regularization,2024,3.464139029789952e-05,2
W3204615515,A semantic approach to post-retrieval query performance prediction,2021,3.464139029789952e-05,2
W4404021255,Biomedical Information Retrieval with Positive-Unlabeled Learning and Knowledge Graphs,2024,3.464139029789952e-05,2
W4386566577,Context Generation Improves Open Domain Question Answering,2023,3.464139029789952e-05,2
W4386587781,Graph-Enriched Biomedical Entity Representation Transformer,2023,3.464139029789952e-05,2
W4408162838,Automated Requirements Terminology Extraction,2025,3.464139029789952e-05,2
W4407407865,Artificially Intelligent or Artificially Inflated? Determinants and Informativeness of Corporate AI Disclosures,2025,3.464139029789952e-05,2
W4410498908,Neural Topic Generation Utilizing Attention Mechanisms With Transformer‐Based Embeddings for Root‐Cause Analysis of Manufacturing Defects in Electronic Products,2025,3.464139029789952e-05,2
W4403577774,A GAIL Fine-Tuned LLM Enhanced Framework for Low-Resource Knowledge Graph Question Answering,2024,3.464139029789952e-05,2
W4386761922,CTSARF: A Chinese Text Similarity Analysis Model based on Residual Fusion,2023,3.464139029789952e-05,2
W4389606799,Automated Domain Modeling with Large Language Models: A Comparative Study,2023,3.464139029789952e-05,2
W4406026208,Explainable Security Requirements Classification Through Transformer Models,2025,3.464139029789952e-05,2
W4281384899,Label Anchored Contrastive Learning for Language Understanding,2022,3.464139029789952e-05,2
W4402584557,Cross-Lingual Short-Text Semantic Similarity for Kannada–English Language Pair,2024,3.464139029789952e-05,2
W4391661692,Explainable Attention Pruning: A Metalearning-Based Approach,2024,3.464139029789952e-05,2
W4409468566,Text-augmented long-term relation dependency learning for knowledge graph representation,2025,3.464139029789952e-05,2
W4319332823,Large language models can segment narrative events similarly to humans,2025,3.464139029789952e-05,2
W4389747470,A Semantic Search System for the Supremo Tribunal de Justiça,2023,3.464139029789952e-05,2
W3176971293,Have We Solved The Hard Problem? It’s Not Easy! Contextual Lexical Contrast as a Means to Probe Neural Coherence,2021,3.464139029789952e-05,2
W4389616438,Understanding the sentiment associated with cultural ecosystem services using images and text from social media,2023,3.464139029789952e-05,2
W4394617362,ACP-DRL: an anticancer peptides recognition method based on deep representation learning,2024,3.464139029789952e-05,2
W4408751761,Entity Disambiguation Using Ensemble Classification,2025,3.464139029789952e-05,2
W4407959012,Toward a Large Language Model-Driven Medical Knowledge Retrieval and QA System: Framework Design and Evaluation,2025,3.464139029789952e-05,2
W4389519095,SpEL: Structured Prediction for Entity Linking,2023,3.464139029789952e-05,2
W4407797263,Effectiveness in retrieving legal precedents: exploring text summarization and cutting-edge language models toward a cost-efficient approach,2025,3.464139029789952e-05,2
W4409270119,Securing NLP Systems: A Comprehensive AI-Based Approach,2025,3.464139029789952e-05,2
W4410398307,End-to-end Chinese clinical event extraction based on large language model,2025,3.464139029789952e-05,2
W4410515601,Improving Knowledge Tracing through Multi-Source Scaling with Decoder-Only Transformers,2025,3.464139029789952e-05,2
W4313201586,Multi-granularity Hierarchical Feature Extraction for Question-Answering Understanding,2022,3.464139029789952e-05,2
W4385569919,NLPeer: A Unified Resource for the Computational Study of Peer Review,2023,3.464139029789952e-05,2
W4409286293,Natural language processing models reveal neural dynamics of human conversation,2025,3.464139029789952e-05,2
W4387846294,Optimizing Upstream Representations for Out-of-Domain Detection with Supervised Contrastive Learning,2023,3.464139029789952e-05,2
W4409952321,ICL: In-loop continual learning framework for language model pre-training for E-commerce,2025,3.464139029789952e-05,2
W4409245884,Complex knowledge base question answering with difficulty-aware active data augmentation,2025,3.464139029789952e-05,2
W4410443327,Aspect-Enhanced Prompting Method for Unsupervised Domain Adaptation in Aspect-Based Sentiment Analysis,2025,3.464139029789952e-05,2
W4402703473,From NLP to Taxonomy: Identifying and Classifying Key Functionality Concepts of Multi-level Project Planning and Control Systems,2024,3.464139029789952e-05,2
W3199475877,Deep Learning Based Wheat Crop Yield Prediction Model in Punjab Region of North India,2021,3.464139029789952e-05,2
W4389524566,Exchange-of-Thought: Enhancing Large Language Model Capabilities through Cross-Model Communication,2023,3.464139029789952e-05,2
W4409716856,Hallucination‐Free? Assessing the Reliability of Leading <scp>AI</scp> Legal Research Tools,2025,3.464139029789952e-05,2
W3159986071,Compositional Processing Emerges in Neural Networks Solving Math Problems,2021,3.464139029789952e-05,2
W4223543859,An Extensive Study on Pretrained Models for Natural Language Processing Based on Transformers,2022,3.464139029789952e-05,2
W4409448707,Shades of zero: Distinguishing impossibility from inconceivability,2025,3.464139029789952e-05,2
W3034893234,Evaluation of Neural Architectures Trained with Square Loss vs Cross-Entropy in Classification Tasks,2020,3.464139029789952e-05,2
W4385571638,Exploring Anisotropy and Outliers in Multilingual Language Models for Cross-Lingual Semantic Sentence Similarity,2023,3.464139029789952e-05,2
W4283314135,An Automatic and Efficient BERT Pruning for Edge AI Systems,2022,3.464139029789952e-05,2
W4400984866,Dr.ICL: Demonstration-Retrieved In-context Learning,2024,3.464139029789952e-05,2
W4400526005,Contrast then Memorize: Semantic Neighbor Retrieval-Enhanced Inductive Multimodal Knowledge Graph Completion,2024,3.464139029789952e-05,2
W4297347595,PEINet: Joint Prompt and Evidence Inference Network via Language Family Policy for Zero-Shot Multilingual Fact Checking,2022,3.464139029789952e-05,2
W4389520553,Adversarial Robustness for Large Language NER models using Disentanglement and Word Attributions,2023,3.464139029789952e-05,2
W4312125493,Clinical Application of Detecting COVID-19 Risks: A Natural Language Processing Approach,2022,3.464139029789952e-05,2
W4385572293,Text Adversarial Purification as Defense against Adversarial Attacks,2023,3.464139029789952e-05,2
W4389520334,Learning from Mistakes via Cooperative Study Assistant for Large Language Models,2023,3.464139029789952e-05,2
W4365393312,Explainable Causal Analysis of Mental Health on Social Media Data,2023,3.464139029789952e-05,2
W4389520378,FedTherapist: Mental Health Monitoring with User-Generated Linguistic Expressions on Smartphones via Federated Learning,2023,3.464139029789952e-05,2
W4375869076,Going in Style: Audio Backdoors Through Stylistic Transformations,2023,3.464139029789952e-05,2
W4409376916,Topic Words‐Based Multilingual Hateful Linguistic Resources Construction for Developing Multilingual Hateful Content Detection Model Using Deep Learning Technique,2025,3.464139029789952e-05,2
W4409989348,Enhanced Handwritten Text Recognition With Spell Checking by Building a Small Language Model (SLM) With Jaro-Winkler Algorithm,2025,3.464139029789952e-05,2
W4382985799,Improving Information Extraction from Pathology Reports using Named Entity Recognition,2023,3.464139029789952e-05,2
W3038147222,Deep Knowledge Tracing with Transformers,2020,3.464139029789952e-05,2
W4396523379,Core-View Contrastive Learning Network for Building Lightweight Cross-Domain Consultation System,2024,3.464139029789952e-05,2
W4408134531,Fusion of Domain Dependent Sensitive Semantics and Large Language Model for Research Text Security Classification Category,2025,3.464139029789952e-05,2
W4409768303,Pre- Trained Language Models for Mental Health: An Empirical Study on Arabic Q&amp;A Classification,2025,3.464139029789952e-05,2
W4408742190,Towards a self-cognitive complex product design system: A fine-grained multi-modal feature recognition and semantic understanding approach using large language models in mechanical engineering,2025,3.464139029789952e-05,2
W4409535830,How Good Are Large Language Models at Arithmetic Reasoning in Low-Resource Language Settings?—A Study on Yorùbá Numerical Probes with Minimal Contamination,2025,3.464139029789952e-05,2
W4386302001,Identifying and Mitigating the Security Risks of Generative AI,2023,3.464139029789952e-05,2
W3207316101,Identifying Similar Test Cases That Are Specified in Natural Language,2022,3.464139029789952e-05,2
W3154710343,HULK: An Energy Efficiency Benchmark Platform for Responsible Natural Language Processing,2021,3.464139029789952e-05,2
W4385571706,Dynamic Transformers Provide a False Sense of Efficiency,2023,3.464139029789952e-05,2
W4388181629,"Stochastic LLMs do not Understand Language: Towards Symbolic, Explainable and Ontologically Based LLMs",2023,3.464139029789952e-05,2
W4406073177,Unveiling the power of language models in chemical research question answering,2025,3.464139029789952e-05,2
W4407772393,Evaluating and Advancing Large Language Models for Water Knowledge Tasks in Engineering and Research,2025,3.464139029789952e-05,2
W4401945007,Heterogeneous-branch integration framework: Introducing first-order predicate logic in Logical Reasoning Question Answering,2024,3.464139029789952e-05,2
W4296142626,Towards More Generalizable and Accurate Sentence Classification in Medical Abstracts with Less Data,2022,3.464139029789952e-05,2
W4408733089,Do multimodal large language models understand welding?,2025,3.464139029789952e-05,2
W4366769254,Surprisal does not explain syntactic disambiguation difficulty: evidence from a large-scale benchmark,2023,3.464139029789952e-05,2
W4280622095,Information Theory as a Bridge Between Language Function and Language Form,2022,3.464139029789952e-05,2
W4389518992,How Predictable Are Large Language Model Capabilities? A Case Study on BIG-bench,2023,3.464139029789952e-05,2
W4385570234,To Adapt or to Annotate: Challenges and Interventions for Domain Adaptation in Open-Domain Question Answering,2023,3.464139029789952e-05,2
W4318541692,Optimus-CC: Efficient Large NLP Model Training with 3D Parallelism Aware Communication Compression,2023,3.464139029789952e-05,2
W3026805444,Fluent Response Generation for Conversational Question Answering,2020,3.464139029789952e-05,2
W4366265333,Improving ransomware detection based on portable executable header using xception convolutional neural network,2023,3.464139029789952e-05,2
W4385570763,Downstream Datasets Make Surprisingly Good Pretraining Corpora,2023,3.464139029789952e-05,2
W4390619884,Contrastive classification: A label-independent generalization model for text classification,2024,3.464139029789952e-05,2
W4407150845,Using Large Language Model to Fill in Web Forms to Support Automated Web Application Testing,2025,3.464139029789952e-05,2
W4392942881,Measuring and Modifying Factual Knowledge in Large Language Models,2023,3.464139029789952e-05,2
W4386574930,Improving information retrieval through correspondence analysis instead of latent semantic analysis,2023,3.464139029789952e-05,2
W4393157091,N-gram Unsupervised Compoundation and Feature Injection for Better Symbolic Music Understanding,2024,3.464139029789952e-05,2
W3175002116,"Not Far Away, Not So Close: Sample Efficient Nearest Neighbour Data Augmentation via MiniMax",2021,3.464139029789952e-05,2
W4407425408,A review on persian question answering systems: from traditional to modern approaches,2025,3.464139029789952e-05,2
W3100075909,Scaling Hidden Markov Language Models,2020,3.464139029789952e-05,2
W4404136417,Exploring the effectiveness of instruction tuning in biomedical language processing,2024,3.464139029789952e-05,2
W3168506297,Telling Stories through Multi-User Dialogue by Modeling Character Relations,2021,3.464139029789952e-05,2
W4405384707,GeoGLUE: A Chinese GeoGraphic Language Understanding Evaluation Benchmark,2024,3.464139029789952e-05,2
W4405537947,Unpacking the Outputs of Generative AI Platforms and Revealing Gender and Social Re-Presentations,2024,3.464139029789952e-05,2
W4321378748,Explainable clinical coding with in-domain adapted transformers,2023,3.464139029789952e-05,2
W4389524441,Generative Table Pre-training Empowers Models for Tabular Prediction,2023,3.464139029789952e-05,2
W3125812125,A Text Mining Approach to Discovering COVID-19 Relevant Factors,2020,3.464139029789952e-05,2
W4321770433,EduQG: A Multi-Format Multiple-Choice Dataset for the Educational Domain,2023,3.464139029789952e-05,2
W4400723242,Arithmetic with language models: From memorization to computation,2024,3.464139029789952e-05,2
W4392637206,Investigating Zero- and Few-shot Generalization in Fact Verification,2023,3.464139029789952e-05,2
W4410592342,Deepfake Text Detection Using Deep Convolutional Neural Networks with Explainable Ai,2025,3.464139029789952e-05,2
W4367623507,Framing the News: From Human Perception to Large Language Model Inferences,2023,3.464139029789952e-05,2
W4406749242,ARCH: Large-scale knowledge graph via aggregated narrative codified health records analysis,2025,3.464139029789952e-05,2
W3139427994,A Deep Learning Approach for Robust Detection of Bots in Twitter Using Transformers,2021,3.464139029789952e-05,2
W4406234910,Identification of Naloxone in Emergency Medical Services Data Substantially Improves by Processing Unstructured Patient Care Narratives,2025,3.464139029789952e-05,2
W4395680635,Semantics of Multiword Expressions in Transformer-Based Models: A Survey,2024,3.464139029789952e-05,2
W4323262115,"Master coach The Consequences Workplace of the Head Nurse's Adherence to Nursing Professional Educational Ethics and Knowledge of Moral Dilemmas at King Abdulaziz Hospital, Makkah, Saudi Arabia",2023,3.464139029789952e-05,2
W3094306499,CharacterBERT: Reconciling ELMo and BERT for Word-Level Open-Vocabulary Representations From Characters,2020,3.464139029789952e-05,2
W4407354885,The foundational capabilities of large language models in predicting postoperative risks using clinical notes,2025,3.464139029789952e-05,2
W4399483233,On Artificial and Post-artificial Texts: Machine Learning and the Reader's Expectations of Literary and Non-literary Writing,2024,3.464139029789952e-05,2
W4406863965,KRongBERT: Enhanced factorization-based morphological approach for the Korean pretrained language model,2025,3.464139029789952e-05,2
W4377116057,Sub-Character Tokenization for Chinese Pretrained Language Models,2023,3.464139029789952e-05,2
W4406596702,Clinical entity augmented retrieval for clinical information extraction,2025,3.464139029789952e-05,2
W4385573323,Uncertainty Quantification with Pre-trained Language Models: A Large-Scale Empirical Analysis,2022,3.464139029789952e-05,2
W4407942790,Interleaving and cross-attention presents efficient knowledge graph embedding,2025,3.464139029789952e-05,2
W4385574242,UniRPG: Unified Discrete Reasoning over Table and Text as Program Generation,2022,3.464139029789952e-05,2
W4393564733,Infusing behavior science into large language models for activity coaching,2024,3.464139029789952e-05,2
W4409176541,Extensive compositionality in the vocal system of bonobos,2025,3.464139029789952e-05,2
W4375928954,AccelTran: A Sparsity-Aware Accelerator for Dynamic Inference With Transformers,2023,3.464139029789952e-05,2
W4393407448,Efficiency at Scale: Investigating the Performance of Diminutive Language Models in Clinical Tasks,2024,3.464139029789952e-05,2
W4410083102,Grammaticality representation in ChatGPT as compared to linguists and laypeople,2025,3.464139029789952e-05,2
W4406152959,Hybrid natural language processing tool for semantic annotation of medical texts in Spanish,2025,3.464139029789952e-05,2
W4387892109,DistillCSE: Distilled Contrastive Learning for Sentence Embeddings,2023,3.464139029789952e-05,2
W4402812485,Is Text Normalization Relevant for Classifying Medieval Charters?,2024,3.464139029789952e-05,2
W3171155106,Joint structured pruning and dense knowledge distillation for efficient transformer model compression,2021,3.464139029789952e-05,2
W4409668151,Words That Matter: Analyzing the Causal Effect of Words,2025,3.464139029789952e-05,2
W4385567030,Probing Structural Knowledge from Pre-trained Language Model for Argumentation Relation Classification,2022,3.464139029789952e-05,2
W4362559126,COCO: an annotated Twitter dataset of COVID-19 conspiracy theories,2023,3.464139029789952e-05,2
W4410049458,Large Language Model Fine-tuning with Low-Rank Adaptation: A Performance Exploration,2025,3.464139029789952e-05,2
W3150870318,“Here Are the Rules: Ignore All Rules”: Automatic Contradiction Detection in Spanish,2021,3.464139029789952e-05,2
W4408254499,Guiding Prototype Networks with label semantics for few-shot text classification,2025,3.464139029789952e-05,2
W4408336406,How to Write Effective Prompts for Screening Biomedical Literature Using Large Language Models,2025,3.464139029789952e-05,2
W4406273314,Applications and Case Studies in Natural Language Understanding,2025,3.464139029789952e-05,2
W4405107145,Audio-based Music Retrieval,2024,3.464139029789952e-05,2
W4379207303,Making Sense of Citizens’ Input through Artificial Intelligence: A Review of Methods for Computational Text Analysis to Support the Evaluation of Contributions in Public Participation,2023,3.464139029789952e-05,2
W4393338077,Advancing Breast Cancer Research Through Collaborative Computing: Harnessing Google Colab for Innovation,2024,3.464139029789952e-05,2
W3214847783,Building a Question Answering System for the Manufacturing Domain,2022,3.464139029789952e-05,2
W4396498274,Empower LlaMa 2 for Advanced Logical Reasoning in Natural Language Understanding,2024,3.464139029789952e-05,2
W4385573042,Prompting for Multimodal Hateful Meme Classification,2022,3.464139029789952e-05,2
W4393906041,SeSICL: Semantic and Structural Integrated Contrastive Learning for Knowledge Graph Error Detection,2024,3.464139029789952e-05,2
W4313071293,Evidence-Based Document-Level Event Factuality Identification,2022,3.464139029789952e-05,2
W4392939486,Graph Structure Enhanced Pre-Training Language Model for Knowledge Graph Completion,2024,3.464139029789952e-05,2
W4401834344,A Scalable Framework for Benchmarking Embedding Models for Semantic Medical Tasks,2024,3.464139029789952e-05,2
W4392904073,Recovering from Privacy-Preserving Masking with Large Language Models,2024,3.464139029789952e-05,2
W4390604950,"Completeness, Recall, and Negation in Open-world Knowledge Bases: A Survey",2024,3.464139029789952e-05,2
W4408905991,PFDP: privacy-preserving federated distillation method for pretrained language models,2025,3.464139029789952e-05,2
W3145777983,Transformer-Based Approach Towards Music Emotion Recognition from Lyrics,2021,3.464139029789952e-05,2
W4386566756,Multimodal Event Transformer for Image-guided Story Ending Generation,2023,3.464139029789952e-05,2
W4385269188,SLR: A million-scale comprehensive crossword dataset for simultaneous learning and reasoning,2023,3.464139029789952e-05,2
W4391697043,The MorPhEMe Machine: An Addressable Neural Memory for Learning Knowledge-Regularized Deep Contextualized Chinese Embedding,2024,3.464139029789952e-05,2
W4389520296,Improving Sequential Model Editing with Fact Retrieval,2023,3.464139029789952e-05,2
W4408295901,Leveraging large language models for knowledge-free weak supervision in clinical natural language processing,2025,3.464139029789952e-05,2
W4389519596,KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level Hallucination Detection,2023,3.464139029789952e-05,2
W4289523473,Performance analysis of transformer-based architectures and their ensembles to detect trait-based cyberbullying,2022,3.464139029789952e-05,2
W4393160979,RoPDA: Robust Prompt-Based Data Augmentation for Low-Resource Named Entity Recognition,2024,3.464139029789952e-05,2
W4323065879,Knowledge Graph-Based Reinforcement Federated Learning for Chinese Question and Answering,2023,3.464139029789952e-05,2
W4393157285,Some Like It Small: Czech Semantic Embedding Models for Industry Applications,2024,3.464139029789952e-05,2
W4318245360,When Transformer models are more compositional than humans: The case of the depth charge illusion,2023,3.464139029789952e-05,2
W4404970290,Mitigating Hallucination in Large Language Model by Leveraging Decoder Layer Contrasting,2024,3.464139029789952e-05,2
W4393148139,KGTS: Contrastive Trajectory Similarity Learning over Prompt Knowledge Graph Embedding,2024,3.464139029789952e-05,2
W4386566719,Question-Answer Sentence Graph for Joint Modeling Answer Selection,2023,3.464139029789952e-05,2
W4318391587,DR.BENCH: Diagnostic Reasoning Benchmark for Clinical Natural Language Processing,2023,3.464139029789952e-05,2
W4393146052,An Enhanced Topic Modeling Method in Educational Domain by Integrating LDA with Semantic,2024,3.464139029789952e-05,2
W4398186161,An Algorithm based on Semantic Similarity to Extract Candidate Answers in Question Answering Systems,2024,3.464139029789952e-05,2
W4229029478,The Entropy of Morphological Systems in Natural Languages Is Modulated by Functional and Semantic Properties,2022,3.464139029789952e-05,2
W4409094323,Lightweight Pre-Trained Korean Language Model Based on Knowledge Distillation and Low-Rank Factorization,2025,3.464139029789952e-05,2
W4407590023,Enhancing Adverse Event Reporting With Clinical Language Models: Inpatient Falls,2025,3.464139029789952e-05,2
W4395956893,Studying and recommending information highlighting in Stack Overflow answers,2024,3.464139029789952e-05,2
W4406277430,Estimating textual treatment effect via causal disentangled representation learning,2025,3.464139029789952e-05,2
W4389037425,Contextualized Sentiment Analysis using Large Language Models,2023,3.464139029789952e-05,2
W4400411628,Unveiling the Impact of Large Language Models on Student Learning: A Comprehensive Case Study,2024,3.464139029789952e-05,2
W4392377312,The Promises and Perils of Foundation Models in Dermatology,2024,3.464139029789952e-05,2
W4407058821,MAGENTA: Generating and Detecting Arabic Machine-Generated Text in Multiple Domains,2025,3.464139029789952e-05,2
W3160648428,Making Punctuation Restoration Robust and Fast with Multi-Task Learning and Knowledge Distillation,2021,3.464139029789952e-05,2
W4410041388,Harnessing Pre-trained Language Models for Efficient Move Recognition in Biomedical Abstracts,2025,3.464139029789952e-05,2
W4407028442,Knowledge Graph Applications and Multi-Relation Learning for Drug Repurposing: A Scoping Review,2025,3.464139029789952e-05,2
W4407414076,Explainable AI for Large Language Models via Context-Aware Word Embeddings,2025,3.464139029789952e-05,2
W4223558833,Characterization inference based on joint-optimization of multi-layer semantics and deep fusion matching network,2022,3.464139029789952e-05,2
W4402264152,SneakyPrompt: Jailbreaking Text-to-image Generative Models,2024,3.464139029789952e-05,2
W4406917337,CoT-driven framework for short text classification: Enhancing and transferring capabilities from large to smaller model,2025,3.464139029789952e-05,2
W4213112533,Machine learning to detect invalid text responses: Validation and comparison to existing detection methods,2022,3.464139029789952e-05,2
W4366975604,A social media event detection framework based on transformers and swarm optimization for public notification of crises and emergency management,2023,3.464139029789952e-05,2
W4401943697,Missed Connections: Lateral Thinking Puzzles for Large Language Models,2024,3.464139029789952e-05,2
W4389520411,Does the English Matter? Elicit Cross-lingual Abilities of Large Language Models,2023,3.464139029789952e-05,2
W4398265013,CoRTEx: contrastive learning for representing terms via explanations with applications on constructing biomedical knowledge graphs,2024,3.464139029789952e-05,2
W4375868933,Meta Learning for Domain Agnostic Soft Prompt,2023,3.464139029789952e-05,2
W4324142688,"Creation, Analysis and Evaluation of AnnoMI, a Dataset of Expert-Annotated Counselling Dialogues",2023,3.464139029789952e-05,2
W4393155827,Does a language model “understand” high school math? A survey of deep learning based word problem solvers,2024,3.464139029789952e-05,2
W4389524381,Prompting with Pseudo-Code Instructions,2023,3.464139029789952e-05,2
W4283789538,Adversarial Data Augmentation for Task-Specific Knowledge Distillation of Pre-trained Transformers,2022,3.464139029789952e-05,2
W4410109416,It’s all in the [MASK]: Simple instruction-tuning enables BERT-like masked language models as generative classifiers,2025,3.464139029789952e-05,2
W4389519026,GD-COMET: A Geo-Diverse Commonsense Inference Model,2023,3.464139029789952e-05,2
W4385270681,Self-supervised Trajectory Representation Learning with Temporal Regularities and Travel Semantics,2023,3.464139029789952e-05,2
W4383336963,Global information-aware argument mining based on a top-down multi-turn QA model,2023,3.464139029789952e-05,2
W4409262680,Enhancing creativity with covert neurofeedback: causal evidence for default-executive network coupling in creative thinking,2025,3.464139029789952e-05,2
W4389523673,NormDial: A Comparable Bilingual Synthetic Dialog Dataset for Modeling Social Norm Adherence and Violation,2023,3.464139029789952e-05,2
W4407025433,A prompt tuning method based on relation graphs for few-shot relation extraction,2025,3.464139029789952e-05,2
W4392266005,AskIt: Unified Programming Interface for Programming with Large Language Models,2024,3.464139029789952e-05,2
W4389518961,MAPO: Boosting Large Language Model Performance with Model-Adaptive Prompt Optimization,2023,3.464139029789952e-05,2
W4407157388,SAFE-NLP: How Accurate and Robust is a Text Classification Model?,2025,3.464139029789952e-05,2
W4322741012,WEIGHTED ENTITY-LINKING AND INTEGRATION ALGORITHM FOR MEDICAL KNOWLEDGE GRAPH GENERATION,2023,3.464139029789952e-05,2
W4390636040,Exploring low-resource medical image classification with weakly supervised prompt learning,2024,3.464139029789952e-05,2
W4284698368,Fast changeset-based bug localization with BERT,2022,3.464139029789952e-05,2
W2971279492,Short Text Understanding Combining Text Conceptualization and Transformer Embedding,2019,3.464139029789952e-05,2
W4410570038,Large Language Models in Portuguese for Healthcare: A Systematic Review,2025,3.464139029789952e-05,2
W4404396281,Fine-tuning language model embeddings to reveal domain knowledge: An explainable artificial intelligence perspective on medical decision making,2024,3.464139029789952e-05,2
W4391691195,Retrieval Augmented Generation Enabled Generative Pre-Trained Transformer 4 (GPT-4) Performance for Clinical Trial Screening,2024,3.464139029789952e-05,2
W4406378170,Personalized federated knowledge graph embedding with client-wise relation graph,2025,3.464139029789952e-05,2
W4310009523,Stance Detection of Political Tweets with Transformer Architectures,2022,3.464139029789952e-05,2
W4392671466,Event-centric hierarchical hyperbolic graph for multi-hop question answering over knowledge graphs,2024,3.464139029789952e-05,2
W4403780660,Enhancing Transformer-based Semantic Matching for Few-shot Learning through Weakly Contrastive Pre-training,2024,3.464139029789952e-05,2
W3186858063,Survey of BERT (Bidirectional Encoder Representation Transformer) types,2021,3.464139029789952e-05,2
W4322760726,Transformers for cardiac patient mortality risk prediction from heterogeneous electronic health records,2023,3.464139029789952e-05,2
W4407601674,A Legal Fact-Finding Model Based on the T5 and LexiLaw Large Language Models,2024,3.464139029789952e-05,2
W4410380157,HMI: hierarchical knowledge management for efficient multi-tenant inference in pretrained language models,2025,3.464139029789952e-05,2
W4385570030,What Do NLP Researchers Believe? Results of the NLP Community Metasurvey,2023,3.464139029789952e-05,2
W4406427478,Implicit knowledge-augmented prompting for commonsense explanation generation,2025,3.464139029789952e-05,2
W3022579746,How Can We Accelerate Progress Towards Human-like Linguistic Generalization?.,2020,3.464139029789952e-05,2
W4408052763,Trusta: Reasoning about Assurance Cases with Formal Methods and Large Language Models,2025,3.464139029789952e-05,2
W4397006802,Makita—A workflow generator for large-scale and reproducible simulation studies mimicking text labeling,2024,3.464139029789952e-05,2
W4408985659,Skill Learning Using Process Mining for Large Language Model Plan Generation,2025,3.464139029789952e-05,2
W4221066116,NewsPod: Automatic and Interactive News Podcasts,2022,3.464139029789952e-05,2
W4409295452,Enhancing clinical information processing with ICRE: an intelligent chain-refinement extraction framework for precision data mining,2025,3.464139029789952e-05,2
W4389565330,A hybrid style transfer with whale optimization algorithm model for textual adversarial attack,2023,3.464139029789952e-05,2
W4385221022,Enhancing Chinese Address Parsing in Low-Resource Scenarios through In-Context Learning,2023,3.464139029789952e-05,2
W4409676988,Transformer-Based Approach for Nuclear Reactor Event Sequence Forecasting and Trip Detection,2025,3.464139029789952e-05,2
W3155487259,NPE: An FPGA-based Overlay Processor for Natural Language Processing,2021,3.464139029789952e-05,2
W4372347502,Quotation Recommendation for Multi-party Online Conversations Based on Semantic and Topic Fusion,2023,3.464139029789952e-05,2
W4408490751,From corporate earnings calls to social impact: Exploring ESG signals in S&amp;P 500 ESG index companies through transformer-based models,2025,3.464139029789952e-05,2
W4390751407,Research on a Mongolian Text to Speech Model Based on Ghost and ILPCnet,2024,3.464139029789952e-05,2
W4388973540,Graph reasoning over explicit semantic relation,2023,3.464139029789952e-05,2
W4386576804,Improving Numeracy by Input Reframing and Quantitative Pre-Finetuning Task,2023,3.464139029789952e-05,2
W4322631694,Using Natural Language Processing to Analyze Political Party Manifestos from New Zealand,2023,3.464139029789952e-05,2
W4390578107,On-Device Smishing Classifier Resistant to Text Evasion Attack,2024,3.464139029789952e-05,2
W4389132345,TransformEHR: transformer-based encoder-decoder generative model to enhance prediction of disease outcomes using electronic health records,2023,3.464139029789952e-05,2
W4401933528,Contrastive Learning with Transformer initialization and clustering prior for text representation,2024,3.464139029789952e-05,2
W4320913850,Biomedical Text Classification Using Augmented Word Representation Based on Distributional and Relational Contexts,2023,3.464139029789952e-05,2
W4409137999,Enhancing data quality in medical concept normalization through large language models,2025,3.464139029789952e-05,2
W4392875681,Enhancing Textbook Question Answering Task with Large Language Models and Retrieval Augmented Generation,2024,3.464139029789952e-05,2
W4283269716,A Unified Understanding of Deep NLP Models for Text Classification,2022,3.464139029789952e-05,2
W4389269373,Towards Effective and Efficient Sparse Neural Information Retrieval,2023,3.464139029789952e-05,2
W4386702854,TeaBERT: An Efficient Knowledge Infused Cross-Lingual Language Model for Mapping Chinese Medical Entities to the Unified Medical Language System,2023,3.464139029789952e-05,2
W4389519954,KEPLET: Knowledge-Enhanced Pretrained Language Model with Topic Entity Awareness,2023,3.464139029789952e-05,2
W4409349005,Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge,2025,3.464139029789952e-05,2
W4401597819,GPT-4 as an X data annotator: Unraveling its performance on a stance classification task,2024,3.464139029789952e-05,2
W4409235391,Application of large language models in medicine,2025,3.464139029789952e-05,2
W4367298114,Multi-MCCR: Multiple models regularization for semi-supervised text classification with few labels,2023,3.464139029789952e-05,2
W4389519322,Connecting Symbolic Statutory Reasoning with Legal Information Extraction,2023,3.464139029789952e-05,2
W4409254068,Self-explaining Neural Network for Multi-criteria Sentiment Analysis,2025,3.464139029789952e-05,2
W4366774505,Enhancing Neural Text Detector Robustness with μAttacking and RR-Training,2023,3.464139029789952e-05,2
W4281706244,Ad astra or astray: Exploring linguistic knowledge of multilingual BERT through NLI task,2022,3.464139029789952e-05,2
W4406304217,Learning Shortcuts: On the Misleading Promise of NLU in Language Models,2025,3.464139029789952e-05,2
W4385570866,ACCENT: An Automatic Event Commonsense Evaluation Metric for Open-Domain Dialogue Systems,2023,3.464139029789952e-05,2
W3170967211,Explaining Neural Network Predictions on Sentence Pairs via Learning Word-Group Masks,2021,3.464139029789952e-05,2
W4327814177,FRD-LSTM: a novel technique for fake reviews detection using DCWR with the Bi-LSTM method,2023,3.464139029789952e-05,2
W4385734210,Improving Dutch Vaccine Hesitancy Monitoring via Multi-Label Data Augmentation with GPT-3.5,2023,3.464139029789952e-05,2
W4409836394,Exploring Methodologies for Computing Sentence Similarity in Natural Language Processing,2025,3.464139029789952e-05,2
W4285164445,Robust Lottery Tickets for Pre-trained Language Models,2022,3.464139029789952e-05,2
W4294044662,Artificial intelligence for topic modelling in Hindu philosophy: Mapping themes between the Upanishads and the Bhagavad Gita,2022,3.464139029789952e-05,2
W4377141577,A general text mining method to extract echocardiography measurement results from echocardiography documents,2023,3.464139029789952e-05,2
W4385570929,Chain-of-Skills: A Configurable Model for Open-Domain Question Answering,2023,3.464139029789952e-05,2
W4407162607,Leveraging LLMs for action item identification in Urdu meetings: Dataset creation and comparative analysis,2025,3.464139029789952e-05,2
W4315705628,Natural Backdoor Attacks on Speech Recognition Models,2023,3.464139029789952e-05,2
W4406469500,Structure-Aware Conversational Legal Case Retrieval,2025,3.464139029789952e-05,2
W4407930496,Issues and trends in generative AI technologies for decision making,2025,3.464139029789952e-05,2
W4407295345,Automated Extraction of Key Entities from Non-English Mammography Reports Using Named Entity Recognition with Prompt Engineering,2025,3.464139029789952e-05,2
W4407359875,Llmbd: Backdoor Defense Via Large Language Model Paraphrasing and Data Voting in Nlp,2025,3.464139029789952e-05,2
W4388016061,Natural Language Processing using Federated Learning: A Structured Literature Review,2023,3.464139029789952e-05,2
W4385767986,FedET: A Communication-Efficient Federated Class-Incremental Learning Framework Based on Enhanced Transformer,2023,3.464139029789952e-05,2
W4400926865,Matching tasks to objectives: Fine-tuning and prompt-tuning strategies for encoder-decoder pre-trained language models,2024,3.464139029789952e-05,2
W4368346119,Paraphrase Detection: Human vs. Machine Content,2023,3.464139029789952e-05,2
W4393159599,SpikingBERT: Distilling BERT to Train Spiking Language Models Using Implicit Differentiation,2024,3.464139029789952e-05,2
W3095211433,KnowlyBERT - Hybrid Query Answering over Language Models and Knowledge Graphs,2020,3.464139029789952e-05,2
W4406107588,M2KGRL: A semantic-matching based framework for multimodal knowledge graph representation learning,2025,3.464139029789952e-05,2
W4402761492,Learning to Score: A Coding System for Constructed Response Items via Interactive Clustering,2024,3.464139029789952e-05,2
W4393346561,Meta-learning framework with updating information flow for enhancing inductive prediction,2024,3.464139029789952e-05,2
W4315630900,Textual Pre-Trained Models for Gender Identification Across Community Question-Answering Members,2023,3.464139029789952e-05,2
W4402856262,Language Model-Based Text Augmentation System for Cerebrovascular Disease Related Medical Report,2024,3.464139029789952e-05,2
W3131577358,MTQA: Text‐Based Multitype Question and Answer Reading Comprehension Model,2021,3.464139029789952e-05,2
W4392157497,A bibliometric analysis of artificial intelligence in L2 teaching and applied linguistics between 1995 and 2022,2024,3.464139029789952e-05,2
W4400904993,One Subgraph for All: Efficient Reasoning on Opening Subgraphs for Inductive Knowledge Graph Completion,2024,3.464139029789952e-05,2
W4407219056,Comparative analysis of generative LLMs for labeling entities in clinical notes,2025,3.464139029789952e-05,2
W4393148027,Mutual-Modality Adversarial Attack with Semantic Perturbation,2024,3.464139029789952e-05,2
W4408094780,Contextual information contributes to biomedical named entity normalization,2025,3.464139029789952e-05,2
W4225110351,Modern Baselines for SPARQL Semantic Parsing,2022,3.464139029789952e-05,2
W3017720918,Enabling Fast and Universal Audio Adversarial Attack Using Generative Model,2021,3.464139029789952e-05,2
W4224981510,Monant Medical Misinformation Dataset,2022,3.464139029789952e-05,2
W4408363728,Enhancing Traditional Chinese Medicine Question Answering and Semantic Reasoning via Historical Exam Retrieval and Sentence Similarity,2025,3.464139029789952e-05,2
W4400230955,Hate Speech Detection using CoT and Post-hoc Explanation through Instruction-based Fine Tuning in Large Language Models,2024,3.464139029789952e-05,2
W4410356809,A Comparison of the Effects of Model Adaptation Techniques on Large Language Models for Non-Linguistic and Linguistic Tasks,2025,3.464139029789952e-05,2
W4410454493,Enhanced effective convolutional attention network with squeeze-and-excitation inception module for multi-label clinical document classification,2025,3.464139029789952e-05,2
W4382318860,An Ensemble Distillation Framework for Sentence Embeddings with Multilingual Round-Trip Translation,2023,3.464139029789952e-05,2
W4382366638,Information Retrieval Using Domain Adapted Language Models: Application to Resume Documents for HR Recruitment Assistance,2023,3.464139029789952e-05,2
W4401622681,Relation labeling in product knowledge graphs with large language models for e-commerce,2024,3.464139029789952e-05,2
W4407986790,Literature-scaled immunological gene set annotation using AI-powered immune cell knowledge graph (ICKG),2025,3.464139029789952e-05,2
W4367322784,Finding Patient Zero and Tracking Narrative Changes in the Context of Online Disinformation Using Semantic Similarity Analysis,2023,3.464139029789952e-05,2
W4308558768,e-TSN: an interactive visual exploration platform for target–disease knowledge mapping from literature,2022,3.464139029789952e-05,2
W3034693764,Text Classification with Negative Supervision,2020,3.464139029789952e-05,2
W4407191181,Large Language Models for Electronic Health Record De-Identification in English and German,2025,3.464139029789952e-05,2
W4386566893,Combining Parameter-efficient Modules for Task-level Generalisation,2023,3.464139029789952e-05,2
W4401824528,Designing Retrieval-Augmented Language Models for Clinical Decision Support,2024,3.464139029789952e-05,2
W4410052319,Breast Cancer Detection Using Convolutional Neural Networks: A Deep Learning-Based Approach,2025,3.464139029789952e-05,2
W4407838598,Weakly supervised veracity classification with LLM-predicted credibility signals,2025,3.464139029789952e-05,2
W4409157940,Multi-level Matching Network for Multimodal Entity Linking,2025,3.464139029789952e-05,2
W4226163593,WikiContradiction: Detecting Self-Contradiction Articles on Wikipedia,2021,3.464139029789952e-05,2
W4385572206,ActiveAED: A Human in the Loop Improves Annotation Error Detection,2023,3.464139029789952e-05,2
W4407207431,Decoding substance use disorder severity from clinical notes using a large language model,2025,3.464139029789952e-05,2
W4386566671,UnifEE: Unified Evidence Extraction for Fact Verification,2023,3.464139029789952e-05,2
W4402353454,Exploring and Improving Consistency in Large Language Models for Multiple-Choice Question Assessment,2024,3.464139029789952e-05,2
W4308931255,Chinese sentence semantic matching based on multi-level relevance extraction and aggregation for intelligent human–robot interaction,2022,3.464139029789952e-05,2
W4409572435,Fact retrieval from knowledge graphs through semantic and contextual attention,2025,3.464139029789952e-05,2
W4390590487,DeBERTa-BiLSTM: A multi-label classification model of arabic medical questions using pre-trained models and deep learning,2024,3.464139029789952e-05,2
W4321597234,A large dataset of semantic ratings and its computational extension,2023,3.464139029789952e-05,2
W4402351439,Time-CoT for Enhancing Time Reasoning Factual Question Answering in Large Language Models,2024,3.464139029789952e-05,2
W4389519914,How to Determine the Most Powerful Pre-trained Language Model without Brute Force Fine-tuning? An Empirical Survey,2023,3.464139029789952e-05,2
W4221150160,GPT-D: Inducing Dementia-related Linguistic Anomalies by Deliberate Degradation of Artificial Neural Language Models,2022,3.464139029789952e-05,2
W4406810072,Synthetically generated text for supervised text analysis,2025,3.464139029789952e-05,2
W4327644048,An Experimental Study on Pretraining Transformers from Scratch for IR,2023,3.464139029789952e-05,2
W4405208940,SPCSE: Soft Positive Enhanced Contrastive Learning for Sentence Embeddings,2024,3.464139029789952e-05,2
W4317520062,Row-based hierarchical graph network for multi-hop question answering over textual and tabular data,2023,3.464139029789952e-05,2
W4406105510,Uncertainty modeling for inductive knowledge graph embedding,2025,3.464139029789952e-05,2
W4409190866,Benchmarking large language models for biomedical natural language processing applications and recommendations,2025,3.464139029789952e-05,2
W4285188740,Discontinuous Constituency and BERT: A Case Study of Dutch,2022,3.464139029789952e-05,2
W4388144893,Detecting and Unmasking AI-Generated Texts through Explainable Artificial Intelligence using Stylistic Features,2023,3.464139029789952e-05,2
W4410552705,Identifying Disinformation on the Extended Impacts of COVID-19: Methodological Investigation Using a Fuzzy Ranking Ensemble of Natural Language Processing Models (Preprint),2025,3.464139029789952e-05,2
W4389260541,Improving the Robustness of Transformer-based Large Language Models with Dynamic Attention,2024,3.464139029789952e-05,2
W4407269018,Parentheses insertion based sentence-level text adversarial attack,2025,3.464139029789952e-05,2
W4389519513,DUnE: Dataset for Unified Editing,2023,3.464139029789952e-05,2
W4409826996,Unravelling the semantic mysteries of transformers layer by layer,2025,3.464139029789952e-05,2
W4386076454,Exploring Structured Semantic Prior for Multi Label Recognition with Incomplete Labels,2023,3.464139029789952e-05,2
W4200631806,From Dense to Sparse: Contrastive Pruning for Better Pre-trained Language Model Compression,2022,3.464139029789952e-05,2
W4400006571,User identification across online social networks based on gated multi-feature extraction,2024,3.464139029789952e-05,2
W4407859403,Assisting Drafting of Chinese Legal Documents Using Fine-Tuned Pre-trained Large Language Models,2025,3.464139029789952e-05,2
W4386771634,GIMM: A graph convolutional network-based paraphrase identification model to detecting duplicate questions in QA communities,2023,3.464139029789952e-05,2
W4286226650,A sequence labeling framework for extracting drug–protein relations from biomedical literature,2022,3.464139029789952e-05,2
W4403864719,Efficiency Optimization of Large-Scale Language Models Based on Deep Learning in Natural Language Processing Tasks,2024,3.464139029789952e-05,2
W3199891962,"More collaboration, less seriousness: Investigating new strategies for promoting youth engagement in government-generated videos during the COVID-19 pandemic in China",2021,3.464139029789952e-05,2
W4392632268,Evaluation of Medium-Sized Language Models in German and English Language,2024,3.464139029789952e-05,2
W4409720527,TELL-ME: Toward Personalized Explanations of Large Language Models,2025,3.464139029789952e-05,2
W4401298243,Assessing Dimensions of Thought Disorder with Large Language Models: The Tradeoff of Accuracy and Consistency,2024,3.464139029789952e-05,2
W4409158849,Leveraging social media for public health: NLP implementations for blood donation data analysis in Japan,2025,3.464139029789952e-05,2
W3117559565,Authorship Identification of a Russian-Language Text Using Support Vector Machine and Deep Neural Networks,2020,3.464139029789952e-05,2
W4225929875,Leashing the Inner Demons: Self-Detoxification for Language Models,2022,3.464139029789952e-05,2
W4409897857,LLMs Open-Domain Question Answering Method Based on Retrieval-Augmented Generation and Soft Prompt Optimization,2025,3.464139029789952e-05,2
W4409671337,TELEClass: Taxonomy Enrichment and LLM-Enhanced Hierarchical Text Classification with Minimal Supervision,2025,3.464139029789952e-05,2
W3114765853,AlexU-AUX-BERT at SemEval-2020 Task 3: Improving BERT Contextual Similarity Using Multiple Auxiliary Contexts,2020,3.464139029789952e-05,2
W4399020384,Experimental Design of Extractive Question-Answering Systems: Influence of Error Scores and Answer Length,2024,3.464139029789952e-05,2
W4397008743,Multi-view fusion for instruction mining of large language model,2024,3.464139029789952e-05,2
W4392902639,A Soft Contrastive Learning-Based Prompt Model for Few-Shot Sentiment Analysis,2024,3.464139029789952e-05,2
W4385570329,Complex Reasoning in Natural Languag,2023,3.464139029789952e-05,2
W4226263264,VALUE: Understanding Dialect Disparity in NLU,2022,3.464139029789952e-05,2
W4392292205,Commonsense knowledge in cognitive robotics: a systematic literature review,2024,3.464139029789952e-05,2
W4317493055,Sentiment enhanced answer generation and information fusing for product-related question answering,2023,3.464139029789952e-05,2
W4408257726,Adaptive Factual Decoding for Hallucination Mitigation with Part-of-Speech Based Critics,2025,3.464139029789952e-05,2
W4388164796,Named Entity Recognition and Linking for Entity Extraction from Italian Civil Judgements,2023,3.464139029789952e-05,2
W3184751871,QA Dataset Explosion: A Taxonomy of NLP Resources for Question Answering and Reading Comprehension,2021,3.464139029789952e-05,2
W4400489793,RSTIE-KGC: A Relation Sensitive Textual Information Enhanced Knowledge Graph Completion Model,2024,3.464139029789952e-05,2
W4389520114,Exploring Distributional Shifts in Large Language Models for Code Analysis,2023,3.464139029789952e-05,2
W4386365475,"Recognizing textual entailment: A review of resources, approaches, applications, and challenges",2023,3.464139029789952e-05,2
W4406472189,Large language models for newspaper sentiment analysis during COVID-19: The Guardian,2025,3.464139029789952e-05,2
W4220686467,Improving exchange rate forecasting via a new deep multimodal fusion model,2022,3.464139029789952e-05,2
W4382204351,AI assistant for document management Using Lang Chain and Pinecone,2023,3.464139029789952e-05,2
W3123802026,Learning Reasoning Paths over Semantic Graphs for Video-grounded Dialogues,2021,3.464139029789952e-05,2
W4399577880,"Natural language processing: An overview of models, transformers and applied practices",2024,3.464139029789952e-05,2
W4393032070,SHAPAttack: Shapley-Guided Multigranularity Adversarial Attack Against Text Transformers,2024,3.464139029789952e-05,2
W4390450387,Towards Mental Health Analysis in Social Media for Low-resourced Languages,2023,3.464139029789952e-05,2
W4396723160,Unifying Local and Global Knowledge: Empowering Large Language Models as Political Experts with Knowledge Graphs,2024,3.464139029789952e-05,2
W4407605136,"The ""Podcast"" ECoG dataset for modeling neural activity during natural language comprehension",2025,3.464139029789952e-05,2
W4408224376,Scaling language model size yields diminishing returns for single-message political persuasion,2025,3.464139029789952e-05,2
W4384664813,RegEMR: a natural language processing system to automatically identify premature ovarian decline from Chinese electronic medical records,2023,3.464139029789952e-05,2
W4313563529,QATest: A Uniform Fuzzing Framework for Question Answering Systems,2022,3.464139029789952e-05,2
W3213394935,Beyond Reptile: Meta-Learned Dot-Product Maximization between Gradients for Improved Single-Task Regularization,2021,3.464139029789952e-05,2
W4395028878,DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era,2024,3.464139029789952e-05,2
W4313182274,Meta-Learning the Difference: Preparing Large Language Models for Efficient Adaptation,2022,3.464139029789952e-05,2
W4408309178,DE-ESD: Dual encoder-based entity synonym discovery using pre-trained contextual embeddings,2025,3.464139029789952e-05,2
W4400644218,A Survey on Symbolic Knowledge Distillation of Large Language Models,2024,3.464139029789952e-05,2
W4409024488,Large Language Models' Ability to Assess Main Concepts in Story Retelling: A Proof-of-Concept Comparison of Human Versus Machine Ratings,2025,3.464139029789952e-05,2
W4311448205,PADL: Language-Directed Physics-Based Character Control,2022,3.464139029789952e-05,2
W4401717597,Toward Robust Evaluation: A Comprehensive Taxonomy of Datasets and Metrics for Open Domain Question Answering in the Era of Large Language Models,2024,3.464139029789952e-05,2
W4385574191,Event-Centric Question Answering via Contrastive Learning and Invertible Event Transformation,2022,3.464139029789952e-05,2
W4392760662,Argumentation effect of a chatbot for ethical discussions about autonomous AI scenarios,2024,3.464139029789952e-05,2
W3161320446,SILT: Efficient transformer training for inter-lingual inference,2022,3.464139029789952e-05,2
W4402264369,Text-CRS: A Generalized Certified Robustness Framework against Textual Adversarial Attacks,2024,3.464139029789952e-05,2
W4386914096,SRSCL: A strong-relatedness-sequence-based fine-grained collective entity linking method for heterogeneous information networks,2023,3.464139029789952e-05,2
W4399767739,Evaluating ChatGPT: Strengths and Limitations in NLP Problem Solving,2024,3.464139029789952e-05,2
W4389520362,Large Language Models Only Pass Primary School Exams in Indonesia: A Comprehensive Test on IndoMMLU,2023,3.464139029789952e-05,2
W4377235148,A Composable Generative Framework Based on Prompt Learning for Various Information Extraction Tasks,2023,3.464139029789952e-05,2
W3118527394,Fake news detection for the Russian language,2020,3.464139029789952e-05,2
W4293344661,Path and future of artificial intelligence in the field of justice: a systematic literature review and a research agenda,2022,3.464139029789952e-05,2
W4391401609,Are my answers medically accurate? Exploiting medical knowledge graphs for medical question answering,2024,3.464139029789952e-05,2
W4384636969,Recipe-MPR: A Test Collection for Evaluating Multi-aspect Preference-based Natural Language Retrieval,2023,3.464139029789952e-05,2
W4409622428,Integrating domain-specific knowledge and fine-tuned general-purpose large language models for question-answering in construction engineering management,2025,3.464139029789952e-05,2
W4386763311,GPT-4 as a Twitter Data Annotator: Unraveling Its Performance on a Stance Classification Task,2023,3.464139029789952e-05,2
W4385764073,A Survey on Out-of-Distribution Evaluation of Neural NLP Models,2023,3.464139029789952e-05,2
W4388267292,Narratives and Valuations,2023,3.464139029789952e-05,2
W4376619178,Investigating the Extent to which Distributional Semantic Models Capture a Broad Range of Semantic Relations,2023,3.464139029789952e-05,2
W4391968384,Sustainable Shift: Analyzing Drivers for Low-Carbon Transportation Adoption in California’s Heavy-Duty and Off-Road Sectors,2024,3.464139029789952e-05,2
W4393147154,LLM vs Small Model? Large Language Model Based Text Augmentation Enhanced Personality Detection Model,2024,3.464139029789952e-05,2
W4402352741,Subgraph-Based Attention Network for Multi-Hop Question Answering,2024,3.464139029789952e-05,2
W4401241231,"Efficiency-Driven Custom Chatbot Development: Unleashing LangChain, RAG, and Performance-Optimized LLM Fusion",2024,3.464139029789952e-05,2
W4385572711,Z-LaVI: Zero-Shot Language Solver Fueled by Visual Imagination,2022,3.464139029789952e-05,2
W4213156872,Interpretable modular knowledge reasoning for machine reading comprehension,2022,3.464139029789952e-05,2
W4409807000,Injecting Bias into Text Classification Models Using Backdoor Attacks,2025,3.464139029789952e-05,2
W4396216171,Understanding writing style in social media with a supervised contrastively pre-trained transformer,2024,3.464139029789952e-05,2
W4405412791,Document embeddings for long texts from Transformers and Autoencoders,2024,3.464139029789952e-05,2
W3173505468,TexSmart: A System for Enhanced Natural Language Understanding,2021,3.464139029789952e-05,2
W4385571175,Proceedings of the Third DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering,2023,3.464139029789952e-05,2
W4387078920,Incorporating entity-level knowledge in pretrained language model for biomedical dense retrieval,2023,3.464139029789952e-05,2
W4404295242,PSSOP: A Prompt-style Approach for Few-Shot Text Classification,2024,3.464139029789952e-05,2
W4366548757,False perspectives on human language: Why statistics needs linguistics,2023,3.464139029789952e-05,2
W4392119501,BioEmoDetector: A flexible platform for detecting emotions from health narratives,2024,3.464139029789952e-05,2
W4396721893,nach0: multimodal natural and chemical languages foundation model,2024,3.464139029789952e-05,2
W4408412978,Towards Effective Time-Aware Language Representation: Exploring Enhanced Temporal Understanding in Language Models,2025,3.464139029789952e-05,2
W4220864053,Text Data Augmentation for the Korean Language,2022,3.464139029789952e-05,2
W4388666116,Evaluating Large Language Models in Relationship Extraction from Unstructured Data: Empirical Study from Holocaust Testimonies,2023,3.464139029789952e-05,2
W4389518800,Ultra-Fine Entity Typing with Prior Knowledge about Labels: A Simple Clustering Based Strategy,2023,3.464139029789952e-05,2
W4392673844,Effective Natural Language Processing Algorithms for Early Alerts of Gout Flares from Chief Complaints,2024,3.464139029789952e-05,2
W3159343375,RECAST,2021,3.464139029789952e-05,2
W4212989157,Gradient Acceptability and Linguistic Theory,2021,3.464139029789952e-05,2
W4360989137,NeRBERT- A Biomedical Named Entity Recognition Tagger,2023,3.464139029789952e-05,2
W4394894051,Preventing the Immense Increase in the Life-Cycle Energy and Carbon Footprints of LLM-Powered Intelligent Chatbots,2024,3.464139029789952e-05,2
W4386947867,Multi-hop question answering using sparse graphs,2023,3.464139029789952e-05,2
W4410478455,Transformer Generative AI Model for Enhanced Molecular Property Prediction,2025,3.464139029789952e-05,2
W4380789085,Semantic similarity models for automated fact-checking: ClaimCheck as a claim matching tool,2023,3.464139029789952e-05,2
W4310331933,LitCovid ensemble learning for COVID-19 multi-label classification,2022,3.464139029789952e-05,2
W4383911975,The Value of Numbers in Clinical Text Classification,2023,3.464139029789952e-05,2
W4398247641,Exposing the Achilles’ heel of textual hate speech classifiers using indistinguishable adversarial examples,2024,3.464139029789952e-05,2
W4386212383,Do Pretrained Language Models Indeed Understand Software Engineering Tasks?,2023,3.464139029789952e-05,2
W4385571047,ContraCLM: Contrastive Learning For Causal Language Model,2023,3.464139029789952e-05,2
W4408886313,Bilingual Dialogue Dataset with Personality and Emotion Annotations for Personality Recognition in Education,2025,3.464139029789952e-05,2
W4390145017,Syntax through rapid synaptic changes,2023,3.464139029789952e-05,2
W4392971467,Enhancing accident cause analysis through text classification and accident causation theory: A case study of coal mine gas explosion accidents,2024,3.464139029789952e-05,2
W3210528623,Fake News Detection on Social Media Using A Natural Language Inference Approach,2020,3.464139029789952e-05,2
W4409054952,Exploring the prospects of multimodal large language models for Automated Emotion Recognition in education: Insights from Gemini,2025,3.464139029789952e-05,2
W4408258990,A large language model-enabled machining process knowledge graph construction method for intelligent process planning,2025,3.464139029789952e-05,2
W4327644584,Learning Query-Space Document Representations for High-Recall Retrieval,2023,3.464139029789952e-05,2
W4386576638,Enhancing Information Retrieval in Fact Extraction and Verification,2023,3.464139029789952e-05,2
W4387185333,Cognitive Effects in Large Language Models,2023,3.464139029789952e-05,2
W4287888710,Extracting Temporal Event Relation with Syntax-guided Graph Transformer,2022,3.464139029789952e-05,2
W4407416297,Enriching RDF Data with LLM Based Named Entity Recognition and Linking on Embedded Natural Language Annotations,2025,3.464139029789952e-05,2
W3166642164,Blow the Dog Whistle: A Chinese Dataset for Cant Understanding with Common Sense and World Knowledge,2021,3.464139029789952e-05,2
W4388194748,Joint unsupervised contrastive learning and robust GMM for text clustering,2023,3.464139029789952e-05,2
W4394993638,ArEntail: manually-curated Arabic natural language inference dataset from news headlines,2024,3.464139029789952e-05,2
W4399500861,INTEGRATING IMAGE FEATURES WITH CONVOLUTIONAL SEQUENCE-TO-SEQUENCE NETWORK FOR MULTILINGUAL VISUAL QUESTION ANSWERING,2024,3.464139029789952e-05,2
W3197002404,Mixed Attention Transformer for Leveraging Word-Level Knowledge to Neural Cross-Lingual Information Retrieval,2021,3.464139029789952e-05,2
W4386566428,Transformers with Learnable Activation Functions,2023,3.464139029789952e-05,2
W4399730120,Building Trust in Conversational AI: A Review and Solution Architecture Using Large Language Models and Knowledge Graphs,2024,3.464139029789952e-05,2
W3213049935,Semi-supervised Intent Discovery with Contrastive Learning,2021,3.464139029789952e-05,2
W4408799105,A survey on moral foundation theory and pre-trained language models: current advances and challenges,2025,3.464139029789952e-05,2
W4394733949,Entity neighborhood awareness and hierarchical message aggregation for inductive relation prediction,2024,3.464139029789952e-05,2
W4400617496,A knowledge graph completion model based on triple level interaction and contrastive learning,2024,3.464139029789952e-05,2
W4409378335,ReranKGC: A cooperative retrieve-and-rerank framework for multi-modal knowledge graph completion,2025,3.464139029789952e-05,2
W4409330220,Exploring Consumer Bias Patterns in Fashion E-Commerce Through LLM-Based Sentiment and Network Analysis,2025,3.464139029789952e-05,2
W4408385008,Conversational AI Model for Effective Responses with Augmented Retrieval (CAMERA) Based Chatbot on NVIDIA Jetson Nano,2025,3.464139029789952e-05,2
W4386566572,Double Retrieval and Ranking for Accurate Question Answering,2023,3.464139029789952e-05,2
W4406642447,Large Language Models vs Human for Classifying Clinical Documents,2025,3.464139029789952e-05,2
W4402324956,Large language multimodal models for new-onset type 2 diabetes prediction using five-year cohort electronic health records,2024,3.464139029789952e-05,2
W4388501732,Comparing text mining and manual coding methods: Analysing interview data on quality of care in long-term care for older adults,2023,3.464139029789952e-05,2
W4406859636,Scalable information extraction from free text electronic health records using large language models,2025,3.464139029789952e-05,2
W4385570586,MeetingQA: Extractive Question-Answering on Meeting Transcripts,2023,3.464139029789952e-05,2
W4408735899,Using similarity network analysis to improve text similarity calculations,2025,3.464139029789952e-05,2
W4387533115,Adversarial attack and training for deep neural network based power quality disturbance classification,2023,3.464139029789952e-05,2
W4285206744,Cluster &amp; Tune: Boost Cold Start Performance in Text Classification,2022,3.464139029789952e-05,2
W4401433330,LitGene: a transformer-based model that uses contrastive learning to integrate textual information into gene representations,2024,3.464139029789952e-05,2
W4410548482,AKER: Arabic Knowledge-Enriched Reader for Machine Reading Comprehension,2025,3.464139029789952e-05,2
W4290613782,Applications of natural language processing in ophthalmology: present and future,2022,3.464139029789952e-05,2
W4403051422,Do Vision and Language Models Share Concepts? A Vector Space Alignment Study,2024,3.464139029789952e-05,2
W4410384179,RelBERT: Embedding Relations with Language Models,2025,3.464139029789952e-05,2
W4407624627,Improving Systematic Review Updates with Natural Language Processing: A Study on Screening Model Efficiency Through Component Classification and Selection (Preprint),2024,3.464139029789952e-05,2
W4281492987,Natural Language Processing for Information Extraction of Gastric Diseases and Its Application in Large-Scale Clinical Research,2022,3.464139029789952e-05,2
W4409875692,Detection of Patient Metadata in Published Articles for Genomic Epidemiology Using Machine Learning and Large Language Models,2025,3.464139029789952e-05,2
W4401943355,Leveraging Large Language Models for Patient Engagement: The Power of Conversational AI in Digital Health,2024,3.464139029789952e-05,2
W4409166550,Large Language Models Are Human-Like Annotators,2025,3.464139029789952e-05,2
W4409962616,Beyond words: evaluating large language models in transportation planning,2025,3.464139029789952e-05,2
W4406738920,Discontinuous named entities in clinical Text: A systematic literature review,2025,3.464139029789952e-05,2
W3195623089,Semantic Approach for Big Five Personality Prediction on Twitter,2021,3.464139029789952e-05,2
W4408341583,Semantic embeddings reveal and address taxonomic incommensurability in psychological measurement,2025,3.464139029789952e-05,2
W4392747524,Label-aware debiased causal reasoning for Natural Language Inference,2024,3.464139029789952e-05,2
W4390545867,Contextual Word Embedding for Biomedical Knowledge Extraction: a Rapid Review and Case Study,2024,3.464139029789952e-05,2
W4386541551,A Study of Contrastive Learning Algorithms for Sentence Representation Based on Simple Data Augmentation,2023,3.464139029789952e-05,2
W4399857017,Use of Bidirectional Encoder Representations from Transformers (BERT) and Robustly Optimized Bert Pretraining Approach (RoBERTa) for Nepali News Classification,2024,3.464139029789952e-05,2
W4312925950,German Medical Named Entity Recognition Model and Data Set Creation Using Machine Translation and Word Alignment: Algorithm Development and Validation,2022,3.464139029789952e-05,2
W4407866557,Adaptive data augmentation for salient sentence identification in Indian judicial decisions,2025,3.464139029789952e-05,2
W4404424464,Enhancing systematic review efficiency in hand surgery using artificial intelligence (natural language processing) for abstract screening,2024,3.464139029789952e-05,2
W4319753750,A data-centric way to improve entity linking in knowledge-based question answering,2023,3.464139029789952e-05,2
W4408132544,An Inference Method for Professional Texts with Computational Expressions Under Few-Shot Scenarios,2025,3.464139029789952e-05,2
W4285404855,GFCNet: Utilizing graph feature collection networks for coronavirus knowledge graph embeddings,2022,3.464139029789952e-05,2
W4389520192,Leveraging Structured Information for Explainable Multi-hop Question Answering and Reasoning,2023,3.464139029789952e-05,2
W4327811582,Review of Natural Language Processing in Pharmacology,2023,3.464139029789952e-05,2
W4394725593,Adaptive Gradient-based Word Saliency for adversarial text attacks,2024,3.464139029789952e-05,2
W3163189794,Word-level human interpretable scoring mechanism for novel text detection using Tsetlin Machines,2022,3.464139029789952e-05,2
W4402057292,A large-scale audit of dataset licensing and attribution in AI,2024,3.464139029789952e-05,2
W4393178543,RetLLM-E: Retrieval-Prompt Strategy for Question-Answering on Student Discussion Forums,2024,3.464139029789952e-05,2
W4406634532,An Application of Natural Language Processing for Hypoglycemic Event Identification in Patients with Diabetes Mellitus,2025,3.464139029789952e-05,2
W4408417561,Conceptual Combination in Large Language Models: Uncovering Implicit Relational Interpretations in Compound Words With Contextualized Word Embeddings,2025,3.464139029789952e-05,2
W4406262262,Enhancing semantical text understanding with fine-tuned large language models: A case study on Quora Question Pair duplicate identification,2025,3.464139029789952e-05,2
W4402577557,Cross-biased Contrastive Learning for Answer Selection with Dual-Tower Structure,2024,3.464139029789952e-05,2
W4388452371,Rhythmic modulation of prediction errors: A top-down gating role for the beta-range in speech processing,2023,3.464139029789952e-05,2
W4385270687,Schema Matching using Pre-Trained Language Models,2023,3.464139029789952e-05,2
W4383226706,An evaluation on large language model outputs: Discourse and memorization,2023,3.464139029789952e-05,2
W4319782877,Compression Methods for Transformers in Multidomain Sentiment Analysis,2022,3.464139029789952e-05,2
W4403577801,"""Reasoning before Responding"": Towards Legal Long-form Question Answering with Interpretability",2024,3.464139029789952e-05,2
W4383215352,Refined SBERT: Representing sentence BERT in manifold space,2023,3.464139029789952e-05,2
W4406941683,Using Complex Networks to Improve Legal Text Hierarchical Classification,2025,3.464139029789952e-05,2
W3128128460,Cone-KG: A Semantic Knowledge Graph with News Content and Social Context for Studying Covid-19 News Articles on Social Media,2020,3.464139029789952e-05,2
W4396808727,VisionVerse: Dynamic Video Question Answering Through Retrieval-Augmented Generation,2024,3.464139029789952e-05,2
W4409012087,Large language model for patent concept generation,2025,3.464139029789952e-05,2
W4385573795,Knowledge Stimulated Contrastive Prompting for Low-Resource Stance Detection,2022,3.464139029789952e-05,2
W4375819616,Generative LLMs and Textual Analysis in Accounting: (Chat) GPT as Research Assistant?,2023,3.464139029789952e-05,2
W4386173035,Applications of the Natural Language Processing Tool ChatGPT in Clinical Practice: Comparative Study and Augmented Systematic Review,2023,3.464139029789952e-05,2
W4304183734,An Entity Linking Algorithm Derived from Graph Convolutional Network and Contextualized Semantic Relevance,2022,3.464139029789952e-05,2
W3184553750,Small-Text: Active Learning for Text Classification in Python,2023,3.464139029789952e-05,2
W4407830444,Behind the mask: Random and selective masking in transformer models applied to specialized social science texts,2025,3.464139029789952e-05,2
W4389518745,ReasoningLM: Enabling Structural Subgraph Reasoning in Pre-trained Language Models for Question Answering over Knowledge Graph,2023,3.464139029789952e-05,2
W4385571096,Human-in-the-loop Evaluation for Early Misinformation Detection: A Case Study of COVID-19 Treatments,2023,3.464139029789952e-05,2
W4406919506,Integrating Speech Recognition and NLP for Efficient Transcription Solutions,2025,3.464139029789952e-05,2
W4408826549,ATIRS: Towards Adaptive Threat Analysis with Intelligent Log Summarization and Response Recommendation,2025,3.464139029789952e-05,2
W4394691488,Utilizing Machine Learning Techniques for Classifying Translated and Non-Translated Corporate Annual Reports,2024,3.464139029789952e-05,2
W3213511181,Review and Arrange: Curriculum Learning for Natural Language Understanding,2021,3.464139029789952e-05,2
W4385573936,Measurement Extraction with Natural Language Processing: A Review,2022,3.464139029789952e-05,2
W4405627622,Knowledge Distillation in RNN-Attention Models for Early Prediction of Student Performance,2025,3.464139029789952e-05,2
W4401522875,Large language model based collaborative robot system for daily task assistance,2024,3.464139029789952e-05,2
W4306661594,Natural Language Processing Techniques for Text Classification of Biomedical Documents: A Systematic Review,2022,3.464139029789952e-05,2
W4402533779,"RegulaTome: a corpus of typed, directed, and signed relations between biomedical entities in the scientific literature",2024,3.464139029789952e-05,2
W4408585377,ICARE: cross-domain text classification with incremental class-aware representation and distillation learning,2025,3.464139029789952e-05,2
W4409291291,ALPET: Active few-shot learning for citation worthiness detection in low-resource Wikipedia languages,2025,3.464139029789952e-05,2
W4390694654,A Case for Business Process-Specific Foundation Models,2024,3.464139029789952e-05,2
W4389523974,Tokenization Consistency Matters for Generative Models on Extractive NLP Tasks,2023,3.464139029789952e-05,2
W4324056402,OdeBERT: One-stage Deep-supervised Early-exiting BERT for Fast Inference in User Intent Classification,2023,3.464139029789952e-05,2
W4410315685,XLR-KGDD: leveraging LLM and RAG for knowledge graph-based explainable disease diagnosis using multimodal clinical information,2025,3.464139029789952e-05,2
W4388131010,Sentence Similarity Using Modified Latent Semantic Analysis and Semantic Relations,2023,3.464139029789952e-05,2
W3173970713,"What do end-to-end speech models learn about speaker, language and channel information? A layer-wise and neuron-level analysis",2023,3.464139029789952e-05,2
W4407222811,Chinese Medical Spoken Language Understanding Based on Prototypical Modification Network and Contrastive Learning,2025,3.464139029789952e-05,2
W4405989608,AMPLE: Emotion-Aware Multimodal Fusion Prompt Learning for Fake News Detection,2025,3.464139029789952e-05,2
W4409167058,"ELOQUENT CLEF Shared Tasks for Evaluation of Generative Language Model Quality, 2025 Edition",2025,3.464139029789952e-05,2
W3138008297,Identifying Machine-Paraphrased Plagiarism,2023,3.464139029789952e-05,2
W4377820893,Improving Pre-trained Language Models,2023,3.464139029789952e-05,2
W4409837816,"Vox Populi, Vox AI? Using Large Language Models to Estimate German Vote Choice",2025,3.464139029789952e-05,2
W4406614395,DeBERTA-Att-LMCQA: A hybrid model of DeBERTA and attention for legal multi-choice question answering,2025,3.464139029789952e-05,2
W4390011054,Prompting Metalinguistic Awareness in Large Language Models: ChatGPT and Bias Effects on the Grammar of Italian and Italian Varieties,2023,3.464139029789952e-05,2
W4410465595,Comparative analysis of text mining and clustering techniques for assessing functional dependency between manual test cases,2025,3.464139029789952e-05,2
W4409445749,MVIFSA: Enhancing relation detection in knowledge base question answering through multi-view information fusion and self-attention,2025,3.464139029789952e-05,2
W3200167504,RNN-Test: Towards Adversarial Testing for Recurrent Neural Network Systems,2021,3.464139029789952e-05,2
W4393411284,Topic Modeling for Mining Opinion Aspects from a Customer Feedback Corpus,2024,3.464139029789952e-05,2
W4394770144,LLaMA-LoRA Neural Prompt Engineering: A Deep Tuning Framework for Automatically Generating Chinese Text Logical Reasoning Thinking Chains,2024,3.464139029789952e-05,2
W3130138360,Anatomy of Catastrophic Forgetting: Hidden Representations and Task Semantics,2021,3.464139029789952e-05,2
W4394744221,Traces of Memorisation in Large Language Models for Code,2024,3.464139029789952e-05,2
W4408224774,MedicalGLM: A Pediatric Medical Question Answering Model with a quality evaluation mechanism,2025,3.464139029789952e-05,2
W4406518786,Hypnos: A domain-specific large language model for anesthesiology,2025,3.464139029789952e-05,2
W4379031423,Using Siamese BiLSTM Models for Identifying Text Semantic Similarity,2023,3.464139029789952e-05,2
W4385572738,Are Hard Examples also Harder to Explain? A Study with Human and Model-Generated Explanations,2022,3.464139029789952e-05,2
W3199386065,Augmenting Open-Domain Event Detection with Synthetic Data from GPT-2,2021,3.464139029789952e-05,2
W4284668485,PTAU,2022,3.464139029789952e-05,2
W3175582404,Self-Supervised Pillar Motion Learning for Autonomous Driving,2021,3.464139029789952e-05,2
W4399282265,Improving Vietnamese Legal Question–Answering System Based on Automatic Data Enrichment,2024,3.464139029789952e-05,2
W4409386930,Causality-Driven Patent Valuation: Integrating Domain Knowledge and Language Models in a Structured Interview-Like Selection Process,2025,3.464139029789952e-05,2
W4408130327,A neurobiologically inspired model of sentence comprehension,2025,3.464139029789952e-05,2
W4385568110,Commonsense Knowledge Graph towards Super APP and Its Applications in Alipay,2023,3.464139029789952e-05,2
W4382318023,Help Me Heal: A Reinforced Polite and Empathetic Mental Health and Legal Counseling Dialogue System for Crime Victims,2023,3.464139029789952e-05,2
W4408252562,Semantic Annotation Model and Method Based on Internet Open Dataset,2025,3.464139029789952e-05,2
W4399326970,BioInstruct: instruction tuning of large language models for biomedical natural language processing,2024,3.464139029789952e-05,2
W4303857107,Sentence-CROBI: A Simple Cross-Bi-Encoder-Based Neural Network Architecture for Paraphrase Identification,2022,3.464139029789952e-05,2
W4388019311,The Chronicles of ChatGPT: Generating and Evaluating Visual Novel Narratives on Climate Change Through ChatGPT,2023,3.464139029789952e-05,2
W4407811419,DeB3RTa: A Transformer-Based Model for the Portuguese Financial Domain,2025,3.464139029789952e-05,2
W4406873853,Natural language processing‐based classification of early Alzheimer's disease from connected speech,2025,3.464139029789952e-05,2
W3199904696,"Extract, Integrate, Compete: Towards Verification Style Reading Comprehension",2021,3.464139029789952e-05,2
W4407766364,Adapting Generative Large Language Models for Information Extraction from Unstructured Electronic Health Records in Residential Aged Care: A Comparative Analysis of Training Approaches,2025,3.464139029789952e-05,2
W4408472883,BERT applications in natural language processing: a review,2025,3.464139029789952e-05,2
W4408705811,Transformers and large language models are efficient feature extractors for electronic health record studies,2025,3.464139029789952e-05,2
W4406740223,"Categorising Corruption in the Vaccine Discourse: A General Taxonomy, Data Set, and Evaluation of LLMs for Classifying Corruption Dialogue in Social Media",2025,3.464139029789952e-05,2
W4392190680,Bridging the gap in biomedical information retrieval: Harnessing machine learning for enhanced search results and query semantics,2024,3.464139029789952e-05,2
W4406714995,Enhancing knowledge retrieval with in-context learning and semantic search through generative AI,2025,3.464139029789952e-05,2
W4410247559,"Long Document Classification in the Transformer Era: A Survey on Challenges, Advances, and Open Issues",2025,3.464139029789952e-05,2
W4399530301,Automatic Knowledge Structuration of Automotive User Manual for Question Answering,2023,3.464139029789952e-05,2
W4405247702,From Fact Drafts to Operational Systems: Semantic Search in Legal Decisions Using Fact Drafts,2024,3.464139029789952e-05,2
W4386938228,A Transformer-Based Framework for Biomedical Information Retrieval Systems,2023,3.464139029789952e-05,2
W4376225338,MSRDL: Deep learning framework for service recommendation in mashup creation,2023,3.464139029789952e-05,2
W4221155892,Deep Learning with Logical Constraints,2022,3.464139029789952e-05,2
W4400770808,Exploring Universal Intrinsic Task Subspace for Few-Shot Learning via Prompt Tuning,2024,3.464139029789952e-05,2
W4400485910,Optimizing Tourism Accommodation Offers by Integrating Language Models and Knowledge Graph Technologies,2024,3.464139029789952e-05,2
W3041169705,How managerial responses to online reviews affect customer satisfaction: An empirical study based on additional reviews,2020,3.464139029789952e-05,2
W4398160651,Training-free retrieval-based log anomaly detection with pre-trained language model considering token-level information,2024,3.464139029789952e-05,2
W4410556555,Identifying Disinformation on the Extended Impacts of COVID-19: Methodological Investigation Using a Fuzzy Ranking Ensemble of Natural Language Processing Models,2025,3.464139029789952e-05,2
W4393146330,Thai-language chatbot security: Detecting instruction attacks with XLM-RoBERTa and Bi-GRU,2024,3.464139029789952e-05,2
W4403582540,Two Heads are Better than One: Zero-shot Cognitive Reasoning via Multi-LLM Knowledge Fusion,2024,3.464139029789952e-05,2
W4406572162,Patient2Trial: From Patient to Participant in Clinical Trials Using Large Language Models,2025,3.464139029789952e-05,2
W4385574025,The Legal Argument Reasoning Task in Civil Procedure,2022,3.464139029789952e-05,2
W4405195133,Recent Advances of Foundation Language Models-based Continual Learning: A Survey,2024,3.464139029789952e-05,2
W4387878813,Dual Process Theory for Large Language Models: An overview of using Psychology to address hallucination and reliability issues,2023,3.464139029789952e-05,2
W4386587785,Overview of BioASQ 2023: The Eleventh BioASQ Challenge on Large-Scale Biomedical Semantic Indexing and Question Answering,2023,3.464139029789952e-05,2
W4408079212,A unified prompt-based framework for few-shot multimodal language analysis,2025,3.464139029789952e-05,2
W4409159698,mFollowIR: A Multilingual Benchmark for Instruction Following in Retrieval,2025,3.464139029789952e-05,2
W4402263913,Advancing Ear Biometrics: Enhancing Accuracy and Robustness Through Deep Learning,2024,3.464139029789952e-05,2
W3035075850,Entity-Aware Dependency-Based Deep Graph Attention Network for Comparative Preference Classification,2020,3.464139029789952e-05,2
W4408037575,Leveraging LLaMA2 for improved document classification in English,2025,3.464139029789952e-05,2
W4407016464,A soft prompt learning method for medical text classification with simulated human cognitive capabilities,2025,3.464139029789952e-05,2
W4407405718,Empowering large language models for automated clinical assessment with generation-augmented retrieval and hierarchical chain-of-thought,2025,3.464139029789952e-05,2
W4407870828,Knowledge assimilation: Implementing knowledge-guided agricultural large language model,2025,3.464139029789952e-05,2
W4401862830,Killing Two Birds with One Stone: Cross-modal Reinforced Prompting for Graph and Language Tasks,2024,3.464139029789952e-05,2
W3171450754,Restoring and Mining the Records of the Joseon Dynasty via Neural Language Modeling and Machine Translation,2021,3.464139029789952e-05,2
W4394805293,Unsupervised Sentence Representation Learning with Frequency-induced Adversarial tuning and Incomplete sentence filtering,2024,3.464139029789952e-05,2
W4401971058,The RL/LLM Taxonomy Tree: Reviewing Synergies Between Reinforcement Learning and Large Language Models,2024,3.464139029789952e-05,2
W4403577762,LeDQA: A Chinese Legal Case Document-based Question Answering Dataset,2024,3.464139029789952e-05,2
W4291012446,Identifying the Perceived Severity of Patient-Generated Telemedical Queries Regarding COVID: Developing and Evaluating a Transfer Learning–Based Solution,2022,3.464139029789952e-05,2
W4390573468,Discovering significant topics from legal decisions with selective inference,2024,3.464139029789952e-05,2
W4401110069,Semantic Textual Similarity Analysis of Clinical Text in the Era of LLM,2024,3.464139029789952e-05,2
W4386163596,Large-Scale Biomedical Relation Extraction Across Diverse Relation Types: Model Development and Usability Study on COVID-19,2023,3.464139029789952e-05,2
W4410252907,Developing Natural Language Processing Algorithms to Fact-Check Speech or Text,2025,3.464139029789952e-05,2
W4402919780,Automated annotation of scientific texts for ML-based keyphrase extraction and validation,2024,3.464139029789952e-05,2
W4400322765,Text Matching Model Combining Ranking Information and Negative Example Smoothing Strategies,2024,3.464139029789952e-05,2
W4402753735,Interpretable Measures of Conceptual Similarity by Complexity-Constrained Descriptive Auto-Encoding,2024,3.464139029789952e-05,2
W4361205837,Can language representation models think in bets?,2023,3.464139029789952e-05,2
W4407761215,Building an intelligent diabetes Q&amp;A system with knowledge graphs and large language models,2025,3.464139029789952e-05,2
W4409815088,Legal judgment prediction via legal knowledge extraction and fusion,2025,3.464139029789952e-05,2
W4385572222,Augmenting Reddit Posts to Determine Wellness Dimensions impacting Mental Health,2023,3.464139029789952e-05,2
W4410199817,SynCSE: Syntax Graph-based Contrastive Learning of Sentence Embeddings,2025,3.464139029789952e-05,2
W4393147036,CORECODE: A Common Sense Annotated Dialogue Dataset with Benchmark Tasks for Chinese Large Language Models,2024,3.464139029789952e-05,2
W4407058661,Qur’an Passage Ranking Using Transformer Models,2025,3.464139029789952e-05,2
W4327498003,ECIR 23 Tutorial: Neuro-Symbolic Approaches for Information Retrieval,2023,3.464139029789952e-05,2
W4399449628,Measuring and Improving the Energy Efficiency of Large Language Models Inference,2024,3.464139029789952e-05,2
W4226400527,An Evaluation of Pretrained BERT Models for Comparing Semantic Similarity Across Unstructured Clinical Trial Texts,2022,3.464139029789952e-05,2
W4407604969,Linguistic coupling between neural systems for speech production and comprehension during real-time dyadic conversations,2025,3.464139029789952e-05,2
W4403203115,Topic Modeling for Faster Literature Screening Using Transformer-Based Embeddings,2024,3.464139029789952e-05,2
W3194712525,No Rumours Please! A Multi-Indic-Lingual Approach for COVID Fake-Tweet Detection,2021,3.464139029789952e-05,2
W3196927838,Multistage BiCross encoder for multilingual access to COVID-19 health information,2021,3.464139029789952e-05,2
W4386566601,Detecting Contextomized Quotes in News Headlines by Contrastive Learning,2023,3.464139029789952e-05,2
W4402320017,CoAT: Corpus of artificial texts,2024,3.464139029789952e-05,2
W4409670780,Paths-over-Graph: Knowledge Graph Empowered Large Language Model Reasoning,2025,3.464139029789952e-05,2
W4379033124,Relphormer: Relational Graph Transformer for Knowledge Graph Representations,2023,3.464139029789952e-05,2
W4386794616,DebCSE: Rethinking Unsupervised Contrastive Sentence Embedding Learning in the Debiasing Perspective,2023,3.464139029789952e-05,2
W4317932826,An Automatic Generation of Heterogeneous Knowledge Graph for Global Disease Support: A Demonstration of a Cancer Use Case,2023,3.464139029789952e-05,2
W4410545705,Unpacking media bias in the growing divide between cable and network news,2025,3.464139029789952e-05,2
W4408102719,Solving the enigma: Enhancing faithfulness and comprehensibility in explanations of deep networks,2025,3.464139029789952e-05,2
W4408075204,To Ensemble or Not: Assessing Majority Voting Strategies for Phishing Detection with Large Language Models,2025,3.464139029789952e-05,2
W4304128530,Systematic Evaluation of Common Natural Language Processing Techniques to Codify Clinical Notes,2022,3.464139029789952e-05,2
W4408466306,Estimating the Confidence of Language Model Generation using Training Data,2025,3.464139029789952e-05,2
W4385570518,"MaChAmp at SemEval-2023 tasks 2, 3, 4, 5, 7, 8, 9, 10, 11, and 12: On the Effectiveness of Intermediate Training on an Uncurated Collection of Datasets.",2023,3.464139029789952e-05,2
W4407750010,Enhancing Recommender Systems: Deep Modality Alignment with Large Multi-Modal Encoders,2025,3.464139029789952e-05,2
W4366547579,Tracing and Visualizing Human-ML/AI Collaborative Processes through Artifacts of Data Work,2023,3.464139029789952e-05,2
W4409651727,LLM-KGMQA: large language model-augmented multi-hop question-answering system based on knowledge graph in medical field,2025,3.464139029789952e-05,2
W4372259985,PQLM - Multilingual Decentralized Portable Quantum Language Model,2023,3.464139029789952e-05,2
W4385572070,Team ISCL_WINTER at SemEval-2023 Task 12:AfriSenti-SemEval: Sentiment Analysis for Low-resource African Languages using Twitter Dataset,2023,3.464139029789952e-05,2
W4408800659,Explainable TabNet Transformer-based on Google Vizier Optimizer for Anomaly Intrusion Detection System,2025,3.464139029789952e-05,2
W4390686303,The determinants of linguistic features in key audit matters: Empirical evidence from Europe,2024,3.464139029789952e-05,2
W4367047445,Hierarchy-Aware Multi-Hop Question Answering over Knowledge Graphs,2023,3.464139029789952e-05,2
W4400338820,Implicit and explicit commonsense for multi-sentence video captioning,2024,3.464139029789952e-05,2
W4402227510,Multi-level Shared Knowledge Guided Learning for Knowledge Graph Completion,2024,3.464139029789952e-05,2
W4372262731,Pyramid Dynamic Inference: Encouraging Faster Inference Via Early Exit Boosting,2023,3.464139029789952e-05,2
W4282945631,Improving Pretrained Language Model Fine-Tuning With Noise Stability Regularization,2023,3.464139029789952e-05,2
W4389010426,OpinionConv: Conversational Product Search with Grounded Opinions,2023,3.464139029789952e-05,2
W4403942912,W2CL: A Multi-task Learning Approach to Improve Domain-Specific Sentence Classification Through Word Classification and Contrastive Learning,2024,3.464139029789952e-05,2
W4392904549,Large Language Models As A Proxy For Human Evaluation In Assessing The Comprehensibility Of Disordered Speech Transcription,2024,3.464139029789952e-05,2
W4320713530,Urban landscape and climate affect residents’ sentiments based on big data,2023,3.464139029789952e-05,2
W3198057698,Mitigation of Diachronic Bias in Fake News Detection Dataset,2021,3.464139029789952e-05,2
W4376122615,Knowledge-enhanced Agents for Interactive Text Games,2023,3.464139029789952e-05,2
W4390884707,A Knowledge-enhanced Two-stage Generative Framework for Medical Dialogue Information Extraction,2024,3.464139029789952e-05,2
W4409438762,DEANE: Context-Aware Dual-Craft Graph Contrastive Learning for Enhanced Extractive Question Answering,2025,3.464139029789952e-05,2
W4408257283,A Comprehensive Ontology Knowledge Evaluation System for Large Language Models,2025,3.464139029789952e-05,2
W4384932493,Lexicon-enhanced Pre-trained Language Models for Chinese Ethics-related Tasks,2023,3.464139029789952e-05,2
W4392594189,Contribution Analysis of Large Language Models and Data Augmentations for Person Names in Solving Legal Bar Examination at COLIEE 2023,2024,3.464139029789952e-05,2
W3181342329,Testing challenges for NLP-intensive bots,2021,3.464139029789952e-05,2
W3193521099,Reusable Templates and Guides For Documenting Datasets and Models for Natural Language Processing and Generation: A Case Study of the HuggingFace and GEM Data and Model Cards,2021,3.464139029789952e-05,2
W4385006064,Identical and Fraternal Twins: Fine-Grained Semantic Contrastive Learning of Sentence Representations,2023,3.464139029789952e-05,2
W4402635336,"Overview of the CLEF-2024 CheckThat! Lab: Check-Worthiness, Subjectivity, Persuasion, Roles, Authorities, and Adversarial Robustness",2024,3.464139029789952e-05,2
W4408176728,Development of a natural language processing algorithm to extract social determinants of health from clinician notes,2025,3.464139029789952e-05,2
W4366597729,Improving Multiparty Interactions with a Robot Using Large Language Models,2023,3.464139029789952e-05,2
W4385541615,Read it Twice: Towards Faithfully Interpretable Fact Verification by Revisiting Evidence,2023,3.464139029789952e-05,2
W3131335651,"Automatic Exam Correction Framework (AECF) for the MCQs, Essays, and Equations Matching",2021,3.464139029789952e-05,2
W4406869923,NeOn-GPT: A Large Language Model-Powered Pipeline for Ontology Learning,2025,3.464139029789952e-05,2
W4389523912,Evaluating Large Language Models on Controlled Generation Tasks,2023,3.464139029789952e-05,2
W4392735498,ReAGent: A Model-agnostic Feature Attribution Method for Generative Language Models,2024,3.464139029789952e-05,2
W4404193844,Monolingual and Cross-Lingual Knowledge Transfer for Topic Classification,2024,3.464139029789952e-05,2
W4385574314,Structural Contrastive Representation Learning for Zero-shot Multi-label Text Classification,2022,3.464139029789952e-05,2
W4393949013,A Generative Artificial Intelligence Using Multilingual Large Language Models for ChatGPT Applications,2024,3.464139029789952e-05,2
W4409384710,Transfer learning for software vulnerability prediction using Transformer models,2025,3.464139029789952e-05,2
W4385571379,Infusing Hierarchical Guidance into Prompt Tuning: A Parameter-Efficient Framework for Multi-level Implicit Discourse Relation Recognition,2023,3.464139029789952e-05,2
W4385572951,Efficient Nearest Neighbor Emotion Classification with BERT-whitening,2022,3.464139029789952e-05,2
W4385572133,Trigger Warning Assignment as a Multi-Label Document Classification Problem,2023,3.464139029789952e-05,2
W4401753105,"Detection of Bipolar Disorder on Social Media Data Utilizing Biomedical, Clinical and Mental Health Domain Fine-Tuned Word Embeddings",2024,3.464139029789952e-05,2
W4409166952,LSTM-Based Selective Dense Text Retrieval Guided by Sparse Lexical Retrieval,2025,3.464139029789952e-05,2
W4399800790,Exploring T5 and RGAN for Enhanced Sarcasm Generation in NLP,2024,3.464139029789952e-05,2
W4286776303,"Towards using visual, semantic and structural features to improve code readability classification",2022,3.464139029789952e-05,2
W4392902804,Enabling Device Control Planning Capabilities of Small Language Model,2024,3.464139029789952e-05,2
W4406513948,Incremental accumulation of linguistic context in artificial and biological neural networks,2025,3.464139029789952e-05,2
W4400399317,OQA : A question-answering dataset on orthodontic literature,2024,3.464139029789952e-05,2
W4395025756,Indian Annual Report Assessment Using Large Language Models,2024,3.464139029789952e-05,2
W4409478869,Elevating Textual Question Answering with On-Demand Visual Augmentation,2025,3.464139029789952e-05,2
W4395117503,How the Listener’s Attention Dynamically Switches Between Different Speakers During a Natural Conversation,2024,3.464139029789952e-05,2
W4391519594,Application of Large Language Models to DDoS Attack Detection,2024,3.464139029789952e-05,2
W4407158522,Structured reasoning and answer verification: Enhancing question answering system accuracy and explainability,2025,3.464139029789952e-05,2
W3022104542,IsoBN: Fine-Tuning BERT with Isotropic Batch Normalization,2021,3.464139029789952e-05,2
W4406071956,"Evaluation of open and closed-source LLMs for low-resource language with zero-shot, few-shot, and chain-of-thought prompting",2025,3.464139029789952e-05,2
W4406418717,Metadata Conditioning Accelerates Language Model Pre-training,2025,3.464139029789952e-05,2
W4407011914,Natural language processing for scalable feature engineering and ultra-high-dimensional confounding adjustment in healthcare database studies.,2025,3.464139029789952e-05,2
W4409085125,Efficient multi-task learning with instance selection for biomedical NLP,2025,3.464139029789952e-05,2
W3174225409,Story Ending Generation with Multi-Level Graph Convolutional Networks over Dependency Trees,2021,3.464139029789952e-05,2
W4287887521,"Yes, No or IDK: The Challenge of Unanswerable Yes/No Questions",2022,3.464139029789952e-05,2
W4409907388,Learn to explain transformer via interpretation path by reinforcement learning,2025,3.464139029789952e-05,2
W4409166218,Hierarchical Prefixes for Long Document Representations,2025,3.464139029789952e-05,2
W4297478855,ALBERT with Knowledge Graph Encoder Utilizing Semantic Similarity for Commonsense Question Answering,2022,3.464139029789952e-05,2
W4410544973,Japanese Author Attribution Using BERT Finetuning with Stylometric Features,2025,3.464139029789952e-05,2
W4364375221,Affix rivalry: Theoretical and methodological challenges,2023,3.464139029789952e-05,2
W4405107149,Conversational Search,2024,3.464139029789952e-05,2
W4403646833,Systematic Analysis of Retrieval-Augmented Generation-Based LLMs for Medical Chatbot Applications,2024,3.464139029789952e-05,2
W4407345433,Topic modeling based BERT &amp; SBERT transformer pretrained language modeling: A survey (2019-2023),2025,3.464139029789952e-05,2
W4385565374,A Practical Toolkit for Multilingual Question and Answer Generation,2023,3.464139029789952e-05,2
W3130747775,GHS-NET a generic hybridized shallow neural network for multi-label biomedical text classification,2021,3.464139029789952e-05,2
W4322718777,Precision information extraction for rare disease epidemiology at scale,2023,3.464139029789952e-05,2
W4404823262,Streamlining Attention for Text Classification: Sequence Length Reduction with Pooling Attention,2024,3.464139029789952e-05,2
W4401507672,Prompt Tuning on Graph-Augmented Low-Resource Text Classification,2024,3.464139029789952e-05,2
W4401413215,The overview of the BioRED (Biomedical Relation Extraction Dataset) track at BioCreative VIII,2024,3.464139029789952e-05,2
W4389519810,Joint Learning for Legal Text Retrieval and Textual Entailment: Leveraging the Relationship between Relevancy and Affirmation,2023,3.464139029789952e-05,2
W4394726121,Enhancing Zero-Shot Stance Detection with Contrastive and Prompt Learning,2024,3.464139029789952e-05,2
W4399130767,Experimental study on short-text clustering using transformer-based semantic similarity measure,2024,3.464139029789952e-05,2
W4408095440,FedLegal: A Real-World Federated Learning Benchmark for Legal Natural Language Processing,2025,3.464139029789952e-05,2
W4391929391,A novel approach to voice of customer extraction using GPT-3.5 Turbo: linking advanced NLP and Lean Six Sigma 4.0,2024,3.464139029789952e-05,2
W4375840656,Automated Test Case Generation Using T5 and GPT-3,2023,3.464139029789952e-05,2
W4393160208,Small Language Model Can Self-Correct,2024,3.464139029789952e-05,2
W4388455852,Improving First-stage Retrieval of Point-of-interest Search by Pre-training Models,2023,3.464139029789952e-05,2
W4379534564,RISC: Generating Realistic Synthetic Bilingual Insurance Contract,2023,3.464139029789952e-05,2
W4409492698,Optimizing Reinforcement Learning with Limited HRI Demonstrations: A Task-Oriented Weight Update Method with Analysis of Multi-Head and Layer Feature Combinations,2025,3.464139029789952e-05,2
W4410461195,Aligning large language models with human preferences using historical text edits,2025,3.464139029789952e-05,2
W4392913295,AI-Generated Text Detector for Arabic Language Using Encoder-Based Transformer Architecture,2024,3.464139029789952e-05,2
W4328098479,Regret and Hope on Transformers: An Analysis of Transformers on Regret and Hope Speech Detection Datasets,2023,3.464139029789952e-05,2
W4389524463,Beyond Factuality: A Comprehensive Evaluation of Large Language Models as Knowledge Generators,2023,3.464139029789952e-05,2
W4327737695,A Systematic Review of Transformer-Based Pre-Trained Language Models through Self-Supervised Learning,2023,3.464139029789952e-05,2
W4407069513,cosmosage: A natural-language assistant for cosmology,2025,3.464139029789952e-05,2
W4407945631,Comprehensive Analysis of Machine Learning and Deep Learning models on Prompt Injection Classification using Natural Language Processing techniques,2025,3.464139029789952e-05,2
W4395689476,Synergizing machine learning &amp; symbolic methods: A survey on hybrid approaches to natural language processing,2024,3.464139029789952e-05,2
W4400971828,"The Effects of the Training Sample Size, Ground Truth Reliability, and NLP Method on Language-Based Automatic Interview Scores’ Psychometric Properties",2024,3.464139029789952e-05,2
W3206843525,Can Explanations Be Useful for Calibrating Black Box Models?,2022,3.464139029789952e-05,2
W4408984182,Automated Knowledge Extraction from IS Research Articles Combining Sentence Classification and Ontological Annotation,2025,3.464139029789952e-05,2
W4408257260,Manu-Eval: A Chinese Language Understanding Benchmark for Manufacturing Industry,2025,3.464139029789952e-05,2
W4386566866,Prompt Tuning with Contradictory Intentions for Sarcasm Recognition,2023,3.464139029789952e-05,2
W4319300084,A URL-Based Social Semantic Attacks Detection With Character-Aware Language Model,2023,3.464139029789952e-05,2
W4406083163,The architecture of language: Understanding the mechanics behind LLMs,2025,3.464139029789952e-05,2
W4400132641,FLMatchQA: a recursive neural network-based question answering with customized federated learning model,2024,3.464139029789952e-05,2
W3106483960,Repulsive Attention: Rethinking Multi-head Attention as Bayesian Inference,2020,3.464139029789952e-05,2
W4386576869,Implicit Temporal Reasoning for Evidence-Based Fact-Checking,2023,3.464139029789952e-05,2
W4400524784,Generative Retrieval as Multi-Vector Dense Retrieval,2024,3.464139029789952e-05,2
W3153018527,Political Ideology Prediction from Bengali Text Using Word Embedding Models,2021,3.464139029789952e-05,2
W4403865056,"The Deep Integration of Knowledge Graphs and Large Language Models: Advancements, Challenges, and Future Directions",2024,3.464139029789952e-05,2
W4372259980,ESCL: Equivariant Self-Contrastive Learning for Sentence Representations,2023,3.464139029789952e-05,2
W4389524268,"Fine-tuned LLMs Know More, Hallucinate Less with Few-Shot Sequence-to-Sequence Semantic Parsing over Wikidata",2023,3.464139029789952e-05,2
W4391474918,Using Artificial Intelligence to Label Free-Text Operative and Ultrasound Reports for Grading Pediatric Appendicitis,2024,3.464139029789952e-05,2
W4317795002,Mask and Cloze: Automatic Open Cloze Question Generation Using a Masked Language Model,2023,3.464139029789952e-05,2
W4288059328,Improving the Quality of Students’ Written Reflections Using Natural Language Processing: Model Design and Classroom Evaluation,2022,3.464139029789952e-05,2
W4378839671,Ask and Ye shall be Answered: Bayesian tag-based collaborative recommendation of trustworthy experts over time in community question answering,2023,3.464139029789952e-05,2
W4386307206,Integrating Text Classification into Topic Discovery Using Semantic Embedding Models,2023,3.464139029789952e-05,2
W4393113494,Neural Data Augmentation for Legal Overruling Task: Small Deep Learning Models vs. Large Language Models,2024,3.464139029789952e-05,2
W3101855539,Natural Language Inference in Context -- Investigating Contextual Reasoning over Long Texts,2020,3.464139029789952e-05,2
W4406752992,Which Reveals Ideology Better? Comparing Self-Presentation and Public Rhetoric in the Facebook Climate Debate via Embeddings Analysis,2025,3.464139029789952e-05,2
W4321483605,ESG information extraction with cross-sectoral and multi-source adaptation based on domain-tuned language models,2023,3.464139029789952e-05,2
W4385569957,Query Structure Modeling for Inductive Logical Reasoning Over Knowledge Graphs,2023,3.464139029789952e-05,2
W4389664922,PromptCast: A New Prompt-Based Learning Paradigm for Time Series Forecasting,2023,3.464139029789952e-05,2
W4382318094,NLP-Based Automated Compliance Checking of Data Processing Agreements Against GDPR,2023,3.464139029789952e-05,2
W4392542324,Trust in Generative AI among Students: An exploratory study,2024,3.464139029789952e-05,2
W4407558735,Automatically resolving conflicts between expert systems: An experimental approach using large language models and fuzzy cognitive maps from participatory modeling studies,2025,3.464139029789952e-05,2
W4389009482,The Next Chapter: A Study of Large Language Models in Storytelling,2023,3.464139029789952e-05,2
W4389686470,UTDRM: unsupervised method for training debunked-narrative retrieval models,2023,3.464139029789952e-05,2
W4401866067,Understanding Logical Reasoning Ability of Large Language Models,2024,3.464139029789952e-05,2
W4409167408,Enhancing FEVER-Style Claim Fact-Checking Against Wikipedia: A Diagnostic Taxonomy and a Generative Framework,2025,3.464139029789952e-05,2
W4385764314,Less Learn Shortcut: Analyzing and Mitigating Learning of Spurious Feature-Label Correlation,2023,3.464139029789952e-05,2
W4409605213,Fake news detection using Hashtag context,2025,3.464139029789952e-05,2
W4410116425,Dynamics of auditory word form encoding in human speech cortex,2025,3.464139029789952e-05,2
W4408146479,Robustness of Large Language Models Against Adversarial Attacks,2024,3.464139029789952e-05,2
W4402704595,Let's Think Outside the Box: Exploring Leap-of-Thought in Large Language Models with Creative Humor Generation,2024,3.464139029789952e-05,2
W4407588883,sunflower: an R package for handling multiple response attempts and conducting error analysis in aphasia and related disorders,2025,3.464139029789952e-05,2
W4381802325,Mining legal arguments in court decisions,2023,3.464139029789952e-05,2
W4385570749,Gradient-based Intra-attention Pruning on Pre-trained Language Models,2023,3.464139029789952e-05,2
W4391181913,Beyond Surface Linguistics,2023,3.464139029789952e-05,2
W4401722583,Lessons from the Use of Natural Language Inference (NLI) in Requirements Engineering Tasks,2024,3.464139029789952e-05,2
W3176111903,Generalizing Cross-Document Event Coreference Resolution Across Multiple Corpora,2021,3.464139029789952e-05,2
W3217005823,GIS-KG: building a large-scale hierarchical knowledge graph for geographic information science,2021,3.464139029789952e-05,2
W3016888066,BanFakeNews: A Dataset for Detecting Fake News in Bangla,2020,3.464139029789952e-05,2
W4407601505,Knowledge Neurons in the Knowledge Graph-based Link Prediction Models,2025,3.464139029789952e-05,2
W4385571643,FiD-ICL: A Fusion-in-Decoder Approach for Efficient In-Context Learning,2023,3.464139029789952e-05,2
W4393152839,Customizing Language Model Responses with Contrastive In-Context Learning,2024,3.464139029789952e-05,2
W4386132120,Deepfake Detection on Social Media: Leveraging Deep Learning and FastText Embeddings for Identifying Machine-Generated Tweets,2023,3.464139029789952e-05,2
W4409649497,Leveraging encoder-only large language models for mobile app review feature extraction,2025,3.464139029789952e-05,2
W4318464952,Multi-task Learning for Features Extraction in Financial Annual Reports,2023,3.464139029789952e-05,2
W4391826804,SPeC: A Soft Prompt-Based Calibration on Performance Variability of Large Language Model in Clinical Notes Summarization,2024,3.464139029789952e-05,2
W4405025882,A BERT-Based Method of Named Entity Recognition for Ukiyo-e Titles,2024,3.464139029789952e-05,2
W4400869639,LLM-Commentator: Novel fine-tuning strategies of large language models for automatic commentary generation using football event data,2024,3.464139029789952e-05,2
W4384342195,The default network dominates neural responses to evolving movie stories,2023,3.464139029789952e-05,2
W4404210426,A fine-tuning enhanced RAG system with quantized influence measure as AI judge,2024,3.464139029789952e-05,2
W4224215744,SensiMix: Sensitivity-Aware 8-bit index &amp; 1-bit value mixed precision quantization for BERT compression,2022,3.464139029789952e-05,2
W3212166010,PalmTree: Learning an Assembly Language Model for Instruction Embedding,2021,3.464139029789952e-05,2
W4391476916,Unveiling the New Frontier: ChatGPT-3 Powered Translation for Arabic-English Language Pairs,2024,3.464139029789952e-05,2
W3126639583,GT-Finder: Classify the family of glucose transporters with pre-trained BERT language models,2021,3.464139029789952e-05,2
W4293262073,Making Adversarially-Trained Language Models Forget with Model Retraining: A Case Study on Hate Speech Detection,2022,3.464139029789952e-05,2
W4399659401,Building a Large Corpus and Pre-trained Language Models from National and Local Assembly Minutes,2024,3.464139029789952e-05,2
W4393381464,Using rhetorical strategies to design prompts: a human-in-the-loop approach to make AI useful,2024,3.464139029789952e-05,2
W3136991969,Tiny Transformers for Environmental Sound Classification at the Edge,2021,3.464139029789952e-05,2
W4281482237,"How to Approach Ambiguous Queries in Conversational Search: A Survey of Techniques, Approaches, Tools, and Challenges",2022,3.464139029789952e-05,2
W3035009410,Bayesian Hierarchical Words Representation Learning,2020,3.464139029789952e-05,2
W4409852399,ASC: Aggregating Sentence-Level Classifications for Multi-label Long Text Classification,2025,3.464139029789952e-05,2
W4327993545,Retrieving false claims on Twitter during the Russia-Ukraine conflict,2023,3.464139029789952e-05,2
W4391467401,Distractor Generation Through Text-to-Text Transformer Models,2024,3.464139029789952e-05,2
W4385572158,Cognitive Reframing of Negative Thoughts through Human-Language Model Interaction,2023,3.464139029789952e-05,2
W4381803920,Transparency Helps Reveal When Language Models Learn Meaning,2023,3.464139029789952e-05,2
W4402169037,A Survey of Text Watermarking in the Era of Large Language Models,2024,3.464139029789952e-05,2
W3173558867,PAWLS: PDF Annotation With Labels and Structure,2021,3.464139029789952e-05,2
W3173295223,KuiLeiXi: a Chinese Open-Ended Text Adventure Game,2021,3.464139029789952e-05,2
W4220973773,Active Learning for Reducing Labeling Effort in Text Classification Tasks,2022,3.464139029789952e-05,2
W4406132119,Natural language processing for chest X‐ray reports in the transformer era: BERT‐like encoders for comprehension and GPT‐like decoders for generation,2025,3.464139029789952e-05,2
W4410201740,A novel data extraction framework using Natural Language Processing (DEFNLP) techniques,2025,3.464139029789952e-05,2
W4399798455,Whither developmental psycholinguistics?,2024,3.464139029789952e-05,2
W4406696010,Question Answer Summary Generation from Unstructured Texts by Using LLMs,2025,3.464139029789952e-05,2
W4405107234,Knowledge Graphs and Search,2024,3.464139029789952e-05,2
W4409166473,A Reproducibility Study on Consistent LLM Reasoning for Natural Language Inference over Clinical Trials,2025,3.464139029789952e-05,2
W4394895522,A Quantization Approach for the Reduced Size of Large Language Models,2024,3.464139029789952e-05,2
W4286955624,Shaking Syntactic Trees on the Sesame Street: Multilingual Probing with Controllable Perturbations,2021,3.464139029789952e-05,2
W4389523927,Retrieval-based Evaluation for LLMs: A Case Study in Korean Legal QA,2023,3.464139029789952e-05,2
W4409762035,Geo-FuB: A Method for Constructing an Operator-Function Knowledge Base for Geospatial Code Generation with Large Language Models,2025,3.464139029789952e-05,2
W4390396506,Evaluating Embeddings from Pre-Trained Language Models and Knowledge Graphs for Educational Content Recommendation,2023,3.464139029789952e-05,2
W4385570910,Measuring Inductive Biases of In-Context Learning with Underspecified Demonstrations,2023,3.464139029789952e-05,2
W4408573322,Benchmarking Interpretability in Healthcare Using Pattern Discovery and Disentanglement,2025,3.464139029789952e-05,2
W4393158201,Bootstrapping Cognitive Agents with a Large Language Model,2024,3.464139029789952e-05,2
W4408221692,Denoising Implicit Feedback for Extractive Question Answering,2025,3.464139029789952e-05,2
W4407009343,Personality in just a few words: Assessment using natural language processing,2025,3.464139029789952e-05,2
W4403051598,Retrieval-style In-context Learning for Few-shot Hierarchical Text Classification,2024,3.464139029789952e-05,2
W4387394525,Language Model-Based Player Goal Recognition in Open World Digital Games,2023,3.464139029789952e-05,2
W4394743995,On Extracting Specialized Code Abilities from Large Language Models: A Feasibility Study,2024,3.464139029789952e-05,2
W4406788559,Automatic instantiation of assurance cases from patterns using large language models,2025,3.464139029789952e-05,2
W4395080118,FT-LLM: Development of a Retrieval Augmented Generation based Language Model Framework for Assisting Data Analysis in the Football Industry,2024,3.464139029789952e-05,2
W4404723816,Distributional Semantics: Meaning Through Culture and Interaction,2024,3.464139029789952e-05,2
W4392351097,WaveFormer: transformer-based denoising method for gravitational-wave data,2024,3.464139029789952e-05,2
W4408229742,irAE-GPT: Leveraging large language models to identify immune-related adverse events in electronic health records and clinical trial datasets,2025,3.464139029789952e-05,2
W4287854424,SemEval-2022 Task 9: R2VQ – Competence-based Multimodal Question Answering,2022,3.464139029789952e-05,2
W4409164491,How do LLMs perform on Turkish? A multi-faceted multi-prompt evaluation,2025,3.464139029789952e-05,2
W4382406466,A Contrastive Self-distillation BERT with Kernel Alignment-Based Inference,2023,3.464139029789952e-05,2
W4384302764,AI-based Question Answering Assistance for Analyzing Natural-language Requirements,2023,3.464139029789952e-05,2
W4386566724,Uncovering Implicit Inferences for Improved Relational Argument Mining,2023,3.464139029789952e-05,2
W4386424132,Prompting meaning: a hermeneutic approach to optimising prompt engineering with ChatGPT,2023,3.464139029789952e-05,2
W4402827393,Larger and more instructable language models become less reliable,2024,3.464139029789952e-05,2
W4387560121,Integrating Graphs With Large Language Models: Methods and Prospects,2024,3.464139029789952e-05,2
W4405400063,Automatic essay scoring for natural language processing: feature extraction and scoring models,2024,3.464139029789952e-05,2
W4409657176,MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot,2025,3.464139029789952e-05,2
W4392384220,Multi-Granular Text Classification with Minimal Supervision,2024,3.464139029789952e-05,2
W4382202728,Adversarial Self-Attention for Language Understanding,2023,3.464139029789952e-05,2
W4393147201,ConsistentEE: A Consistent and Hardness-Guided Early Exiting Method for Accelerating Language Models Inference,2024,3.464139029789952e-05,2
W4401577991,Gauging Airbnb review sentiments and critical key-topics by small area estimation,2024,3.464139029789952e-05,2
W3181113307,LexSubCon: Integrating Knowledge from Lexical Resources into Contextual Embeddings for Lexical Substitution,2022,3.464139029789952e-05,2
W4389523998,Token Prediction as Implicit Classification to Identify LLM-Generated Text,2023,3.464139029789952e-05,2
W4410398522,A Symmetric Dual-Drive Text Matching Model Based on Dynamically Gated Sparse Attention Feature Distillation with a Faithful Semantic Preservation Strategy,2025,3.464139029789952e-05,2
W4392903952,Sensi-Bert: Towards Sensitivity Driven Fine-Tuning for Parameter-Efficient Language Model,2024,3.464139029789952e-05,2
W4382202633,Converge to the Truth: Factual Error Correction via Iterative Constrained Editing,2023,3.464139029789952e-05,2
W4389520047,WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia,2023,3.464139029789952e-05,2
W4391132527,Can large language models help augment English psycholinguistic datasets?,2024,3.464139029789952e-05,2
W4400916398,Dissociating prosodic from syntactic delta activity during natural speech comprehension,2024,3.464139029789952e-05,2
W4386968362,Biomedical generative pre-trained based transformer language model for age-related disease target discovery,2023,3.464139029789952e-05,2
W4409211441,Debate divides: Argument relation-based contrastive opinion summarization via multi-task learning for online discussions,2025,3.464139029789952e-05,2
W4389520409,TaskWeb: Selecting Better Source Tasks for Multi-task NLP,2023,3.464139029789952e-05,2
W4409332187,"Multimodal Data Fusion for Tabular and Textual Data: Zero-Shot, Few-Shot, and Fine-Tuning of Generative Pre-Trained Transformer Models",2025,3.464139029789952e-05,2
W4327652408,Contextualized Graph Embeddings for Adverse Drug Event Detection,2023,3.464139029789952e-05,2
W4385571150,Building blocks for complex tasks: Robust generative event extraction for radiology reports under domain shifts,2023,3.464139029789952e-05,2
W4389520485,NEWTON: Are Large Language Models Capable of Physical Reasoning?,2023,3.464139029789952e-05,2
W4368340828,A hybrid deep learning approach for detecting sentiment polarities and knowledge graph representation on monkeypox tweets,2023,3.464139029789952e-05,2
W3208393080,EasyTransfer,2021,3.464139029789952e-05,2
W4385572447,NormMark: A Weakly Supervised Markov Model for Socio-cultural Norm Discovery,2023,3.464139029789952e-05,2
W4399073778,A Review of State of the Art Deep Learning Models for Ontology Construction,2024,3.464139029789952e-05,2
W4409202661,SMAR + NIE IdeaGen: A knowledge graph based node importance estimation with analogical reasoning on large language model for idea generation,2025,3.464139029789952e-05,2
W4400046281,Injecting the score of the first-stage retriever as text improves BERT-based re-rankers,2024,3.464139029789952e-05,2
W4385532506,Multi-level Adversarial Training for Stock Sentiment Prediction,2023,3.464139029789952e-05,2
W4392179379,Talkin' 'Bout AI Generation,2024,3.464139029789952e-05,2
W4312602419,Value-Wise ConvNet for Transformer Models: An Infinite Time-Aware Recommender System,2022,3.464139029789952e-05,2
W4319996342,A 95.6-TOPS/W Deep Learning Inference Accelerator With Per-Vector Scaled 4-bit Quantization in 5 nm,2023,3.464139029789952e-05,2
W4406998844,TurkMedNLI: a Turkish medical natural language inference dataset through large language model based translation,2025,3.464139029789952e-05,2
W4389524573,Large Language Models Are Better Adversaries: Exploring Generative Clean-Label Backdoor Attacks Against Text Classifiers,2023,3.464139029789952e-05,2
W4399856164,Evaluation of Language Models for Multilabel Classification of Biomedical Texts,2024,3.464139029789952e-05,2
W4393147971,UniGen: A Unified Generative Framework for Retrieval and Question Answering with Large Language Models,2024,3.464139029789952e-05,2
W4393066104,Gs-Cbr-Kbqa: Graph-Structured Case-Based Reasoning for Knowledge Base Question Answering,2024,3.464139029789952e-05,2
W4389520494,KG-GPT: A General Framework for Reasoning on Knowledge Graphs Using Large Language Models,2023,3.464139029789952e-05,2
W4313567241,Material transformers: deep learning language models for generative materials design,2022,3.464139029789952e-05,2
W4366378733,A Prompt-Based Topic-Modeling Method for Depression Detection on Low-Resource Data,2023,3.464139029789952e-05,2
W4221151164,IAM: A Comprehensive and Large-Scale Dataset for Integrated Argument Mining Tasks,2022,3.464139029789952e-05,2
W4409150672,GraphLoRA: Structure-Aware Contrastive Low-Rank Adaptation for Cross-Graph Transfer Learning,2025,3.464139029789952e-05,2
W4287888046,Enhancing Self-Attention with Knowledge-Assisted Attention Maps,2022,3.464139029789952e-05,2
W4376614852,Automated Subject Identification using the Universal Decimal Classification: The ANN Approach,2023,3.464139029789952e-05,2
W3160847843,Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters,2022,3.464139029789952e-05,2
W4380302120,Catch Me If You Can: Deceiving Stance Detection and Geotagging Models to Protect Privacy of Individuals on Twitter,2023,3.464139029789952e-05,2
W3175183722,Unsupervised Energy-based Adversarial Domain Adaptation for Cross-domain Text Classification,2021,3.464139029789952e-05,2
W3017131202,Coreferential Reasoning Learning for Language Representation,2020,3.464139029789952e-05,2
W4408321847,Multimodal retrieval-augmented generation for financial documents: image-centric analysis of charts and tables with large language models,2025,3.464139029789952e-05,2
W4388645436,pysentimiento: A Python Toolkit for Opinion Mining and Social NLP tasks,2023,3.464139029789952e-05,2
W4400529044,SuicidEmoji: Derived Emoji Dataset and Tasks for Suicide-Related Social Content,2024,3.464139029789952e-05,2
W4390755743,RecBERT: Semantic recommendation engine with large language model enhanced query segmentation for k-nearest neighbors ranking retrieval,2024,3.464139029789952e-05,2
W3137216496,Studying Catastrophic Forgetting in Neural Ranking Models,2021,3.464139029789952e-05,2
W4407633513,Analysis of social media language reveals the psychological interaction of three successive upheavals,2025,3.464139029789952e-05,2
W4381661201,Continual Pre-Training of Language Models for Concept Prerequisite Learning with Graph Neural Networks,2023,3.464139029789952e-05,2
W4409607349,Leveraging Large Language Models for Sentiment Analysis and Investment Strategy Development in Financial Markets,2025,3.464139029789952e-05,2
W4394730685,Lookahead Bias in Pretrained Language Models,2024,3.464139029789952e-05,2
W4372270459,Weighted Sampling for Masked Language Modeling,2023,3.464139029789952e-05,2
W4405031232,MELTing Point: Mobile Evaluation of Language Transformers,2024,3.464139029789952e-05,2
W4387211709,Text-Guided Foundation Model Adaptation for Pathological Image Classification,2023,3.464139029789952e-05,2
W4394567450,An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing: Algorithm Development and Validation Study (Preprint),2023,3.464139029789952e-05,2
W4409351910,STAF-LLM: A scalable and task-adaptive fine-tuning framework for large language models in medical domain,2025,3.464139029789952e-05,2
W4390825188,Simple knowledge graph completion model based on PU learning and prompt learning,2024,3.464139029789952e-05,2
W4388141694,An effective negative sampling approach for contrastive learning of sentence embedding,2023,3.464139029789952e-05,2
W4391992225,Application of large language models in professional fields,2023,3.464139029789952e-05,2
W4387506531,A Comprehensive Review of the Latest Advancements in Large Generative AI Models,2023,3.464139029789952e-05,2
W4389520726,SCITAB: A Challenging Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables,2023,3.464139029789952e-05,2
W4398780873,Human-annotated rationales and explainable text classification: a survey,2024,3.464139029789952e-05,2
W4393948962,Clustering-Based Joint Topic-Sentiment Modeling of Social Media Data: A Neural Networks Approach,2024,3.464139029789952e-05,2
W4406761441,An Ensemble Framework for Text Classification,2025,3.464139029789952e-05,2
W4404900783,"Multi-modal large language models in radiology: principles, applications, and potential",2024,3.464139029789952e-05,2
W3128560087,Biomedical Question Answering: A Comprehensive Review.,2021,3.464139029789952e-05,2
W4389639285,Network intrusion detection system by learning jointly from tabular and text‐based features,2023,3.464139029789952e-05,2
W4410218224,Prompting large language models with knowledge graphs for question answering involving long-tail facts,2025,3.464139029789952e-05,2
W3205226109,DiscoDVT: Generating Long Text with Discourse-Aware Discrete Variational Transformer,2021,3.464139029789952e-05,2
W4200350226,What Does a Language-And-Vision Transformer See: The Impact of Semantic Information on Visual Representations,2021,3.464139029789952e-05,2
W4406870075,OntoChat: A Framework for Conversational Ontology Engineering Using Language Models,2025,3.464139029789952e-05,2
W3190876505,Perturbing Inputs for Fragile Interpretations in Deep Natural Language Processing,2021,3.464139029789952e-05,2
W4391577874,Extracting adverse drug events from clinical Notes: A systematic review of approaches used,2024,3.464139029789952e-05,2
W4386587410,Overview of the CLEF-2023 LongEval Lab on Longitudinal Evaluation of Model Performance,2023,3.464139029789952e-05,2
W4406827500,Identifying protected health information by transformers-based deep learning approach in Chinese medical text,2025,3.464139029789952e-05,2
W3156869386,Extremely Small BERT Models from Mixed-Vocabulary Training,2021,3.464139029789952e-05,2
W4406151683,Using Computational Models to Detect Autistic Tendencies for Children from their Story Book Narratives,2025,3.464139029789952e-05,2
W4400773813,Automated Scoring of Constructed Response Items in Math Assessment Using Large Language Models,2024,3.464139029789952e-05,2
W4409485225,HyEED: embedding learning of knowledge graphs with entity description in hyperbolic space,2025,3.464139029789952e-05,2
W4409157766,LLM-Eraser: Optimizing Large Language Model Unlearning through Selective Pruning,2025,3.464139029789952e-05,2
W4391164144,Human Versus Machine Intelligence: Assessing Natural Language Generation Models Through Complex Systems Theory,2024,3.464139029789952e-05,2
W4225294552,Comparison of Transfer Learning and Traditional Machine Learning Approach for Text Classification,2022,3.464139029789952e-05,2
W4285165270,"SURREY-CTS-NLP at WASSA2022: An Experiment of Discourse and Sentiment Analysis for the Prediction of Empathy, Distress and Emotion",2022,3.464139029789952e-05,2
W4392669904,Joint Representations of Text and Knowledge Graphs for Retrieval and Evaluation,2023,3.464139029789952e-05,2
W2951073610,Understanding artificial intelligence ethics and safety.,2019,3.464139029789952e-05,2
W4400978391,Empowering Language Model with Guided Knowledge Fusion for Biomedical Document Re-ranking,2024,3.464139029789952e-05,2
W4386710827,<scp>MapIntel</scp>: A visual analytics platform for competitive intelligence,2023,3.464139029789952e-05,2
W4407336703,(Chinavis 2024) TextLens: large language models-powered visual analytics enhancing text clustering,2025,3.464139029789952e-05,2
W4385573038,A Framework for Adapting Pre-Trained Language Models to Knowledge Graph Completion,2022,3.464139029789952e-05,2
W4410368723,Dissociable frequency effects attenuate as large language model surprisal predictors improve,2025,3.464139029789952e-05,2
W4385570415,Counterfactual Active Learning for Out-of-Distribution Generalization,2023,3.464139029789952e-05,2
W4382933960,Bengali Text Classification: A New multi-class Dataset and Performance Evaluation of Machine Learning and Deep Learning Models,2023,3.464139029789952e-05,2
W3115990655,Natural Language Processing-Based Quantication of the Mental State of Psychiatric Patients,2020,3.464139029789952e-05,2
W4386898865,Does ChatGPT have semantic understanding? A problem with the statistics-of-occurrence strategy,2023,3.464139029789952e-05,2
W4409183375,Hierarchical Skip Decoding for Efficient Autoregressive Language Model,2025,3.464139029789952e-05,2
W4390532736,Enhancing Heterogeneous Knowledge Graph Completion with a Novel GAT-based Approach,2024,3.464139029789952e-05,2
W4406900436,Maritime near-miss prediction framework and model interpretation analysis method based on Transformer neural network model with multi-task classification variables,2025,3.464139029789952e-05,2
W4389519959,HiCL: Hierarchical Contrastive Learning of Unsupervised Sentence Embeddings,2023,3.464139029789952e-05,2
W4400491826,A survey on short text similarity measurement methods,2023,3.464139029789952e-05,2
W4401748419,A Proposed Model for Distinguishing Between Human-Based and ChatGPT Content in Scientific Articles,2024,3.464139029789952e-05,2
W4401076218,Transformer models in biomedicine,2024,3.464139029789952e-05,2
W4406424213,Use of Natural Language Processing to Retrospectively Identify and Improve Follow-Up of Adrenal Incidentalomas Based on Patient and Nodule Characteristics,2025,3.464139029789952e-05,2
W4384656691,Benchmarking Middle-Trained Language Models for Neural Search,2023,3.464139029789952e-05,2
W4380080770,AI-based novelty detection in crowdsourced idea spaces,2023,3.464139029789952e-05,2
W4407230512,Dynamic link prediction: Using language models and graph structures for temporal knowledge graph completion with emerging entities and relations,2025,3.464139029789952e-05,2
W4408564445,Evaluating knowledge fusion models on detecting adverse drug events in text,2025,3.464139029789952e-05,2
W4406458013,A Negative Sample Enhancement Strategy to Improve Contrastive Learning for Unsupervised Sentence Representation,2024,3.464139029789952e-05,2
W4392669760,Retrieval Augmented Generation with Rich Answer Encoding,2023,3.464139029789952e-05,2
W4396982467,Advancing Multimodal Diagnostics: Integrating Industrial Textual Data and Domain Knowledge with Large Language Models,2024,3.464139029789952e-05,2
W4399848758,Defsent+: Improving Sentence Embeddings of Language Models by Projecting Definition Sentences into a Quasi-Isotropic or Isotropic Vector Space of Unlimited Dictionary Entries,2024,3.464139029789952e-05,2
W4385570744,Direct Fact Retrieval from Knowledge Graphs without Entity Linking,2023,3.464139029789952e-05,2
W4383878309,Research on the Classification Methods of Social Bots,2023,3.464139029789952e-05,2
W4384155443,Temporal word embedding with predictive capability,2023,3.464139029789952e-05,2
W4409732945,Augmenting Dark Patterns Text Data by Leveraging Large Language Models: A Multi-agent Framework and Parameter-Efficient Fine-Tuning,2025,3.464139029789952e-05,2
W4407861121,How Creative is This Child?: Student Demographics Affect How Teachers Rate Creativity,2025,3.464139029789952e-05,2
W4396214772,Learning to Improve Out-of-Distribution Generalization via Self-adaptive Language Masking,2024,3.464139029789952e-05,2
W4317382484,Vietnamese Fact Checking based on the Knowledge Graph and Deep Learning,2022,3.464139029789952e-05,2
W4409254463,Research on Legal Question Answering System with Retrieval-Augmented Large Language Models,2025,3.464139029789952e-05,2
W4377695252,"Unveiling the inventive process from patents by extracting problems, solutions and advantages with natural language processing",2023,3.464139029789952e-05,2
W3034717099,Math-word embedding in math search and semantic extraction,2020,3.464139029789952e-05,2
W4385570815,Parameter-Efficient Fine-Tuning without Introducing New Latency,2023,3.464139029789952e-05,2
W4392012809,Generating Context-Aware Contrastive Explanations in Rule-based Systems,2024,3.464139029789952e-05,2
W4409581847,Arch-Eval benchmark for assessing chinese architectural domain knowledge in large language models,2025,3.464139029789952e-05,2
W4392909818,Sparsely Shared Lora on Whisper for Child Speech Recognition,2024,3.464139029789952e-05,2
W4388037674,Lost in translation? Not for Large Language Models: Automated divergent thinking scoring performance translates to non-English contexts,2023,3.464139029789952e-05,2
W4318460697,Multi-stage transfer learning with BERTology-based language models for question answering system in vietnamese,2023,3.464139029789952e-05,2
W4390739985,<scp>AmbiFC</scp>: Fact-Checking Ambiguous Claims with Evidence,2024,3.464139029789952e-05,2
W4409979535,Bigram Knowledge Extraction from GPT-2,2025,3.464139029789952e-05,2
W4401751312,LERCause: Deep learning approaches for causal sentence identification from nuclear safety reports,2024,3.464139029789952e-05,2
W4312659766,Answer Fast: Accelerating BERT on the Tensor Streaming Processor,2022,3.464139029789952e-05,2
W4407134183,Multimodal Convolutional Neural Networks for the Prediction of Acute Kidney Injury in the Intensive Care,2025,3.464139029789952e-05,2
W4283778430,Chemical identification and indexing in PubMed full-text articles using deep learning and heuristics,2022,3.464139029789952e-05,2
W4392849751,<scp>CySecBERT</scp> : A Domain-Adapted Language Model for the Cybersecurity Domain,2024,3.464139029789952e-05,2
W4392901911,TOCOL: improving contextual representation of pre-trained language models via token-level contrastive learning,2024,3.464139029789952e-05,2
W4406805597,Urinary Bladder Acute Inflammations and Nephritis of the Renal Pelvis: Diagnosis Using Fine-Tuned Large Language Models,2025,3.464139029789952e-05,2
W4224296706,MoEBERT: from BERT to Mixture-of-Experts via Importance-Guided Adaptation,2022,3.464139029789952e-05,2
W4408583140,MARRO: multi-headed attention for rhetorical role labeling in legal documents,2025,3.464139029789952e-05,2
W4385830460,FNCSE: contrastive learning for unsupervised sentence embedding with false negative samples,2023,3.464139029789952e-05,2
W4394811216,Supporting Text Entry in Virtual Reality with Large Language Models,2024,3.464139029789952e-05,2
W4406522012,Historical facts learning from Long-Short Terms with Language Model for Temporal Knowledge Graph Reasoning,2025,3.464139029789952e-05,2
W4401892472,Spatial–Temporal Transformer Networks for Traffic Flow Forecasting Using a Pre-Trained Language Model,2024,3.464139029789952e-05,2
W4408117980,Enhancing Domain-Specific Knowledge Graph Reasoning via Metapath-Based Large Model Prompt Learning,2025,3.464139029789952e-05,2
W4387005290,Learning Representations on Logs for AIOps,2023,3.464139029789952e-05,2
W4221161137,Type-aware Embeddings for Multi-Hop Reasoning over Knowledge Graphs,2022,3.464139029789952e-05,2
W4387267812,Knowledge-Driven Online Multimodal Automated Phenotyping System,2023,3.464139029789952e-05,2
W4400985603,PIM GPT a hybrid process in memory accelerator for autoregressive transformers,2024,3.464139029789952e-05,2
W4406550498,On the suitability of hugging face hub for empirical studies,2025,3.464139029789952e-05,2
W4398976621,InA: Inhibition Adaption on pre-trained language models,2024,3.464139029789952e-05,2
W4367297437,Enhancing Data Space Semantic Interoperability through Machine Learning: a Visionary Perspective,2023,3.464139029789952e-05,2
W4393084433,Ensemble learning with soft-prompted pretrained language models for fact checking,2024,3.464139029789952e-05,2
W4409902375,Enhancing food safety review classification with large language models and label embedding,2025,3.464139029789952e-05,2
W4409581404,Handling Causal Tasks by Large Language Models: From Discovery to Reasoning,2025,3.464139029789952e-05,2
W4407852890,Expert-level policy style measurement via knowledge distillation with large language model collaboration,2025,3.464139029789952e-05,2
W4389520282,Chain-of-Thought Reasoning in Tabular Language Models,2023,3.464139029789952e-05,2
W4396762144,"Natural Language Reasoning, A Survey",2024,3.464139029789952e-05,2
W4390745240,Legal Information Retrieval and Entailment Using Transformer-based Approaches,2024,3.464139029789952e-05,2
W4389493320,Application and evaluation of sentence embedding and clustering methods in the context of concept hierarchy construction,2023,3.464139029789952e-05,2
W4226119767,Progressive changes in descriptive discourse in First Episode Schizophrenia: a longitudinal computational semantics study,2022,3.464139029789952e-05,2
W4382449327,Aggretriever: A Simple Approach to Aggregate Textual Representations for Robust Dense Passage Retrieval,2023,3.464139029789952e-05,2
W4401907507,Answering Spatial Commonsense Questions Based on Chain-of-Thought Reasoning with Adaptive Complexity,2024,3.464139029789952e-05,2
W4408960620,Large language model for interpreting research policy using adaptive two-stage retrieval augmented fine-tuning method,2025,3.464139029789952e-05,2
W4327928482,Text-Defend: Detecting Adversarial Examples using Local Outlier Factor,2023,3.464139029789952e-05,2
W4225295188,Detecting Textual Adversarial Examples Based on Distributional Characteristics of Data Representations,2022,3.464139029789952e-05,2
W3158990693,Goldilocks: Just-Right Tuning of BERT for Technology-Assisted Review,2022,3.464139029789952e-05,2
W4388266051,Integrating legal event and context information for Chinese similar case analysis,2023,3.464139029789952e-05,2
W4399205243,TeC: A Novel Method for Text Clustering with Large Language Models Guidance and Weakly-Supervised Contrastive Learning,2024,3.464139029789952e-05,2
W4408389185,Semantic information-based attention mapping network for few-shot knowledge graph completion,2025,3.464139029789952e-05,2
W4392752389,MCFCN: Multi-scale capsule-weighted fusion classification network for lung disease classification based on chest CT scans,2024,3.464139029789952e-05,2
W3198005027,Sent2Span: Span Detection for PICO Extraction in the Biomedical Text without Span Annotations,2021,3.464139029789952e-05,2
W4221152448,“Is Whole Word Masking Always Better for Chinese BERT?”: Probing on Chinese Grammatical Error Correction,2022,3.464139029789952e-05,2
W4256179132,Modeling misretrieval and feature substitution in agreement attraction: A computational evaluation,2020,3.464139029789952e-05,2
W4409189376,Unified link prediction modeling for enhanced knowledge graph completion task,2025,3.464139029789952e-05,2
W3119308520,A GA-Based Approach to Fine-Tuning BERT for Hate Speech Detection,2020,3.464139029789952e-05,2
W4403672405,Discovering Hidden Patterns: Applying Topic Modeling in Qualitative Research,2024,3.464139029789952e-05,2
W4285160452,CoCoLM: Complex Commonsense Enhanced Language Model with Discourse Relations,2022,3.464139029789952e-05,2
W4406924410,Construction Grammar and Language Models,2025,3.464139029789952e-05,2
W3199938859,Transforming Fake News: Robust Generalisable News Classification Using Transformers,2021,3.464139029789952e-05,2
W4407487400,Predicting learning performance using NLP: an exploratory study using two semantic textual similarity methods,2025,3.464139029789952e-05,2
W4382239116,SKDBERT: Compressing BERT via Stochastic Knowledge Distillation,2023,3.464139029789952e-05,2
W4388921019,A T5-based interpretable reading comprehension model with more accurate evidence training,2023,3.464139029789952e-05,2
W4386567268,Multisource hierarchical neural network for knowledge graph embedding,2023,3.464139029789952e-05,2
W4408029885,Image processing on linguistics for biometric NLP trainers using AI-text analysis systems,2025,3.464139029789952e-05,2
W3214523360,CATE: A Contrastive Pre-trained Model for Metaphor Detection with Semi-supervised Learning,2021,3.464139029789952e-05,2
W3111538899,AIST: An Interpretable Attention-Based Deep Learning Model for Crime Prediction,2023,3.464139029789952e-05,2
W4285240641,OPI@LT-EDI-ACL2022: Detecting Signs of Depression from Social Media Text using RoBERTa Pre-trained Language Models,2022,3.464139029789952e-05,2
W4385768243,Fine-tuned vs. Prompt-tuned Supervised Representations: Which Better Account for Brain Language Representations?,2023,3.464139029789952e-05,2
W4385572433,Metaphor Detection via Explicit Basic Meanings Modelling,2023,3.464139029789952e-05,2
W4386569329,Reliability and Performance of the Online Literature Database CAMbase after Changing from a Semantic Search to a Score Ranking Algorithm,2023,3.464139029789952e-05,2
W4221150629,Hierarchical Interpretation of Neural Text Classification,2022,3.464139029789952e-05,2
W4385155440,UMLS-KGI-BERT: Data-Centric Knowledge Integration in Transformers for Biomedical Entity Recognition,2023,3.464139029789952e-05,2
W4403173949,Knowledge Augmented Intelligence Using Large Language Models for Advanced Data Analytics,2024,3.464139029789952e-05,2
W4406751855,Evaluating the effectiveness of XAI techniques for encoder-based language models,2025,3.464139029789952e-05,2
W4384930037,Lexicon-enhanced Pre-trained Language Models for Chinese Ethics-related Tasks,2023,3.464139029789952e-05,2
W4409955947,BERT-Prompt Based Equipment to Support Domain Sentence Vector Training,2025,3.464139029789952e-05,2
W4396655051,Using Large Language Models to Detect Self-Regulated Learning in Think-Aloud Protocols,2024,3.464139029789952e-05,2
W4396665924,Automatically Correcting Large Language Models: <i>Surveying the Landscape of Diverse Automated Correction Strategies</i>,2024,3.464139029789952e-05,2
W4392435065,PROSAIL-Net: A transfer learning-based dual stream neural network to estimate leaf chlorophyll and leaf angle of crops from UAV hyperspectral images,2024,3.464139029789952e-05,2
W4408231555,A unified acoustic-to-speech-to-language embedding space captures the neural basis of natural language processing in everyday conversations,2025,3.464139029789952e-05,2
W4327644602,Towards Effective Paraphrasing for Information Disguise,2023,3.464139029789952e-05,2
W4409918358,Including Co-Relation via Concatenate Operator for Static and Temporal Knowledge Graph Embedding,2025,3.464139029789952e-05,2
W4229072483,Knowledge graph embedding for data mining vs. knowledge graph embedding for link prediction – two sides of the same coin?,2022,3.464139029789952e-05,2
W4394815468,A dilated convolution‐based method with time series fine tuning for data‐driven crack length estimation,2024,3.464139029789952e-05,2
W4392484147,Large language model augmented exercise retrieval for personalized language learning,2024,3.464139029789952e-05,2
W4400231005,BETA: Binarized Energy-Efficient Transformer Accelerator at the Edge,2024,3.464139029789952e-05,2
W4385301120,Chatbot Integration for Metaverse - A University Platform Prototype,2023,3.464139029789952e-05,2
W4409892328,Assessing and Understanding Creativity in Large Language Models,2025,3.464139029789952e-05,2
W4392647583,Predictive models for flexible pavement fatigue cracking based on machine learning,2024,3.464139029789952e-05,2
W4313555442,Transformer-Based Named Entity Recognition on Drone Flight Logs to Support Forensic Investigation,2023,3.464139029789952e-05,2
W4382240075,Entity-Agnostic Representation Learning for Parameter-Efficient Knowledge Graph Embedding,2023,3.464139029789952e-05,2
W4398182257,Towards Controllable Generative Design: A Conceptual Design Generation Approach Leveraging the FBS Ontology and Large Language Models,2024,3.464139029789952e-05,2
W4385573562,Learning to Infer from Unlabeled Data: A Semi-supervised Learning Approach for Robust Natural Language Inference,2022,3.464139029789952e-05,2
W4406820596,Semantic Analysis of test items through Large Language Model embeddings predicts a-priori factorial structure of personality tests,2025,3.464139029789952e-05,2
W4406172063,Adaptive Prompt Learning with Distilled Connective Knowledge for Implicit Discourse Relation Recognition,2025,3.464139029789952e-05,2
W4409186139,Annotating scientific uncertainty: A comprehensive model using linguistic patterns and comparison with existing approaches,2025,3.464139029789952e-05,2
W4385572468,EPIC: Multi-Perspective Annotation of a Corpus of Irony,2023,3.464139029789952e-05,2
W4408735404,Estimating the plausibility of commonsense statements by novelly fusing large language model and graph neural network,2025,3.464139029789952e-05,2
W4407953233,Towards Reliable Latent Knowledge Estimation in LLMs: Zero-Prompt Many-Shot Based Factual Knowledge Extraction,2025,3.464139029789952e-05,2
W4385567351,Is anisotropy really the cause of BERT embeddings not being semantic?,2022,3.464139029789952e-05,2
W4293212040,Automatic depression score estimation with word embedding models,2022,3.464139029789952e-05,2
W4225496162,Toward Practical Usage of the Attention Mechanism as a Tool for Interpretability,2022,3.464139029789952e-05,2
W4285134706,MoEfication: Transformer Feed-forward Layers are Mixtures of Experts,2022,3.464139029789952e-05,2
W4408610570,Subset selection for domain adaptive pre-training of language model,2025,3.464139029789952e-05,2
W4405107143,Cross-language Retrieval,2024,3.464139029789952e-05,2
W4393159880,Knowledge Graph Error Detection with Contrastive Confidence Adaption,2024,3.464139029789952e-05,2
W3151620310,PGT: Pseudo Relevance Feedback Using a Graph-Based Transformer,2021,3.464139029789952e-05,2
W4403811090,Automatic categorization of medical documents in Afaan Oromo using ensemble machine learning techniques,2024,3.464139029789952e-05,2
W4385567092,Towards Intention Understanding in Suicidal Risk Assessment with Natural Language Processing,2022,3.464139029789952e-05,2
W4385256174,An Inferential Commonsense-Driven Framework for Predicting Political Bias in News Headlines,2023,3.464139029789952e-05,2
W4392154900,Interpretability of deep learning models in analysis of Spanish financial text,2024,3.464139029789952e-05,2
W4399879615,Enhancing Natural Language Query to SQL Query Generation Through Classification-Based Table Selection,2024,3.464139029789952e-05,2
W4317611844,Automated Creation of an Intent Model for Conversational Agents,2023,3.464139029789952e-05,2
W4385571890,What does a Text Classifier Learn about Morality? An Explainable Method for Cross-Domain Comparison of Moral Rhetoric,2023,3.464139029789952e-05,2
W4388471935,Multi-hop community question answering based on multi-aspect heterogeneous graph,2023,3.464139029789952e-05,2
W4390098547,Prompting or Fine-tuning? A Comparative Study of Large Language Models for Taxonomy Construction,2023,3.464139029789952e-05,2
W4407392849,"Grammar Induction from Visual, Speech and Text",2025,3.464139029789952e-05,2
W4385573055,Robustness of Demonstration-based Learning Under Limited Data Scenario,2022,3.464139029789952e-05,2
W4395098217,Two-Stage Knowledge Graph Completion Based on Semantic Features and High-Order Structural Features,2024,3.464139029789952e-05,2
W4405962550,An Automated Hybrid Exam Evaluation Framework for Textual Courses Using AI,2024,3.464139029789952e-05,2
W3110875274,HAPI,2020,3.464139029789952e-05,2
W4385202102,Moving thoughts: emotion concepts from the perspective of context dependent embodied simulation,2023,3.464139029789952e-05,2
W4406483874,Sentence-graph-level knowledge injection with multi-task learning,2025,3.464139029789952e-05,2
W4375869145,Discriminative Speaker Representation Via Contrastive Learning with Class-Aware Attention in Angular Space,2023,3.464139029789952e-05,2
W4372259936,Exploiting Prompt Learning with Pre-Trained Language Models for Alzheimer’s Disease Detection,2023,3.464139029789952e-05,2
W4402646312,Enhancing Small Language Models via ChatGPT and Dataset Augmentation,2024,3.464139029789952e-05,2
W4318559756,Improving biomedical named entity recognition through transfer learning and asymmetric tri-training,2023,3.464139029789952e-05,2
W4410065220,Crisis impact extraction language model using transformer-based synergy via transfer learning,2025,3.464139029789952e-05,2
W4385573369,CORE: A Retrieve-then-Edit Framework for Counterfactual Data Generation,2022,3.464139029789952e-05,2
W4385987638,Adapting an ASR Foundation Model for Spoken Language Assessment,2023,3.464139029789952e-05,2
W4394910399,Understanding the Role of Self-Attention in a Transformer Model for the Discrimination of SCD From MCI Using Resting-State EEG,2024,3.464139029789952e-05,2
W4401379766,Knowledge-tuning Large Language Models with Structured Medical Knowledge Bases for Trustworthy Response Generation in Chinese,2024,3.464139029789952e-05,2
W4385572960,Back to the Future: Bidirectional Information Decoupling Network for Multi-turn Dialogue Modeling,2022,3.464139029789952e-05,2
W4403770996,A Study of the State of the Art Approaches and Datasets for Multilingual Natural Language Inference,2024,3.464139029789952e-05,2
W3142516437,Extending Multi-Sense Word Embedding to Phrases and Sentences for Unsupervised Semantic Applications,2021,3.464139029789952e-05,2
W4385570673,Neural Architecture Search for Parameter-Efficient Fine-tuning of Large Pre-trained Language Models,2023,3.464139029789952e-05,2
W4377969288,ELICE: Embedding Language through Informative Contrastive-Encoder,2023,3.464139029789952e-05,2
W4394994622,High-Order Neighbors Aware Representation Learning for Knowledge Graph Completion,2024,3.464139029789952e-05,2
W4385562585,PAT: Geometry-Aware Hard-Label Black-Box Adversarial Attacks on Text,2023,3.464139029789952e-05,2
W4327644088,Query Performance Prediction for Neural IR: Are We There Yet?,2023,3.464139029789952e-05,2
W4401411847,Natural Language Processing Accurately Differentiates Cancer Symptom Information in Electronic Health Record Narratives,2024,3.464139029789952e-05,2
W4401940777,Integrating deep learning architectures for enhanced biomedical relation extraction: a pipeline approach,2024,3.464139029789952e-05,2
W4385574097,Trial2Vec: Zero-Shot Clinical Trial Document Similarity Search using Self-Supervision,2022,3.464139029789952e-05,2
W4361199350,Technological forecasting based on estimation of word embedding matrix using LSTM networks,2023,3.464139029789952e-05,2
W4321458671,Improving text mining in plant health domain with GAN and/or pre-trained language model,2023,3.464139029789952e-05,2
W4408854165,LLM4Jobs: Unsupervised occupation extraction and standardization leveraging Large Language Models,2025,3.464139029789952e-05,2
W4362723303,A BERT-based deontic logic learner,2023,3.464139029789952e-05,2
W4406942015,InRanker: Distilled Rankers for Zero-Shot Information Retrieval,2025,3.464139029789952e-05,2
W4405695223,A comprehensive survey of large language models and multimodal large language models in medicine,2024,3.464139029789952e-05,2
W4368373721,Pairwise contrastive learning for sentence semantic equivalence identification with limited supervision,2023,3.464139029789952e-05,2
W4401907124,Complex Knowledge Base Question Answering via Structure and Content Dual-Driven Method,2024,3.464139029789952e-05,2
W4392794210,ProMvSD: Towards unsupervised knowledge graph anomaly detection via prior knowledge integration and multi-view semantic-driven estimation,2024,3.464139029789952e-05,2
W3017541546,A Simple and Effective Model for Answering Multi-span Questions,2019,3.464139029789952e-05,2
W4210900105,Fine-Grained Entity Typing with a Type Taxonomy: a Systematic Review,2022,3.464139029789952e-05,2
W4322775994,Around the GLOBE: Numerical Aggregation Question-answering on Heterogeneous Genealogical Knowledge Graphs with Deep Neural Networks,2023,3.464139029789952e-05,2
W4389523827,AdaSent: Efficient Domain-Adapted Sentence Embeddings for Few-Shot Classification,2023,3.464139029789952e-05,2
W4284705591,On the Role of Relevance in Natural Language Processing Tasks,2022,3.464139029789952e-05,2
W4409527751,Stimulus dependencies—rather than next-word prediction—can explain pre-onset brain encoding during natural listening,2025,3.464139029789952e-05,2
W4389520219,impact of sample selection on in-context learning for entity extraction from scientific writing,2023,3.464139029789952e-05,2
W4366824677,Joint modeling for early predictions of Li-ion battery cycle life and degradation trajectory,2023,3.464139029789952e-05,2
W4388829218,Bringing order into the realm of Transformer-based language models for artificial intelligence and law,2023,3.464139029789952e-05,2
W4404440409,Decoding text from electroencephalography signals: A novel Hierarchical Gated Recurrent Unit with Masked Residual Attention Mechanism,2024,3.464139029789952e-05,2
W4406299883,Digital forgetting in large language models: a survey of unlearning methods,2025,3.464139029789952e-05,2
W4400065641,A few-shot word-structure embedded model for bridge inspection reports learning,2024,3.464139029789952e-05,2
W4396985403,Sample Size Considerations for Fine-Tuning Large Language Models for Named Entity Recognition Tasks: Methodological Study,2024,3.464139029789952e-05,2
W4394718458,AI and narrative embeddings detect PTSD following childbirth via birth stories,2024,3.464139029789952e-05,2
W4410221225,Contrastive zero-shot relational learning for knowledge graph completion,2025,3.464139029789952e-05,2
W4409975498,Weakly supervised text classification on free-text comments in patient-reported outcome measures,2025,3.464139029789952e-05,2
W4409648970,Detecting sarcasm in user-generated content integrating transformers and gated graph neural networks,2025,3.464139029789952e-05,2
W4385453176,ArEmotive Bridging the Gap: Automatic Ontology Augmentation Using Zero-Shot Classification for Fine-Grained Sentiment Analysis of Arabic Text,2023,3.464139029789952e-05,2
W3209223032,Large-Scale News Classification using BERT Language Model: Spark NLP Approach,2021,3.464139029789952e-05,2
W4388676590,The Combination of Contextualized Topic Model and MPNet for User Feedback Topic Modeling,2023,3.464139029789952e-05,2
W4407611747,Optimizing Self-training Sample Selection for Euphemism Detection in Special Scenarios,2025,3.464139029789952e-05,2
W4408743297,Positionally Restricted Masked Knowledge Graph Completion via Multi-Head Mutual Attention,2025,3.464139029789952e-05,2
W4388333192,Does Human Collaboration Enhance the Accuracy of Identifying LLM-Generated Deepfake Texts?,2023,3.464139029789952e-05,2
W4409663614,Natural Language Processing (NLP)- and Machine Learning (ML)-Enabled Operating Room Optimization: A Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) Systematic Review Anchored in Project Planning Theory,2025,3.464139029789952e-05,2
W4387171611,Preserving Semantics in Textual Adversarial Attacks,2023,3.464139029789952e-05,2
W4408417706,A definition and taxonomy of digital twins: case studies with machine learning and scientific applications,2025,3.464139029789952e-05,2
W4285305556,Learning to Generate Programs for Table Fact Verification via Structure-Aware Semantic Parsing,2022,3.464139029789952e-05,2
W4406207370,A Primer on Large Language Models and their Limitations,2025,3.464139029789952e-05,2
W4406705870,Zero-shot reranking with dense encoder models for news background linking,2025,3.464139029789952e-05,2
W3016364508,Advantages and Constraints of a Hybrid Model K-12 E-Learning Assistant Chatbot,2020,3.464139029789952e-05,2
W4409852380,Multi-agent Chatbot for Efficient Interaction with Blockchain APIs,2025,3.464139029789952e-05,2
W4313003468,Automated Detection of Typed Links in Issue Trackers,2022,3.464139029789952e-05,2
W4328053377,Development and external validation of automated ICD-10 coding from discharge summaries using deep learning approaches,2023,3.464139029789952e-05,2
W4391676924,Enhancing Continuous Auditing with Large Language Models: A Framework for Cross-Verification Using Exogenous Textual Data,2024,3.464139029789952e-05,2
W4407096805,Generalist Large Language Models in a Specialized World: Evidence from the Italian National Medical Education Pathway,2025,3.464139029789952e-05,2
W4285294253,Shallow Neural Network and Ontology-Based Novel Semantic Document Indexing for Information Retrieval,2022,3.464139029789952e-05,2
W4385572429,"Don’t Retrain, Just Rewrite: Countering Adversarial Perturbations by Rewriting Text",2023,3.464139029789952e-05,2
W4410495528,More than meets the eye: Feature concerns and suggestions in mobile XR app reviews,2025,3.464139029789952e-05,2
W4385570624,Content Moderation for Evolving Policies using Binary Question Answering,2023,3.464139029789952e-05,2
W4397013501,Identification of patients’ smoking status using an explainable AI approach: a Danish electronic health records case study,2024,3.464139029789952e-05,2
W3099577420,RecoBERT: A Catalog Language Model for Text-Based Recommendations,2020,3.464139029789952e-05,2
W4390264399,StackER: a novel SMILES-based stacked approach for the accelerated and efficient discovery of ERα and ERβ antagonists,2023,3.464139029789952e-05,2
W4389166691,GPT4AIGChip: Towards Next-Generation AI Accelerator Design Automation via Large Language Models,2023,3.464139029789952e-05,2
W4407958102,Identifying Useful Answers on Community-Based Question Answering Platforms: A Novel Unified Answer Comment-Based Approach,2025,3.464139029789952e-05,2
