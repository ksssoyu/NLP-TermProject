# Dynamic Analysis of Scientific Literature (Adaptive Parameters, Extended Search)

# Analysis for Window: 2012-2014
**Stats:** Papers: 71, Edges: 207
**Best Found DBCV Score:** 0.7712
**Optimal Parameters:** `n_neighbors`: 25, `min_cluster_size`: 15, `min_samples`: 5, `epsilon`: 0.0

### Dominant Topics

- **Topic (ID: 1, Size: 36, Confidence: 0.8331):** word, representations, language, neural, networks, translation, modeling, distributed, linguistic, embeddings, space, based, models, machine, 2012
- **Topic (ID: 0, Size: 18, Confidence: 0.9944):** neural, networks, recurrent, translation, sequence, models, machine, continuous, recognition, learning, deep, speech, statistical, space, modeling

### Top 20 Papers by Citation Count

- (Citation Count: 149584.0000) Adam: A Method for Stochastic Optimization
- (Citation Count: 119504.0000) ImageNet classification with deep convolutional neural networks
- (Citation Count: 39709.0000) Dropout: a simple way to prevent neural networks from overfitting
- (Citation Count: 33467.0000) Distributed Representations of Words and Phrases and their Compositionality
- (Citation Count: 32016.0000) GloVe: Global Vectors for Word Representation
- (Citation Count: 31416.0000) Efficient Estimation of Word Representations in Vector Space
- (Citation Count: 27210.0000) Neural Machine Translation by Jointly Learning to Align and Translate
- (Citation Count: 23254.0000) Learning Phrase Representations using RNN Encoder–Decoder for Statistical M...
- (Citation Count: 20484.0000) Sequence to Sequence Learning with Neural Networks
- (Citation Count: 12647.0000) Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modelin...
- (Citation Count: 9231.0000) Distributed Representations of Sentences and Documents
- (Citation Count: 8448.0000) Recursive Deep Models for Semantic Compositionality Over a Sentiment Treeba...
- (Citation Count: 8313.0000) How transferable are features in deep neural networks?
- (Citation Count: 7335.0000) The Stanford CoreNLP Natural Language Processing Toolkit
- (Citation Count: 6760.0000) On the Properties of Neural Machine Translation: Encoder–Decoder Approaches
- (Citation Count: 6620.0000) ADADELTA: An Adaptive Learning Rate Method
- (Citation Count: 6177.0000) DeepFace: Closing the Gap to Human-Level Performance in Face Verification
- (Citation Count: 6012.0000) Show and tell: A neural image caption generator
- (Citation Count: 5322.0000) On the difficulty of training recurrent neural networks
- (Citation Count: 4026.0000) Generating Sequences With Recurrent Neural Networks

### Top 20 Papers by PageRank

- (PageRank: 0.0556) Statistical Language Models Based on Neural Networks
- (PageRank: 0.0464) ImageNet classification with deep convolutional neural networks
- (PageRank: 0.0445) Efficient Estimation of Word Representations in Vector Space
- (PageRank: 0.0410) Improving Word Representations via Global Context and Multiple Word Prototy...
- (PageRank: 0.0327) Linguistic Regularities in Continuous Space Word Representations
- (PageRank: 0.0248) Large Scale Distributed Deep Networks
- (PageRank: 0.0215) Bilingual Word Embeddings for Phrase-Based Machine Translation
- (PageRank: 0.0210) Continuous Space Translation Models for Phrase-Based Statistical Machine Tr...
- (PageRank: 0.0209) Continuous Space Translation Models with Neural Networks
- (PageRank: 0.0206) A fast and simple algorithm for training neural probabilistic language mode...
- (PageRank: 0.0197) Distributed Representations of Words and Phrases and their Compositionality
- (PageRank: 0.0192) Recursive Deep Models for Semantic Compositionality Over a Sentiment Treeba...
- (PageRank: 0.0179) Generating Sequences With Recurrent Neural Networks
- (PageRank: 0.0179) Theano: new features and speed improvements
- (PageRank: 0.0176) Learning Phrase Representations using RNN Encoder–Decoder for Statistical M...
- (PageRank: 0.0175) On the difficulty of training recurrent neural networks
- (PageRank: 0.0170) Maxout Networks
- (PageRank: 0.0165) Sequence to Sequence Learning with Neural Networks
- (PageRank: 0.0159) Recurrent Continuous Translation Models
- (PageRank: 0.0151) CoNLL-2012 Shared Task: Modeling Multilingual Unrestricted Coreference in O...

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.1311) Efficient Estimation of Word Representations in Vector Space
- (HITS Authority: 0.0882) Linguistic Regularities in Continuous Space Word Representations
- (HITS Authority: 0.0814) Distributed Representations of Words and Phrases and their Compositionality
- (HITS Authority: 0.0498) Learning Phrase Representations using RNN Encoder–Decoder for Statistical M...
- (HITS Authority: 0.0479) Sequence to Sequence Learning with Neural Networks
- (HITS Authority: 0.0450) Recurrent Continuous Translation Models
- (HITS Authority: 0.0446) Generating Sequences With Recurrent Neural Networks
- (HITS Authority: 0.0364) Bilingual Word Embeddings for Phrase-Based Machine Translation
- (HITS Authority: 0.0342) On the difficulty of training recurrent neural networks
- (HITS Authority: 0.0300) Statistical Language Models Based on Neural Networks
- (HITS Authority: 0.0248) On the Properties of Neural Machine Translation: Encoder–Decoder Approaches
- (HITS Authority: 0.0246) Improving Word Representations via Global Context and Multiple Word Prototy...
- (HITS Authority: 0.0245) Neural Machine Translation by Jointly Learning to Align and Translate
- (HITS Authority: 0.0209) Deep Neural Networks for Acoustic Modeling in Speech Recognition
- (HITS Authority: 0.0193) Audio Chord Recognition with Recurrent Neural Networks
- (HITS Authority: 0.0190) Maxout Networks
- (HITS Authority: 0.0181) Multilingual Distributed Representations without Word Alignment
- (HITS Authority: 0.0154) Sequence Transduction with Recurrent Neural Networks
- (HITS Authority: 0.0150) Combining Heterogeneous Models for Measuring Relational Similarity
- (HITS Authority: 0.0146) Continuous Space Translation Models for Phrase-Based Statistical Machine Tr...


# Analysis for Window: 2013-2015
**Stats:** Papers: 71, Edges: 240
**Best Found DBCV Score:** 0.2525
**Optimal Parameters:** `n_neighbors`: 10, `min_cluster_size`: 15, `min_samples`: 5, `epsilon`: 0.5

### Dominant Topics

- **Topic (ID: 0, Size: 25, Confidence: 1.0000):** word, neural, representations, end, language, translation, vectors, space, machine, networks, distributed, linguistic, regularities, embeddings, words
- **Topic (ID: 1, Size: 20, Confidence: 1.0000):** neural, language, word, question, models, networks, translation, learning, semantic, answering, recurrent, representations, bilingual, character, parsing

### Top 20 Papers by Citation Count

- (Citation Count: 192834.0000) Deep Residual Learning for Image Recognition
- (Citation Count: 149584.0000) Adam: A Method for Stochastic Optimization
- (Citation Count: 39709.0000) Dropout: a simple way to prevent neural networks from overfitting
- (Citation Count: 33467.0000) Distributed Representations of Words and Phrases and their Compositionality
- (Citation Count: 32016.0000) GloVe: Global Vectors for Word Representation
- (Citation Count: 31416.0000) Efficient Estimation of Word Representations in Vector Space
- (Citation Count: 27242.0000) Rethinking the Inception Architecture for Computer Vision
- (Citation Count: 27210.0000) Neural Machine Translation by Jointly Learning to Align and Translate
- (Citation Count: 23254.0000) Learning Phrase Representations using RNN Encoder–Decoder for Statistical M...
- (Citation Count: 20484.0000) Sequence to Sequence Learning with Neural Networks
- (Citation Count: 19498.0000) Distilling the Knowledge in a Neural Network
- (Citation Count: 12647.0000) Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modelin...
- (Citation Count: 9231.0000) Distributed Representations of Sentences and Documents
- (Citation Count: 8448.0000) Recursive Deep Models for Semantic Compositionality Over a Sentiment Treeba...
- (Citation Count: 8313.0000) How transferable are features in deep neural networks?
- (Citation Count: 7948.0000) Effective Approaches to Attention-based Neural Machine Translation
- (Citation Count: 7701.0000) Neural Machine Translation of Rare Words with Subword Units
- (Citation Count: 7335.0000) The Stanford CoreNLP Natural Language Processing Toolkit
- (Citation Count: 6760.0000) On the Properties of Neural Machine Translation: Encoder–Decoder Approaches
- (Citation Count: 6177.0000) DeepFace: Closing the Gap to Human-Level Performance in Face Verification

### Top 20 Papers by PageRank

- (PageRank: 0.0881) Efficient Estimation of Word Representations in Vector Space
- (PageRank: 0.0824) Linguistic Regularities in Continuous Space Word Representations
- (PageRank: 0.0364) Learning Phrase Representations using RNN Encoder–Decoder for Statistical M...
- (PageRank: 0.0361) Generating Sequences With Recurrent Neural Networks
- (PageRank: 0.0353) Distributed Representations of Words and Phrases and their Compositionality
- (PageRank: 0.0352) Maxout Networks
- (PageRank: 0.0309) Sequence to Sequence Learning with Neural Networks
- (PageRank: 0.0287) Recurrent Continuous Translation Models
- (PageRank: 0.0276) Combining Heterogeneous Models for Measuring Relational Similarity
- (PageRank: 0.0264) Neural Machine Translation by Jointly Learning to Align and Translate
- (PageRank: 0.0252) Bilingual Word Embeddings for Phrase-Based Machine Translation
- (PageRank: 0.0237) Recursive Deep Models for Semantic Compositionality Over a Sentiment Treeba...
- (PageRank: 0.0187) Learning Semantic Representations for the Phrase Translation Model
- (PageRank: 0.0162) Joint Language and Translation Modeling with Recurrent Neural Networks
- (PageRank: 0.0146) Dropout: a simple way to prevent neural networks from overfitting
- (PageRank: 0.0145) On the Properties of Neural Machine Translation: Encoder–Decoder Approaches
- (PageRank: 0.0127) Exact solutions to the nonlinear dynamics of learning in deep linear neural...
- (PageRank: 0.0120) Skip-Thought Vectors
- (PageRank: 0.0119) Multilingual Distributed Representations without Word Alignment
- (PageRank: 0.0117) Show and tell: A neural image caption generator

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.1238) Learning Phrase Representations using RNN Encoder–Decoder for Statistical M...
- (HITS Authority: 0.1139) Sequence to Sequence Learning with Neural Networks
- (HITS Authority: 0.0821) Recurrent Continuous Translation Models
- (HITS Authority: 0.0770) Neural Machine Translation by Jointly Learning to Align and Translate
- (HITS Authority: 0.0720) Efficient Estimation of Word Representations in Vector Space
- (HITS Authority: 0.0481) Generating Sequences With Recurrent Neural Networks
- (HITS Authority: 0.0442) On the Properties of Neural Machine Translation: Encoder–Decoder Approaches
- (HITS Authority: 0.0327) Distributed Representations of Words and Phrases and their Compositionality
- (HITS Authority: 0.0324) Linguistic Regularities in Continuous Space Word Representations
- (HITS Authority: 0.0261) Audio Chord Recognition with Recurrent Neural Networks
- (HITS Authority: 0.0256) Recursive Deep Models for Semantic Compositionality Over a Sentiment Treeba...
- (HITS Authority: 0.0243) Skip-Thought Vectors
- (HITS Authority: 0.0230) Show and tell: A neural image caption generator
- (HITS Authority: 0.0215) Multilingual Distributed Representations without Word Alignment
- (HITS Authority: 0.0195) Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modelin...
- (HITS Authority: 0.0182) GloVe: Global Vectors for Word Representation
- (HITS Authority: 0.0159) A Neural Network for Factoid Question Answering over Paragraphs
- (HITS Authority: 0.0157) Grammar as a Foreign Language
- (HITS Authority: 0.0154) Adam: A Method for Stochastic Optimization
- (HITS Authority: 0.0141) Fast and Accurate Shift-Reduce Constituent Parsing


# Analysis for Window: 2014-2016
**Stats:** Papers: 80, Edges: 303
**Best Found DBCV Score:** 0.6264
**Optimal Parameters:** `n_neighbors`: 25, `min_cluster_size`: 15, `min_samples`: 5, `epsilon`: 0.0

### Dominant Topics

- **Topic (ID: 1, Size: 49, Confidence: 0.9950):** learning, neural, language, word, machine, end, translation, networks, models, lstm, representations, vectors, network, sentences, sequence
- **Topic (ID: 0, Size: 20, Confidence: 1.0000):** neural, networks, sequence, deep, learning, machine, translation, recurrent, time, empirical, network, dropout, training, encoder, decoder


### Top 20 Papers by Citation Count

- (Citation Count: 192834.0000) Deep Residual Learning for Image Recognition
- (Citation Count: 149584.0000) Adam: A Method for Stochastic Optimization
- (Citation Count: 39709.0000) Dropout: a simple way to prevent neural networks from overfitting
- (Citation Count: 32016.0000) GloVe: Global Vectors for Word Representation
- (Citation Count: 27242.0000) Rethinking the Inception Architecture for Computer Vision
- (Citation Count: 27210.0000) Neural Machine Translation by Jointly Learning to Align and Translate
- (Citation Count: 23254.0000) Learning Phrase Representations using RNN Encoder–Decoder for Statistical M...
- (Citation Count: 20484.0000) Sequence to Sequence Learning with Neural Networks
- (Citation Count: 19498.0000) Distilling the Knowledge in a Neural Network
- (Citation Count: 14474.0000) Xception: Deep Learning with Depthwise Separable Convolutions
- (Citation Count: 12647.0000) Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modelin...
- (Citation Count: 10421.0000) Layer Normalization
- (Citation Count: 9944.0000) Enriching Word Vectors with Subword Information
- (Citation Count: 9231.0000) Distributed Representations of Sentences and Documents
- (Citation Count: 8313.0000) How transferable are features in deep neural networks?
- (Citation Count: 8081.0000) SQuAD: 100,000+ Questions for Machine Comprehension of Text
- (Citation Count: 7948.0000) Effective Approaches to Attention-based Neural Machine Translation
- (Citation Count: 7701.0000) Neural Machine Translation of Rare Words with Subword Units
- (Citation Count: 7335.0000) The Stanford CoreNLP Natural Language Processing Toolkit
- (Citation Count: 7295.0000) Matching Networks for One Shot Learning

### Top 20 Papers by PageRank

- (PageRank: 0.0992) Learning Phrase Representations using RNN Encoder–Decoder for Statistical M...
- (PageRank: 0.0742) Sequence to Sequence Learning with Neural Networks
- (PageRank: 0.0683) An Autoencoder Approach to Learning Bilingual Word Representations
- (PageRank: 0.0549) Neural Machine Translation by Jointly Learning to Align and Translate
- (PageRank: 0.0389) Fast and Robust Neural Network Joint Models for Statistical Machine Transla...
- (PageRank: 0.0309) On the Properties of Neural Machine Translation: Encoder–Decoder Approaches
- (PageRank: 0.0295) Don’t count, predict! A systematic comparison of context-counting vs. conte...
- (PageRank: 0.0241) Dropout: a simple way to prevent neural networks from overfitting
- (PageRank: 0.0230) Distributed Representations of Sentences and Documents
- (PageRank: 0.0224) Adam: A Method for Stochastic Optimization
- (PageRank: 0.0218) GloVe: Global Vectors for Word Representation
- (PageRank: 0.0186) Overcoming the Curse of Sentence Length for Neural Machine Translation usin...
- (PageRank: 0.0170) Skip-Thought Vectors
- (PageRank: 0.0162) Training Very Deep Networks
- (PageRank: 0.0157) Finding Function in Form: Compositional Character Models for Open Vocabular...
- (PageRank: 0.0143) Linguistic Regularities in Sparse and Explicit Word Representations
- (PageRank: 0.0142) Grammar as a Foreign Language
- (PageRank: 0.0126) Show and tell: A neural image caption generator
- (PageRank: 0.0120) Character-Aware Neural Language Models
- (PageRank: 0.0112) Multi-task Sequence to Sequence Learning

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.1672) Sequence to Sequence Learning with Neural Networks
- (HITS Authority: 0.1540) Neural Machine Translation by Jointly Learning to Align and Translate
- (HITS Authority: 0.1421) Learning Phrase Representations using RNN Encoder–Decoder for Statistical M...
- (HITS Authority: 0.0518) Adam: A Method for Stochastic Optimization
- (HITS Authority: 0.0375) On the Properties of Neural Machine Translation: Encoder–Decoder Approaches
- (HITS Authority: 0.0373) Skip-Thought Vectors
- (HITS Authority: 0.0341) Grammar as a Foreign Language
- (HITS Authority: 0.0298) Effective Approaches to Attention-based Neural Machine Translation
- (HITS Authority: 0.0285) Deep Residual Learning for Image Recognition
- (HITS Authority: 0.0241) Show and tell: A neural image caption generator
- (HITS Authority: 0.0232) GloVe: Global Vectors for Word Representation
- (HITS Authority: 0.0196) Edinburgh’s Phrase-based Machine Translation Systems for WMT-14
- (HITS Authority: 0.0191) Google's Neural Machine Translation System: Bridging the Gap between Human ...
- (HITS Authority: 0.0169) Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modelin...
- (HITS Authority: 0.0167) Neural GPUs Learn Algorithms
- (HITS Authority: 0.0151) Deep Recurrent Models with Fast-Forward Connections for Neural Machine Tran...
- (HITS Authority: 0.0132) Dropout: a simple way to prevent neural networks from overfitting
- (HITS Authority: 0.0120) A Neural Network for Factoid Question Answering over Paragraphs
- (HITS Authority: 0.0117) Distributed Representations of Sentences and Documents
- (HITS Authority: 0.0114) A large annotated corpus for learning natural language inference


# Analysis for Window: 2015-2017
**Stats:** Papers: 94, Edges: 319
**Best Found DBCV Score:** 0.7537
**Optimal Parameters:** `n_neighbors`: 10, `min_cluster_size`: 15, `min_samples`: 5, `epsilon`: 0.0

### Dominant Topics

- **Topic (ID: 1, Size: 36, Confidence: 0.7669):** learning, neural, networks, end, machine, deep, attention, translation, language, model, sequence, memory, natural, shot, structured
- **Topic (ID: 2, Size: 22, Confidence: 0.8845):** neural, models, word, learning, language, disambiguation, sense, evaluation, character, coreference, embedding, bidirectional, vectors, sequence, end
- **Topic (ID: 0, Size: 16, Confidence: 0.9980):** comprehension, reading, machine, language, natural, inference, question, large, networks, learning, attention, answering, scale, dataset, visual

### Top 20 Papers by Citation Count

- (Citation Count: 192834.0000) Deep Residual Learning for Image Recognition
- (Citation Count: 130102.0000) Attention is All you Need
- (Citation Count: 27242.0000) Rethinking the Inception Architecture for Computer Vision
- (Citation Count: 22656.0000) Decoupled Weight Decay Regularization
- (Citation Count: 19498.0000) Distilling the Knowledge in a Neural Network
- (Citation Count: 14474.0000) Xception: Deep Learning with Depthwise Separable Convolutions
- (Citation Count: 11810.0000) Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks
- (Citation Count: 10421.0000) Layer Normalization
- (Citation Count: 9944.0000) Enriching Word Vectors with Subword Information
- (Citation Count: 8081.0000) SQuAD: 100,000+ Questions for Machine Comprehension of Text
- (Citation Count: 7948.0000) Effective Approaches to Attention-based Neural Machine Translation
- (Citation Count: 7701.0000) Neural Machine Translation of Rare Words with Subword Units
- (Citation Count: 7295.0000) Matching Networks for One Shot Learning
- (Citation Count: 6772.0000) Google's Neural Machine Translation System: Bridging the Gap between Human ...
- (Citation Count: 5436.0000) VQA: Visual Question Answering
- (Citation Count: 4452.0000) A Broad-Coverage Challenge Corpus for Sentence Understanding through Infere...
- (Citation Count: 4264.0000) A large annotated corpus for learning natural language inference
- (Citation Count: 4005.0000) Neural Architectures for Named Entity Recognition
- (Citation Count: 3394.0000) Optimization as a Model for Few-Shot Learning
- (Citation Count: 3279.0000) Convolutional Sequence to Sequence Learning

### Top 20 Papers by PageRank

- (PageRank: 0.1563) Skip-Thought Vectors
- (PageRank: 0.1392) Aligning Books and Movies: Towards Story-Like Visual Explanations by Watchi...
- (PageRank: 0.0340) Training Very Deep Networks
- (PageRank: 0.0264) Finding Function in Form: Compositional Character Models for Open Vocabular...
- (PageRank: 0.0216) Effective Approaches to Attention-based Neural Machine Translation
- (PageRank: 0.0214) A large annotated corpus for learning natural language inference
- (PageRank: 0.0187) SQuAD: 100,000+ Questions for Machine Comprehension of Text
- (PageRank: 0.0185) Character-Aware Neural Language Models
- (PageRank: 0.0175) Deep Residual Learning for Image Recognition
- (PageRank: 0.0158) End-To-End Memory Networks
- (PageRank: 0.0152) Neural GPUs Learn Algorithms
- (PageRank: 0.0151) Long Short-Term Memory-Networks for Machine Reading
- (PageRank: 0.0144) Neural Machine Translation of Rare Words with Subword Units
- (PageRank: 0.0131) End-to-end learning of semantic role labeling using recurrent neural networ...
- (PageRank: 0.0123) Multi-task Sequence to Sequence Learning
- (PageRank: 0.0120) A Theoretically Grounded Application of Dropout in Recurrent Neural Network...
- (PageRank: 0.0120) Rethinking the Inception Architecture for Computer Vision
- (PageRank: 0.0113) Google's Neural Machine Translation System: Bridging the Gap between Human ...
- (PageRank: 0.0105) Bidirectional Attention Flow for Machine Comprehension
- (PageRank: 0.0105) A Decomposable Attention Model for Natural Language Inference

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.0977) Google's Neural Machine Translation System: Bridging the Gap between Human ...
- (HITS Authority: 0.0781) Effective Approaches to Attention-based Neural Machine Translation
- (HITS Authority: 0.0769) Deep Residual Learning for Image Recognition
- (HITS Authority: 0.0624) Deep Recurrent Models with Fast-Forward Connections for Neural Machine Tran...
- (HITS Authority: 0.0531) A large annotated corpus for learning natural language inference
- (HITS Authority: 0.0523) Skip-Thought Vectors
- (HITS Authority: 0.0450) Neural Machine Translation of Rare Words with Subword Units
- (HITS Authority: 0.0336) Exploring the Limits of Language Modeling
- (HITS Authority: 0.0306) End-To-End Memory Networks
- (HITS Authority: 0.0264) SQuAD: 100,000+ Questions for Machine Comprehension of Text
- (HITS Authority: 0.0260) Neural Machine Translation in Linear Time
- (HITS Authority: 0.0246) Character-Aware Neural Language Models
- (HITS Authority: 0.0244) A Decomposable Attention Model for Natural Language Inference
- (HITS Authority: 0.0241) Bidirectional Attention Flow for Machine Comprehension
- (HITS Authority: 0.0210) End-to-end learning of semantic role labeling using recurrent neural networ...
- (HITS Authority: 0.0198) Attention is All you Need
- (HITS Authority: 0.0197) Learning Distributed Representations of Sentences from Unlabelled Data
- (HITS Authority: 0.0173) Layer Normalization
- (HITS Authority: 0.0155) Long Short-Term Memory-Networks for Machine Reading
- (HITS Authority: 0.0150) Convolutional Sequence to Sequence Learning


# Analysis for Window: 2016-2018
**Stats:** Papers: 1812, Edges: 1221
**Best Found DBCV Score:** 0.6370
**Optimal Parameters:** `n_neighbors`: 35, `min_cluster_size`: 25, `min_samples`: 15, `epsilon`: 0.0

### Dominant Topics

- **Topic (ID: 1, Size: 695, Confidence: 0.9743):** language, learning, natural, neural, processing, deep, text, using, based, networks, machine, word, data, analysis, network
- **Topic (ID: 0, Size: 25, Confidence: 1.0000):** comprehension, question, reading, answering, machine, inference, language, natural, attention, challenge, networks, learning, dataset, multi, scale

### Top 20 Papers by Citation Count

- (Citation Count: 130102.0000) Attention is All you Need
- (Citation Count: 22656.0000) Decoupled Weight Decay Regularization
- (Citation Count: 14474.0000) Xception: Deep Learning with Depthwise Separable Convolutions
- (Citation Count: 11860.0000) Improving Language Understanding by Generative Pre-Training
- (Citation Count: 11810.0000) Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks
- (Citation Count: 11526.0000) Deep Contextualized Word Representations
- (Citation Count: 10421.0000) Layer Normalization
- (Citation Count: 9944.0000) Enriching Word Vectors with Subword Information
- (Citation Count: 8081.0000) SQuAD: 100,000+ Questions for Machine Comprehension of Text
- (Citation Count: 7295.0000) Matching Networks for One Shot Learning
- (Citation Count: 7103.0000) GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Und...
- (Citation Count: 6772.0000) Google's Neural Machine Translation System: Bridging the Gap between Human ...
- (Citation Count: 4452.0000) A Broad-Coverage Challenge Corpus for Sentence Understanding through Infere...
- (Citation Count: 4005.0000) Neural Architectures for Named Entity Recognition
- (Citation Count: 3628.0000) Universal Language Model Fine-tuning for Text Classification
- (Citation Count: 3499.0000) SentencePiece: A simple and language independent subword tokenizer and deto...
- (Citation Count: 3394.0000) Optimization as a Model for Few-Shot Learning
- (Citation Count: 3279.0000) Convolutional Sequence to Sequence Learning
- (Citation Count: 2958.0000) A Call for Clarity in Reporting BLEU Scores
- (Citation Count: 2954.0000) Domain randomization for transferring deep neural networks from simulation ...

### Top 20 Papers by PageRank

- (PageRank: 0.0150) Enriching Word Vectors with Subword Information
- (PageRank: 0.0146) Charagram: Embedding Words and Sentences via Character n-grams
- (PageRank: 0.0142) Neural Architectures for Named Entity Recognition
- (PageRank: 0.0126) Learning Distributed Representations of Sentences from Unlabelled Data
- (PageRank: 0.0122) Deep Recurrent Models with Fast-Forward Connections for Neural Machine Tran...
- (PageRank: 0.0113) Exploring the Limits of Language Modeling
- (PageRank: 0.0105) SQuAD: 100,000+ Questions for Machine Comprehension of Text
- (PageRank: 0.0104) Google's Neural Machine Translation System: Bridging the Gap between Human ...
- (PageRank: 0.0091) Attention is All you Need
- (PageRank: 0.0088) Long Short-Term Memory-Networks for Machine Reading
- (PageRank: 0.0061) Supervised Learning of Universal Sentence Representations from Natural Lang...
- (PageRank: 0.0060) Bidirectional Attention Flow for Machine Comprehension
- (PageRank: 0.0057) End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF
- (PageRank: 0.0056) A Decomposable Attention Model for Natural Language Inference
- (PageRank: 0.0054) Deep Contextualized Word Representations
- (PageRank: 0.0036) Convolutional Sequence to Sequence Learning
- (PageRank: 0.0034) A Broad-Coverage Challenge Corpus for Sentence Understanding through Infere...
- (PageRank: 0.0033) Learning Global Features for Coreference Resolution
- (PageRank: 0.0031) Neural Machine Translation in Linear Time
- (PageRank: 0.0031) Layer Normalization

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.0774) Deep Contextualized Word Representations
- (HITS Authority: 0.0683) Attention is All you Need
- (HITS Authority: 0.0613) Bidirectional Attention Flow for Machine Comprehension
- (HITS Authority: 0.0545) SQuAD: 100,000+ Questions for Machine Comprehension of Text
- (HITS Authority: 0.0440) Learned in Translation: Contextualized Word Vectors
- (HITS Authority: 0.0438) Supervised Learning of Universal Sentence Representations from Natural Lang...
- (HITS Authority: 0.0312) A Broad-Coverage Challenge Corpus for Sentence Understanding through Infere...
- (HITS Authority: 0.0271) Enhanced LSTM for Natural Language Inference
- (HITS Authority: 0.0263) TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading ...
- (HITS Authority: 0.0228) A Decomposable Attention Model for Natural Language Inference
- (HITS Authority: 0.0219) Neural Architectures for Named Entity Recognition
- (HITS Authority: 0.0196) Google's Neural Machine Translation System: Bridging the Gap between Human ...
- (HITS Authority: 0.0187) Convolutional Sequence to Sequence Learning
- (HITS Authority: 0.0181) Semi-supervised sequence tagging with bidirectional language models
- (HITS Authority: 0.0173) A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks
- (HITS Authority: 0.0170) Gated Self-Matching Networks for Reading Comprehension and Question Answeri...
- (HITS Authority: 0.0152) Enriching Word Vectors with Subword Information
- (HITS Authority: 0.0151) Deep Semantic Role Labeling: What Works and What’s Next
- (HITS Authority: 0.0151) Stochastic Answer Networks for Machine Reading Comprehension
- (HITS Authority: 0.0145) Learning Distributed Representations of Sentences from Unlabelled Data


# Analysis for Window: 2017-2019
**Stats:** Papers: 3646, Edges: 3818
**Best Found DBCV Score:** 0.5841
**Optimal Parameters:** `n_neighbors`: 10, `min_cluster_size`: 35, `min_samples`: 15, `epsilon`: 0.25

### Dominant Topics

- **Topic (ID: 1, Size: 1598, Confidence: 0.9976):** language, learning, natural, neural, deep, processing, using, text, based, analysis, networks, machine, word, sentiment, model
- **Topic (ID: 0, Size: 280, Confidence: 0.9980):** language, processing, natural, learning, clinical, using, deep, based, health, machine, data, medical, biomedical, text, electronic

### Top 20 Papers by Citation Count

- (Citation Count: 130102.0000) Attention is All you Need
- (Citation Count: 94099.0000) BERT: Pre-training of Deep Bidirectional Transformers for Language Understa...
- (Citation Count: 24213.0000) RoBERTa: A Robustly Optimized BERT Pretraining Approach
- (Citation Count: 22682.0000) Language Models are Unsupervised Multitask Learners
- (Citation Count: 22656.0000) Decoupled Weight Decay Regularization
- (Citation Count: 19888.0000) Exploring the Limits of Transfer Learning with a Unified Text-to-Text Trans...
- (Citation Count: 11860.0000) Improving Language Understanding by Generative Pre-Training
- (Citation Count: 11810.0000) Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks
- (Citation Count: 11526.0000) Deep Contextualized Word Representations
- (Citation Count: 10743.0000) BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Gene...
- (Citation Count: 8395.0000) XLNet: Generalized Autoregressive Pretraining for Language Understanding
- (Citation Count: 7422.0000) DistilBERT, a distilled version of BERT: smaller, faster, cheaper and light...
- (Citation Count: 7103.0000) GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Und...
- (Citation Count: 6424.0000) ALBERT: A Lite BERT for Self-supervised Learning of Language Representation...
- (Citation Count: 5602.0000) BioBERT: a pre-trained biomedical language representation model for biomedi...
- (Citation Count: 4452.0000) A Broad-Coverage Challenge Corpus for Sentence Understanding through Infere...
- (Citation Count: 3715.0000) Transformer-XL: Attentive Language Models beyond a Fixed-Length Context
- (Citation Count: 3664.0000) ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Visi...
- (Citation Count: 3628.0000) Universal Language Model Fine-tuning for Text Classification
- (Citation Count: 3499.0000) SentencePiece: A simple and language independent subword tokenizer and deto...

### Top 20 Papers by PageRank

- (PageRank: 0.0233) Attention is All you Need
- (PageRank: 0.0181) Supervised Learning of Universal Sentence Representations from Natural Lang...
- (PageRank: 0.0164) TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading ...
- (PageRank: 0.0152) BERT: Pre-training of Deep Bidirectional Transformers for Language Understa...
- (PageRank: 0.0148) Deep Contextualized Word Representations
- (PageRank: 0.0146) RACE: Large-scale ReAding Comprehension Dataset From Examinations
- (PageRank: 0.0136) A Structured Self-attentive Sentence Embedding
- (PageRank: 0.0095) A Broad-Coverage Challenge Corpus for Sentence Understanding through Infere...
- (PageRank: 0.0081) Neural Sequence Learning Models for Word Sense Disambiguation
- (PageRank: 0.0079) Word Sense Disambiguation: A Unified Evaluation Framework and Empirical Com...
- (PageRank: 0.0057) Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts L...
- (PageRank: 0.0052) Learned in Translation: Contextualized Word Vectors
- (PageRank: 0.0051) Convolutional Sequence to Sequence Learning
- (PageRank: 0.0046) Semi-supervised sequence tagging with bidirectional language models
- (PageRank: 0.0042) Gated Self-Matching Networks for Reading Comprehension and Question Answeri...
- (PageRank: 0.0042) Deep Semantic Role Labeling: What Works and What’s Next
- (PageRank: 0.0041) Recent Trends in Deep Learning Based Natural Language Processing
- (PageRank: 0.0036) On the State of the Art of Evaluation in Neural Language Models
- (PageRank: 0.0035) Improving Language Understanding by Generative Pre-Training
- (PageRank: 0.0032) End-to-end Neural Coreference Resolution

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.1405) BERT: Pre-training of Deep Bidirectional Transformers for Language Understa...
- (HITS Authority: 0.0985) Attention is All you Need
- (HITS Authority: 0.0863) Deep Contextualized Word Representations
- (HITS Authority: 0.0557) Improving Language Understanding by Generative Pre-Training
- (HITS Authority: 0.0319) GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Und...
- (HITS Authority: 0.0312) Language Models are Unsupervised Multitask Learners
- (HITS Authority: 0.0302) XLNet: Generalized Autoregressive Pretraining for Language Understanding
- (HITS Authority: 0.0266) Universal Language Model Fine-tuning for Text Classification
- (HITS Authority: 0.0245) RoBERTa: A Robustly Optimized BERT Pretraining Approach
- (HITS Authority: 0.0213) A Broad-Coverage Challenge Corpus for Sentence Understanding through Infere...
- (HITS Authority: 0.0184) Cross-lingual Language Model Pretraining
- (HITS Authority: 0.0169) Learned in Translation: Contextualized Word Vectors
- (HITS Authority: 0.0151) Multi-Task Deep Neural Networks for Natural Language Understanding
- (HITS Authority: 0.0140) Transformer-XL: Attentive Language Models beyond a Fixed-Length Context
- (HITS Authority: 0.0138) Know What You Don’t Know: Unanswerable Questions for SQuAD
- (HITS Authority: 0.0119) Supervised Learning of Universal Sentence Representations from Natural Lang...
- (HITS Authority: 0.0083) RACE: Large-scale ReAding Comprehension Dataset From Examinations
- (HITS Authority: 0.0082) ALBERT: A Lite BERT for Self-supervised Learning of Language Representation...
- (HITS Authority: 0.0081) Convolutional Sequence to Sequence Learning
- (HITS Authority: 0.0078) Semi-supervised sequence tagging with bidirectional language models


# Analysis for Window: 2018-2020
**Stats:** Papers: 5511, Edges: 8505
**Best Found DBCV Score:** 0.5204
**Optimal Parameters:** `n_neighbors`: 50, `min_cluster_size`: 15, `min_samples`: 5, `epsilon`: 0.5

### Dominant Topics

- **Topic (ID: 3, Size: 3161, Confidence: 0.9974):** language, natural, learning, processing, using, deep, based, text, neural, analysis, survey, machine, data, models, sentiment
- **Topic (ID: 1, Size: 501, Confidence: 0.9974):** language, processing, natural, clinical, learning, using, medical, based, health, data, machine, text, electronic, deep, biomedical
- **Topic (ID: 0, Size: 86, Confidence: 0.6439):** learning, deep, language, using, chemical, natural, processing, protein, prediction, machine, based, modeling, molecular, sequence, drug
- **Topic (ID: 2, Size: 35, Confidence: 0.6006):** language, survey, learning, neural, processing, model, natural, data, word, models, embeddings, deep, bias, gender, methods

### Top 20 Papers by Citation Count

- (Citation Count: 94099.0000) BERT: Pre-training of Deep Bidirectional Transformers for Language Understa...
- (Citation Count: 41302.0000) Language Models are Few-Shot Learners
- (Citation Count: 24213.0000) RoBERTa: A Robustly Optimized BERT Pretraining Approach
- (Citation Count: 22682.0000) Language Models are Unsupervised Multitask Learners
- (Citation Count: 19888.0000) Exploring the Limits of Transfer Learning with a Unified Text-to-Text Trans...
- (Citation Count: 11860.0000) Improving Language Understanding by Generative Pre-Training
- (Citation Count: 11526.0000) Deep Contextualized Word Representations
- (Citation Count: 10743.0000) BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Gene...
- (Citation Count: 8395.0000) XLNet: Generalized Autoregressive Pretraining for Language Understanding
- (Citation Count: 7422.0000) DistilBERT, a distilled version of BERT: smaller, faster, cheaper and light...
- (Citation Count: 7103.0000) GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Und...
- (Citation Count: 6690.0000) Training data-efficient image transformers & distillation through attention
- (Citation Count: 6424.0000) ALBERT: A Lite BERT for Self-supervised Learning of Language Representation...
- (Citation Count: 6136.0000) Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks
- (Citation Count: 5602.0000) BioBERT: a pre-trained biomedical language representation model for biomedi...
- (Citation Count: 4707.0000) Scaling Laws for Neural Language Models
- (Citation Count: 4304.0000) Measuring Massive Multitask Language Understanding
- (Citation Count: 3715.0000) Transformer-XL: Attentive Language Models beyond a Fixed-Length Context
- (Citation Count: 3664.0000) ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Visi...
- (Citation Count: 3628.0000) Universal Language Model Fine-tuning for Text Classification

### Top 20 Papers by PageRank

- (PageRank: 0.0453) Deep Contextualized Word Representations
- (PageRank: 0.0371) BERT: Pre-training of Deep Bidirectional Transformers for Language Understa...
- (PageRank: 0.0121) Annotation Artifacts in Natural Language Inference Data
- (PageRank: 0.0095) Visual Referring Expression Recognition: What Do Systems Actually Learn?
- (PageRank: 0.0086) Universal Language Model Fine-tuning for Text Classification
- (PageRank: 0.0068) Improving Language Understanding by Generative Pre-Training
- (PageRank: 0.0066) GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Und...
- (PageRank: 0.0059) Dissecting Contextual Word Embeddings: Architecture and Representation
- (PageRank: 0.0055) Language Models are Unsupervised Multitask Learners
- (PageRank: 0.0052) RoBERTa: A Robustly Optimized BERT Pretraining Approach
- (PageRank: 0.0050) Semi-Supervised Sequence Modeling with Cross-View Training
- (PageRank: 0.0047) XLNet: Generalized Autoregressive Pretraining for Language Understanding
- (PageRank: 0.0043) QANet: Combining Local Convolution with Global Self-Attention for Reading C...
- (PageRank: 0.0041) Character-Level Language Modeling with Deeper Self-Attention
- (PageRank: 0.0036) AllenNLP: A Deep Semantic Natural Language Processing Platform
- (PageRank: 0.0031) Neural Network Acceptability Judgments
- (PageRank: 0.0029) Learning Word Vectors for 157 Languages
- (PageRank: 0.0027) Learning General Purpose Distributed Sentence Representations via Large Sca...
- (PageRank: 0.0026) Know What You Don’t Know: Unanswerable Questions for SQuAD
- (PageRank: 0.0026) Contextual String Embeddings for Sequence Labeling

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.1722) BERT: Pre-training of Deep Bidirectional Transformers for Language Understa...
- (HITS Authority: 0.0637) Deep Contextualized Word Representations
- (HITS Authority: 0.0612) RoBERTa: A Robustly Optimized BERT Pretraining Approach
- (HITS Authority: 0.0417) XLNet: Generalized Autoregressive Pretraining for Language Understanding
- (HITS Authority: 0.0399) Improving Language Understanding by Generative Pre-Training
- (HITS Authority: 0.0390) GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Und...
- (HITS Authority: 0.0360) Language Models are Unsupervised Multitask Learners
- (HITS Authority: 0.0276) ALBERT: A Lite BERT for Self-supervised Learning of Language Representation...
- (HITS Authority: 0.0220) Universal Language Model Fine-tuning for Text Classification
- (HITS Authority: 0.0180) Exploring the Limits of Transfer Learning with a Unified Text-to-Text Trans...
- (HITS Authority: 0.0159) Cross-lingual Language Model Pretraining
- (HITS Authority: 0.0142) DistilBERT, a distilled version of BERT: smaller, faster, cheaper and light...
- (HITS Authority: 0.0140) Multi-Task Deep Neural Networks for Natural Language Understanding
- (HITS Authority: 0.0122) Transformer-XL: Attentive Language Models beyond a Fixed-Length Context
- (HITS Authority: 0.0112) Know What You Don’t Know: Unanswerable Questions for SQuAD
- (HITS Authority: 0.0101) BioBERT: a pre-trained biomedical language representation model for biomedi...
- (HITS Authority: 0.0084) SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding ...
- (HITS Authority: 0.0074) Unified Language Model Pre-training for Natural Language Understanding and ...
- (HITS Authority: 0.0072) Contextual String Embeddings for Sequence Labeling
- (HITS Authority: 0.0072) Patient Knowledge Distillation for BERT Model Compression


# Analysis for Window: 2019-2021
**Stats:** Papers: 5582, Edges: 11216
**Best Found DBCV Score:** 0.4279
**Optimal Parameters:** `n_neighbors`: 15, `min_cluster_size`: 50, `min_samples`: 25, `epsilon`: 0.0

### Dominant Topics

- **Topic (ID: 2, Size: 4569, Confidence: 0.9923):** language, natural, processing, learning, using, based, deep, text, analysis, models, neural, machine, survey, data, model
- **Topic (ID: 0, Size: 229, Confidence: 0.9721):** adversarial, language, learning, natural, detection, processing, using, deep, based, attacks, privacy, models, machine, text, attack
- **Topic (ID: 1, Size: 101, Confidence: 0.9372):** learning, deep, language, using, protein, sequence, chemical, molecular, natural, prediction, models, based, data, processing, model

### Top 20 Papers by Citation Count

- (Citation Count: 94099.0000) BERT: Pre-training of Deep Bidirectional Transformers for Language Understa...
- (Citation Count: 41302.0000) Language Models are Few-Shot Learners
- (Citation Count: 28903.0000) Learning Transferable Visual Models From Natural Language Supervision
- (Citation Count: 24213.0000) RoBERTa: A Robustly Optimized BERT Pretraining Approach
- (Citation Count: 22682.0000) Language Models are Unsupervised Multitask Learners
- (Citation Count: 19888.0000) Exploring the Limits of Transfer Learning with a Unified Text-to-Text Trans...
- (Citation Count: 10743.0000) BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Gene...
- (Citation Count: 10099.0000) LoRA: Low-Rank Adaptation of Large Language Models
- (Citation Count: 8395.0000) XLNet: Generalized Autoregressive Pretraining for Language Understanding
- (Citation Count: 7422.0000) DistilBERT, a distilled version of BERT: smaller, faster, cheaper and light...
- (Citation Count: 6690.0000) Training data-efficient image transformers & distillation through attention
- (Citation Count: 6424.0000) ALBERT: A Lite BERT for Self-supervised Learning of Language Representation...
- (Citation Count: 6136.0000) Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks
- (Citation Count: 5602.0000) BioBERT: a pre-trained biomedical language representation model for biomedi...
- (Citation Count: 5385.0000) Evaluating Large Language Models Trained on Code
- (Citation Count: 4707.0000) Scaling Laws for Neural Language Models
- (Citation Count: 4617.0000) Review of deep learning: concepts, CNN architectures, challenges, applicati...
- (Citation Count: 4304.0000) Measuring Massive Multitask Language Understanding
- (Citation Count: 3934.0000) Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in...
- (Citation Count: 3715.0000) Transformer-XL: Attentive Language Models beyond a Fixed-Length Context

### Top 20 Papers by PageRank

- (PageRank: 0.1130) BERT: Pre-training of Deep Bidirectional Transformers for Language Understa...
- (PageRank: 0.0168) Language Models are Unsupervised Multitask Learners
- (PageRank: 0.0155) RoBERTa: A Robustly Optimized BERT Pretraining Approach
- (PageRank: 0.0121) XLNet: Generalized Autoregressive Pretraining for Language Understanding
- (PageRank: 0.0101) Multi-Task Deep Neural Networks for Natural Language Understanding
- (PageRank: 0.0072) Transformer-XL: Attentive Language Models beyond a Fixed-Length Context
- (PageRank: 0.0064) Cross-lingual Language Model Pretraining
- (PageRank: 0.0059) ALBERT: A Lite BERT for Self-supervised Learning of Language Representation...
- (PageRank: 0.0049) Improving Multi-Task Deep Neural Networks via Knowledge Distillation for Na...
- (PageRank: 0.0046) BioBERT: a pre-trained biomedical language representation model for biomedi...
- (PageRank: 0.0045) Exploring the Limits of Transfer Learning with a Unified Text-to-Text Trans...
- (PageRank: 0.0044) Unified Language Model Pre-training for Natural Language Understanding and ...
- (PageRank: 0.0042) Language Models are Few-Shot Learners
- (PageRank: 0.0031) DistilBERT, a distilled version of BERT: smaller, faster, cheaper and light...
- (PageRank: 0.0029) SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding ...
- (PageRank: 0.0027) MASS: Masked Sequence to Sequence Pre-training for Language Generation
- (PageRank: 0.0025) Publicly Available Clinical BERT Embeddings
- (PageRank: 0.0023) Lipstick on a Pig: Debiasing Methods Cover up Systematic Gender Biases in W...
- (PageRank: 0.0021) BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Gene...
- (PageRank: 0.0019) Generating Long Sequences with Sparse Transformers

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.2137) BERT: Pre-training of Deep Bidirectional Transformers for Language Understa...
- (HITS Authority: 0.0778) RoBERTa: A Robustly Optimized BERT Pretraining Approach
- (HITS Authority: 0.0446) Language Models are Unsupervised Multitask Learners
- (HITS Authority: 0.0414) XLNet: Generalized Autoregressive Pretraining for Language Understanding
- (HITS Authority: 0.0359) ALBERT: A Lite BERT for Self-supervised Learning of Language Representation...
- (HITS Authority: 0.0260) Exploring the Limits of Transfer Learning with a Unified Text-to-Text Trans...
- (HITS Authority: 0.0232) Language Models are Few-Shot Learners
- (HITS Authority: 0.0203) DistilBERT, a distilled version of BERT: smaller, faster, cheaper and light...
- (HITS Authority: 0.0167) Cross-lingual Language Model Pretraining
- (HITS Authority: 0.0146) BioBERT: a pre-trained biomedical language representation model for biomedi...
- (HITS Authority: 0.0131) Transformer-XL: Attentive Language Models beyond a Fixed-Length Context
- (HITS Authority: 0.0130) BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Gene...
- (HITS Authority: 0.0117) Multi-Task Deep Neural Networks for Natural Language Understanding
- (HITS Authority: 0.0105) TinyBERT: Distilling BERT for Natural Language Understanding
- (HITS Authority: 0.0104) SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding ...
- (HITS Authority: 0.0098) SciBERT: A Pretrained Language Model for Scientific Text
- (HITS Authority: 0.0084) Patient Knowledge Distillation for BERT Model Compression
- (HITS Authority: 0.0069) Unified Language Model Pre-training for Natural Language Understanding and ...
- (HITS Authority: 0.0069) MASS: Masked Sequence to Sequence Pre-training for Language Generation
- (HITS Authority: 0.0068) Publicly Available Clinical BERT Embeddings


# Analysis for Window: 2020-2022
**Stats:** Papers: 5579, Edges: 7223
**Best Found DBCV Score:** 0.5879
**Optimal Parameters:** `n_neighbors`: 25, `min_cluster_size`: 35, `min_samples`: 25, `epsilon`: 0.5

### Dominant Topics

- **Topic (ID: 3, Size: 4344, Confidence: 0.9991):** language, natural, learning, processing, using, based, text, models, deep, analysis, survey, neural, model, machine, sentiment
- **Topic (ID: 2, Size: 805, Confidence: 0.9804):** language, natural, processing, using, learning, clinical, health, based, machine, medical, review, electronic, data, text, records
- **Topic (ID: 1, Size: 235, Confidence: 0.9992):** language, learning, adversarial, natural, processing, detection, models, using, privacy, based, attacks, attack, nlp, deep, text
- **Topic (ID: 0, Size: 127, Confidence: 0.5983):** language, learning, deep, using, natural, models, protein, model, processing, chemical, data, sequence, prediction, based, molecular

### Top 20 Papers by Citation Count

- (Citation Count: 41302.0000) Language Models are Few-Shot Learners
- (Citation Count: 28903.0000) Learning Transferable Visual Models From Natural Language Supervision
- (Citation Count: 12686.0000) Training language models to follow instructions with human feedback
- (Citation Count: 10099.0000) LoRA: Low-Rank Adaptation of Large Language Models
- (Citation Count: 9151.0000) Chain of Thought Prompting Elicits Reasoning in Large Language Models
- (Citation Count: 6690.0000) Training data-efficient image transformers & distillation through attention
- (Citation Count: 6159.0000) PaLM: Scaling Language Modeling with Pathways
- (Citation Count: 6136.0000) Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks
- (Citation Count: 5385.0000) Evaluating Large Language Models Trained on Code
- (Citation Count: 4707.0000) Scaling Laws for Neural Language Models
- (Citation Count: 4617.0000) Review of deep learning: concepts, CNN architectures, challenges, applicati...
- (Citation Count: 4332.0000) Large Language Models are Zero-Shot Reasoners
- (Citation Count: 4304.0000) Measuring Massive Multitask Language Understanding
- (Citation Count: 3934.0000) Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in...
- (Citation Count: 3533.0000) Self-Consistency Improves Chain of Thought Reasoning in Language Models
- (Citation Count: 3350.0000) SimCSE: Simple Contrastive Learning of Sentence Embeddings
- (Citation Count: 2790.0000) BEiT: BERT Pre-Training of Image Transformers
- (Citation Count: 2698.0000) DeBERTa: Decoding-enhanced BERT with Disentangled Attention
- (Citation Count: 2675.0000) A Survey of Convolutional Neural Networks: Analysis, Applications, and Pros...
- (Citation Count: 2478.0000) Transformers in Vision: A Survey

### Top 20 Papers by PageRank

- (PageRank: 0.0439) How Much Knowledge Can You Pack into the Parameters of a Language Model?
- (PageRank: 0.0418) REALM: Retrieval-Augmented Language Model Pre-Training
- (PageRank: 0.0318) Language Models are Few-Shot Learners
- (PageRank: 0.0068) Scaling Laws for Neural Language Models
- (PageRank: 0.0054) Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks
- (PageRank: 0.0048) Language (Technology) is Power: A Critical Survey of “Bias” in NLP
- (PageRank: 0.0046) Learning Transferable Visual Models From Natural Language Supervision
- (PageRank: 0.0044) Adversarial Training for Large Neural Language Models
- (PageRank: 0.0040) Training data-efficient image transformers & distillation through attention
- (PageRank: 0.0036) Pretrained Transformers Improve Out-of-Distribution Robustness
- (PageRank: 0.0034) Train Large, Then Compress: Rethinking Model Size for Efficient Training an...
- (PageRank: 0.0034) Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Lan...
- (PageRank: 0.0032) StereoSet: Measuring stereotypical bias in pretrained language models
- (PageRank: 0.0030) Multilingual Denoising Pre-training for Neural Machine Translation
- (PageRank: 0.0029) How Can We Accelerate Progress Towards Human-like Linguistic Generalization...
- (PageRank: 0.0029) Stanza: A Python Natural Language Processing Toolkit for Many Human Languag...
- (PageRank: 0.0028) AraBERT: Transformer-based Model for Arabic Language Understanding
- (PageRank: 0.0028) UnifiedQA: Crossing Format Boundaries With a Single QA System
- (PageRank: 0.0024) Compressing Large-Scale Transformer-Based Models: A Case Study on BERT
- (PageRank: 0.0023) Pre-trained models for natural language processing: A survey

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.2121) Language Models are Few-Shot Learners
- (HITS Authority: 0.0324) Learning Transferable Visual Models From Natural Language Supervision
- (HITS Authority: 0.0218) Chain of Thought Prompting Elicits Reasoning in Large Language Models
- (HITS Authority: 0.0205) Evaluating Large Language Models Trained on Code
- (HITS Authority: 0.0174) PaLM: Scaling Language Modeling with Pathways
- (HITS Authority: 0.0166) Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in...
- (HITS Authority: 0.0161) Scaling Laws for Neural Language Models
- (HITS Authority: 0.0158) REALM: Retrieval-Augmented Language Model Pre-Training
- (HITS Authority: 0.0147) Training data-efficient image transformers & distillation through attention
- (HITS Authority: 0.0146) Training language models to follow instructions with human feedback
- (HITS Authority: 0.0115) DeBERTa: Decoding-enhanced BERT with Disentangled Attention
- (HITS Authority: 0.0110) GLaM: Efficient Scaling of Language Models with Mixture-of-Experts
- (HITS Authority: 0.0109) How Much Knowledge Can You Pack into the Parameters of a Language Model?
- (HITS Authority: 0.0104) Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Lan...
- (HITS Authority: 0.0097) Self-Consistency Improves Chain of Thought Reasoning in Language Models
- (HITS Authority: 0.0095) Linformer: Self-Attention with Linear Complexity
- (HITS Authority: 0.0086) Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks
- (HITS Authority: 0.0086) Large Language Models are Zero-Shot Reasoners
- (HITS Authority: 0.0081) Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Sca...
- (HITS Authority: 0.0080) Domain-Specific Language Model Pretraining for Biomedical Natural Language ...


# Analysis for Window: 2021-2023
**Stats:** Papers: 5684, Edges: 8779
**Best Found DBCV Score:** 0.4073
**Optimal Parameters:** `n_neighbors`: 15, `min_cluster_size`: 15, `min_samples`: 10, `epsilon`: 0.0

### Dominant Topics

- **Topic (ID: 3, Size: 760, Confidence: 0.9756):** language, natural, processing, using, clinical, learning, health, review, models, based, medical, electronic, records, machine, large
- **Topic (ID: 45, Size: 217, Confidence: 0.9292):** sentiment, analysis, language, based, using, learning, natural, processing, deep, text, data, aspect, arabic, social, model
- **Topic (ID: 59, Size: 143, Confidence: 0.9431):** language, models, multilingual, languages, natural, processing, model, large, speech, low, cross, based, tagging, lingual, corpus
- **Topic (ID: 26, Size: 126, Confidence: 0.4936):** language, models, natural, processing, human, brain, neural, learning, word, large, representations, structure, linguistic, using, corpus
- **Topic (ID: 17, Size: 116, Confidence: 0.6892):** code, language, models, large, natural, generation, test, using, bug, model, software, source, testing, gpt, based
- **Topic (ID: 60, Size: 101, Confidence: 0.9145):** learning, deep, survey, neural, review, networks, applications, convolutional, models, network, machine, data, algorithms, based, cnn
- **Topic (ID: 66, Size: 101, Confidence: 0.8943):** language, learning, models, tuning, shot, fine, task, large, natural, processing, pre, text, efficient, based, training
- **Topic (ID: 32, Size: 82, Confidence: 0.6566):** bias, language, gender, models, natural, fairness, processing, survey, biases, large, nlp, social, analysis, languages, evaluating
- **Topic (ID: 57, Size: 79, Confidence: 0.9101):** language, learning, reinforcement, survey, large, models, robot, robotic, based, navigation, autonomous, multi, model, vision, applications
- **Topic (ID: 34, Size: 76, Confidence: 0.7658):** chatgpt, language, chatbots, ai, natural, chatbot, processing, models, using, generative, conversational, survey, gpt, review, development
- **Topic (ID: 36, Size: 68, Confidence: 0.8080):** language, learning, natural, chatgpt, students, education, using, processing, based, student, assessment, teaching, large, exploring, research
- **Topic (ID: 64, Size: 68, Confidence: 0.8000):** language, reasoning, models, large, natural, survey, logical, causal, commonsense, reasoners, symbolic, thought, chain, logic, knowledge
- **Topic (ID: 19, Size: 67, Confidence: 0.6610):** chatgpt, medical, language, ai, health, artificial, chatbot, intelligence, future, large, review, potential, gpt, natural, models
- **Topic (ID: 5, Size: 64, Confidence: 0.7537):** protein, language, models, model, learning, sequence, deep, based, using, sequences, prediction, cell, biological, design, processing
- **Topic (ID: 67, Size: 62, Confidence: 0.8787):** transformers, transformer, vision, survey, image, classification, visual, based, networks, remote, sensing, point, deep, attention, 3d
- **Topic (ID: 38, Size: 60, Confidence: 0.9629):** language, natural, processing, text, extraction, survey, information, data, analysis, based, techniques, using, materials, summarization, literature
- **Topic (ID: 4, Size: 56, Confidence: 0.6513):** language, molecular, models, learning, chemical, using, model, molecules, design, materials, property, transformer, prediction, machine, based
- **Topic (ID: 41, Size: 51, Confidence: 0.7440):** language, requirements, natural, processing, engineering, using, models, software, systematic, learning, based, classification, techniques, review, systems
- **Topic (ID: 55, Size: 50, Confidence: 0.7507):** dialogue, conversational, language, based, agents, generation, dataset, learning, model, systems, conversations, task, question, human, multi
- **Topic (ID: 22, Size: 50, Confidence: 0.7017):** fake, news, detection, learning, language, using, processing, natural, based, deep, machine, spam, classification, model, analysis
- **Topic (ID: 10, Size: 50, Confidence: 0.7322):** adversarial, robustness, language, survey, attacks, nlp, attack, natural, word, defenses, models, learning, deep, textual, based
- **Topic (ID: 48, Size: 49, Confidence: 0.7555):** language, vision, models, learning, visual, prompt, survey, context, understanding, pre, multimodal, modal, multi, unified, scene
- **Topic (ID: 7, Size: 49, Confidence: 0.6953):** speech, language, recognition, self, end, learning, processing, supervised, models, model, large, representation, tasks, training, automatic
- **Topic (ID: 42, Size: 48, Confidence: 0.7217):** text, classification, based, multi, learning, label, model, graph, deep, neural, representation, network, bert, networks, using
- **Topic (ID: 53, Size: 47, Confidence: 0.6986):** image, captioning, learning, using, deep, caption, based, generation, review, text, transformer, attention, generator, video, survey
- **Topic (ID: 69, Size: 45, Confidence: 0.8152):** transformer, based, accelerator, acceleration, processing, language, memory, fpga, efficient, transformers, natural, accelerating, networks, inference, vision
- **Topic (ID: 43, Size: 45, Confidence: 0.6616):** covid, 19, analysis, sentiment, twitter, using, language, natural, processing, learning, pandemic, vaccine, tweets, vaccination, deep
- **Topic (ID: 14, Size: 44, Confidence: 0.5629):** recommendation, recommender, language, models, large, based, systems, learning, survey, personalized, news, generative, chatgpt, model, using
- **Topic (ID: 39, Size: 43, Confidence: 0.9679):** language, processing, natural, nlp, survey, research, review, applications, models, large, analysis, systematic, role, study, techniques
- **Topic (ID: 0, Size: 40, Confidence: 0.5592):** language, processing, natural, learning, deep, survey, using, analysis, models, based, machine, representation, nlp, techniques, approaches
- **Topic (ID: 1, Size: 40, Confidence: 0.7705):** privacy, language, models, differential, private, text, preserving, natural, learning, differentially, large, policies, federated, processing, analysis
- **Topic (ID: 30, Size: 39, Confidence: 0.9054):** question, answering, based, learning, survey, language, models, using, transformer, deep, answer, grading, comparative, transformers, automated
- **Topic (ID: 13, Size: 38, Confidence: 0.8595):** detection, language, based, using, processing, natural, malware, learning, vulnerability, code, deep, techniques, classification, android, security
- **Topic (ID: 46, Size: 38, Confidence: 0.6471):** hate, speech, detection, language, learning, using, natural, processing, based, automatic, challenges, offensive, media, social, review
- **Topic (ID: 23, Size: 38, Confidence: 0.7061):** emotion, text, recognition, based, learning, speech, using, deep, detection, classification, approach, review, analysis, personality, challenges
- **Topic (ID: 58, Size: 37, Confidence: 0.7966):** machine, translation, language, neural, english, based, processing, natural, statistical, corpus, using, languages, survey, parallel, level
- **Topic (ID: 56, Size: 36, Confidence: 0.9359):** evaluation, language, nlp, human, metrics, natural, tasks, generation, survey, models, benchmark, processing, large, data, model
- **Topic (ID: 28, Size: 36, Confidence: 0.7518):** entity, recognition, named, model, using, based, crf, learning, bert, chinese, domain, deep, nested, review, network
- **Topic (ID: 6, Size: 34, Confidence: 0.7572):** audio, language, music, captioning, training, pre, models, natural, text, generation, supervision, transformer, representations, large, automated
- **Topic (ID: 29, Size: 33, Confidence: 0.9276):** sql, language, natural, text, data, database, query, survey, querying, models, large, processing, systems, queries, learning
- **Topic (ID: 35, Size: 32, Confidence: 0.8411):** education, intelligence, artificial, language, ai, review, systematic, learning, based, future, role, intelligent, teaching, processing, natural
- **Topic (ID: 47, Size: 30, Confidence: 0.8043):** language, detection, cyberbullying, using, natural, processing, learning, machine, media, social, techniques, urdu, based, cyber, model
- **Topic (ID: 9, Size: 30, Confidence: 0.8846):** models, language, backdoor, attacks, trained, pre, backdoors, natural, processing, review, textual, survey, nlp, large, based
- **Topic (ID: 25, Size: 29, Confidence: 0.6609):** processing, language, natural, aviation, safety, reports, using, learning, based, machine, application, data, factors, text, analysis
- **Topic (ID: 40, Size: 28, Confidence: 0.9538):** natural, language, processing, based, information, building, ontology, automated, management, construction, using, knowledge, checking, compliance, semantic
- **Topic (ID: 65, Size: 28, Confidence: 0.8385):** segmentation, medical, image, transformer, transformers, 3d, brain, unet, review, swin, using, tumor, vision, imaging, architecture
- **Topic (ID: 37, Size: 26, Confidence: 0.8361):** legal, language, natural, processing, law, prediction, models, large, survey, judgment, using, domain, retrieval, brazilian, case
- **Topic (ID: 51, Size: 25, Confidence: 0.8615):** learning, contrastive, sentence, representations, embeddings, representation, unsupervised, supervised, language, self, text, review, model, label, understanding
- **Topic (ID: 16, Size: 25, Confidence: 0.8439):** graph, networks, neural, survey, learning, applications, self, supervised, node, processing, deep, classification, methods, attention, transformer
- **Topic (ID: 52, Size: 22, Confidence: 0.8789):** diffusion, text, image, motion, editing, human, driven, models, generation, clip, guided, zero, shot, synthesis, language
- **Topic (ID: 12, Size: 22, Confidence: 0.9026):** cybersecurity, threat, intelligence, based, cyber, language, security, natural, learning, systems, processing, nlp, domain, assessment, automated
- **Topic (ID: 63, Size: 22, Confidence: 0.9879):** language, explanations, nlp, model, models, survey, natural, explainability, explainable, based, explanation, processing, rationalization, improving, pretrained
- **Topic (ID: 68, Size: 22, Confidence: 0.9634):** bert, quantization, transformer, models, language, efficient, quantized, bit, inference, large, training, moe, low, high, size
- **Topic (ID: 8, Size: 22, Confidence: 0.8673):** language, sign, using, recognition, translation, speech, learning, processing, natural, deep, languages, neural, machine, indian, translating
- **Topic (ID: 49, Size: 21, Confidence: 0.9432):** visual, answering, question, sensing, remote, language, survey, transformers, datasets, image, indic, attention, future, reasoning, challenges
- **Topic (ID: 27, Size: 21, Confidence: 0.9969):** extraction, language, retrieval, relation, matching, semantic, based, passage, network, bert, neural, graph, text, survey, information
- **Topic (ID: 24, Size: 21, Confidence: 0.8171):** stock, sentiment, prediction, using, based, price, market, analysis, learning, natural, language, processing, forecasting, financial, news
- **Topic (ID: 50, Size: 20, Confidence: 0.9430):** word, embeddings, language, survey, embedding, processing, natural, learning, representation, neural, deep, evaluation, models, methods, word2vec
- **Topic (ID: 15, Size: 20, Confidence: 0.9049):** intelligence, artificial, ai, applications, management, processing, industry, information, impact, library, natural, language, future, frontiers, opportunities
- **Topic (ID: 21, Size: 20, Confidence: 0.9094):** language, natural, data, visualization, interfaces, survey, based, interactive, visual, analysis, exploration, authoring, synthesis, processing, interface
- **Topic (ID: 61, Size: 18, Confidence: 0.9788):** time, series, forecasting, transformer, survey, models, transformers, pre, based, model, analysis, learning, foundation, trained, multivariate
- **Topic (ID: 31, Size: 18, Confidence: 0.9414):** answering, question, knowledge, graphs, graph, based, process, querying, approach, domain, bio, enabling, language, natural, soda
- **Topic (ID: 54, Size: 17, Confidence: 0.9999):** language, models, large, gpt, natural, financial, model, tasks, comprehensive, benchmark, instruction, use, challenges, evaluating, llms
- **Topic (ID: 11, Size: 17, Confidence: 0.9623):** phishing, detection, learning, using, language, machine, natural, processing, deep, email, model, emails, malicious, detect, based
- **Topic (ID: 2, Size: 17, Confidence: 0.9880):** quantum, natural, language, processing, intelligence, approach, near, term, neural, attention, network, vision, transformers, mathematics, artificial
- **Topic (ID: 62, Size: 17, Confidence: 0.9972):** language, models, pre, knowledge, trained, survey, enhanced, natural, model, understanding, based, processing, transformer, transformers, learning
- **Topic (ID: 18, Size: 16, Confidence: 0.9699):** language, model, geoscience, understanding, modeling, large, platform, geospatially, models, challenges, scientific, building, processes, numerical, earth
- **Topic (ID: 20, Size: 16, Confidence: 0.9956):** language, personality, chatgpt, models, processing, natural, large, affective, traits, responses, item, development, generation, using, emerge
- **Topic (ID: 44, Size: 16, Confidence: 0.9986):** tourism, language, natural, processing, text, based, analysis, mining, fuzzy, product, industry, approach, decision, group, application
- **Topic (ID: 33, Size: 15, Confidence: 1.0000):** language, natural, processing, cities, based, sustainable, intelligence, smart, governance, research, participation, citizen, innovation, alignment, service

### Top 20 Papers by Citation Count

- (Citation Count: 28903.0000) Learning Transferable Visual Models From Natural Language Supervision
- (Citation Count: 12954.0000) LLaMA: Open and Efficient Foundation Language Models
- (Citation Count: 12686.0000) Training language models to follow instructions with human feedback
- (Citation Count: 10099.0000) LoRA: Low-Rank Adaptation of Large Language Models
- (Citation Count: 9151.0000) Chain of Thought Prompting Elicits Reasoning in Large Language Models
- (Citation Count: 6159.0000) PaLM: Scaling Language Modeling with Pathways
- (Citation Count: 5385.0000) Evaluating Large Language Models Trained on Code
- (Citation Count: 4617.0000) Review of deep learning: concepts, CNN architectures, challenges, applicati...
- (Citation Count: 4332.0000) Large Language Models are Zero-Shot Reasoners
- (Citation Count: 3934.0000) Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in...
- (Citation Count: 3800.0000) Direct Preference Optimization: Your Language Model is Secretly a Reward Mo...
- (Citation Count: 3533.0000) Self-Consistency Improves Chain of Thought Reasoning in Language Models
- (Citation Count: 3350.0000) SimCSE: Simple Contrastive Learning of Sentence Embeddings
- (Citation Count: 3256.0000) DINOv2: Learning Robust Visual Features without Supervision
- (Citation Count: 2790.0000) BEiT: BERT Pre-Training of Image Transformers
- (Citation Count: 2659.0000) A Survey of Large Language Models
- (Citation Count: 2478.0000) Transformers in Vision: A Survey
- (Citation Count: 2364.0000) BLOOM: A 176B-Parameter Open-Access Multilingual Language Model
- (Citation Count: 2355.0000) Learning to Prompt for Vision-Language Models
- (Citation Count: 2098.0000) Efficient Memory Management for Large Language Model Serving with PagedAtte...

### Top 20 Papers by PageRank

- (PageRank: 0.0292) Learning Transferable Visual Models From Natural Language Supervision
- (PageRank: 0.0159) Evaluating Large Language Models Trained on Code
- (PageRank: 0.0118) Training language models to follow instructions with human feedback
- (PageRank: 0.0106) PaLM: Scaling Language Modeling with Pathways
- (PageRank: 0.0096) Chain of Thought Prompting Elicits Reasoning in Large Language Models
- (PageRank: 0.0089) Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in...
- (PageRank: 0.0072) BEiT: BERT Pre-Training of Image Transformers
- (PageRank: 0.0068) ExT5: Towards Extreme Multi-Task Scaling for Transfer Learning
- (PageRank: 0.0060) What’s in Your Head? Emergent Behaviour in Multi-Task Transformer Models
- (PageRank: 0.0058) LLaMA: Open and Efficient Foundation Language Models
- (PageRank: 0.0052) Self-Consistency Improves Chain of Thought Reasoning in Language Models
- (PageRank: 0.0051) PanGu-α: Large-scale Autoregressive Pretrained Chinese Language Models with...
- (PageRank: 0.0042) Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Sca...
- (PageRank: 0.0039) SimCSE: Simple Contrastive Learning of Sentence Embeddings
- (PageRank: 0.0037) BLOOM: A 176B-Parameter Open-Access Multilingual Language Model
- (PageRank: 0.0035) QNLP in Practice: Running Compositional Models of Meaning on a Quantum Comp...
- (PageRank: 0.0034) LoRA: Low-Rank Adaptation of Large Language Models
- (PageRank: 0.0033) Large Language Models are Zero-Shot Reasoners
- (PageRank: 0.0029) lambeq: An Efficient High-Level Python Library for Quantum NLP
- (PageRank: 0.0028) GLaM: Efficient Scaling of Language Models with Mixture-of-Experts

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.0802) Training language models to follow instructions with human feedback
- (HITS Authority: 0.0700) Chain of Thought Prompting Elicits Reasoning in Large Language Models
- (HITS Authority: 0.0540) LLaMA: Open and Efficient Foundation Language Models
- (HITS Authority: 0.0511) Learning Transferable Visual Models From Natural Language Supervision
- (HITS Authority: 0.0505) PaLM: Scaling Language Modeling with Pathways
- (HITS Authority: 0.0391) Evaluating Large Language Models Trained on Code
- (HITS Authority: 0.0335) Self-Consistency Improves Chain of Thought Reasoning in Language Models
- (HITS Authority: 0.0319) Large Language Models are Zero-Shot Reasoners
- (HITS Authority: 0.0267) LoRA: Low-Rank Adaptation of Large Language Models
- (HITS Authority: 0.0214) BLOOM: A 176B-Parameter Open-Access Multilingual Language Model
- (HITS Authority: 0.0144) A Survey of Large Language Models
- (HITS Authority: 0.0139) Solving Quantitative Reasoning Problems with Language Models
- (HITS Authority: 0.0137) Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in...
- (HITS Authority: 0.0136) Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Sca...
- (HITS Authority: 0.0114) GLaM: Efficient Scaling of Language Models with Mixture-of-Experts
- (HITS Authority: 0.0079) CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Cod...
- (HITS Authority: 0.0067) Is ChatGPT a General-Purpose Natural Language Processing Task Solver?
- (HITS Authority: 0.0065) Inner Monologue: Embodied Reasoning through Planning with Language Models
- (HITS Authority: 0.0062) PanGu-α: Large-scale Autoregressive Pretrained Chinese Language Models with...
- (HITS Authority: 0.0061) Code as Policies: Language Model Programs for Embodied Control


# Analysis for Window: 2022-2024
**Stats:** Papers: 5921, Edges: 10079
**Best Found DBCV Score:** 0.5291
**Optimal Parameters:** `n_neighbors`: 10, `min_cluster_size`: 75, `min_samples`: 5, `epsilon`: 0.0

### Dominant Topics

- **Topic (ID: 1, Size: 4548, Confidence: 0.9858):** language, models, large, natural, learning, processing, based, using, model, survey, text, analysis, deep, generation, review
- **Topic (ID: 3, Size: 824, Confidence: 0.8957):** language, natural, processing, clinical, using, medical, models, review, large, health, learning, model, based, artificial, intelligence
- **Topic (ID: 0, Size: 252, Confidence: 0.9376):** language, models, large, learning, privacy, natural, attacks, detection, processing, based, adversarial, survey, model, using, federated
- **Topic (ID: 2, Size: 179, Confidence: 0.8885):** language, models, protein, learning, large, model, based, using, deep, prediction, molecular, natural, design, drug, processing

### Top 20 Papers by Citation Count

- (Citation Count: 12954.0000) LLaMA: Open and Efficient Foundation Language Models
- (Citation Count: 12686.0000) Training language models to follow instructions with human feedback
- (Citation Count: 9151.0000) Chain of Thought Prompting Elicits Reasoning in Large Language Models
- (Citation Count: 6159.0000) PaLM: Scaling Language Modeling with Pathways
- (Citation Count: 4332.0000) Large Language Models are Zero-Shot Reasoners
- (Citation Count: 3800.0000) Direct Preference Optimization: Your Language Model is Secretly a Reward Mo...
- (Citation Count: 3533.0000) Self-Consistency Improves Chain of Thought Reasoning in Language Models
- (Citation Count: 3256.0000) DINOv2: Learning Robust Visual Features without Supervision
- (Citation Count: 2659.0000) A Survey of Large Language Models
- (Citation Count: 2364.0000) BLOOM: A 176B-Parameter Open-Access Multilingual Language Model
- (Citation Count: 2098.0000) Efficient Memory Management for Large Language Model Serving with PagedAtte...
- (Citation Count: 1756.0000) Qwen Technical Report
- (Citation Count: 1619.0000) A Survey on Evaluation of Large Language Models
- (Citation Count: 1360.0000) Diffusion Models: A Comprehensive Survey of Methods and Applications
- (Citation Count: 1225.0000) A Survey on Large Language Model based Autonomous Agents
- (Citation Count: 1224.0000) How Does ChatGPT Perform on the United States Medical Licensing Examination...
- (Citation Count: 1178.0000) PaLM 2 Technical Report
- (Citation Count: 1155.0000) G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment
- (Citation Count: 1098.0000) Swin UNETR: Swin Transformers for Semantic Segmentation of Brain Tumors in ...
- (Citation Count: 1084.0000) RT-1: Robotics Transformer for Real-World Control at Scale

### Top 20 Papers by PageRank

- (PageRank: 0.0445) PaLM: Scaling Language Modeling with Pathways
- (PageRank: 0.0413) Training language models to follow instructions with human feedback
- (PageRank: 0.0377) Chain of Thought Prompting Elicits Reasoning in Large Language Models
- (PageRank: 0.0234) Self-Consistency Improves Chain of Thought Reasoning in Language Models
- (PageRank: 0.0203) Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Sca...
- (PageRank: 0.0180) LLaMA: Open and Efficient Foundation Language Models
- (PageRank: 0.0110) BLOOM: A 176B-Parameter Open-Access Multilingual Language Model
- (PageRank: 0.0107) Large Language Models are Zero-Shot Reasoners
- (PageRank: 0.0085) Designing Effective Sparse Expert Models
- (PageRank: 0.0070) Solving Quantitative Reasoning Problems with Language Models
- (PageRank: 0.0057) Repairing the Cracked Foundation: A Survey of Obstacles in Evaluation Pract...
- (PageRank: 0.0029) A Survey of Large Language Models
- (PageRank: 0.0027) Natural Language to Code Translation with Execution
- (PageRank: 0.0026) Is ChatGPT a General-Purpose Natural Language Processing Task Solver?
- (PageRank: 0.0020) EleutherAI: Going Beyond "Open Science" to "Science in the Open"
- (PageRank: 0.0019) BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation a...
- (PageRank: 0.0019) Autoformalization with Large Language Models
- (PageRank: 0.0018) Direct Preference Optimization: Your Language Model is Secretly a Reward Mo...
- (PageRank: 0.0018) A Contrastive Framework for Neural Text Generation
- (PageRank: 0.0016) Contrastive Search Is What You Need For Neural Text Generation

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.1048) Training language models to follow instructions with human feedback
- (HITS Authority: 0.0943) LLaMA: Open and Efficient Foundation Language Models
- (HITS Authority: 0.0777) Chain of Thought Prompting Elicits Reasoning in Large Language Models
- (HITS Authority: 0.0592) PaLM: Scaling Language Modeling with Pathways
- (HITS Authority: 0.0385) Self-Consistency Improves Chain of Thought Reasoning in Language Models
- (HITS Authority: 0.0346) Large Language Models are Zero-Shot Reasoners
- (HITS Authority: 0.0290) BLOOM: A 176B-Parameter Open-Access Multilingual Language Model
- (HITS Authority: 0.0202) A Survey of Large Language Models
- (HITS Authority: 0.0139) Solving Quantitative Reasoning Problems with Language Models
- (HITS Authority: 0.0119) Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Sca...
- (HITS Authority: 0.0107) Direct Preference Optimization: Your Language Model is Secretly a Reward Mo...
- (HITS Authority: 0.0082) PaLM 2 Technical Report
- (HITS Authority: 0.0075) Is ChatGPT a General-Purpose Natural Language Processing Task Solver?
- (HITS Authority: 0.0065) Selection-Inference: Exploiting Large Language Models for Interpretable Log...
- (HITS Authority: 0.0062) Inner Monologue: Embodied Reasoning through Planning with Language Models
- (HITS Authority: 0.0057) Qwen Technical Report
- (HITS Authority: 0.0056) Towards Reasoning in Large Language Models: A Survey
- (HITS Authority: 0.0055) CodeT5+: Open Code Large Language Models for Code Understanding and Generat...
- (HITS Authority: 0.0054) Red Teaming Language Models with Language Models
- (HITS Authority: 0.0053) BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation a...


# Analysis for Window: 2023-2025
**Stats:** Papers: 4766, Edges: 6128
**Best Found DBCV Score:** 0.4546
**Optimal Parameters:** `n_neighbors`: 10, `min_cluster_size`: 25, `min_samples`: 25, `epsilon`: 0.0

### Dominant Topics

- **Topic (ID: 2, Size: 590, Confidence: 0.9789):** language, natural, processing, models, large, clinical, medical, review, using, health, healthcare, learning, chatgpt, intelligence, artificial
- **Topic (ID: 9, Size: 271, Confidence: 0.9251):** language, chatgpt, ai, education, natural, learning, processing, models, artificial, intelligence, large, review, using, chatbot, chatbots
- **Topic (ID: 17, Size: 231, Confidence: 0.8978):** language, models, image, multimodal, vision, visual, generation, learning, text, large, video, understanding, natural, survey, 3d
- **Topic (ID: 24, Size: 207, Confidence: 0.7783):** language, models, large, translation, languages, multilingual, machine, processing, natural, low, arabic, resource, model, survey, english
- **Topic (ID: 4, Size: 174, Confidence: 0.9289):** language, models, large, attacks, privacy, survey, security, llm, adversarial, model, detection, backdoor, learning, based, natural
- **Topic (ID: 8, Size: 173, Confidence: 0.6061):** language, code, models, large, generation, natural, software, llm, using, requirements, engineering, llms, automated, based, study
- **Topic (ID: 3, Size: 163, Confidence: 0.8346):** language, models, protein, large, learning, model, based, using, drug, natural, molecular, prediction, design, transformer, processing
- **Topic (ID: 27, Size: 152, Confidence: 0.9122):** language, models, large, survey, evaluation, model, llms, natural, llm, text, generation, comprehensive, context, learning, challenges
- **Topic (ID: 22, Size: 152, Confidence: 0.9321):** language, knowledge, graph, models, large, graphs, extraction, model, text, information, natural, question, processing, answering, using
- **Topic (ID: 10, Size: 126, Confidence: 0.7266):** intelligence, ai, artificial, language, processing, natural, management, review, role, challenges, driven, learning, machine, financial, applications
- **Topic (ID: 15, Size: 123, Confidence: 0.7347):** analysis, sentiment, language, learning, natural, based, processing, deep, using, classification, text, model, techniques, social, survey
- **Topic (ID: 23, Size: 91, Confidence: 0.8695):** language, reasoning, models, large, natural, survey, symbolic, causal, logical, explanations, model, mathematical, chain, thought, llms
- **Topic (ID: 6, Size: 79, Confidence: 0.6513):** speech, language, audio, models, large, generation, text, survey, natural, model, using, diffusion, processing, synthesis, learning
- **Topic (ID: 26, Size: 67, Confidence: 0.8249):** language, robot, large, models, model, robotic, manipulation, vision, survey, navigation, using, autonomous, planning, ai, action
- **Topic (ID: 28, Size: 62, Confidence: 0.9022):** time, series, forecasting, models, survey, transformer, learning, large, model, language, temporal, prediction, transformers, based, deep
- **Topic (ID: 25, Size: 61, Confidence: 0.9177):** language, agents, large, models, planning, based, llm, agent, multi, model, framework, ai, llms, reasoning, collaboration
- **Topic (ID: 16, Size: 60, Confidence: 0.8745):** detection, language, processing, natural, using, news, learning, fake, based, deep, model, speech, hate, spam, social
- **Topic (ID: 7, Size: 58, Confidence: 0.8239):** language, models, bias, large, fairness, gender, llms, social, natural, mitigating, biases, model, processing, survey, detecting
- **Topic (ID: 32, Size: 55, Confidence: 0.8733):** language, large, models, model, inference, llm, efficient, speculative, decoding, quantization, energy, kv, efficiency, device, llms
- **Topic (ID: 19, Size: 53, Confidence: 0.8091):** sql, language, data, text, large, models, natural, visualization, database, based, survey, tabular, model, ai, querying
- **Topic (ID: 18, Size: 49, Confidence: 0.7810):** recommendation, language, large, models, recommender, survey, systems, based, model, personalized, generation, generative, llm, chatgpt, user
- **Topic (ID: 11, Size: 48, Confidence: 0.8517):** conversational, dialogue, language, models, based, large, conversation, multi, ai, generation, natural, agents, llms, systems, model
- **Topic (ID: 13, Size: 47, Confidence: 0.7701):** language, models, large, human, brain, natural, neural, processing, model, semantic, word, comprehension, eeg, encoding, representations
- **Topic (ID: 0, Size: 47, Confidence: 0.8622):** language, natural, processing, using, learning, analysis, deep, machine, prediction, based, text, sentiment, construction, intelligence, social
- **Topic (ID: 12, Size: 44, Confidence: 0.9534):** emotion, language, models, personality, recognition, emotional, speech, large, chatgpt, based, natural, emotions, analysis, processing, text
- **Topic (ID: 31, Size: 40, Confidence: 0.9717):** tuning, fine, language, models, large, efficient, parameter, low, rank, adaptation, mixture, experts, training, sparse, adaptive
- **Topic (ID: 14, Size: 40, Confidence: 0.8943):** summarization, text, language, abstractive, using, survey, models, review, based, large, learning, generation, natural, automatic, techniques
- **Topic (ID: 20, Size: 39, Confidence: 0.9255):** retrieval, augmented, generation, language, models, survey, large, rag, question, answering, information, generative, evaluation, framework, multi
- **Topic (ID: 21, Size: 38, Confidence: 0.8745):** language, legal, natural, processing, large, models, law, domain, survey, review, case, text, documents, nlp, reasoning
- **Topic (ID: 5, Size: 37, Confidence: 0.8778):** language, large, models, hallucination, hallucinations, llms, survey, based, mitigating, open, vision, generation, detecting, knowledge, layers
- **Topic (ID: 30, Size: 31, Confidence: 0.9970):** models, language, learning, model, dynamics, neural, optimization, deep, bias, diffusion, oscillatory, trained, attention, generative, transformers
- **Topic (ID: 1, Size: 30, Confidence: 0.9548):** language, processing, natural, models, survey, large, learning, deep, challenges, using, based, detection, news, framework, overview
- **Topic (ID: 29, Size: 25, Confidence: 1.0000):** transformers, transformer, long, efficient, context, sequence, modeling, models, attention, faster, range, linear, length, fast, method

### Top 20 Papers by Citation Count

- (Citation Count: 12954.0000) LLaMA: Open and Efficient Foundation Language Models
- (Citation Count: 3800.0000) Direct Preference Optimization: Your Language Model is Secretly a Reward Mo...
- (Citation Count: 3256.0000) DINOv2: Learning Robust Visual Features without Supervision
- (Citation Count: 2659.0000) A Survey of Large Language Models
- (Citation Count: 2098.0000) Efficient Memory Management for Large Language Model Serving with PagedAtte...
- (Citation Count: 1756.0000) Qwen Technical Report
- (Citation Count: 1619.0000) A Survey on Evaluation of Large Language Models
- (Citation Count: 1225.0000) A Survey on Large Language Model based Autonomous Agents
- (Citation Count: 1224.0000) How Does ChatGPT Perform on the United States Medical Licensing Examination...
- (Citation Count: 1178.0000) PaLM 2 Technical Report
- (Citation Count: 1155.0000) G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment
- (Citation Count: 943.0000) Intelligent Clinical Documentation: Harnessing Generative AI for Patient-Ce...
- (Citation Count: 830.0000) Sentiment Analysis
- (Citation Count: 816.0000) A Survey on Hallucination in Large Language Models: Principles, Taxonomy, C...
- (Citation Count: 774.0000) A Brief Overview of ChatGPT: The History, Status Quo and Potential Future D...
- (Citation Count: 760.0000) Unifying Large Language Models and Knowledge Graphs: A Roadmap
- (Citation Count: 755.0000) Evaluating Object Hallucination in Large Vision-Language Models
- (Citation Count: 747.0000) StarCoder: may the source be with you!
- (Citation Count: 702.0000) Abstractive Text Summarization Using GAN
- (Citation Count: 692.0000) Is ChatGPT a General-Purpose Natural Language Processing Task Solver?

### Top 20 Papers by PageRank

- (PageRank: 0.0658) LLaMA: Open and Efficient Foundation Language Models
- (PageRank: 0.0114) A Survey of Large Language Models
- (PageRank: 0.0111) Is ChatGPT a General-Purpose Natural Language Processing Task Solver?
- (PageRank: 0.0059) Direct Preference Optimization: Your Language Model is Secretly a Reward Mo...
- (PageRank: 0.0050) PaLM 2 Technical Report
- (PageRank: 0.0047) Pretraining Language Models with Human Preferences
- (PageRank: 0.0037) A Comprehensive Survey on Pretrained Foundation Models: A History from BERT...
- (PageRank: 0.0035) Efficient Memory Management for Large Language Model Serving with PagedAtte...
- (PageRank: 0.0035) G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment
- (PageRank: 0.0034) Qwen Technical Report
- (PageRank: 0.0034) A Survey on Evaluation of Large Language Models
- (PageRank: 0.0031) How Does ChatGPT Perform on the United States Medical Licensing Examination...
- (PageRank: 0.0030) Large Language Models
- (PageRank: 0.0026) Scaling Transformer to 1M tokens and beyond with RMT
- (PageRank: 0.0026) RWKV: Reinventing RNNs for the Transformer Era
- (PageRank: 0.0024) Augmented Language Models: a Survey
- (PageRank: 0.0024) StarCoder: may the source be with you!
- (PageRank: 0.0022) Natural Language Processing in the Legal Domain
- (PageRank: 0.0022) A Survey on Large Language Model based Autonomous Agents
- (PageRank: 0.0020) Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.3034) LLaMA: Open and Efficient Foundation Language Models
- (HITS Authority: 0.0411) A Survey of Large Language Models
- (HITS Authority: 0.0169) Direct Preference Optimization: Your Language Model is Secretly a Reward Mo...
- (HITS Authority: 0.0156) Qwen Technical Report
- (HITS Authority: 0.0149) PaLM 2 Technical Report
- (HITS Authority: 0.0104) Efficient Memory Management for Large Language Model Serving with PagedAtte...
- (HITS Authority: 0.0096) One Fits All: Power General Time Series Analysis by Pretrained LM
- (HITS Authority: 0.0089) StarCoder: may the source be with you!
- (HITS Authority: 0.0087) Is ChatGPT a General-Purpose Natural Language Processing Task Solver?
- (HITS Authority: 0.0086) Time-LLM: Time Series Forecasting by Reprogramming Large Language Models
- (HITS Authority: 0.0084) HuaTuo: Tuning LLaMA Model with Chinese Medical Knowledge
- (HITS Authority: 0.0079) CodeT5+: Open Code Large Language Models for Code Understanding and Generat...
- (HITS Authority: 0.0077) A Survey on Evaluation of Large Language Models
- (HITS Authority: 0.0068) Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond
- (HITS Authority: 0.0067) G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment
- (HITS Authority: 0.0059) A Survey on Large Language Model based Autonomous Agents
- (HITS Authority: 0.0058) Augmented Language Models: a Survey
- (HITS Authority: 0.0057) ChatCAD: Interactive Computer-Aided Diagnosis on Medical Image using Large ...
- (HITS Authority: 0.0056) PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark fo...
- (HITS Authority: 0.0055) Language is All a Graph Needs


# Analysis for Window: 2024-2026
**Stats:** Papers: 2760, Edges: 898
**Best Found DBCV Score:** 0.5208
**Optimal Parameters:** `n_neighbors`: 35, `min_cluster_size`: 50, `min_samples`: 25, `epsilon`: 0.5

### Dominant Topics

- **Topic (ID: 1, Size: 2300, Confidence: 0.9974):** language, models, large, natural, learning, processing, model, survey, based, llm, generation, llms, using, ai, analysis
- **Topic (ID: 0, Size: 420, Confidence: 0.9946):** language, natural, models, processing, large, review, learning, medical, using, clinical, model, healthcare, protein, applications, systematic

### Top 20 Papers by Citation Count

- (Citation Count: 943.0000) Intelligent Clinical Documentation: Harnessing Generative AI for Patient-Ce...
- (Citation Count: 830.0000) Sentiment Analysis
- (Citation Count: 702.0000) Abstractive Text Summarization Using GAN
- (Citation Count: 400.0000) GPT-4 passes the bar exam
- (Citation Count: 394.0000) Large Language Models: A Survey
- (Citation Count: 388.0000) OLMo: Accelerating the Science of Language Models
- (Citation Count: 216.0000) AI-Driven Proactive Cloud Application Data Access Security
- (Citation Count: 215.0000) Statistical mechanics of deep learning
- (Citation Count: 210.0000) SegMamba: Long-range Sequential Modeling Mamba For 3D Medical Image Segment...
- (Citation Count: 205.0000) TrustLLM: Trustworthiness in Large Language Models
- (Citation Count: 181.0000) PMC-LLaMA: toward building open-source language models for medicine
- (Citation Count: 177.0000) A Survey on Large Language Models for Code Generation
- (Citation Count: 169.0000) SliceGPT: Compress Large Language Models by Deleting Rows and Columns
- (Citation Count: 168.0000) Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Clos...
- (Citation Count: 149.0000) Autoencoders and their applications in machine learning: a survey
- (Citation Count: 149.0000) Evaluating Text-to-Visual Generation with Image-to-Text Generation
- (Citation Count: 144.0000) Transformative Potential of AI in Healthcare: Definitions, Applications, an...
- (Citation Count: 136.0000) Qwen2-Audio Technical Report
- (Citation Count: 135.0000) Chatbots and Large Language Models in Radiology: A Practical Primer for Cli...
- (Citation Count: 125.0000) Security and Privacy Challenges of Large Language Models: A Survey

### Top 20 Papers by PageRank

- (PageRank: 0.0052) TrustLLM: Trustworthiness in Large Language Models
- (PageRank: 0.0036) OLMo: Accelerating the Science of Language Models
- (PageRank: 0.0032) Implicit Optimization Bias of Next-token Prediction in Linear Models
- (PageRank: 0.0032) Large Language Models: A Survey
- (PageRank: 0.0032) Evaluating Text-to-Visual Generation with Image-to-Text Generation
- (PageRank: 0.0030) GenAI-Bench: Evaluating and Improving Compositional Text-to-Visual Generati...
- (PageRank: 0.0027) SpeechVerse: A Large-scale Generalizable Audio Language Model
- (PageRank: 0.0019) SliceGPT: Compress Large Language Models by Deleting Rows and Columns
- (PageRank: 0.0019) Efficiency Optimization of Large-Scale Language Models Based on Deep Learni...
- (PageRank: 0.0018) Mechanics of Next Token Prediction with Self-Attention
- (PageRank: 0.0017) Qwen2-Audio Technical Report
- (PageRank: 0.0017) Implicit Geometry of Next-token Prediction: From Language Sparsity Patterns...
- (PageRank: 0.0016) PMC-LLaMA: toward building open-source language models for medicine
- (PageRank: 0.0016) ShieldGPT: An LLM-based Framework for DDoS Mitigation
- (PageRank: 0.0015) CAMEx: Curvature-aware Merging of Experts
- (PageRank: 0.0015) Self-Exploring Language Models: Active Preference Elicitation for Online Al...
- (PageRank: 0.0015) Exploratory Preference Optimization: Harnessing Implicit Q*-Approximation f...
- (PageRank: 0.0015) MoLEx: Mixture of Layer Experts for Finetuning with Sparse Upcycling
- (PageRank: 0.0015) Word-specific tonal realizations in Mandarin
- (PageRank: 0.0015) Time and thyme again: Connecting English spoken word duration to models of ...

### Top 20 Papers by HITS Authority

- (HITS Authority: 0.4782) BitDistiller: Unleashing the Potential of Sub-4-Bit LLMs via Self-Distillat...
- (HITS Authority: 0.4424) DB-LLM: Accurate Dual-Binarization for Efficient LLMs
- (HITS Authority: 0.0543) SliceGPT: Compress Large Language Models by Deleting Rows and Columns
- (HITS Authority: 0.0098) ARB-LLM: Alternating Refined Binarizations for Large Language Models
- (HITS Authority: 0.0028) SLEB: Streamlining LLMs through Redundancy Verification and Elimination of ...
- (HITS Authority: 0.0015) Security and Privacy Challenges of Large Language Models: A Survey
- (HITS Authority: 0.0011) EdgeLLM: Fast On-Device LLM Inference With Speculative Decoding
- (HITS Authority: 0.0008) EdgeShard: Efficient LLM Inference via Collaborative Edge Computing
- (HITS Authority: 0.0007) A Survey on Mixture of Experts in Large Language Models
- (HITS Authority: 0.0007) Evaluation of Retrieval-Augmented Generation: A Survey
- (HITS Authority: 0.0006) PMC-LLaMA: toward building open-source language models for medicine
- (HITS Authority: 0.0006) Mobile-LLaMA: Instruction Fine-Tuning Open-Source LLM for Network Analysis ...
- (HITS Authority: 0.0006) Harnessing LLMs for API Interactions: A Framework for Classification and Sy...
- (HITS Authority: 0.0006) Generative AI Meets Semantic Communication: Evolution and Revolution of Com...
- (HITS Authority: 0.0006) Personalized Wireless Federated Learning for Large Language Models
- (HITS Authority: 0.0006) A Survey on Large Language Models for Communication, Network, and Service M...
- (HITS Authority: 0.0006) Distributed Foundation Models for Multi-Modal Learning in 6G Wireless Netwo...
- (HITS Authority: 0.0006) Multilingual Brain Surgeon: Large Language Models Can Be Compressed Leaving...
- (HITS Authority: 0.0004) SpeechVerse: A Large-scale Generalizable Audio Language Model
- (HITS Authority: 0.0003) WavLLM: Towards Robust and Adaptive Speech Large Language Model

