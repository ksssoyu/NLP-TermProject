import json
import networkx as nx
import ast
from collections import defaultdict

# ğŸ”§ íŒŒì¼ ê²½ë¡œ ì„¤ì •
GRAPH_JSON = "citation_graph_with_cluster_v2.json"    # ì…ë ¥ íŒŒì¼: ë…¼ë¬¸ + í´ëŸ¬ìŠ¤í„° + citation ì •ë³´
OUTPUT_JSON = "cluster_author_pagerank.json"          # ì¶œë ¥ íŒŒì¼: í´ëŸ¬ìŠ¤í„°ë³„ ì €ì PageRank ê²°ê³¼
TOP_K_AUTHORS = 5                                     # í´ëŸ¬ìŠ¤í„°ë³„ ì¶”ì¶œí•  ìƒìœ„ ì €ì ìˆ˜

# ğŸ“¥ JSON íŒŒì¼ ë¡œë“œ
with open(GRAPH_JSON, "r", encoding="utf-8") as f:
    data = json.load(f)

nodes = data["nodes"]  # ë…¼ë¬¸ ë…¸ë“œ ì •ë³´
links = data["links"]  # ë…¼ë¬¸ ê°„ citation ì •ë³´

# ğŸ“Œ í´ëŸ¬ìŠ¤í„°ë³„ ë…¼ë¬¸ ë° ì €ì ì •ë³´ ìˆ˜ì§‘
cluster_to_papers = defaultdict(list)  # í´ëŸ¬ìŠ¤í„° ID â†’ ë…¼ë¬¸ ID ë¦¬ìŠ¤íŠ¸
paper_authors = {}                     # ë…¼ë¬¸ ID â†’ ì €ì ë¦¬ìŠ¤íŠ¸
for node in nodes:
    pid = node["id"]
    group = node["group"]  # í´ëŸ¬ìŠ¤í„° ID
    authors = ast.literal_eval(node.get("authors", "[]"))  # ë¬¸ìì—´ì„ ì‹¤ì œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    cluster_to_papers[group].append(pid)
    paper_authors[pid] = authors

# ğŸ“Œ í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ citation ë§í¬ ìˆ˜ì§‘
edges_by_cluster = defaultdict(list)
for link in links:
    src = link["source"]
    tgt = link["target"]
    weight = link.get("weight", 1.0)

    # ê°ê°ì˜ ë…¼ë¬¸ì´ ì†í•œ í´ëŸ¬ìŠ¤í„° ID í™•ì¸
    src_group = next((node["group"] for node in nodes if node["id"] == src), None)
    tgt_group = next((node["group"] for node in nodes if node["id"] == tgt), None)

    # ë™ì¼ í´ëŸ¬ìŠ¤í„° ë‚´ citationë§Œ ì €ì¥
    if src_group == tgt_group and src_group is not None:
        edges_by_cluster[src_group].append((src, tgt, weight))

# ğŸ“Š í´ëŸ¬ìŠ¤í„°ë³„ ì €ì PageRank ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
author_rank_by_cluster = {}

# ğŸ” í´ëŸ¬ìŠ¤í„°ë³„ë¡œ PageRank ìˆ˜í–‰
for cluster_id in sorted(cluster_to_papers.keys()):
    paper_ids = set(cluster_to_papers[cluster_id])         # í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì˜ ë…¼ë¬¸ ID ì§‘í•©
    edges = edges_by_cluster.get(cluster_id, [])           # ë‚´ë¶€ citation ë§í¬

    # í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ ë…¼ë¬¸ìœ¼ë¡œ Directed Graph ìƒì„±
    G = nx.DiGraph()
    G.add_nodes_from(paper_ids)
    for src, tgt, w in edges:
        G.add_edge(src, tgt, weight=w)

    # ë¹ˆ ê·¸ë˜í”„ëŠ” ë¶„ì„í•˜ì§€ ì•ŠìŒ
    if len(G) == 0:
        continue

    # ğŸ“Œ ë…¼ë¬¸ ë‹¨ìœ„ PageRank ê³„ì‚°
    pr = nx.pagerank(G, weight="weight")

    # ğŸ“Œ ë…¼ë¬¸ PageRankë¥¼ ì €ìì—ê²Œ ëˆ„ì 
    author_scores = defaultdict(float)
    for pid, score in pr.items():
        for author in paper_authors.get(pid, []):
            author_scores[author] += score  # ë‹¤ì €ì ë…¼ë¬¸ì€ ëª¨ë‘ì—ê²Œ ë™ì¼ ì ìˆ˜ ë¶€ì—¬

    # ğŸ”„ ì „ì²´ ëˆ„ì  ì ìˆ˜ë¥¼ 1ë¡œ ì •ê·œí™” (ìƒëŒ€ì  ë¹„êµ ê°€ëŠ¥í•˜ê²Œ í•¨)
    total_score = sum(author_scores.values())
    if total_score > 0:
        for author in author_scores:
            author_scores[author] /= total_score

    # ğŸ” ìƒìœ„ ì €ì Këª… ì¶”ì¶œ (PageRank ê¸°ì¤€ ì •ë ¬)
    top_authors = sorted(author_scores.items(), key=lambda x: x[1], reverse=True)[:TOP_K_AUTHORS]

    # ê²°ê³¼ ì €ì¥: { cluster_id: [{author: str, score: float}, ...] }
    author_rank_by_cluster[cluster_id] = [
        {"author": author, "score": score} for author, score in top_authors
    ]

# ğŸ“¤ ì „ì²´ ê²°ê³¼ JSON íŒŒì¼ë¡œ ì €ì¥
with open(OUTPUT_JSON, "w", encoding="utf-8") as f:
    json.dump(author_rank_by_cluster, f, ensure_ascii=False, indent=2)

print(f"âœ… í´ëŸ¬ìŠ¤í„°ë³„ ì €ì PageRank ì €ì¥ ì™„ë£Œ: {OUTPUT_JSON}")
