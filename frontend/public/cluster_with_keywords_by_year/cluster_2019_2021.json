{
  "window": "2019_2021",
  "num_clusters": 11,
  "cluster_details": {
    "0": [
      {
        "id": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
        "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
      },
      {
        "id": "39e801ca0dbc69c3697f118e24dac964abb63d4a",
        "title": "The CommitmentBank: Investigating projection in naturally occurring discourse"
      },
      {
        "id": "4b6f6669060367ae8f58e8a749bde085102f6298",
        "title": "Fair Is Better than Sensational: Man Is to Doctor as Woman Is to Doctor"
      },
      {
        "id": "07c53193b50aa0b108b14b9edfbef64ea1e9119b",
        "title": "Story Ending Prediction by Transferable BERT"
      },
      {
        "id": "19281b9ecdb5c07a93423a506627ab9d9b0cf039",
        "title": "Learning and Evaluating General Linguistic Intelligence"
      },
      {
        "id": "f6fe240f1e9348f92df538df4e6c035ac0ced4a0",
        "title": "Cyberbullying Detection: Hybrid Models Based on Machine Learning and Natural Language Processing Techniques"
      },
      {
        "id": "7d6abf2e0ea46125e881a48d5bd8f84de2e58f80",
        "title": "CVSS-BERT: Explainable Natural Language Processing to Determine the Severity of a Computer Security Vulnerability from its Description"
      },
      {
        "id": "379ae767d3a49a32c5223b450e89854a369c5f72",
        "title": "Natural language processing models that automate programming will transform chemistry research and teaching"
      },
      {
        "id": "e50749776ec7c16de4f14b56d5d904285e17b8a1",
        "title": "Exploring Natural Language Processing in Construction and Integration with Building Information Modeling: A Scientometric Analysis"
      },
      {
        "id": "7cf0d71014b6a1a5397d37481c91efbb1a5660ea",
        "title": "A Comparison of Natural Language Processing and Machine Learning Methods for Phishing Email Detection"
      },
      {
        "id": "bc25b9159a8dbe0524ed29bf9e99742c61c12627",
        "title": "Stress detection using natural language processing and machine learning over social interactions"
      },
      {
        "id": "89d17b41448ab85a13931eb72482eb7017063199",
        "title": "Gender Bias and Under-Representation in Natural Language Processing Across Human Languages"
      },
      {
        "id": "906e8bae5249b8581ed5ae558494bf6b87911ff8",
        "title": "A Review of Bangla Natural Language Processing Tasks and the Utility of Transformer Models"
      },
      {
        "id": "0eae931c2d419a926508b9f46368a4538c258d4a",
        "title": "Linking Free Text Documentation of Functioning and Disability to the ICF With Natural Language Processing"
      },
      {
        "id": "1deab15a5a30c1da962804527c1139f9d38c5f5b",
        "title": "A Scoping Review of Publicly Available Language Tasks in Clinical Natural Language Processing"
      },
      {
        "id": "aca2b2c722ed6ca4d2d19def0d926ddeb0011d20",
        "title": "BERT-Based Natural Language Processing of Drug Labeling Documents: A Case Study for Classifying Drug-Induced Liver Injury Risk"
      },
      {
        "id": "b8db1ddcae0820e84f9f3aafbbc6875cd7565329",
        "title": "LINDA: Unsupervised Learning to Interpolate in Natural Language Processing"
      },
      {
        "id": "6015ffe3678e56704caff26c4455d8e2a5207d3d",
        "title": "Deep-Learning-Based Natural Language Processing of Serial Free-Text Radiological Reports for Predicting Rectal Cancer Patient Survival"
      },
      {
        "id": "95d87b6be48c8ad22ea8a5ff3d5b787b946b6463",
        "title": "A Review of Recent Work in Transfer Learning and Domain Adaptation for Natural Language Processing of Electronic Health Records"
      },
      {
        "id": "1067c44e473b6998f89e13f0d4c0de730def43f0",
        "title": "SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing"
      },
      {
        "id": "973217ce9681b7627da01075f0707e812e9a55c0",
        "title": "Open Aspect Target Sentiment Classification with Natural Language Prompts"
      },
      {
        "id": "d54f0b453f205f68e24e1b3515c846e23aca196f",
        "title": "A Systematic Survey of Text Worlds as Embodied Natural Language Environments"
      },
      {
        "id": "5883c3dbd4d46aa8cc35554ad54388a64636c1e7",
        "title": "FarSick: A Persian Semantic Textual Similarity And Natural Language Inference Dataset"
      },
      {
        "id": "58ad7dd2bba99329bc41363f9741aa01c18e2546",
        "title": "Evaluating Off-the-Shelf Machine Listening and Natural Language Models for Automated Audio Captioning"
      },
      {
        "id": "ebe259796870ebccf26577044d0087884209b884",
        "title": "w2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training"
      },
      {
        "id": "66ccb2efc2c9d813e82d82db471426b7358bfe07",
        "title": "Survey of Post-OCR Processing Approaches"
      },
      {
        "id": "d92e0443768ec3715205cb232ef1a1917372b0af",
        "title": "ESPnet-SLU: Advancing Spoken Language Understanding Through ESPnet"
      },
      {
        "id": "7e3deabd44eccb0fe2823d8cecf1e182efeeb0f6",
        "title": "Automatic Detection and Assessment of Alzheimer Disease Using Speech and Language Technologies in Low-Resource Scenarios"
      },
      {
        "id": "3979141ef17f9bd2b8a5c290e33775f90a14154c",
        "title": "DziriBERT: a Pre-trained Language Model for the Algerian Dialect"
      },
      {
        "id": "4c95fe3fa18dc319bb4cd7d76491953dbbb3efe1",
        "title": "Deep Learning Methods for Sign Language Translation"
      },
      {
        "id": "92cc3ad15df772b41cb1fb6c6d1eddbdadd4043e",
        "title": "TopicBERT: A Topic-Enhanced Neural Language Model Fine-Tuned for Sentiment Classification"
      },
      {
        "id": "955953e2202edd7ba93443c4b80d20070fead872",
        "title": "Using Language Model to Bootstrap Human Activity Recognition Ambient Sensors Based in Smart Homes"
      },
      {
        "id": "8c11748b8dc82e85e519adfdd706c826e3d8c997",
        "title": "Aspect-Based Sentiment Analysis in Hindi Language by Ensembling Pre-Trained mBERT Models"
      },
      {
        "id": "62da76a8dbff4de50495be2f4746f25c4cd7ac0c",
        "title": "CLIN-X: pre-trained language models and a study on cross-task transfer for concept extraction in the clinical domain"
      },
      {
        "id": "503fc0edd883e8ddaa6c542eb47c45669c276864",
        "title": "Epigenomic language models powered by Cerebras"
      },
      {
        "id": "677f0b5c01c16565a6c802ad7d253928fa6ae8ec",
        "title": "MultiModal Language Modelling on Knowledge Graphs for Deep Video Understanding"
      },
      {
        "id": "c3ea8eb80bc8ca0b21efa273b9e4a9fd059c65be",
        "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification"
      },
      {
        "id": "7d23c83d58d1d3d4cdd67514a32e549df3f5f0e3",
        "title": "Semi-supervised Visual Feature Integration for Language Models through Sentence Visualization"
      },
      {
        "id": "216d093cb2ad81bf55c21dbce2217f2b9032e67b",
        "title": "Just Train Twice: Improving Group Robustness without Training Group Information"
      },
      {
        "id": "dca4d9abbc82e57dfa52f932e893d467a63e0682",
        "title": "Transformers4Rec: Bridging the Gap between NLP and Sequential / Session-Based Recommendation"
      },
      {
        "id": "62be538a25a6ca7ebf1b1ac9f338ad01fdc481fb",
        "title": "Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning"
      },
      {
        "id": "786f7608e1eed7cfac18b9ad379b8ed0c6d3414f",
        "title": "Detection of Hate Speech using BERT and Hate Speech Word Embedding with Deep Model"
      },
      {
        "id": "d90f300320d970dc8e1f4ef4381bbb1597737a22",
        "title": "Ten Years of BabelNet: A Survey"
      },
      {
        "id": "ce8af20d0bf7483484840cf6d4e0bb725d29ee48",
        "title": "A Transformer-Based Approach to Multilingual Fake News Detection in Low-Resource Languages"
      },
      {
        "id": "5b0926522572161dd10fb35b229b3dfb2014faee",
        "title": "Balancing out Bias: Achieving Fairness Through Balanced Training"
      },
      {
        "id": "8cf3a454556060d6e9aa86dbabf221bd10bf9759",
        "title": "On the Effectiveness of Transfer Learning for Code Search"
      },
      {
        "id": "537c72a77bce81310fe60b8c3b6cfe8f769d7f68",
        "title": "Multi-View Self-Attention Based Transformer for Speaker Recognition"
      },
      {
        "id": "ba805d34f762df65f499183f2010647829351def",
        "title": "Scientia Potentia Est—On the Role of Knowledge in Computational Argumentation"
      },
      {
        "id": "c14533475524ff9ef092df71b4f3f6f5050bc86f",
        "title": "DOZEN: Cross-Domain Zero Shot Named Entity Recognition with Knowledge Graph"
      },
      {
        "id": "3c15628bfb892ab67a66353e072a84c24f4cef5b",
        "title": "How Different Text-preprocessing Techniques Using The BERT Model Affect The Gender Profiling of Authors"
      },
      {
        "id": "9c58df84d6eddd4830a430dc5e164429cf89a79a",
        "title": "Improving the Performance of Automated Audio Captioning via Integrating the Acoustic and Semantic Information"
      },
      {
        "id": "b21e1ffeae34d878e21699d142f37b200688ddbf",
        "title": "Identification of Bias Against People with Disabilities in Sentiment Analysis and Toxicity Detection Models"
      },
      {
        "id": "19f03f571cf84559e8844de5e9dcc5b82fcdbed5",
        "title": "Knowledge Distillation from BERT Transformer to Speech Transformer for Intent Classification"
      },
      {
        "id": "d7af5edf573116367cadd048b213a4f63e8367c9",
        "title": "How to transfer algorithmic reasoning knowledge to learn new algorithms?"
      },
      {
        "id": "638cedba3635bdd7d18f97246c40ad3a2201d354",
        "title": "A Systematic Literature Review of Automated ICD Coding and Classification Systems using Discharge Summaries"
      },
      {
        "id": "b3b259080f5069042b96347b258ceabd40e8f377",
        "title": "Part-of-Speech Tagging with Rule-Based Data Preprocessing and Transformer"
      },
      {
        "id": "10b0ef66f8010fef53c3aa51c43b73e121ba7e6d",
        "title": "DILBERT: Customized Pre-Training for Domain Adaptation with Category Shift, with an Application to Aspect Extraction"
      },
      {
        "id": "70a3b41f00372d782262a803620e66901b320405",
        "title": "Stock Price Prediction Using Sentiment Analysis"
      },
      {
        "id": "7a8fd46975183af80f8c0f38431ca0be77216d17",
        "title": "Word Representation Learning Based on Bidirectional GRUs With Drop Loss for Sentiment Classification"
      },
      {
        "id": "5d3cacb8735a6c45e4df0b4e4b75a754d35177eb",
        "title": "Countering Online Hate Speech: An NLP Perspective"
      },
      {
        "id": "fb95e7dd04bd4437b64a2b20b7c0b68fc0f2d42e",
        "title": "Privacy enabled Financial Text Classification using Differential Privacy and Federated Learning"
      },
      {
        "id": "f7ac2956642e58b8ed6290d0060763bbb5ddd21e",
        "title": "MuVER: Improving First-Stage Entity Retrieval with Multi-View Entity Representations"
      },
      {
        "id": "78a0d6c9899be720ec8052a8a593885bdd6e7cce",
        "title": "Data Augmentation for Low-Resource Named Entity Recognition Using Backtranslation"
      },
      {
        "id": "6711479f03469dcf58feae310ada783e06974a50",
        "title": "Transformer-Encoder-GRU (T-E-GRU) for Chinese Sentiment Analysis on Chinese Comment Text"
      },
      {
        "id": "3e7972eb3468848c648941342da4535e5e5df0b4",
        "title": "Contributions of Transformer Attention Heads in Multi- and Cross-lingual Tasks"
      },
      {
        "id": "d1abef2ddae74fbcbbd27111b7e859df48006b45",
        "title": "MELHISSA: a multilingual entity linking architecture for historical press articles"
      },
      {
        "id": "25b3aacaa9b98f0e0d41588cf0e36efe4fb7dc43",
        "title": "BERTax: taxonomic classification of DNA sequences with Deep Neural Networks"
      },
      {
        "id": "2416459e2ff3124c17af353df582b41beaceeb59",
        "title": "BERT is Robust! A Case Against Synonym-Based Adversarial Examples in Text Classification"
      },
      {
        "id": "f08fae8d475982defac514fb773f059d1353d6d2",
        "title": "CANs: Coupled-Attention Networks for Sarcasm Detection on Social Media"
      },
      {
        "id": "1297f087e4d539cf7b322641f98e4a15a90b6bc1",
        "title": "Boosting Cross-Lingual Transfer via Self-Learning with Uncertainty Estimation"
      },
      {
        "id": "ada278151c8d1ed1449495c20c2102bc4f443cd7",
        "title": "Automatic Diagnosis and Prediction of Cognitive Decline Associated with Alzheimer’s Dementia through Spontaneous Speech"
      },
      {
        "id": "9580fa38e6c5482c30a6761193464bc8fdd8834b",
        "title": "VSEC: Transformer-based Model for Vietnamese Spelling Correction"
      },
      {
        "id": "9b1263b047b13276f03030670da8175677102c74",
        "title": "Towards Document-Level Paraphrase Generation with Sentence Rewriting and Reordering"
      },
      {
        "id": "4f467fdbd4db10ad65109df5e50e0888776b9d05",
        "title": "Speech Representation Learning Through Self-supervised Pretraining And Multi-task Finetuning"
      },
      {
        "id": "1db2db07718fc635787303be78af34ac6a46e83d",
        "title": "BioVerbNet: a large semantic-syntactic classification of verbs in biomedicine"
      },
      {
        "id": "b2ccf3205c2f482d2fa769670a999f45aef4db61",
        "title": "Extraction and Visualization of Tourist Attraction Semantics from Travel Blogs"
      },
      {
        "id": "e8cd5269c8ffd37356a756af2204ba64773881d5",
        "title": "Detecting Fake Online Reviews using Fine-tuned BERT"
      },
      {
        "id": "c6935f3f839bf36a406f55aa807df14b771f4c94",
        "title": "An unsupervised framework for tracing textual sources of moral change"
      },
      {
        "id": "bc8b65a7358ff2a3c1026a21bf8615216f5fa012",
        "title": "Detecting Requirements Smells With Deep Learning: Experiences, Challenges and Future Work"
      },
      {
        "id": "9f54b02d32835a6dc977a335444df707494763ec",
        "title": "Proto: A Neural Cocktail for Generating Appealing Conversations"
      },
      {
        "id": "04bac77744499c79650daeffa37d0f641e17de7f",
        "title": "FHAC at GermEval 2021: Identifying German toxic, engaging, and fact-claiming comments with ensemble learning"
      },
      {
        "id": "f9061f28dcbacee9c2a876be8985760086d8c680",
        "title": "Social Analysis of Young Basque Speaking Communities in Twitter"
      },
      {
        "id": "b75131ed4f50fa556ff0ad91c970a2df38b24e5f",
        "title": "How May I Help You? Using Neural Text Simplification to Improve Downstream NLP Tasks"
      },
      {
        "id": "1c4bb3f8b2683cbd9c0d1230132364d16c39fb89",
        "title": "Using Transfer Learning to contextually Optimize Optical Character Recognition (OCR) output and perform new Feature Extraction on a digitized cultural and historical dataset"
      },
      {
        "id": "b65678ab20315f2a6ed256155409214cba07c677",
        "title": "Integrated Semantic and Phonetic Post-correction for Chinese Speech Recognition"
      },
      {
        "id": "ad7673befd591a868a24f1f309f700ba0a846caa",
        "title": "Joint Chinese Word Segmentation and Part-of-speech Tagging via Two-stage Span Labeling"
      },
      {
        "id": "991adf5065c2f0cb52a7273edf2773453066f857",
        "title": "Study of Positional Encoding Approaches for Audio Spectrogram Transformers"
      },
      {
        "id": "a521707521dd3348d4f69e4fbceb07f8fe6fe118",
        "title": "Identifying Similar Test Cases That Are Specified in Natural Language"
      },
      {
        "id": "2569a7309142e40815cf556b6417059df9abbda8",
        "title": "Protecting Intellectual Property of Language Generation APIs with Lexical Watermark"
      },
      {
        "id": "b42d20ec9580ebd76860890a1d7a7fdcc742677e",
        "title": "Modeling Protein Using Large-scale Pretrain Language Model"
      },
      {
        "id": "9fecc1d7e0c5ff9c4789a45ff05509079b7c81c1",
        "title": "A Review of Text Style Transfer Using Deep Learning"
      },
      {
        "id": "37caf49db601f8017a910a1b5215d103316f2f42",
        "title": "Uncertainty-Aware Reliable Text Classification"
      },
      {
        "id": "6409fc5351fd84289875926b19bb16cb734ddbd5",
        "title": "Optimal Deep Neural Network-Based Model for Answering Visual Medical Question"
      },
      {
        "id": "630a5dd9798b9ee35be09f152a36bf72d9f333a3",
        "title": "A critical review of state‐of‐the‐art chatbot designs and applications"
      },
      {
        "id": "04da44b70c675dc921b0d65425666da1d920210e",
        "title": "A Text-Based Hybrid Approach for Multiple Emotion Detection Using Contextual and Semantic Analysis"
      },
      {
        "id": "dfbed20d72cb8d72c41d8482944623e033638617",
        "title": "DeepNote-GNN: predicting hospital readmission using clinical notes and patient network"
      },
      {
        "id": "8bd130a5531622d58f819db4cab743a83eae90e6",
        "title": "Natural Language Processing for Requirements Engineering"
      },
      {
        "id": "b8caee15c58a7dc98a7bc13a978be261903721e6",
        "title": "Accelerating Mixed Methods Research With Natural Language Processing of Big Text Data"
      },
      {
        "id": "6fc26fff276e34685e0f55f2dc73cb1bceafa2f2",
        "title": "Monitoring COVID-19 pandemic through the lens of social media using natural language processing and machine learning"
      },
      {
        "id": "c79a5856fa4840a0df960ec366526ea3306a4a55",
        "title": "Advancing natural language processing (NLP) applications of morphologically rich languages with bidirectional encoder representations from transformers (BERT): an empirical case study for Turkish"
      },
      {
        "id": "237574d9f45bbb7278156ea602f2f5b726cb317d",
        "title": "Automatic Classification of the Korean Triage Acuity Scale in Simulated Emergency Rooms Using Speech Recognition and Natural Language Processing: a Proof of Concept Study"
      },
      {
        "id": "362c711845aea227a2f461ffaa86664ae7b7631f",
        "title": "Natural language processing for urban research: A systematic review"
      },
      {
        "id": "6e9c5660c8aec1c98bfb04e211bf2878d3c60abe",
        "title": "Natural Language Processing through BERT for Identifying Gender-Based Violence Messages on Social Media"
      },
      {
        "id": "8b28d9e3ca408b8a41d32f8bd4da7fbbd4f12a4b",
        "title": "Towards Zero-Shot Knowledge Distillation for Natural Language Processing"
      },
      {
        "id": "a0c40c5bf41c7bbb95014132d25f99ac15b2d0d9",
        "title": "Survey on reinforcement learning for language processing"
      },
      {
        "id": "dc551a804c50cc9f1952926ae4a6365db61d8fc4",
        "title": "A survey on extraction of causal relations from natural language text"
      },
      {
        "id": "cfd7ee17c22692834677400dd04b6c3f93cb515e",
        "title": "Dataset of Natural Language Queries for E-Commerce"
      },
      {
        "id": "d8e81e80490113434f7ac338c5f8d5a23f05a3de",
        "title": "SUPERB: Speech processing Universal PERformance Benchmark"
      },
      {
        "id": "ff9d04fc15a2c52d982b5b7daa787a373ed7f899",
        "title": "Differential Privacy for Text Analytics via Natural Text Sanitization"
      },
      {
        "id": "3be3146737c4b83cab1b754beafa738c1f941bf0",
        "title": "Innovative Bert-Based Reranking Language Models for Speech Recognition"
      },
      {
        "id": "d4257644a8a01eca6ad25c0ba6f6d014f7bf9a8b",
        "title": "A Comparative Study of Using Pre-trained Language Models for Toxic Comment Classification"
      },
      {
        "id": "ada0e2e476523714a5109c8bb19588140e2314e7",
        "title": "Core Challenges in Embodied Vision-Language Planning"
      },
      {
        "id": "6fefb9bdce7c70f473574edc3ded714680030d2f",
        "title": "On the Importance of Effectively Adapting Pretrained Language Models for Active Learning"
      },
      {
        "id": "af1bd2bd9ded6a729a2ee89d6caac14d7ccd9cfd",
        "title": "Towards offensive language detection and reduction in four Software Engineering communities"
      },
      {
        "id": "f36e2d783a88ea984e39c89b44de4e843b5c8df2",
        "title": "Where are we in semantic concept extraction for Spoken Language Understanding?"
      },
      {
        "id": "52c0dd1f81e3d3693f41c3068cf37d5e5fbfa2d0",
        "title": "Does injecting linguistic structure into language models lead to better alignment with brain recordings?"
      },
      {
        "id": "a4bc44a41b0ddfb70d3a1a189127991cd3d68b7c",
        "title": "Correcting Automated and Manual Speech Transcription Errors using Warped Language Models"
      },
      {
        "id": "2d27fc841823364561a6c8afae27b246bec9c6d9",
        "title": "Graph Enhanced Query Rewriting for Spoken Language Understanding System"
      },
      {
        "id": "722ad6ac92286507437b31486f47987d6ece05c9",
        "title": "BEiT: BERT Pre-Training of Image Transformers"
      },
      {
        "id": "6995aff0c181ef6c8236b7e9cc27af8ddcf935a1",
        "title": "The first large scale collection of diverse Hausa language datasets"
      },
      {
        "id": "c97e2fc4640536cf3f7ac46d97306bc71fbb9cda",
        "title": "Tuning Language Representation Models for Classification of Turkish News"
      },
      {
        "id": "80ad370f4e4b537e666f9f8acfeb9c7f628efbf3",
        "title": "Self-Contextualized Attention for Abusive Language Identification"
      },
      {
        "id": "c07651110d3b98b63607557b57808d15d99013dd",
        "title": "ProteinBERT: a universal deep-learning model of protein sequence and function"
      },
      {
        "id": "3dcfa05a1c162e6cab927c5b08d0444f7b6691f4",
        "title": "Probing Classifiers: Promises, Shortcomings, and Advances"
      },
      {
        "id": "2d00798b8a7d979c925901e9faa5fe4360030ca2",
        "title": "Self-Supervised Learning on Graphs: Contrastive, Generative, or Predictive"
      },
      {
        "id": "98bb75dcb7dfe8e675781fe2008170e8f00a5dee",
        "title": "FEVEROUS: Fact Extraction and VERification Over Unstructured and Structured information"
      },
      {
        "id": "0ab855d5a81fdcb33a884465df6598570a1d0a21",
        "title": "Locate and Label: A Two-stage Identifier for Nested Named Entity Recognition"
      },
      {
        "id": "811d6182f4a6152782f1c3f67fd4bdbd6bf811ff",
        "title": "Hyperbolic Deep Neural Networks: A Survey"
      },
      {
        "id": "36b9d0f8610a82fd25854889d9327a04da4ff8fd",
        "title": "MST: Masked Self-Supervised Transformer for Visual Representation"
      },
      {
        "id": "494b06f4c12952abe582e91e94513814a68738de",
        "title": "Towards generalisable hate speech detection: a review on obstacles and solutions"
      },
      {
        "id": "93cef0465c9632c0f8de1a48c7014b4d20813b85",
        "title": "Non-invasive Self-attention for Side Information Fusion in Sequential Recommendation"
      },
      {
        "id": "6563251e69e4378c189d0a0c94d8d19508d552c8",
        "title": "MathBERT: A Pre-Trained Model for Mathematical Formula Understanding"
      },
      {
        "id": "df157cb42b574c3f46b269504c18375bfa5bc5b1",
        "title": "FairFil: Contrastive Neural Debiasing Method for Pretrained Text Encoders"
      },
      {
        "id": "ef8ebdc6892648c61c7803a99373a47d96373294",
        "title": "Bridging Towers of Multi-task Learning with a Gating Mechanism for Aspect-based Sentiment Analysis and Sequential Metaphor Identification"
      },
      {
        "id": "16a8e329c06b4c6f61762da7fa77a84bf3e12dca",
        "title": "Model Extraction and Adversarial Transferability, Your BERT is Vulnerable!"
      },
      {
        "id": "79a05e01b2eb5b8ab006f57b9a0cb7843c77f719",
        "title": "SpanEmo: Casting Multi-label Emotion Classification as Span-prediction"
      },
      {
        "id": "7693f4ea777c0529dac63d3b38a8ad9af8c9145c",
        "title": "Open-world Machine Learning: Applications, Challenges, and Opportunities"
      },
      {
        "id": "99095dd6a4b595862d6415d3344a6115d029899e",
        "title": "SelfHAR"
      },
      {
        "id": "5c02db41364cd7ba251c7accde6bac1c29feb80e",
        "title": "Machine Learning with Applications"
      },
      {
        "id": "ac006d13d98d80c5bde2a6f9a3d41af56bf20153",
        "title": "Deep Learning for Android Malware Defenses: A Systematic Literature Review"
      },
      {
        "id": "b3537407b00c76103ac21bb7cd0ce7047dfdf025",
        "title": "Comparing Pre-trained and Feature-Based Models for Prediction of Alzheimer's Disease Based on Speech"
      },
      {
        "id": "552dd5274a7caeeb0052f6827811b798b71b8bff",
        "title": "Arabic Fake News Detection: Comparative Study of Neural Networks and Transformer-Based Approaches"
      },
      {
        "id": "87a0279c1d640b486dc5c9f1e0d3705ed87754cf",
        "title": "Improving Generation and Evaluation of Visual Stories via Semantic Consistency"
      },
      {
        "id": "5cdd2cc5ef826a10785d3c6aeb56f1ea5fc0075a",
        "title": "B-PROP: Bootstrapped Pre-training with Representative Words Prediction for Ad-hoc Retrieval"
      },
      {
        "id": "34c8976f50e83aeaff75a32055e8e9880f2d11f5",
        "title": "Emotion Detection of Textual Data: An Interdisciplinary Survey"
      },
      {
        "id": "999338b94359c4c271c65f17bc7205d3f6c59d60",
        "title": "Adaptivity without Compromise: A Momentumized, Adaptive, Dual Averaged Gradient Method for Stochastic Optimization"
      },
      {
        "id": "b257038ef379092509b1dd1d66a351f47363d6eb",
        "title": "LeBenchmark: A Reproducible Framework for Assessing Self-Supervised Representation Learning from Speech"
      },
      {
        "id": "c426ce2819990b2de233f93c11940cfb0161b836",
        "title": "Audio Transformers: Transformer Architectures For Large Scale Audio Understanding. Adieu Convolutions"
      },
      {
        "id": "a0fcced57c26ff5dad30e7a404a84ea26844764e",
        "title": "A clinical trials corpus annotated with UMLS entities to enhance the access to evidence-based medicine"
      },
      {
        "id": "d77ad36898a623b2e82d96a0b8d9920204ca60bf",
        "title": "Ungoliant: An Optimized Pipeline for the Generation of a Very Large-Scale Multilingual Web Corpus"
      },
      {
        "id": "bb8d2aa9ef06ecc830828dee92bfdeb46e14e25f",
        "title": "L3CubeMahaSent: A Marathi Tweet-based Sentiment Analysis Dataset"
      },
      {
        "id": "7f4b12eec7d4a6873f03e7cc4f4f244a2d06c74a",
        "title": "V2W-BERT: A Framework for Effective Hierarchical Multiclass Classification of Software Vulnerabilities"
      },
      {
        "id": "194d1089b730e4a1d15a60a0144b50771909c3c5",
        "title": "Active Learning for Sequence Tagging with Deep Pre-trained Models and Bayesian Uncertainty Estimates"
      },
      {
        "id": "afa72122ba06b6a694c21cf67d82620662e4917c",
        "title": "A full-stack search technique for domain optimized deep learning accelerators"
      },
      {
        "id": "0d2f279be0e985cf875e57ee7af45b80de81962b",
        "title": "Multimodal Hate Speech Detection in Greek Social Media"
      },
      {
        "id": "d6357b1c61611f744acbae69484acd7f21c89dff",
        "title": "Substructure Substitution: Structured Data Augmentation for NLP"
      },
      {
        "id": "32a6daa76efd00f657e65842771971decf104efc",
        "title": "Improving the Faithfulness of Attention-based Explanations with Task-specific Information for Text Classification"
      },
      {
        "id": "489666f4c11787b679b36238dee95b63248ed60a",
        "title": "Training Larger Networks for Deep Reinforcement Learning"
      },
      {
        "id": "241abdd1a8f2e98b0b0dbb04df54a4795d799ffe",
        "title": "Multi-Task Learning and Adapted Knowledge Models for Emotion-Cause Extraction"
      },
      {
        "id": "9dfd46fb6ce4f4dc19060f874d31f859de705c15",
        "title": "Deep Learning for Technical Document Classification"
      },
      {
        "id": "d61387def94f4a21125b143c6db909466574f306",
        "title": "Zero-shot Label-Aware Event Trigger and Argument Classification"
      },
      {
        "id": "bbb8a88be9b7b6f24e39aa48c6352ce1fb7826fb",
        "title": "Method Of Text Summarization Using Lsa And Sentence Based Topic Modelling With Bert"
      },
      {
        "id": "d7a32ef41ed5a9221be35ecc8e231b617e0cc026",
        "title": "On the Sensitivity and Stability of Model Interpretations in NLP"
      },
      {
        "id": "8eab7d02805180af4ec724de04cd1834b9b11ceb",
        "title": "An Assessment of Deep Learning Models and Word Embeddings for Toxicity Detection within Online Textual Comments"
      },
      {
        "id": "0992638c434257f4b9691637dd5ada046eb14b17",
        "title": "Weighted Training for Cross-Task Learning"
      },
      {
        "id": "5c1ead68c2053669a4d38dc39728a93ec34338df",
        "title": "A Unified Span-Based Approach for Opinion Mining with Syntactic Constituents"
      },
      {
        "id": "188cd686fb2200f237f688dbda7f64ffc75e67ac",
        "title": "Subword Pooling Makes a Difference"
      },
      {
        "id": "70ffcb07856768ea2ba0766f841459fb8fc10b87",
        "title": "Semantic Textual Similarity in Japanese Clinical Domain Texts Using BERT"
      },
      {
        "id": "1204e893b13a50697ea176275123d29501f7d7c7",
        "title": "A Novel COVID-19 Data Set and an Effective Deep Learning Approach for the De-Identification of Italian Medical Records"
      },
      {
        "id": "143e4fecf823d059e9a3ba2fa3fcf4debb02e463",
        "title": "A review of Chinese named entity recognition"
      },
      {
        "id": "0d39d525f30609d0541330f933007025cd457a83",
        "title": "Exploring Transitivity in Neural NLI Models through Veridicality"
      },
      {
        "id": "052aeae0ea45609f854632f38d690fef00ab2274",
        "title": "IITP in COLIEE@ICAIL 2019: Legal Information Retrieval using BM25 and BERT"
      },
      {
        "id": "f76a2774f2b3189f80a998869d5d3fb28eb2b092",
        "title": "Experimental Evaluation of Deep Learning models for Marathi Text Classification"
      },
      {
        "id": "814b8122520d1d461af62c39d3e99e4575262c40",
        "title": "Long Short-term Memory RNN"
      },
      {
        "id": "33eb644319191de1b6c1166d4bad2ca73049cebb",
        "title": "BERT-based ensemble methods with data augmentation for legal textual entailment in COLIEE statute law task"
      },
      {
        "id": "66b76bd54f35d314b6eb359d06afddfcb83712d6",
        "title": "Reinforcement Learning-Based Dialogue Guided Event Extraction to Exploit Argument Relations"
      },
      {
        "id": "2bb21cfeec28ca743c2174fe5565738a1f72e23c",
        "title": "How can I help you? An Intelligent Virtual Assistant for Industrial Robots"
      },
      {
        "id": "cf7eacb2f30ac1e74747e8f442e693a6b3de880d",
        "title": "MenuNER: Domain-Adapted BERT Based NER Approach for a Domain with Limited Dataset and Its Application to Food Menu Domain"
      },
      {
        "id": "8550a97f269246034a98aae7ab12f287cea65590",
        "title": "RECAST"
      },
      {
        "id": "bf459cca52f336de2afe61e6e6348571c73943c1",
        "title": "Improving the Efficiency of Transformers for Resource-Constrained Devices"
      },
      {
        "id": "084ddd4d93ad151536ea86761f52d877aba47cfc",
        "title": "World-GAN: a Generative Model for Minecraft Worlds"
      },
      {
        "id": "fcd5572e81dd47438bc8e5144e7fb07191f7f0ad",
        "title": "A Framework for Indonesian Grammar Error Correction"
      },
      {
        "id": "0fc1229f542f24a8a5756634291eace6d3a037d8",
        "title": "Geospatial and Semantic Mapping Platform for Massive COVID-19 Scientific Publication Search"
      },
      {
        "id": "3316bc75e1d46e58008e89f109da1fb2f6b6efb4",
        "title": "Unsupervised Cross-Domain Prerequisite Chain Learning using Variational Graph Autoencoders"
      },
      {
        "id": "9fca3388b1a7065478eb4992c9217040fcaac982",
        "title": "Sentence Extraction-Based Machine Reading Comprehension for Vietnamese"
      },
      {
        "id": "22eb34fb297226e11233cc7b7534c73cbab79e77",
        "title": "Potential Idiomatic Expression (PIE)-English: Corpus for Classes of Idioms"
      },
      {
        "id": "3623a39bfbbefff942a2f370d76dd18fbc1d9139",
        "title": "Demystifying BERT: Implications for Accelerator Design"
      },
      {
        "id": "bb77ab10ad9831fc9f1bb51a85006c50b7c1d643",
        "title": "BERT-CoQAC: BERT-Based Conversational Question Answering in Context"
      },
      {
        "id": "cd3d8f92f260979fea102127589ed6321fe68477",
        "title": "Active Learning for Effectively Fine-Tuning Transfer Learning to Downstream Task"
      },
      {
        "id": "1de08bac98bc074da5f2479919e4b4e17e0c8afb",
        "title": "Spatial-Channel Transformer Network for Trajectory Prediction on the Traffic Scenes"
      },
      {
        "id": "cd287288c9fbaa97cbd3f4a070e9552592626fa5",
        "title": "Rare Disease Identification from Clinical Notes with Ontologies and Weak Supervision"
      },
      {
        "id": "0364102c8805bd1889467b5a1aaa6916764ffa0e",
        "title": "Few-shot Learning for Slot Tagging with Attentive Relational Network"
      },
      {
        "id": "9fd4557eaee34235d79a816a3ebd56c55229d450",
        "title": "A Deeper Look at Sheet Music Composer Classification Using Self-Supervised Pretraining"
      },
      {
        "id": "8e88f835acdabf16eda88ece9c5acedac64a6274",
        "title": "Adversarial Regularization as Stackelberg Game: An Unrolled Optimization Approach"
      },
      {
        "id": "6e91cfc05688330aa26395efa8e814e951191186",
        "title": "TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation"
      },
      {
        "id": "90b43e7c7f3c251de5c9e38b3900c2b3bd198e5b",
        "title": "Enhancing Model Robustness by Incorporating Adversarial Knowledge into Semantic Representation"
      },
      {
        "id": "b4d84d29bdfed1b9490e75951eee647d2a9bea05",
        "title": "Label-Aware Text Representation for Multi-Label Text Classification"
      },
      {
        "id": "aec5fb6e776102778cbb697d102d207fa64055c6",
        "title": "Making Sense of Subtitles: Sentence Boundary Detection and Speaker Change Detection in Unpunctuated Texts"
      },
      {
        "id": "060ffa95caec15a972c6b88d3b4a4cd6f9eb4f80",
        "title": "Identifying Distributional Perspectives from Colingual Groups"
      },
      {
        "id": "f4dda4524bba281141829aaf6967431f59257e74",
        "title": "Identifying inherent disagreement in natural language inference"
      },
      {
        "id": "c981b3566140096b79543ba4fef77cbb71e8557c",
        "title": "Extracting Semantic Process Information from the Natural Language in Event Logs"
      },
      {
        "id": "46dfe93b284c929e7340e3f59303f25ad1a9df88",
        "title": "Generating Syntactically Controlled Paraphrases without Using Annotated Parallel Pairs"
      },
      {
        "id": "fde0b404220505f1df0f0bde84ee24fe6e12a354",
        "title": "Improving Text-to-SQL with Schema Dependency Learning"
      },
      {
        "id": "901e552b6b807563d698f809931432181d8b27fd",
        "title": "AI Research Funding Portfolios and Extreme Growth"
      },
      {
        "id": "a867894db8f9d544a471e86d8844008861f6a2ec",
        "title": "Personalized News Recommendation: Methods and Challenges"
      },
      {
        "id": "0578dfb2a28b77abde19b32de777e0365df3020e",
        "title": "Data-driven materials research enabled by natural language processing and information extraction"
      },
      {
        "id": "4c25acf91e0b0b475e69cb9ab9f0041d16bc7c7d",
        "title": "Using State of the Art Speaker Recognition and Natural Language Processing Technologies to Detect Alzheimer's Disease and Assess its Severity"
      },
      {
        "id": "494885502d712ebff9d45010a7f23159725ae9cc",
        "title": "Natural Language Processing for Rapid Response to Emergent Diseases: Case Study of Calcium Channel Blockers and Hypertension in the COVID-19 Pandemic"
      },
      {
        "id": "76e69e67d50092a01cd7e8320b82ee861d01de66",
        "title": "Natural language processing for similar languages, varieties, and dialects: A survey"
      },
      {
        "id": "96ee09542f31bcaf21a139fbec62e0864da33687",
        "title": "A Survey on Using Gaze Behaviour for Natural Language Processing"
      },
      {
        "id": "21ae09d8eb9a1169a93eaf35133feddc8d70b72a",
        "title": "Clinical concept normalization with a hybrid natural language processing system combining multilevel matching and machine learning ranking"
      },
      {
        "id": "8e8c9e907f9be0c098d90eec387da88dd0111238",
        "title": "Targeting the Benchmark: On Methodology in Current Natural Language Processing Research"
      },
      {
        "id": "176fac7bcfa9c764b586295e7a8b8b5c8ba4c526",
        "title": "Family History Extraction From Synthetic Clinical Narratives Using Natural Language Processing: Overview and Evaluation of a Challenge Data Set and Solutions for the 2019 National NLP Clinical Challenges (n2c2)/Open Health Natural Language Processing (OHNLP) Competition"
      },
      {
        "id": "1e58f78209fd0733e1229bcb0b4f1caeb8866972",
        "title": "Automatic Discovery of Heterogeneous Machine Learning Pipelines: An Application to Natural Language Processing"
      },
      {
        "id": "5a74d9e437c14fd6f0922d9d21f61b64102673fa",
        "title": "Low-shot Learning in Natural Language Processing"
      },
      {
        "id": "b3c4d82774afe3bbea13de183c28545c43cd7673",
        "title": "Embeddings in Natural Language Processing"
      },
      {
        "id": "5dcad60d3ae2271e209badeb1755b06423415e27",
        "title": "Safe Reinforcement Learning with Natural Language Constraints"
      },
      {
        "id": "ab38bbb36ba38047c5bb556694d148225971957f",
        "title": "Premise Selection in Natural Language Mathematical Texts"
      },
      {
        "id": "3bc6ade1b4e668d0b176703f6a49d6143b355610",
        "title": "Learning a Planning Domain Model From Natural Language Process Manuals"
      },
      {
        "id": "9a4aa7848d58d536a63357d6cd996def52a5de0d",
        "title": "Structuring Natural Language to Query Language: A Review"
      },
      {
        "id": "7ca4abace88db259faed67686ed7bba02b46eb82",
        "title": "Language-Conditioned Imitation Learning for Robot Manipulation Tasks"
      },
      {
        "id": "00c5abdffe51ab33e745e6804d4821ca59db52d8",
        "title": "To BERT or Not To BERT: Comparing Speech and Language-based Approaches for Alzheimer's Disease Detection"
      },
      {
        "id": "dec2f6d3215de9aa2d87d358b7933fb21eeb3bc0",
        "title": "Multimodal Pretraining Unmasked: A Meta-Analysis and a Unified Framework of Vision-and-Language BERTs"
      },
      {
        "id": "2cf2d1491f72f198ae9990971cf2846e9fe51141",
        "title": "Confronting Abusive Language Online: A Survey from the Ethical and Human Rights Perspective"
      },
      {
        "id": "c0f2ce69250fb1c995fec0fb2567ac495e1aefe6",
        "title": "End-to-End Neural Transformer Based Spoken Language Understanding"
      },
      {
        "id": "dec43c7511acfc02f5f22fbe4e19ed2aed49b015",
        "title": "MOSEAS: A Multimodal Language Dataset for Spanish, Portuguese, German and French"
      },
      {
        "id": "e15c7538417486417cf1e8408cc06073d8b76f27",
        "title": "Causal-BERT : Language models for causality detection between events expressed in text"
      },
      {
        "id": "38d5e7774e79861315e043dc2dd764d051516d74",
        "title": "Language Through a Prism: A Spectral Approach for Multiscale Language Representations"
      },
      {
        "id": "c77ad1104ffcb3df74915923dd1f72aa3ff4d619",
        "title": "AnchiBERT: A Pre-Trained Model for Ancient Chinese Language Understanding and Generation"
      },
      {
        "id": "3c7250dc37a3e3f110fe19884343ee61988f70b6",
        "title": "Misspelling Correction with Pre-trained Contextual Language Model"
      },
      {
        "id": "e2ecd2498effad4f5d67928f54dfaf45d06cec66",
        "title": "Automatic offensive language detection from Twitter data using machine learning and feature selection of metadata"
      },
      {
        "id": "e60fbb9db3aa3e4db6616d45cc46b01ce1371c53",
        "title": "Schema-Agnostic Entity Matching using Pre-trained Language Models"
      },
      {
        "id": "73f2a1db0e9d03ac61b498fb3405cbd049eb4577",
        "title": "Towards Machine Translation for the Kurdish Language"
      },
      {
        "id": "b440d724562919056cec57e3aaa02d08385c3685",
        "title": "End-to-End Spoken Language Understanding Using Transformer Networks and Self-Supervised Pre-Trained Features"
      },
      {
        "id": "671a3b82c09413dd4a8a7e6f5f21853cff917f11",
        "title": "GUIR at SemEval-2020 Task 12: Domain-Tuned Contextualized Models for Offensive Language Detection"
      },
      {
        "id": "bcafdf8ca05a49cb15ccfbe35f0c6103b8cb8849",
        "title": "From Universal Language Model to Downstream Task: Improving RoBERTa-Based Vietnamese Hate Speech Detection"
      },
      {
        "id": "4f0a8cad6d6a8d0397ad1bd35acce6458aa7164c",
        "title": "Contrastive Representation Learning: A Framework and Review"
      },
      {
        "id": "dbdfd22ec8b71d48ff100819235eff56a4a374a3",
        "title": "MIND: A Large-scale Dataset for News Recommendation"
      },
      {
        "id": "14bef0c3ea1fff4ff85861377242d872fc7afcd9",
        "title": "Pre-trained Language Model Based Active Learning for Sentence Matching"
      },
      {
        "id": "c41655809f991fa0553cbb8e9a66f184a6cdc154",
        "title": "Resources and benchmark corpora for hate speech detection: a systematic review"
      },
      {
        "id": "2b4bc49a3b23229a060609380752666b24b435fb",
        "title": "Distilling Knowledge from Reader to Retriever for Question Answering"
      },
      {
        "id": "f6b9ff8cfc60241008e3748efcf05cbe91037aa0",
        "title": "Bi-LSTM Model to Increase Accuracy in Text Classification: Combining Word2vec CNN and Attention Mechanism"
      },
      {
        "id": "5aed438fecf702ead9c0cddfa9a80bd00cff0138",
        "title": "SSE-PT: Sequential Recommendation Via Personalized Transformer"
      },
      {
        "id": "bdbb944a84b8cdec8d120d2d2535995e335d0174",
        "title": "An Analysis of Simple Data Augmentation for Named Entity Recognition"
      },
      {
        "id": "5cc60e5129f8b8efdaf2ae62c26084e874fe5231",
        "title": "Transformer For Image Quality Assessment"
      },
      {
        "id": "9b9654ec375b73b2001ec84cf59227e816f005e7",
        "title": "Prediction of chemical reaction yields using deep learning"
      },
      {
        "id": "9958887e8dd5f84595818c50fb734b566996541a",
        "title": "ConceptBert: Concept-Aware Representation for Visual Question Answering"
      },
      {
        "id": "e1e438381418751f16b6813b00bd62a8949f8374",
        "title": "Joint Entity and Relation Extraction With Set Prediction Networks"
      },
      {
        "id": "a946d369760b4505774b6cd24825cefc0c08eff8",
        "title": "Machine Knowledge: Creation and Curation of Comprehensive Knowledge Bases"
      },
      {
        "id": "3aba6c5f59080c24301121bfc3a1445fc292476b",
        "title": "Mixup-Transformer: Dynamic Data Augmentation for NLP Tasks"
      },
      {
        "id": "0fc2b08409def9f7ef6beff8ff2155c0dcff2345",
        "title": "A Relation-Specific Attention Network for Joint Entity and Relation Extraction"
      },
      {
        "id": "b932a2c610a16566639f8d693eaa98181bef06f1",
        "title": "With More Contexts Comes Better Performance: Contextualized Sense Embeddings for All-Round Word Sense Disambiguation"
      },
      {
        "id": "773d51dbb619a167102f75d93f39582a67c24c82",
        "title": "CM-BERT: Cross-Modal BERT for Text-Audio Sentiment Analysis"
      },
      {
        "id": "590180246854ec4e1ab557e9d4e260c61c49a69c",
        "title": "Neural Networks for Entity Matching: A Survey"
      },
      {
        "id": "8b4c857311c001f6ed0cd790cce4af4dfcfb6533",
        "title": "Deep Graph Matching and Searching for Semantic Code Retrieval"
      },
      {
        "id": "14bfe1af57cad759b0b2d771e941d8e8602060cc",
        "title": "Detecting White Supremacist Hate Speech Using Domain Specific Word Embedding With Deep Learning and BERT"
      },
      {
        "id": "58ef9f9682c0ae4561dc30079a52867f108f704e",
        "title": "Seq2Edits: Sequence Transduction Using Span-level Edit Operations"
      },
      {
        "id": "d75def276d70f9468811a93eff1670a4e6ca5091",
        "title": "Self-attention encoding and pooling for speaker recognition"
      },
      {
        "id": "5585c7fcbda5d94e946fe9091860e2e574927ed8",
        "title": "Efficient Meta Lifelong-Learning with Limited Memory"
      },
      {
        "id": "1ed15531e935641f0cfeee6be8856b53c567ff61",
        "title": "Using BERT to Extract Topic-Independent Sentiment Features for Social Media Bot Detection"
      },
      {
        "id": "94e586cd3342940422c0bd01ad7f252db9327394",
        "title": "Understanding Attention for Text Classification"
      },
      {
        "id": "ca7e8bc95864805c15e667ad016dfff98865fd51",
        "title": "Artificial Intelligence in Drug Discovery: A Comprehensive Review of Data-driven and Machine Learning Approaches"
      },
      {
        "id": "9eda9bbb3317452646e23f8341e5a4e5c7e73c58",
        "title": "Do Response Selection Models Really Know What's Next? Utterance Manipulation Strategies for Multi-turn Response Selection"
      },
      {
        "id": "044ebe003405eae1715f729c80546210be05363d",
        "title": "Interpretation of NLP Models through Input Marginalization"
      },
      {
        "id": "c363eb0e244c50e9e8a7b59c85c0862b80730444",
        "title": "Financial Sentiment Analysis: An Investigation into Common Mistakes and Silver Bullets"
      },
      {
        "id": "af6de8ee0c8bf4639763b73f205b51dacd490627",
        "title": "D2RL: Deep Dense Architectures in Reinforcement Learning"
      },
      {
        "id": "ecb1e4738c14d6cf1c68f04afa6e7d509767f83e",
        "title": "Achieving Reliable Sentiment Analysis in the Software Engineering Domain using BERT"
      },
      {
        "id": "06439c29150efb6441bfc928dfa5c0e0967edd9b",
        "title": "Exploring BERT’s sensitivity to lexical cues using tests from semantic priming"
      },
      {
        "id": "0ca7033ef57ebb3df51a229bd81d15efe3341382",
        "title": "MAEC: A Multimodal Aligned Earnings Conference Call Dataset for Financial Risk Prediction"
      },
      {
        "id": "d77a343662eb00b859a8c7f6f658fed79829d2ee",
        "title": "Neural Machine Translation with BERT for Post-OCR Error Detection and Correction"
      },
      {
        "id": "b4c3be06f695a3aa04a90b540cbbd6e99643cfb9",
        "title": "Arabic text summarization using deep learning approach"
      },
      {
        "id": "5dfcc1f19a22c3bc081f2ff4410eb1efc7061838",
        "title": "Nested Named Entity Recognition with Partially-Observed TreeCRFs"
      },
      {
        "id": "50ed578725883a52897b290004515ed8ac304974",
        "title": "Exploring the Role of Argument Structure in Online Debate Persuasion"
      },
      {
        "id": "c7af54975379ef2e50d530219843b2cdc754a1a0",
        "title": "Emotion Detection in Roman Urdu Text using Machine Learning"
      },
      {
        "id": "3f02219184319aa8ca1ef182e6b091b6a7539a04",
        "title": "Domain adaptation challenges of BERT in tokenization and sub-word representations of Out-of-Vocabulary words"
      },
      {
        "id": "8f1540644fd56fbb6701a9d3e570a81271592263",
        "title": "A Two-phase Prototypical Network Model for Incremental Few-shot Relation Classification"
      },
      {
        "id": "e7e333042383c41b4f2d86d362fcc15d25261d57",
        "title": "VolTAGE: Volatility Forecasting via Text-Audio Fusion with Graph Convolution Networks for Earnings Calls"
      },
      {
        "id": "3b69b369a5c829dec14051e94a200c3eeb5f2692",
        "title": "Biased TextRank: Unsupervised Graph-Based Content Extraction"
      },
      {
        "id": "1c04c17b0f6545b832d05fd6a09b9eb2d49ce0da",
        "title": "Bangla Text Classification using Transformers"
      },
      {
        "id": "c570764d127bed9b9a1e5e0b83ba3a7b57043131",
        "title": "Adapting BERT for Word Sense Disambiguation with Gloss Selection Objective and Example Sentences"
      },
      {
        "id": "f5a18c7c40e62ef891275d1fab64175bfdbf3488",
        "title": "Dilated Convolutional Attention Network for Medical Code Assignment from Clinical Text"
      },
      {
        "id": "2a8a2ab581f2e89c9a66e1b353346e1bb86ee6f6",
        "title": "Mixup-Transfomer: Dynamic Data Augmentation for NLP Tasks"
      },
      {
        "id": "ff0188537c9ff474ce654b6610ba7d3b5fa5c0c1",
        "title": "Will artificial intelligence revolutionise the student evaluation of teaching? A big data study of 1.6 million student reviews"
      },
      {
        "id": "48fab33897674fedb9f816054cad7e8851600cdf",
        "title": "IITK at SemEval-2020 Task 8: Unimodal and Bimodal Sentiment Analysis of Internet Memes"
      },
      {
        "id": "5915d8399db79796bb032f9102c7ba56916cc4c9",
        "title": "Attention-based Bidirectional Long Short-Term Memory Networks for Relation Classification Using Knowledge Distillation from BERT"
      },
      {
        "id": "907a5239ea4b8d0bed424d18aa229eafdfaf1bd2",
        "title": "End to End Binarized Neural Networks for Text Classification"
      },
      {
        "id": "d4489958386c4ad9b7e72c957faa29a4eacc3265",
        "title": "Efficiency Implications of Term Weighting for Passage Retrieval"
      },
      {
        "id": "110ef8f751d1abf3f18b10ee90f883f2709f2312",
        "title": "DeText: A Deep Text Ranking Framework with BERT"
      },
      {
        "id": "10b79d7b377fac08c2569fdc9cb7b3cd903c9637",
        "title": "Exploring the Limits of Simple Learners in Knowledge Distillation for Document Classification with DocBERT"
      },
      {
        "id": "868e6aeb67853f9815935ea2ff6990a25afd40a6",
        "title": "An empirical investigation of neural methods for content scoring of science explanations"
      },
      {
        "id": "1b188f604f52f5809711a31d3b505e7cbc82a455",
        "title": "Go Simple and Pre-Train on Domain-Specific Corpora: On the Role of Training Data for Text Classification"
      },
      {
        "id": "4b6da028739a126b0df08e9b5d4f01c288c210f3",
        "title": "A BERT-Based Named Entity Recognition in Chinese Electronic Medical Record"
      },
      {
        "id": "800d0e41bdab9dc8150ae31831ce5b5dfc16f899",
        "title": "A Joint Multiple Criteria Model in Transfer Learning for Cross-domain Chinese Word Segmentation"
      },
      {
        "id": "c93118f7f05484a70df37a811b91eac7f5ba651c",
        "title": "Large-scale quantitative evidence of media impact on public opinion toward China"
      },
      {
        "id": "8c1f6797aeaaa86011891e24fc4985866fb1ec1c",
        "title": "Data Driven and Psycholinguistics Motivated Approaches to Hate Speech Detection"
      },
      {
        "id": "f9189dcb3a79fa5fc264dc74e99243a0ac519a79",
        "title": "Deep Reinforcement Learning with Transformers for Text Adventure Games"
      },
      {
        "id": "3aca1277f5da7b6d4307182cd92dc9fbcb9c298e",
        "title": "GANBERT: Generative Adversarial Networks with Bidirectional Encoder Representations from Transformers for MRI to PET synthesis"
      },
      {
        "id": "5efe3a02974e2e42d790d9932823674776bd843a",
        "title": "Sentiment Analysis of Code-Mixed Roman Urdu-English Social Media Text using Deep Learning Approaches"
      },
      {
        "id": "3f74ac68ee7a852c9891e9f356d932bbfbb34145",
        "title": "Intermediate Self-supervised Learning for Machine Translation Quality Estimation"
      },
      {
        "id": "2cdb7f395a234815d07a989f38774ecb61d74a6b",
        "title": "A Survey on VQA: Datasets and Approaches"
      },
      {
        "id": "306ec4956aa2bb4e29a0b5c8b52d1c0e6007a32b",
        "title": "Generating Image Descriptions via Sequential Cross-Modal Alignment Guided by Human Gaze"
      },
      {
        "id": "9210dc01a1586e3452bf944624a2269ad9010f2f",
        "title": "A Text Classification Survey: From Shallow to Deep Learning"
      },
      {
        "id": "3432ae8405d6e35a0a987adbb8327bffeb6eef80",
        "title": "Domain Adversarial Fine-Tuning as an Effective Regularizer"
      },
      {
        "id": "03826718c8c47d8f1f25e437fd6ff15165162e8c",
        "title": "Will it Unblend?"
      },
      {
        "id": "6bca3a95584763856bd352efc31e2d5de5e0ecad",
        "title": "Visually Analyzing Contextualized Embeddings"
      },
      {
        "id": "cf3d1379477cfe8b426f6d9723674e1b2e4bc641",
        "title": "UoB at SemEval-2020 Task 12: Boosting BERT with Corpus Level Information"
      },
      {
        "id": "03a9d5831959bf679b7b18f51682e9645e4ed301",
        "title": "A simple and efficient ensemble classifier combining multiple neural network models on social media datasets in Vietnamese"
      },
      {
        "id": "5cd4df62a18b7dc05a55f857aaf76e12e8444688",
        "title": "Exploiting News Article Structure for Automatic Corpus Generation of Entailment Datasets"
      },
      {
        "id": "e6e542352acb0db184aba2c3ce8232fc94c4f538",
        "title": "The Impact of Indirect Machine Translation on Sentiment Classification"
      },
      {
        "id": "0916f2b0ffbf16aba6891e9d1c6098c32f357be9",
        "title": "PatchBERT: Just-in-Time, Out-of-Vocabulary Patching"
      },
      {
        "id": "d26ca8af972909ac9de7302d04f552321f57e3f0",
        "title": "Comparison of Deep Learning and Rule-based Method for the Sentiment Analysis Task"
      },
      {
        "id": "848192e13f79193572639416e3fbd89649818211",
        "title": "Feature Extraction with Bidirectional Encoder Representations from Transformers in Hyperspectral Images"
      },
      {
        "id": "5b6d03ed66473599ee31872b3cd5ad2ce282371f",
        "title": "Roles and Utilization of Attention Heads in Transformer-based Neural Language Models"
      },
      {
        "id": "c328a1ea31eaa4b357e584285ffb6ff2671b5bd4",
        "title": "Concept2Robot: Learning manipulation concepts from instructions and human demonstrations"
      },
      {
        "id": "9f3f5458f20ccba284633fd15476cb3771a85f64",
        "title": "Integrating User History into Heterogeneous Graph for Dialogue Act Recognition"
      },
      {
        "id": "1e8faa7e0acce12983b5c77ae70a57d6d91ff2d2",
        "title": "McDRAM v2: In-Dynamic Random Access Memory Systolic Array Accelerator to Address the Large Model Problem in Deep Neural Networks on the Edge"
      },
      {
        "id": "5c2117f244d38f6b6c6b04aaa2e4f122f7a883e7",
        "title": "What are We Depressed about When We Talk about COVID19: Mental Health Analysis on Tweets Using Natural Language Processing"
      },
      {
        "id": "fb365d20eae355a3a8f9ca12933e15d9c73e1719",
        "title": "Med7: a transferable clinical natural language processing model for electronic health records"
      },
      {
        "id": "56a87c5f533be4cbcf76c65328a54ffb227c0395",
        "title": "Language as a biomarker for psychosis: A natural language processing approach"
      },
      {
        "id": "de13643c82a42501dabfeb8ca33008652aa21745",
        "title": "Fighting post-truth using natural language processing: A review and open challenges"
      },
      {
        "id": "ebe7c37c60024330bc8e90f7057961f9b849ff8d",
        "title": "Rhetoric, Logic, and Dialectic: Advancing Theory-based Argument Quality Assessment in Natural Language Processing"
      },
      {
        "id": "3f424216d8a086defd73da2432f181ef88d8674b",
        "title": "Comparing Natural Language Processing Techniques for Alzheimer's Dementia Prediction in Spontaneous Speech"
      },
      {
        "id": "d9dd2be773cb7de6d7cf61e601144453c680dc53",
        "title": "Data and Representation for Turkish Natural Language Inference"
      },
      {
        "id": "ad98f7d494fc30380fc4a857a3efa2f8ec03e704",
        "title": "State of the Art and Open Challenges in Natural Language Interfaces to Data"
      },
      {
        "id": "e7b31c3129120c5f459fed7451429d2045c88e9d",
        "title": "Stress Test Evaluation of Transformer-based Models in Natural Language Understanding Tasks"
      },
      {
        "id": "696ce5df90ab3fdae43b482c1cc673ff98e54605",
        "title": "Enhancing Natural Language Inference Using New and Expanded Training Data Sets and New Learning Models"
      },
      {
        "id": "406afe68e789fcb0d7e3d24ebea65b53d206f740",
        "title": "Exploring Software Naturalness through Neural Language Models"
      },
      {
        "id": "407ebb66dfe7d36a9d74168ce5ee4343e141a546",
        "title": "Classification Benchmarks for Under-resourced Bengali Language based on Multichannel Convolutional-LSTM Network"
      },
      {
        "id": "edc09e3a68208fc77527efcc17568c59876d3c84",
        "title": "Natural Backdoor Attack on Text Data"
      },
      {
        "id": "316302a916852e674caf85e5e047a9e149f4a720",
        "title": "Downstream Model Design of Pre-trained Language Model for Relation Extraction Task"
      },
      {
        "id": "d2638eabe97b661414b38ed0e0dd45652480aa6e",
        "title": "The Impact of Pretrained Language Models on Negation and Speculation Detection in Cross-Lingual Medical Text: Comparative Study"
      },
      {
        "id": "370648eabfcde7e0d6ef2c9e2a332672b556e8a6",
        "title": "Can Multilingual Language Models Transfer to an Unseen Dialect? A Case Study on North African Arabizi"
      },
      {
        "id": "42605c1ee030721cb38a3c225992d63297a6ace0",
        "title": "A Summary of the First Workshop on Language Technology for Language Documentation and Revitalization"
      },
      {
        "id": "84286c4a614c198593d0e19623cdce318416f212",
        "title": "Named Entity Recognition as Dependency Parsing"
      },
      {
        "id": "ae94c9499e53cdbd2676601839afa85dfaf36a5f",
        "title": "Transformer Networks for Trajectory Forecasting"
      },
      {
        "id": "9b529fe170823f95509585d5aa39fa01a43558fd",
        "title": "How Does NLP Benefit Legal System: A Summary of Legal Artificial Intelligence"
      },
      {
        "id": "6602100baa3399b5d3a390d6281a7caadb626ea6",
        "title": "Structure-Augmented Text Representation Learning for Efficient Knowledge Graph Completion"
      },
      {
        "id": "c570a7ddc5fb9e09c82a3fdd5601dd0c9a48a671",
        "title": "Toward multi-label sentiment analysis: a transfer learning based approach"
      },
      {
        "id": "d808e7468ef6265d39d3cd9c657c9f52e889cbc2",
        "title": "SBERT-WK: A Sentence Embedding Method by Dissecting BERT-Based Word Models"
      },
      {
        "id": "e96016d5e3c6492230aa172efcf733596dc64b6e",
        "title": "Multi-Scale Representation Learning for Spatial Feature Distributions using Grid Cells"
      },
      {
        "id": "e2b358bff94b06ab8527a8af482395034f3b0d29",
        "title": "HTML: Hierarchical Transformer-based Multi-task Learning for Volatility Prediction"
      },
      {
        "id": "c75d95b4bb5c8d8e0bb2e9cc8f3dc97c7080fe0f",
        "title": "Massive Choice, Ample Tasks (MaChAmp): A Toolkit for Multi-task Learning in NLP"
      },
      {
        "id": "186f69beeed6ee9b697010863f3a72ba6754a53a",
        "title": "Boundary Enhanced Neural Span Classification for Nested Named Entity Recognition"
      },
      {
        "id": "6eb4d128282b4e07eccdb0a0b6fe54006f63ba4c",
        "title": "Creating Embeddings of Heterogeneous Relational Datasets for Data Integration Tasks"
      },
      {
        "id": "b1c39d042fdf8f00a407b0df734764beb6c3b062",
        "title": "Low-Rank Bottleneck in Multi-head Attention Models"
      },
      {
        "id": "c8383c46b52ad023b75b6b10be11cad7720a3200",
        "title": "Multimodal Categorization of Crisis Events in Social Media"
      },
      {
        "id": "17a43e798ede87cadf71793fd29bb12b92ca71d4",
        "title": "Beyond 512 Tokens: Siamese Multi-depth Transformer-based Hierarchical Encoder for Long-Form Document Matching"
      },
      {
        "id": "8094337b369c17efb65d653daba1ea2c86e66399",
        "title": "AL: An Adaptive Learning Support System for Argumentation Skills"
      },
      {
        "id": "a9e6222e71dd101d444b7192b3a0636c71edb0a4",
        "title": "Differentiable Reasoning over a Virtual Knowledge Base"
      },
      {
        "id": "4ecf4356c3b451b16780788a3f94e422d4deeda5",
        "title": "Tree-structured Attention with Hierarchical Accumulation"
      },
      {
        "id": "f1149bc8cf83fc2d8b982a2eb9ac033ee80a6c43",
        "title": "Masakhane - Machine Translation For Africa"
      },
      {
        "id": "12aa5c0c9fa3077f41f153cdccfa2aacf8940be3",
        "title": "From static to dynamic word representations: a survey"
      },
      {
        "id": "c12e46d7d0bb9fa062bce0549f2a6a9de00758d5",
        "title": "Weakly-Supervised Sound Event Detection with Self-Attention"
      },
      {
        "id": "1bb338368a49d477efd883a5a187a28451b22df2",
        "title": "Multiple Data Augmentation Strategies for Improving Performance on Automatic Short Answer Scoring"
      },
      {
        "id": "1d29e42bda72365f4eea9522f769d9aa83281d32",
        "title": "Quantifying Gender Bias in Different Corpora"
      },
      {
        "id": "20bcf62aab07398325a08785cb74b1f78abed279",
        "title": "Caspar: Extracting and Synthesizing User Stories of Problems from App Reviews"
      },
      {
        "id": "616e0f73229c118e1e50a1d9e868a198915cecd8",
        "title": "Testing Contextualized Word Embeddings to Improve NER in Spanish Clinical Case Narratives"
      },
      {
        "id": "37ad7b9dd64ba6f52e007c562868e1f51226c427",
        "title": "Privacy-Preserving Deep Learning NLP Models for Cancer Registries"
      },
      {
        "id": "719af99501c8b2435cec86547afbca6b224bb2ea",
        "title": "Semi-Supervised Learning on Meta Structure: Multi-Task Tagging and Parsing in Low-Resource Scenarios"
      },
      {
        "id": "a3abf8fa9f569c79f44c286a617eb8157e5b3998",
        "title": "R-VGAE: Relational-variational Graph Autoencoder for Unsupervised Prerequisite Chain Learning"
      },
      {
        "id": "10f11f32b35c8842fd24f33e0facb595f739b485",
        "title": "Comparative Analysis of Word Embeddings for Capturing Word Similarities"
      },
      {
        "id": "2354baf0af08d955d49d38d4c2f4cdcb2f9426aa",
        "title": "A Chronological and Geographical Analysis of Personal Reports of COVID-19 on Twitter"
      },
      {
        "id": "4defc309ccc5c5c4d92a08a9c61295a6326d1813",
        "title": "Unsupervised WhatsApp Fake News Detection using Semantic Search"
      },
      {
        "id": "1938cc6ab419a87007c95905bc55ab37af9e178a",
        "title": "Data Mining in Clinical Trial Text: Transformers for Classification and Question Answering Tasks"
      },
      {
        "id": "6d0131cdbc85da6339d1c203d21f90a86b327e10",
        "title": "Diversity, Density, and Homogeneity: Quantitative Characteristic Metrics for Text Collections"
      },
      {
        "id": "f43fa2e1f2bb4822160fa9c90be8902f359faa9c",
        "title": "Digital begriffsgeschichte: Tracing semantic change using word embeddings"
      },
      {
        "id": "a5ae9f992264908e51c7925280f42ee17a500858",
        "title": "NLP in FinTech Applications: Past, Present and Future"
      },
      {
        "id": "0c31659f97dfef09b5dd9986e40890255995198e",
        "title": "Multilingual Transformer-Based Personality Traits Estimation"
      },
      {
        "id": "4e55a883f2f88d98a74c9848cbcc110e008026ad",
        "title": "OTEANN: Estimating the Transparency of Orthographies with an Artificial Neural Network"
      },
      {
        "id": "b9fcec933d83c12ed091294bce2b5025c9eaf63d",
        "title": "Exploring Automatic Short Answer Grading as a Tool to Assist in Human Rating"
      },
      {
        "id": "9662af3cf81edfb337f35cab02fa4520f846fcaa",
        "title": "Coreference Resolution: Toward End-to-End and Cross-Lingual Systems"
      },
      {
        "id": "0c30438e316043c6f7288851fea7b663dcbf8638",
        "title": "Sequential Interpretability: Methods, Applications, and Future Direction for Understanding Deep Learning Models in the Context of Sequential Data"
      },
      {
        "id": "0d4f97ad34b2292fe9f0affcd04f9559f5ac4bc5",
        "title": "Named Entity Recognition Method of Brazilian Legal Text based on pre-training model"
      },
      {
        "id": "673094a4ee36d3e8fc4f739fc2006756e24ce0ef",
        "title": "Distant Supervision and Noisy Label Learning for Low Resource Named Entity Recognition: A Study on Hausa and Yorùbá"
      },
      {
        "id": "8edf445d2639946f2128d9c445816d6e83f1fd87",
        "title": "AMALGUM – A Free, Balanced, Multilayer English Web Corpus"
      },
      {
        "id": "13cbb4fa75192275dcb4d929c07841ca505c2bda",
        "title": "Lexical Normalization for Code-switched Data and its Effect on POS Tagging"
      },
      {
        "id": "7119249d02998a3f164c94ce825195ef56c4b828",
        "title": "Talk to Papers: Bringing Neural Question Answering to Academic Search"
      },
      {
        "id": "109093b9e4b658e1b7e799975350268db2cc28a0",
        "title": "Will_Go at SemEval-2020 Task 3: An Accurate Model for Predicting the (Graded) Effect of Context in Word Similarity Based on BERT"
      },
      {
        "id": "40518496bca9b7ca797790e47f5dd5d811fe7f26",
        "title": "Avoiding Unintended Bias in Toxicity Classification with Neural Networks"
      },
      {
        "id": "90bdd388e007335113c27738a4b9c963671942d0",
        "title": "What counts as an exemplar model, anyway? A commentary on Ambridge (2020)"
      },
      {
        "id": "8492975a32595878cff9ae645bf54d133c24b066",
        "title": "Spoken Document Retrieval Leveraging Bert-Based Modeling and Query Reformulation"
      },
      {
        "id": "daece8de4b67fd67c4e1645102c087fbf7e391ce",
        "title": "NARMADA: Need and Available Resource Managing Assistant for Disasters and Adversities"
      },
      {
        "id": "ca1219ab491c146c7f814121978bde9b782df658",
        "title": "To BERT or Not to BERT Dealing with Possible BERT Failures in an Entailment Task"
      },
      {
        "id": "8114cf0628c29e8309d6f1e2ef61030f64a7b28c",
        "title": "Stance Detection"
      },
      {
        "id": "0c5480ba0e07da4995006bf7959e6a2e7b3e279d",
        "title": "Neural Syntactic Preordering for Controlled Paraphrase Generation"
      },
      {
        "id": "f1fdca866e59b2763619f4a0f8571a7b5d7d3b05",
        "title": "Can fMRI reveal the representation of syntactic structure in the brain?"
      },
      {
        "id": "1f7c168c046adc74e61ce767a09926524965e140",
        "title": "Collaborative Bug Finding for Android Apps"
      },
      {
        "id": "940874fb53709e54918ea91f6d00112fbed5f01b",
        "title": "Survey on categorical data for neural networks"
      },
      {
        "id": "2733574d40ce8e861d7d658bfc33ab36f529864d",
        "title": "GluonCV and GluonNLP: Deep Learning in Computer Vision and Natural Language Processing"
      },
      {
        "id": "4d93ad53d08a62da93455e1433ff601cd71de5b1",
        "title": "Inducing brain-relevant bias in natural language processing models"
      },
      {
        "id": "4c5d391e4e23007c4ce380767d4c384bc257fb11",
        "title": "Evolution of transfer learning in natural language processing"
      },
      {
        "id": "cd401ada14160781233db80f279d9b99d4150a3d",
        "title": "Cooperation and Codenames: Understanding Natural Language Processing via Codenames"
      },
      {
        "id": "a8abe785f46ebdeec6768ab741162830ba66b4ec",
        "title": "Latent Structure Models for Natural Language Processing"
      },
      {
        "id": "981b30dc063d1ebd1929d417d883258328e03876",
        "title": "Self-Supervised Contextual Data Augmentation for Natural Language Processing"
      },
      {
        "id": "a67955df15688a908190e57420df5cea9278cdcb",
        "title": "Evaluating BERT for natural language inference: A case study on the CommitmentBank"
      },
      {
        "id": "a758828d2865592fb7ee0c95fe4d2517cf405196",
        "title": "WSLLN:Weakly Supervised Natural Language Localization Networks"
      },
      {
        "id": "7f1a6c67d03de88b898271d52dd2e51907d5b615",
        "title": "Generalizing Natural Language Analysis through Span-relation Representations"
      },
      {
        "id": "c425800d30e88893ad95b7d5fff778945611d26a",
        "title": "ALTER: Auxiliary Text Rewriting Tool for Natural Language Generation"
      },
      {
        "id": "8a9a798c56fc83858d7ace0352606d73aeaa204d",
        "title": "Adversarial Language Games for Advanced Natural Language Intelligence"
      },
      {
        "id": "4f2841cf0ed8edd5f9d2b7f76b95ec2a8674afb1",
        "title": "Adapt or Get Left Behind: Domain Adaptation through BERT Language Model Finetuning for Aspect-Target Sentiment Classification"
      },
      {
        "id": "f8a48678094adbe421d61d0045361bfc635a2900",
        "title": "Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods"
      },
      {
        "id": "65d53938a12c77e7920b8eb3a49df249c978ba3f",
        "title": "PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition"
      },
      {
        "id": "659ce190ece2fe577153e5c36beb6db18a6f9c85",
        "title": "Neural Word Decomposition Models for Abusive Language Detection"
      },
      {
        "id": "a0791d5f71168d25cfee8f2eb09d656bf31026e3",
        "title": "EduBERT: Pretrained Deep Language Models for Learning Analytics"
      },
      {
        "id": "7b762eed4875f192109b7f847ec109ed94dcf48e",
        "title": "Context-specific Language Modeling for Human Trafficking Detection from Online Advertisements"
      },
      {
        "id": "62be60059266d37a5b9d81c9b5a1e754bac8732a",
        "title": "Multimodal Embeddings From Language Models for Emotion Recognition in the Wild"
      },
      {
        "id": "ff7c2a424f3bbc5785fc0c82f80b8bdd21915b88",
        "title": "Contextual Text Denoising with Masked Language Model"
      },
      {
        "id": "743d39f81ae653c0d5ebf6e8ef3d0a4d17dfe75e",
        "title": "A BERT-Based Transfer Learning Approach for Hate Speech Detection in Online Social Media"
      },
      {
        "id": "cc8871b27970b9f4e596c9e334abb6d7e38e3010",
        "title": "Deep Learning Language Modeling Workloads: Where Time Goes on Graphics Processors"
      },
      {
        "id": "415efb7b4d9d1e5b64dbaf3fe4229ad462acce71",
        "title": "Multimodal Intelligence: Representation Learning, Information Fusion, and Applications"
      },
      {
        "id": "8a23a2e6ece34bec461cc41da35e65bf16873752",
        "title": "Target-Dependent Sentiment Classification With BERT"
      },
      {
        "id": "7aecc17019619589b3bcbbb7f5289923878cf29f",
        "title": "A Benchmark Dataset for Learning to Intervene in Online Hate Speech"
      },
      {
        "id": "2c87b6b48dba6315a6581098861f8bf2994799f6",
        "title": "MineRL: A Large-Scale Dataset of Minecraft Demonstrations"
      },
      {
        "id": "ac713aebdcc06f15f8ea61e1140bb360341fdf27",
        "title": "Thieves on Sesame Street! Model Extraction of BERT-based APIs"
      },
      {
        "id": "335b80aea1c815f1e0ad3843ce98b487056d01d4",
        "title": "Automated Essay Scoring: A Survey of the State of the Art"
      },
      {
        "id": "bd2fbe5f6c7f26851c004e659a1e38a8f5005d80",
        "title": "Fine-grained Sentiment Classification using BERT"
      },
      {
        "id": "6289471f2eca01dbde71e4832f93891f54b91cfe",
        "title": "SMILES Transformer: Pre-trained Molecular Fingerprint for Low Data Drug Discovery"
      },
      {
        "id": "6675b8ddeba7bfebb63a9ec506332f1e29b8b8ea",
        "title": "Semantic-Emotion Neural Network for Emotion Recognition From Text"
      },
      {
        "id": "8492269d2bb474d57d6def97efcf86c42735554a",
        "title": "BERT-based Ranking for Biomedical Entity Normalization"
      },
      {
        "id": "d645296d056978ef872d0d44286d6fac111425af",
        "title": "A Boundary-aware Neural Model for Nested Named Entity Recognition"
      },
      {
        "id": "ff336e68f6927d101b64978f1c94a2b4fdc42279",
        "title": "A Review of Text Corpus-Based Tourism Big Data Mining"
      },
      {
        "id": "460ab2a10990e67b38b6b37b4208d6c552864419",
        "title": "Improved Word Sense Disambiguation Using Pre-Trained Contextualized Word Representations"
      },
      {
        "id": "463fefdbd81a4a0a32cf59bc58a9545757c8cf2e",
        "title": "Pre-trained Contextual Embedding of Source Code"
      },
      {
        "id": "fbf2a6a887ea92311cf207d522c535daf867a6ba",
        "title": "Pre-Trained Text Embeddings for Enhanced Text-to-Speech Synthesis"
      },
      {
        "id": "1a08879a705412baa146977c0bd73dc9a2dc3f3f",
        "title": "Semantic Textual Similarity with Siamese Neural Networks"
      },
      {
        "id": "bd01b18df9a39cdd5c66f44051d62f176e9c8e7e",
        "title": "A BERT-BiLSTM-CRF Model for Chinese Electronic Medical Records Named Entity Recognition"
      },
      {
        "id": "829efe5ee2ea45fde92cc0a288f2d39a44820bee",
        "title": "Introducing MANtIS: a novel Multi-Domain Information Seeking Dialogues Dataset"
      },
      {
        "id": "2115ea50eb12845d6bf9193b969ea144415cd0f1",
        "title": "Pretrained Transformers for Simple Question Answering over Knowledge Graphs"
      },
      {
        "id": "9209e4e599f4a64671d979fbcb89c8dcf6a77580",
        "title": "Emotion Recognition for Vietnamese Social Media Text"
      },
      {
        "id": "2e94d9ba9199b874f966881949f57ea6c417773c",
        "title": "CoSimLex: A Resource for Evaluating Graded Word Similarity in Context"
      },
      {
        "id": "94f5bf97725424ab9672273179238050440736cd",
        "title": "Enhancing BERT for Lexical Normalization"
      },
      {
        "id": "d48c92e3e34e64c26f0bee4c4dec3e5d809dd1d7",
        "title": "Text-based inference of moral sentiment change"
      },
      {
        "id": "dec69765fc6c188897b09c8282d32db788e2c261",
        "title": "Improving Pre-Trained Multilingual Model with Vocabulary Expansion"
      },
      {
        "id": "c080e6a779a7eb6a0d72f36bacebf11e4d4143e3",
        "title": "Attention-based Sentiment Reasoner for aspect-based sentiment analysis"
      },
      {
        "id": "c26324a903aeda98da8f83406990ceb33673334d",
        "title": "An overview of word and sense similarity"
      },
      {
        "id": "71901b0476961981162a6a4086eaa40012becfce",
        "title": "From English to Code-Switching: Transfer Learning with Strong Morphological Clues"
      },
      {
        "id": "1fb6e059600bbd6c7ce56cb1edaf674f590c5ebe",
        "title": "Transfer Learning for Punctuation Prediction"
      },
      {
        "id": "7b6d7cf6dd44b7a4af419c1b9a281c16f9028195",
        "title": "A Survey on Named Entity Recognition"
      },
      {
        "id": "ca564ef7619168e371ce1e80742e521c8f037641",
        "title": "QE BERT: Bilingual BERT Using Multi-task Learning for Neural Quality Estimation"
      },
      {
        "id": "19a6f2a6ef7f1448208123878d3f6352a0ab9534",
        "title": "Predicting Prosodic Prominence from Text with Pre-trained Contextualized Word Representations"
      },
      {
        "id": "efd81977f1e74138cf2ac3e9a42112b95f648c66",
        "title": "Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling"
      },
      {
        "id": "e3e706af4cff21b3b79cccc2fe1751d93b083a2d",
        "title": "Resume Information Extraction with A Novel Text Block Segmentation Algorithm"
      },
      {
        "id": "252879b227f494df00d465602342f6c38effd27b",
        "title": "M-BERT: Injecting Multimodal Information in the BERT Structure"
      },
      {
        "id": "4ddb924d2018f006324d930034a031b41af8c763",
        "title": "Effective Adversarial Regularization for Neural Machine Translation"
      },
      {
        "id": "5d48d44bea63e1706e731dc4d33fe77daa38a166",
        "title": "Active Learning with Deep Pre-trained Models for Sequence Tagging of Clinical and Biomedical Texts"
      },
      {
        "id": "5608b84d3ccd33e2be2e266b8e61d8db6f96d7c7",
        "title": "A Survey on Document-level Machine Translation: Methods and Evaluation"
      },
      {
        "id": "e6f3d54968803cf18f58248f0fb3c7345917dd65",
        "title": "Analyzing Wikipedia Deletion Debates with a Group Decision-Making Forecast Model"
      },
      {
        "id": "71e43ea1b91213d5bb35e9e79476f03c56e2af60",
        "title": "A regionalization method for clustering and partitioning based on trajectories from NLP perspective"
      },
      {
        "id": "1fe27f02b5f03f02e702e90ea76b7f41b6a52e80",
        "title": "Big spatio‐temporal data mining for emergency management information systems"
      },
      {
        "id": "645a96e5c474d919415850892880005e4ad3fb43",
        "title": "Does BERT agree? Evaluating knowledge of structure dependence through agreement relations"
      },
      {
        "id": "ef6bc72585db907775a43cebd494df62b9065be1",
        "title": "Answering questions by learning to rank - Learning to rank by answering questions"
      },
      {
        "id": "c05692dd5c69b142c0f5e1c796b120794cbfe3cd",
        "title": "Research on Chinese Naming Recognition Model Based on BERT Embedding"
      },
      {
        "id": "38e38bf3e6adf7060f889f5c1e54ef60ee0924c1",
        "title": "Automatic Creation of Text Corpora for Low-Resource Languages from the Internet: The Case of Swiss German"
      },
      {
        "id": "ac038639159fd921b16b88278a77c629188380cd",
        "title": "ArbEngVec : Arabic-English Cross-Lingual Word Embedding Model"
      },
      {
        "id": "5087869b407f7bf96327e8145bf05c275207bd36",
        "title": "Improving Machine Reading Comprehension via Adversarial Training"
      },
      {
        "id": "7eaf9a7baa66ab6edf7d739d93e2e95f964c222f",
        "title": "L2RS: A Learning-to-Rescore Mechanism for Automatic Speech Recognition"
      },
      {
        "id": "d8d7e338e528bdf89c589ab5926fc9ec4339c78b",
        "title": "Embedding Strategies for Specialized Domains: Application to Clinical Entity Recognition"
      },
      {
        "id": "e80fb4dba760800871b277246dcec548a63b3d46",
        "title": "A Comparison of Architectures and Pretraining Methods for Contextualized Multilingual Word Embeddings"
      },
      {
        "id": "07b338e2443370838f0ab5d7073d43b8e4175605",
        "title": "Leveraging BERT to Improve the FEARS Index for Stock Forecasting"
      },
      {
        "id": "28ebca4443249f83bae246fbb1d377b4a68b1439",
        "title": "DCNN-BiGRU Text Classification Model Based on BERT Embedding"
      },
      {
        "id": "054a9b139151afa3158244c0bfe0761c72488a9e",
        "title": "Representing Multiword Chemical Terms through Phrase-Level Preprocessing and Word Embedding"
      },
      {
        "id": "e953af85982d17a75ee4f9c647b888a891575ce7",
        "title": "Enhancing Unsupervised Sentence Similarity Methods with Deep Contextualised Word Representations"
      },
      {
        "id": "8c8a4bc6d026de598f52a6f4c39d3c1a383ab5bf",
        "title": "BioReddit: Word Embeddings for User-Generated Biomedical NLP"
      },
      {
        "id": "b30a339d53c32c5557f6ec1d817c7a16b9f2b331",
        "title": "Machine Translation for Machines: the Sentiment Classification Use Case"
      },
      {
        "id": "ba7f953f8b1c31057375ab56c0cc0e0820e2fbfe",
        "title": "Topic Segmentation for Dialogue Stream"
      },
      {
        "id": "27e04b42da1d1535eb9752195b7c1c6d662bc313",
        "title": "Minimally Supervised Learning of Affective Events Using Discourse Relations"
      },
      {
        "id": "04fbd8d95e71734f3bac31b6741751f6f7ac0244",
        "title": "Deep learning contextual models for prediction of sport event outcome from sportsman’s interviews"
      },
      {
        "id": "9abd13caa32b1a90e32462a884a512f8666e80cc",
        "title": "A Split-and-Recombine Approach for Follow-up Query Analysis"
      },
      {
        "id": "16981cc4ddefd3ea7655754fd83a2a8ff2203a8b",
        "title": "Automatically Neutralizing Subjective Bias in Text"
      },
      {
        "id": "78f4368f0e4b0ba65dd1a9d79995b2d0873061aa",
        "title": "Automatic Generation of Acceptance Test Cases From Use Case Specifications: An NLP-Based Approach"
      },
      {
        "id": "ccc6a553a671b8d3bcc81f105636d273e829cb1a",
        "title": "Automatic Generation of System Test Cases from Use Case Specifications: an NLP-based Approach"
      },
      {
        "id": "b94a72dc6f2da90717f3a6810500e81dbbdc308d",
        "title": "Harnessing Evolution of Multi-Turn Conversations for Effective Answer Retrieval"
      },
      {
        "id": "42cf4bd30534a10b48004d74ee9a964d1edebb3e",
        "title": "Exploring Knowledge Graphs in an Interpretable Composite Approach for Text Entailment"
      },
      {
        "id": "596c5016b4c6541419c20d72b7e7d4d238402bfe",
        "title": "AutoML Strategy Based on Grammatical Evolution: A Case Study about Knowledge Discovery from Text"
      },
      {
        "id": "0f7b5ca9535c972f783960e9d87ba9014b578495",
        "title": "Drug-Drug Interaction Extraction Based on Transfer Weight Matrix and Memory Network"
      },
      {
        "id": "8aa1d9145640b4a63258b82bc8180c3683d072b5",
        "title": "KU_ai at MEDIQA 2019: Domain-specific Pre-training and Transfer Learning for Medical NLI"
      },
      {
        "id": "ab456c1ed181c5c48a34adb61395d4806a0ba949",
        "title": "Attention in Natural Language Processing"
      },
      {
        "id": "e3567830f32444917af2d06c213435b7f1a92cd2",
        "title": "Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain)"
      },
      {
        "id": "85e3010ff82c07961bc21f63b91a4981fa5123fe",
        "title": "Neural transfer learning for natural language processing"
      },
      {
        "id": "4d271f0129de69cb1c57b06260b40a6d6f59dacf",
        "title": "NULI at SemEval-2019 Task 6: Transfer Learning for Offensive Language Detection using Bidirectional Transformers"
      },
      {
        "id": "81ef57662f3a9410f8e7008005758c719a0293e7",
        "title": "A Review of Automated Speech and Language Features for Assessment of Cognitive and Thought Disorders"
      },
      {
        "id": "5507d267bbf0b4cdb9f893c3c0960a45016f7010",
        "title": "Deep Leakage from Gradients"
      },
      {
        "id": "d4c1cfc0cce2140fb8cf5c175c0a34b467298ee9",
        "title": "Deep Closest Point: Learning Representations for Point Cloud Registration"
      },
      {
        "id": "ae0b188793d999e44ec84fce18d7b0c22edaa063",
        "title": "Large Scale Linguistic Processing of Tweets to Understand Social Interactions among Speakers of Less Resourced Languages: The Basque Case"
      },
      {
        "id": "c8b1a81835d2e3973a1a1ea49a8ef236c16a910b",
        "title": "BioWordVec, improving biomedical word embeddings with subword information and MeSH"
      },
      {
        "id": "80270172e6c341626458b1daaf0c642e85d205ec",
        "title": "Evaluating word embedding models: methods and experimental results"
      },
      {
        "id": "e601c09867dfbee176333067b2e79b8548e993a9",
        "title": "Augmenting Data with Mixup for Sentence Classification: An Empirical Study"
      },
      {
        "id": "81e1d123a85562555befb0243256b1a0d9fca014",
        "title": "Understanding and Improving Transformer From a Multi-Particle Dynamic System Point of View"
      },
      {
        "id": "51a30be48add8b9bf8f8d2e3f69ee1d4e06e2db0",
        "title": "Latent Space Cartography: Visual Analysis of Vector Space Embeddings"
      },
      {
        "id": "7f9ca11d122957dc59088543f6cd9f907c00d0d3",
        "title": "Neural Models of Text Normalization for Speech Applications"
      },
      {
        "id": "98d8f540f5b31f507db75535162b9eadda4a5b0c",
        "title": "Toward Interpretable Music Tagging with Self-Attention"
      },
      {
        "id": "c4692e5d11cde0f10cbd5a534a5870eb299e8156",
        "title": "Jointly Measuring Diversity and Quality in Text Generation Models"
      },
      {
        "id": "d1952ce95709e714e6e468e52f1140941f7cbb47",
        "title": "Merge and Label: A Novel Neural Network Architecture for Nested NER"
      },
      {
        "id": "1d8f4f54ed7a80d1d7172a09c33cd627de570bca",
        "title": "MatchZoo: A Learning, Practicing, and Developing System for Neural Text Matching"
      },
      {
        "id": "4c48b8237557c94f643792b44855c83ae98f3eda",
        "title": "Emotion Detection and Analysis on Social Media"
      },
      {
        "id": "202431160558d927a8ebc0f25885df0749803117",
        "title": "FoodIE: A Rule-based Named-entity Recognition Method for Food Information Extraction"
      },
      {
        "id": "2a8a2c0bc425bde5facef371607b194db2eda658",
        "title": "FoodBase corpus: a new resource of annotated food entities"
      },
      {
        "id": "61d24c45e41f4f6cfc3d9da2f03efde1862b839e",
        "title": "Using Similarity Measures to Select Pretraining Data for NER"
      },
      {
        "id": "b2fc15dcd0f223b06be7195fee16364c260433fa",
        "title": "An Approach for Process Model Extraction by Multi-grained Text Classification"
      },
      {
        "id": "e0f4cbf73be7b75d068396539bc9c94a10d3b40e",
        "title": "BERT-based Financial Sentiment Index and LSTM-based Stock Return Predictability"
      },
      {
        "id": "32bedc53ff777fc2f15d231ab856db2b1c9ee8c2",
        "title": "A Graph-based Model for Joint Chinese Word Segmentation and Dependency Parsing"
      },
      {
        "id": "b5c7a101240de7d59e7a8e18e2dbfd1fcba1d1c8",
        "title": "Adapting Sequence to Sequence models for Text Normalization in Social Media"
      },
      {
        "id": "abcad78d2dba846e7c02ab853f86fbb258ad9952",
        "title": "An Active Learning Approach for Improving the Accuracy of Automated Domain Model Extraction"
      },
      {
        "id": "ef16cfb732304eac420ccb344859dd660ace0b6a",
        "title": "Performance Analysis of Deep Learning Workloads on Leading-edge Systems"
      },
      {
        "id": "dd47e8b3405c7d7ebd16d33267dc7c0feff3e873",
        "title": "Is It Worth the Attention? A Comparative Evaluation of Attention Layers for Argument Unit Segmentation"
      },
      {
        "id": "a52ad4f73f690c350c054a2463db9bc5f94e9360",
        "title": "Gendered Pronoun Resolution using BERT and an Extractive Question Answering Formulation"
      },
      {
        "id": "be04748e87facf2df63dc709d8d289766376d193",
        "title": "Bridging the Semantic Gap with SQL Query Logs in Natural Language Interfaces to Databases"
      },
      {
        "id": "9695676deace8c05d4e95274b92f20ed1e97470c",
        "title": "CLEVR-Ref+: Diagnosing Visual Reasoning With Referring Expressions"
      },
      {
        "id": "596b46dbe4fa8eee72e517ea9fd5f8ef83c9c64e",
        "title": "Quizbowl: The Case for Incremental Question Answering"
      }
    ],
    "2": [
      {
        "id": "9405cc0d6169988371b2755e573cc28650d14dfe",
        "title": "Language Models are Unsupervised Multitask Learners"
      },
      {
        "id": "90abbc2cf38462b954ae1b772fac9532e2ccd8b0",
        "title": "Language Models are Few-Shot Learners"
      },
      {
        "id": "9ffcb3624f2637b5d0fe28c61ec8472293cfebc7",
        "title": "All the News That’s Fit to Fabricate: AI-Generated Text as a Tool of Media Misinformation"
      },
      {
        "id": "bb6c2a64ecb6e4c9f3f5720d53cca76a2c37505d",
        "title": "Experience Grounds Language"
      },
      {
        "id": "babeda48b10a4d638252118f2238d05a06f4ec55",
        "title": "StereoSet: Measuring stereotypical bias in pretrained language models"
      },
      {
        "id": "2ffcf8352223c95ae8cef4daaec995525ecc926b",
        "title": "Adversarial Training for Large Neural Language Models"
      },
      {
        "id": "5d22b241836e30d5b0d852b463951ab7e3245ea4",
        "title": "Reducing Sentiment Bias in Language Models via Counterfactual Evaluation"
      },
      {
        "id": "9146414fca384e73f11ccfd3db8ad6d2a1e8eda2",
        "title": "Automatic Detection of Generated Text is Easiest when Humans are Fooled"
      },
      {
        "id": "dfc7b58b67c31932b48586b3e23a43cc94695290",
        "title": "UNITER: UNiversal Image-TExt Representation Learning"
      },
      {
        "id": "54416048772b921720f19869ed11c2a360589d03",
        "title": "UNITER: Learning UNiversal Image-TExt Representations"
      },
      {
        "id": "7a15950dc71079285a4eaf195de5aadd87c41b40",
        "title": "Fine-Tuning Language Models from Human Preferences"
      },
      {
        "id": "5019dbe8d1da5f128f4f373d6849095cf18fd519",
        "title": "The Woman Worked as a Babysitter: On Biases in Language Generation"
      },
      {
        "id": "c7462e0ee928f095a7fc40b91f1e7557d283ae8e",
        "title": "Release Strategies and the Social Impacts of Language Models"
      },
      {
        "id": "867db5097ad6aaef098c60b0845785b440eca49a",
        "title": "GLTR: Statistical Detection and Visualization of Generated Text"
      },
      {
        "id": "ad7129af0644dbcafa9aa2f111cb76526ea444a1",
        "title": "Defending Against Neural Fake News"
      },
      {
        "id": "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad",
        "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"
      },
      {
        "id": "cf4aa38ae31b43fd07abe13b4ffdb265babb7be1",
        "title": "The Curious Case of Neural Text Degeneration"
      },
      {
        "id": "88bd75ce3ce22ed85bf9271877aa85da7b7bb312",
        "title": "Massively Multilingual Neural Machine Translation"
      },
      {
        "id": "ad7ddcc14984caae308c397f1a589aae75d4ab71",
        "title": "Training data-efficient image transformers & distillation through attention"
      },
      {
        "id": "a8ca46b171467ceb2d7652fbfb67fe701ad86092",
        "title": "LoRA: Low-Rank Adaptation of Large Language Models"
      },
      {
        "id": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269",
        "title": "Evaluating Large Language Models Trained on Code"
      },
      {
        "id": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4",
        "title": "Learning Transferable Visual Models From Natural Language Supervision"
      },
      {
        "id": "f0110d0f7e938038bc1305c4c243b2d631d32c39",
        "title": "Federated Learning Meets Natural Language Processing: A Survey"
      },
      {
        "id": "8a191a131b2d81783ca9baac21f499548821c032",
        "title": "The Dawn of Quantum Natural Language Processing"
      },
      {
        "id": "5e86c1adbe5b7cfccf2201e1c34400c819cdcdab",
        "title": "The King is Naked: on the Notion of Robustness for Natural Language Processing"
      },
      {
        "id": "dad19370f9713bbce9f7df77c7ee000e011e3b8f",
        "title": "Natural Language Video Localization with Learnable Moment Proposals"
      },
      {
        "id": "52db8674337e5d86dcb96d013734befc8c3d4581",
        "title": "Large Language Models are not Models of Natural Language: they are Corpus Models."
      },
      {
        "id": "75c864fc2e384ce299a4031e31c48f9ebc0a9842",
        "title": "Natural Language for Human-Robot Collaboration: Problems Beyond Language Grounding"
      },
      {
        "id": "80d0116d77beeded0c23cf48946d9d10d4faee14",
        "title": "GLaM: Efficient Scaling of Language Models with Mixture-of-Experts"
      },
      {
        "id": "c2a79e2a65b721d4de5f6d4806323174b9f8f393",
        "title": "Towards Zero-Label Language Learning"
      },
      {
        "id": "20a01009d38d083a49e01ef46005363135453661",
        "title": "The great Transformer: Examining the role of large language models in the political economy of AI"
      },
      {
        "id": "4ce2ceb4ee975b032578e8816cb8f50a9984c76e",
        "title": "Adapting GPT, GPT-2 and BERT Language Models for Speech Recognition"
      },
      {
        "id": "8f7f9d973c511f80a29d7f081949a317fc742d63",
        "title": "Transformer-Based Deep Neural Language Modeling for Construct-Specific Automatic Item Generation"
      },
      {
        "id": "0d232524732c133e428e8867de69a48886509a7e",
        "title": "Explainable Semantic Space by Grounding Language to Vision with Cross-Modal Contrastive Learning"
      },
      {
        "id": "3d46e008543b353b51407fb805edbd1da23dfe6c",
        "title": "Language Models as a Knowledge Source for Cognitive Agents"
      },
      {
        "id": "5dcc65466e4dd1f400823f424d720422a65cd7a5",
        "title": "Technical Language Supervision for Intelligent Fault Diagnosis in Process Industry"
      },
      {
        "id": "bd9ab344da99022cbbbfd3f5c9c82a0b21c60ad9",
        "title": "nnFormer: Volumetric Medical Image Segmentation via a 3D Transformer"
      },
      {
        "id": "a9c214e846188adb645021cd7b1964b8ea1fef6f",
        "title": "Rethinking and Improving Relative Position Encoding for Vision Transformer"
      },
      {
        "id": "614dd2ae6db71cd5b2a6069407d3e0705ab2c19c",
        "title": "OpenPrompt: An Open-source Framework for Prompt-learning"
      },
      {
        "id": "333212e246fb65f7c9d43862021e78f007c48449",
        "title": "A Survey of Visual Transformers"
      },
      {
        "id": "c215987b9fb31c2152773368102b9e45f75181a1",
        "title": "End-to-End Referring Video Object Segmentation with Multimodal Transformers"
      },
      {
        "id": "1cbb3d96242c3f47c3f40aada33616d0f5c07737",
        "title": "Inductive Biases and Variable Creation in Self-Attention Mechanisms"
      },
      {
        "id": "5e2180e4ce9d218cccb1c78a93a863d5f967d907",
        "title": "Transformers in computational visual media: A survey"
      },
      {
        "id": "e3b400db8dfe913d7865d8ded26a621e1902b830",
        "title": "TRS: Transformers for Remote Sensing Scene Classification"
      },
      {
        "id": "60c498956cb5737c4964aaca0b920592bd7f5689",
        "title": "Are Gender-Neutral Queries Really Gender-Neutral? Mitigating Gender Bias in Image Search"
      },
      {
        "id": "16a17202cdd05a88282d2471912e6dd512cc1c25",
        "title": "Meta Self-training for Few-shot Neural Sequence Labeling"
      },
      {
        "id": "a702ceeabc4c2e959513747f7ed2f5c29f7dbfcd",
        "title": "Collective intelligence for deep learning: A survey of recent developments"
      },
      {
        "id": "82edbb92d0f6952224c5aa0aff264b44b8fb4e98",
        "title": "Toward Foundation Models for Earth Monitoring: Proposal for a Climate Change Benchmark"
      },
      {
        "id": "03da17fc6d1868efc0b91872f1823e8ff4612824",
        "title": "Direction Relation Transformer for Image Captioning"
      },
      {
        "id": "f8cdb94c0446f3170cbb32ad6019b21839c4b237",
        "title": "Words to Matter: De novo Architected Materials Design Using Transformer Neural Networks"
      },
      {
        "id": "203b965e5c9eb1e1c521ec66f82b036335c7cd4d",
        "title": "Shifted Chunk Transformer for Spatio-Temporal Representational Learning"
      },
      {
        "id": "1667f299ecabc56206967b14caa06dd3350b6c87",
        "title": "Serf: Towards better training of deep neural networks using log-Softplus ERror activation Function"
      },
      {
        "id": "3299a03c49bc1a0a5f396ae6c6a659fe2b4ee3b0",
        "title": "Q-Pain: A Question Answering Dataset to Measure Social Bias in Pain Management"
      },
      {
        "id": "2ba1a332484d30b86871a30b4fe85e7e9e7266cb",
        "title": "Capitalization and punctuation restoration: a survey"
      },
      {
        "id": "a0e6eeae8755260b8e0092e83b0249ab4f80d964",
        "title": "Creating User Interface Mock-ups from High-Level Text Descriptions with Deep-Learning Models"
      },
      {
        "id": "61df7b79b7c1df8557d9f6a1642a6315cad40d7d",
        "title": "Make A Long Image Short: Adaptive Token Length for Vision Transformers"
      },
      {
        "id": "e1f7478294fe01ce271cdef9ba93f4c675d92dc9",
        "title": "Object Detection of Road Assets Using Transformer-Based YOLOX with Feature Pyramid Decoder on Thai Highway Panorama"
      },
      {
        "id": "e9c0378ae58fb48c776605a855dd52abcaa9aa27",
        "title": "DaCy: A Unified Framework for Danish NLP"
      },
      {
        "id": "cbeff5462c08822f483bc7ed6678ce192e215d99",
        "title": "Causal Transformers Perform Below Chance on Recursive Nested Constructions, Unlike Humans"
      },
      {
        "id": "13524c776d9f143ea98625bca8b291dd5d9bc71c",
        "title": "Calibrate your listeners! Robust communication-based training for pragmatic speakers"
      },
      {
        "id": "0e8d71db17c07378ccee228a198abcd425b0cf21",
        "title": "Indian Legal NLP Benchmarks : A Survey"
      },
      {
        "id": "5436193122dff271796bca07df7cecb7a8d6dea6",
        "title": "Natural language-guided programming"
      },
      {
        "id": "88e8801e4daf404d3d40f1648ef29faeb8e6d58a",
        "title": "Blended Diffusion for Text-driven Editing of Natural Images"
      },
      {
        "id": "e2d328f98a6249a5e86c06c1934360e3c055141d",
        "title": "Multimodal Transformer with Variable-length Memory for Vision-and-Language Navigation"
      },
      {
        "id": "1ea78b1684371de0e859edf759e5e659152d31e3",
        "title": "What do Large Language Models Learn about Scripts?"
      },
      {
        "id": "42ba421092c4272a747b5321a27f988fd7b0d7f3",
        "title": "Adversarial Reinforced Instruction Attacker for Robust Vision-Language Navigation"
      },
      {
        "id": "e7f58f7463757ba4fe8b696a5f545db5386af2dc",
        "title": "DiMBERT: Learning Vision-Language Grounded Representations with Disentangled Multimodal-Attention"
      },
      {
        "id": "738e3e0623054da29dc57fc6aee5e6711867c4e8",
        "title": "CLIP-Forge: Towards Zero-Shot Text-to-Shape Generation"
      },
      {
        "id": "76a2b197b5427ffd1d3470c6d3ea026588eb5d0a",
        "title": "CRIS: CLIP-Driven Referring Image Segmentation"
      },
      {
        "id": "b73a9d4e42dbdd0c8320231111c2bdc8243c6d3a",
        "title": "Fast Video Moment Retrieval"
      },
      {
        "id": "38dcd087f0c2801fcd75c0906a0e12258087ce8b",
        "title": "FairyTailor: A Multimodal Generative Framework for Storytelling"
      },
      {
        "id": "1c83f3f9789df43bf937ae2618721e2da83dcc06",
        "title": "From Show to Tell: A Survey on Deep Learning-Based Image Captioning"
      },
      {
        "id": "fe9d978f7718474e9613bac114c398614f09be71",
        "title": "Sinkformers: Transformers with Doubly Stochastic Attention"
      },
      {
        "id": "8473e8a6534130418e05977e91fc874dcd5e56de",
        "title": "Context-Sensitive Visualization of Deep Learning Natural Language Processing Models"
      },
      {
        "id": "528c392b89d0bfc67923b51ac62820b5ec1d1632",
        "title": "Mapping the plague through natural language processing"
      },
      {
        "id": "8be99c2d0802d6222e233dd67d2927c75a0bed24",
        "title": "Towards Accurate Visual and Natural Language-Based Vehicle Retrieval Systems"
      },
      {
        "id": "55b17a76d8b9f0a9adb5c116450a2cfd2844448c",
        "title": "ImaginE: An Imagination-Based Automatic Evaluation Metric for Natural Language Generation"
      },
      {
        "id": "f5d1dbdaa6c8a44f388f3f7fe538403baefc1252",
        "title": "Large pre-trained language models contain human-like biases of what is right and wrong to do"
      },
      {
        "id": "c586f3a69102fffdff178ca79b0be767d384da43",
        "title": "Hidden Backdoors in Human-Centric Language Models"
      },
      {
        "id": "4891cc27e296e0ead23407a835bcd3bbb802ce67",
        "title": "Automatic Code Generation using Pre-Trained Language Models"
      },
      {
        "id": "b3e0e149669d21582b3bb6add9124aa4fb3f90dd",
        "title": "ParaLaw Nets - Cross-lingual Sentence-level Pretraining for Legal Text Processing"
      },
      {
        "id": "3a906b77fa218adc171fecb28bb81c24c14dcc7b",
        "title": "Transformers in Vision: A Survey"
      },
      {
        "id": "7519a1e9e7371df79bd8a21cee871feb0ec597a5",
        "title": "UNETR: Transformers for 3D Medical Image Segmentation"
      },
      {
        "id": "147164a3905f41a7a5a10f732d086a621c9c5862",
        "title": "TransBTS: Multimodal Brain Tumor Segmentation Using Transformer"
      },
      {
        "id": "7fff8018bf625447df837c2fda5c58a705fbc038",
        "title": "XCiT: Cross-Covariance Image Transformers"
      },
      {
        "id": "7507603da9711c0e43e29f3094f33d9337e7dfbd",
        "title": "3D Human Pose Estimation with Spatial and Temporal Transformers"
      },
      {
        "id": "2984ab83ade26639c3a82d29628d0d9e4abbebb0",
        "title": "Incorporating Convolution Designs into Visual Transformers"
      },
      {
        "id": "3cbe314cc5407a6c3249815b5173f22ea15173c2",
        "title": "Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding"
      },
      {
        "id": "f8b5340b221ac2ac7c2067f28032c00636e6fc14",
        "title": "Vision Transformers for Remote Sensing Image Classification"
      },
      {
        "id": "c8559021289f08eaf8cf2294e406bc1c6b506d19",
        "title": "Recent advances in deep learning based dialogue systems: a systematic survey"
      },
      {
        "id": "2e8149dafb864ec3675087c99bf5572fcf4eb170",
        "title": "RegionViT: Regional-to-Local Attention for Vision Transformers"
      },
      {
        "id": "0c97903e7d85c05bcd2a7e26fc2a4a47998f5dde",
        "title": "Plagiarism in the age of massive Generative Pre-trained Transformers (GPT-3)"
      },
      {
        "id": "d4f6ef636e16b001986b541aa2afc76eed42ae34",
        "title": "Considering the possibilities and pitfalls of Generative Pre-trained Transformer 3 (GPT-3) in healthcare delivery"
      },
      {
        "id": "c0e6cd2ec3bc9eb46c7d45bb708854da3327339e",
        "title": "A Survey on Bias in Deep NLP"
      },
      {
        "id": "166e98317ed9c4687e71bef55a6800431e00b8fa",
        "title": "SiT: Self-supervised vIsion Transformer"
      },
      {
        "id": "8e27d8069035cb22a8c1c50d3971b4a61f0143f4",
        "title": "Keyword Transformer: A Self-Attention Model for Keyword Spotting"
      },
      {
        "id": "b2186dd1ccc4b7adcf70c0cf7649c2c118e4ceea",
        "title": "Self-Attention Networks Can Process Bounded Hierarchical Languages"
      },
      {
        "id": "1f668aebd03b5150c2c2fddae48f4a65cb4a80a8",
        "title": "Container: Context Aggregation Network"
      },
      {
        "id": "09a4d9ab6a305ecf04d8a2e8f4d979f1bfbe1dc3",
        "title": "URLTran: Improving Phishing URL Detection Using Transformers"
      },
      {
        "id": "d93b5079c9d668d89948ab2b8e14e88f63ff806b",
        "title": "A Package for Learning on Tabular and Text Data with Transformers"
      },
      {
        "id": "26e3d58181724f9ef77973ff0f65bac06e499fec",
        "title": "ProphetNet-X: Large-Scale Pre-training Models for English, Chinese, Multi-lingual, Dialog, and Code Generation"
      },
      {
        "id": "26b7eacd6aaff6c2bd1beac40b96597fb1d29a1e",
        "title": "Lawyers are Dishonest? Quantifying Representational Harms in Commonsense Knowledge Resources"
      },
      {
        "id": "e4720dfdbc2d0da5db0ddf04cdab3a531c74680f",
        "title": "Text analysis using deep neural networks in digital humanities and information science"
      },
      {
        "id": "a53806d486c42d2eb7ba57d8f2c81e5b2a51479c",
        "title": "Parallel Attention Network with Sequence Matching for Video Grounding"
      },
      {
        "id": "fbcbe5a222786f38a1c69c3487b4edf8ca469934",
        "title": "Fully Transformer Networks for Semantic Image Segmentation"
      },
      {
        "id": "8005e5bee6da81d44602e788100f7050728d0fdf",
        "title": "Generating Synthetic Training Data for Supervised De-Identification of Electronic Health Records"
      },
      {
        "id": "0216e5538eeb93c3adea7a6e01bd87709b277b0a",
        "title": "Spatiotemporal Transformer for Video-based Person Re-identification"
      },
      {
        "id": "ca7f973fdccba54b2625c6a7e3d1b3ee4090808a",
        "title": "Analysis of Text Feature Extractors using Deep Learning on Fake News"
      },
      {
        "id": "7303d35fd15ac87e9c3f7dc7b8b9ec05cccef95b",
        "title": "Point Cloud Learning with Transformer"
      },
      {
        "id": "b3c914c8fc3eb3620ed1406289ae4f1ca2c617b0",
        "title": "Cross-Modal Retrieval Augmentation for Multi-Modal Classification"
      },
      {
        "id": "98adf45ce7a9b6bc5424b641ca22724fb770e529",
        "title": "Understanding Emails and Drafting Responses - An Approach Using GPT-3"
      },
      {
        "id": "fce6039fb422c830f814b4be601396fce2d2db1e",
        "title": "Divergence Frontiers for Generative Models: Sample Complexity, Quantization Effects, and Frontier Integrals"
      },
      {
        "id": "bd818d68b7709d79c0e4e8afa53d900abe419342",
        "title": "An Approach to Improve Robustness of NLP Systems against ASR Errors"
      },
      {
        "id": "4e474ee850f271e580fcc2a5c5fcb5c3cbf13543",
        "title": "When Word Embeddings Become Endangered"
      },
      {
        "id": "830adc0819013d90fd682d2e60a1e62626c7f2c0",
        "title": "Using Sub-character Level Information for Neural Machine Translation of Logographic Languages"
      },
      {
        "id": "f58691777d9f534a55d8ea3b7e1c3c3a44933b05",
        "title": "Neural Dialogue Generation Methods in Open Domain: A Survey"
      },
      {
        "id": "ae3d6eb676079d67068cbef2dcac7bcd220e3803",
        "title": "Knowledge-driven Natural Language Understanding of English Text and its Applications"
      },
      {
        "id": "9c0b7bdb8d81c31063aa805556167a35767ec5d7",
        "title": "Perception Matters: Detecting Perception Failures of VQA Models Using Metamorphic Testing"
      },
      {
        "id": "f13bbe25e59fef5a209091b6192841367b2a87a4",
        "title": "MusCaps: Generating Captions for Music Audio"
      },
      {
        "id": "9adc1a3307c05ff3c9b0ae595cb57b1de041713f",
        "title": "Generating Synthetic Text Data to Evaluate Causal Inference Methods"
      },
      {
        "id": "2d535629ca98d22ea6b8a33a7a600f8f926eee7e",
        "title": "Non-Complementarity of Information in Word-Embedding and Brain Representations in Distinguishing between Concrete and Abstract Words"
      },
      {
        "id": "2dc59238ad0f010f505238fcd0dd0695681200ef",
        "title": "Neural Code Search Revisited: Enhancing Code Snippet Retrieval through Natural Language Intent"
      },
      {
        "id": "6fe9177f0dd44764b15fe4d42bd96b50dc5fb144",
        "title": "Multimodal Text Style Transfer for Outdoor Vision-and-Language Navigation"
      },
      {
        "id": "769b2f239bde15c01dbe3856a2ff216f6b0e003b",
        "title": "Brain2Word: Decoding Brain Activity for Language Generation"
      },
      {
        "id": "d40c77c010c8dbef6142903a02f2a73a85012d5d",
        "title": "A Survey on Vision Transformer"
      },
      {
        "id": "ff50b46b4e1cc0fd9beb832fc3468785b635a824",
        "title": "PCT: Point cloud transformer"
      },
      {
        "id": "71a85e735a3686bef8cce3725ae5ba82e2cabb1b",
        "title": "Underspecification Presents Challenges for Credibility in Modern Machine Learning"
      },
      {
        "id": "c13a8f9edb933e60c7a989244aee56283a54ce37",
        "title": "UP-DETR: Unsupervised Pre-training for Object Detection with Transformers"
      },
      {
        "id": "7b49bcd9fd53158a57d158550461bcb72ac83fbc",
        "title": "Overview of the Transformer-based Models for NLP Tasks"
      },
      {
        "id": "d2e54b3a596a1dce0def9d035dfe1fb7c0c6142a",
        "title": "Toward Transformer-Based Object Detection"
      },
      {
        "id": "9438bc5626b2d9a771cecc7a41ecabf6639db53c",
        "title": "Automatic Detection of Machine Generated Text: A Critical Survey"
      },
      {
        "id": "d3833e446e536f7627ae01c45cf265d6e736e78c",
        "title": "A Survey on Computational Propaganda Detection"
      },
      {
        "id": "8e6ae3ed8804ad097ce7e4587c33bf398688d763",
        "title": "Word meaning in minds and machines"
      },
      {
        "id": "6b1c351c7969e70daf13b4af83ac256c45041074",
        "title": "Leveraging Abstract Meaning Representation for Knowledge Base Question Answering"
      },
      {
        "id": "68a439902fd7d8005222f75d354a41fba6d60741",
        "title": "Efficient sparse collective communication and its application to accelerate distributed deep learning"
      },
      {
        "id": "9d8398d9c36d25ad1363d9a5dd922dbbfa7be3be",
        "title": "Referring Expression Comprehension: A Survey of Methods and Datasets"
      },
      {
        "id": "5dd8e4b80f5033aef1db1fad974437bc9b8e8112",
        "title": "Towards Holistic and Automatic Evaluation of Open-Domain Dialogue Generation"
      },
      {
        "id": "c299a4083443bea26188567979f20b8305554c0b",
        "title": "GenAug: Data Augmentation for Finetuning Text Generators"
      },
      {
        "id": "f0f81bda8974900a46d19ac9882cdeaa3dccf458",
        "title": "Visualizing Transformers for NLP: A Brief Survey"
      },
      {
        "id": "a22bbe723effe7deaec998b1b3690c8a7559d180",
        "title": "Contrastive Pre-training for Sequential Recommendation"
      },
      {
        "id": "e15982656e43cb880aee0388a9daf06a5f3d6464",
        "title": "A Semi-supervised Approach to Generate the Code-Mixed Text using Pre-trained Encoder and Transfer Learning"
      },
      {
        "id": "49f780951539665dea602c5ae4528fc67e656404",
        "title": "Adversarial Attack and Defense of Structured Prediction Models"
      },
      {
        "id": "b0903f184dfccc813d8165d0f69c87f79520014e",
        "title": "A Multimodal Memes Classification: A Survey and Open Research Issues"
      },
      {
        "id": "31fad264bb767909e337c56aded6b45873d555ce",
        "title": "Pushing the Limits of AMR Parsing with Self-Learning"
      },
      {
        "id": "4b2410f42b694d8a86a3860a245b7af234161d5c",
        "title": "Leveraging ParsBERT and Pretrained mT5 for Persian Abstractive Text Summarization"
      },
      {
        "id": "b0f7aac40fd8623c5cbbb40fa488d3a546818f48",
        "title": "SEMANTIC NETWORKS FOR ENGINEERING DESIGN: A SURVEY"
      },
      {
        "id": "73c06804ff4585925456e616f2202276e15621c5",
        "title": "Langsmith: An Interactive Academic Text Revision System"
      },
      {
        "id": "e25c85054084b33091d40aedb5dc063195dc33ee",
        "title": "Syntax Representation in Word Embeddings and Neural Networks - A Survey"
      },
      {
        "id": "9619cde5c79d91ca5c432186668618312175f8dd",
        "title": "Querying knowledge graphs in natural language"
      },
      {
        "id": "949b698f4aaaeea923d451db8175c5b464520f27",
        "title": "Reinforcement Learning for Weakly Supervised Temporal Grounding of Natural Language in Untrimmed Videos"
      },
      {
        "id": "5bb4f4be3aad75da5a64a52b56e697ee6df71e39",
        "title": "DAVE: Deriving Automatically Verilog from English"
      },
      {
        "id": "e0ce00b2c8bfa11cc15b1eb14d5656bed06012af",
        "title": "Neural Encoding and Decoding With Distributed Sentence Representations"
      },
      {
        "id": "dc3877e3058bc9c854e57770e596acf188d9b57e",
        "title": "Unit Test Case Generation with Transformers"
      },
      {
        "id": "bb6ae805a00f57c7d5316b18c83d9eead9ae0177",
        "title": "Natural Language Processing Applications in Business"
      },
      {
        "id": "5b015296730273921889e54a0a31e3b173017026",
        "title": "TOD-BERT: Pre-trained Natural Language Understanding for Task-Oriented Dialogue"
      },
      {
        "id": "1c6ae3f0e6f35d72f36832fe54d26383ddaf84c0",
        "title": "Stopwords in technical language processing"
      },
      {
        "id": "2a81f6bf76bcb70244aa40217ff316025971bd0f",
        "title": "Graph Optimal Transport for Cross-Domain Alignment"
      },
      {
        "id": "868c3a07ca240ad66d953bfb5094ad962f1cdca4",
        "title": "Causal Mediation Analysis for Interpreting Neural NLP: The Case of Gender Bias"
      },
      {
        "id": "7e0f91e51ee372939c96714c7919dde6dc756849",
        "title": "Improving Image Captioning with Better Use of Caption"
      },
      {
        "id": "76912f2d895788189c301286d486b31e5b99a33d",
        "title": "Exploring Transformer Text Generation for Medical Dataset Augmentation"
      },
      {
        "id": "4bce0e394c2bfdcbfbe5910a7740a653af3284d6",
        "title": "AQuA: ASP-Based Visual Question Answering"
      },
      {
        "id": "4bac79a4fb5e233d3d78a0967407e438a852220d",
        "title": "Visuo-Lingustic Question Answering (VLQA) Challenge"
      },
      {
        "id": "725d5acdbdf0a11677f785a16e1722b92c55a47f",
        "title": "MATINF: A Jointly Labeled Large-Scale Dataset for Classification, Question Answering and Summarization"
      },
      {
        "id": "3b2ae2a1de566788a6c4af2b2fffa9431a4eb91d",
        "title": "Is artificial data useful for biomedical Natural Language Processing algorithms?"
      },
      {
        "id": "ced2c3cacedd521e660ef4c85bebb1988c71cb96",
        "title": "Fast Compression and Optimization of Deep Learning Models for Natural Language Processing"
      },
      {
        "id": "872091517b0bfad0e9bc1826d4668022d1d57953",
        "title": "DEBUG: A Dense Bottom-Up Grounding Approach for Natural Language Video Localization"
      },
      {
        "id": "791c3c30f2af10ac06f4fbc5b1e8960064aacbc7",
        "title": "Large-Scale Transfer Learning for Natural Language Generation"
      },
      {
        "id": "65a9c7b0800c86a196bc14e7621ff895cc6ab287",
        "title": "ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks"
      },
      {
        "id": "1b31557fb34dcea11097e00b4de0ab08bedf0c23",
        "title": "Countering Language Drift via Visual Grounding"
      },
      {
        "id": "3630494fd49a059d52485743718b4b07dec7b374",
        "title": "Vision and language: from visual perception to content creation"
      },
      {
        "id": "6ebfbc954b9975d2f2651f380b9bdf46ae963178",
        "title": "PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable"
      },
      {
        "id": "7a09101ac03b74db501648597fa54e992a0fc84f",
        "title": "Towards Making the Most of BERT in Neural Machine Translation"
      },
      {
        "id": "be283fc67ecbfe0cb1e50718181ce7b9c0d53a74",
        "title": "How Does BERT Answer Questions?: A Layer-Wise Analysis of Transformer Representations"
      },
      {
        "id": "f5e04b56e412eb5243a232fed2b8de1c33e65e6b",
        "title": "A Replicable Comparison Study of NER Software: StanfordNLP, NLTK, OpenNLP, SpaCy, Gate"
      },
      {
        "id": "439377eb15b623cc223a1c59771d0d6535ee97de",
        "title": "MC-BERT4HATE: Hate Speech Detection using Multi-channel BERT for Different Languages and Translations"
      },
      {
        "id": "0f6b9ef228a0d396a55e972a07f91499953e3903",
        "title": "Towards Sentence-Level Brain Decoding with Distributed Representations"
      },
      {
        "id": "1a9de6d7ef12aa5c75a55b9088d8bf249674f20a",
        "title": "Visual Question Answering using Deep Learning: A Survey and Performance Analysis"
      },
      {
        "id": "aa89c5480d118e9d2ef0643ef082736d0bb1622d",
        "title": "Engineering Knowledge Graph for Keyword Discovery in Patent Search"
      },
      {
        "id": "df4e3aa275b8f81e22a5332ab550805083094dae",
        "title": "Findings of the Third Workshop on Neural Generation and Translation"
      },
      {
        "id": "da9ed8fcf82961562fee91a7ffe4b9da1f676345",
        "title": "INSET: Sentence Infilling with INter-SEntential Transformer"
      },
      {
        "id": "455c31d401981a49b08d7f6fefd62101734b925d",
        "title": "RadioTalk: a large-scale corpus of talk radio transcripts"
      },
      {
        "id": "e4c65ff44eb69d6b5631b8d352fb8c5dd947ee30",
        "title": "TEASPN: Framework and Protocol for Integrated Writing Assistance Environments"
      },
      {
        "id": "bf7cbd37e6be38f4c8871d70e639153479717a2d",
        "title": "Counterfactual Vision-and-Language Navigation via Adversarial Path Sampling"
      },
      {
        "id": "05106b86ec45914d1136719d311078182d437872",
        "title": "Hierarchy Parsing for Image Captioning"
      },
      {
        "id": "200050c1f51e2c930e62b078c6ce20f2a6675468",
        "title": "A Pre-training Based Personalized Dialogue Generation Model with Persona-sparse Data"
      },
      {
        "id": "7dc156eb9d84ae8fd521ecac5ccc5b5426a42b50",
        "title": "A Survey of Reinforcement Learning Informed by Natural Language"
      },
      {
        "id": "82e32585088ae5b8bf5497919f85022e397a75ad",
        "title": "Linguistic generalization and compositionality in modern artificial neural networks"
      },
      {
        "id": "a9c3a009d754a110379574b069b48c0b4c75db40",
        "title": "Rare Words: A Major Problem for Contextualized Embeddings And How to Fix it by Attentive Mimicking"
      },
      {
        "id": "43fbaa810a5b46a5439ca466692b9986befc97e6",
        "title": "Transfer Learning for Scientific Data Chain Extraction in Small Chemical Corpus with joint BERT-CRF Model"
      },
      {
        "id": "3ceae5a0913d61e3753276c2f95df718eb970893",
        "title": "Empirical Evaluation and Combination of Punctuation Prediction Models Applied to Broadcast News"
      },
      {
        "id": "b3564be8b79f25585acb035f3deaf4ae93c26d8f",
        "title": "Theoretical Limitations of Self-Attention in Neural Sequence Models"
      }
    ],
    "8": [
      {
        "id": "d47a682723f710395454687319bb55635e653105",
        "title": "Language (Technology) is Power: A Critical Survey of “Bias” in NLP"
      },
      {
        "id": "623b1c61aa36048a38485a44551cb3fdcbcc827b",
        "title": "Reducing Gender Bias in Word-Level Language Models with a Gender-Equalizing Loss Function"
      },
      {
        "id": "049f4c438ce9eefa622ae5ba5fb7e34443b86133",
        "title": "Lipstick on a Pig: Debiasing Methods Cover up Systematic Gender Biases in Word Embeddings But do not Remove Them"
      },
      {
        "id": "8b430ae5af9d7991cb3e698b2b30296fdf43dd15",
        "title": "Five sources of bias in natural language processing"
      },
      {
        "id": "04ec406caebff60e226695c921f0af1b29162c5f",
        "title": "A Survey on Gender Bias in Natural Language Processing"
      },
      {
        "id": "67ad491b16bf77e9a54a8b8b1dc23dadc5545467",
        "title": "Measuring Fairness with Biased Rulers: A Survey on Quantifying Biases in Pretrained Language Models"
      },
      {
        "id": "beb4f0ef465212c5eae59e85dc838d3ba47dbacc",
        "title": "On Measures of Biases and Harms in NLP"
      },
      {
        "id": "89e5ffd5ce92011e234f0b0ea0d6f2e43647b463",
        "title": "Unpacking the Interdependent Systems of Discrimination: Ableist Bias in NLP Systems through an Intersectional Lens"
      },
      {
        "id": "1847784333aab5a3f3aa718b755eae4996765021",
        "title": "Word Embeddings via Causal Inference: Gender Bias Reducing and Semantic Information Preserving"
      },
      {
        "id": "058e1d5faa5499c35a5e651dead828785bccfd03",
        "title": "Gender Bias in Text: Origin, Taxonomy, and Implications"
      },
      {
        "id": "300e65aec7bda43e0849be3dd67acfde018228b5",
        "title": "The Arabic Parallel Gender Corpus 2.0: Extensions and Analyses"
      },
      {
        "id": "0ad8f1d3fd138fa1c254289edefd86f6c87f92d0",
        "title": "The Gender Gap Tracker: Using Natural Language Processing to measure gender bias in media"
      },
      {
        "id": "437727b6c00a5eb4944600091f66f41626d1002d",
        "title": "Unmasking the Mask - Evaluating Social Biases in Masked Language Models"
      },
      {
        "id": "497d29459a894ac38a48ed58753976ccbf2aa433",
        "title": "Intrinsic Bias Metrics Do Not Correlate with Application Bias"
      },
      {
        "id": "f28208f6847012f986c4ce63b34236284e65407c",
        "title": "Machine Translationese: Effects of Algorithmic Bias on Linguistic Complexity in Machine Translation"
      },
      {
        "id": "7707d54987b4ac7a7b94d8b932e3757a92a6a559",
        "title": "BiasFinder: Metamorphic Test Generation to Uncover Bias for Sentiment Analysis Systems"
      },
      {
        "id": "50f1e5c3a2e703628622dd188300e987f67a4e76",
        "title": "Detecting Cross-Geographic Biases in Toxicity Modeling on Social Media"
      },
      {
        "id": "ad113aa8aedb6a352720a54bcd3018ef2364b69c",
        "title": "Content Analysis of Textbooks via Natural Language Processing: Findings on Gender, Race, and Ethnicity in Texas U.S. History Textbooks"
      },
      {
        "id": "59faa64d2681b6257ca5a87bc28d7d535b8c8809",
        "title": "Situated Data, Situated Systems: A Methodology to Engage with Power Relations in Natural Language Processing Research"
      },
      {
        "id": "8208e19fde8ab27b6cf41b6aa3260f7bf5fff6c8",
        "title": "Artificial Intelligence in mental health and the biases of language based models"
      },
      {
        "id": "5f5e9366983b53d4a753627d1144daa8e890e02f",
        "title": "Metamorphic Testing and Certified Mitigation of Fairness Violations in NLP Models"
      },
      {
        "id": "9a33f92315803d5f280eff026746f1665777a28f",
        "title": "LOGAN: Local Group Bias Detection by Clustering"
      },
      {
        "id": "3313d6c1425d96f68c6107f640c8c385a0e5aec5",
        "title": "Astraea: Grammar-Based Fairness Testing"
      },
      {
        "id": "99fe63245121726cbab65847718ec10d5ab9355e",
        "title": "Bias in word embeddings"
      },
      {
        "id": "e3e9d2bdcc3fefab7c294196c8b2e149727376ed",
        "title": "Gender Bias in Multilingual Embeddings and Cross-Lingual Transfer"
      },
      {
        "id": "307ed22ce979f1a6c5d4afd996d53cd022217f57",
        "title": "deb2viz: Debiasing gender in word embedding data using subspace visualization"
      },
      {
        "id": "eef4df3a5232c7ce70123aaebb326ff9169a3c8c",
        "title": "Predictive Biases in Natural Language Processing Models: A Conceptual Framework and Overview"
      },
      {
        "id": "039b1c1210c437f3b3ce6e0275ee2137bf5b951c",
        "title": "Assessing Social and Intersectional Biases in Contextualized Word Representations"
      },
      {
        "id": "e3d3571533e43f42218bceaa8cfda9fdaedb89d0",
        "title": "Perturbation Sensitivity Analysis to Detect Unintended Model Biases"
      },
      {
        "id": "f007180553dd8e62b348a403ea8aafa36ec7d4ce",
        "title": "A Transparent Framework for Evaluating Unintended Demographic Bias in Word Embeddings"
      },
      {
        "id": "2573ce8edcec066582fb7b14c01cfd9effa92f82",
        "title": "Automatic Gender Identification and Reinflection in Arabic"
      },
      {
        "id": "94a20d1d7062224e9aeba05aea901fd8d6881e85",
        "title": "A Causal Inference Method for Reducing Gender Bias in Word Embedding Relations"
      },
      {
        "id": "493fac37cea49afb98c52c2f5dd75c303a325b25",
        "title": "Mitigating Gender Bias in Natural Language Processing: Literature Review"
      },
      {
        "id": "69accd35f2ae56aa71ceaa5abeb814fcedc8a58e",
        "title": "Evaluating the Underlying Gender Bias in Contextualized Word Embeddings"
      },
      {
        "id": "50154080ccbaec1a3b4ba401bebd94b80225d21a",
        "title": "Equalizing Gender Bias in Neural Machine Translation with Word Embeddings Techniques"
      },
      {
        "id": "004fbcb0f3248afcbc158d97d3b02f0ea42e137a",
        "title": "On Measuring Gender Bias in Translation of Gender-neutral Pronouns"
      },
      {
        "id": "a6f8fd15058e3386aa02c95f88da7ad9ba7481d1",
        "title": "Look Again at the Syntax: Relational Graph Convolutional Network for Gendered Ambiguous Pronoun Resolution"
      },
      {
        "id": "a13a35eb10900a0e830b96d003faf01a4b16b27d",
        "title": "Grammar Based Directed Testing of Machine Learning Systems"
      },
      {
        "id": "8a0323f2319b52da562ff30e4df1f12375a9d4c1",
        "title": "Metamorphic Relations for Data Validation: A Case Study of Translated Text Messages"
      }
    ],
    "3": [
      {
        "id": "659bf9ce7175e1ec266ff54359e2bd76e0b7ff31",
        "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
      },
      {
        "id": "d0cda85c030711aaa5383c80d5928a4d22f8d3bf",
        "title": "How Can We Accelerate Progress Towards Human-like Linguistic Generalization?"
      },
      {
        "id": "ad5970584754cc7a1d91c95ab84a1e210258183a",
        "title": "UnifiedQA: Crossing Format Boundaries With a Single QA System"
      },
      {
        "id": "832fff14d2ed50eb7969c4c4b976c35776548f56",
        "title": "REALM: Retrieval-Augmented Language Model Pre-Training"
      },
      {
        "id": "80376bdec5f534be78ba82821f540590ebce5559",
        "title": "How Much Knowledge Can You Pack into the Parameters of a Language Model?"
      },
      {
        "id": "495da6f19baa09c6db3697d839e10432cdc25934",
        "title": "Multilingual Denoising Pre-training for Neural Machine Translation"
      },
      {
        "id": "8ae9a17c87a4518b513e860683a0ef7824be994d",
        "title": "Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference"
      },
      {
        "id": "04f4e55e14150b7c48b0287ba77c7443df76ed45",
        "title": "PIQA: Reasoning about Physical Commonsense in Natural Language"
      },
      {
        "id": "395de0bd3837fdf4b4b5e5f04835bcc69c279481",
        "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"
      },
      {
        "id": "6c4b76232bb72897685d19b3d264c6ee3005bc2b",
        "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
      },
      {
        "id": "730043364aed106241ef18ab3e3b5e316802a254",
        "title": "NumNet: Machine Reading Comprehension with Numerical Reasoning"
      },
      {
        "id": "17dbd7b72029181327732e4d11b52a08ed4630d0",
        "title": "Natural Questions: A Benchmark for Question Answering Research"
      },
      {
        "id": "f3b89e9a2b8ce1b6058e6984c3556bc2dded0938",
        "title": "Probing Neural Network Comprehension of Natural Language Arguments"
      },
      {
        "id": "d9f6ada77448664b71128bb19df15765336974a6",
        "title": "SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"
      },
      {
        "id": "9770fff7379a7ab9006b48939462354dda9a2053",
        "title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions"
      },
      {
        "id": "dda6fb309f62e2557a071522354d8c2c897a2805",
        "title": "DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs"
      },
      {
        "id": "42ed4a9994e6121a9f325f5b901c5b3d7ce104f5",
        "title": "Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference"
      },
      {
        "id": "92e121c6e114fe3cfb89370df03847c66a9b4e28",
        "title": "An Adversarial Winograd Schema Challenge at Scale"
      },
      {
        "id": "814a4f680b9ba6baba23b93499f4b48af1a27678",
        "title": "Measuring Massive Multitask Language Understanding"
      },
      {
        "id": "28692beece311a90f5fa1ca2ec9d0c2ce293d069",
        "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"
      },
      {
        "id": "c23d9d44e8bc68408cea9f305d1f24d915bc0d0d",
        "title": "Recent Advances in Natural Language Processing via Large Pre-trained Language Models: A Survey"
      },
      {
        "id": "cddf40e579a596d0110b260313adf43470617c4c",
        "title": "Datasets: A Community Library for Natural Language Processing"
      },
      {
        "id": "130d432ccbc836380a212bea618f84ff094a6a52",
        "title": "Causal Inference in Natural Language Processing: Estimation, Prediction, Interpretation and Beyond"
      },
      {
        "id": "8a9fd97dafd664b8fd1ae4ed5ca5071adf9f20ba",
        "title": "Paradigm Shift in Natural Language Processing"
      },
      {
        "id": "46d846aa7df7b5c0cd4b129591b5754272701eae",
        "title": "On Transferability of Prompt Tuning for Natural Language Processing"
      },
      {
        "id": "13e6e04cdafdca76ecf1447734f75bdbe7ea4086",
        "title": "Novelty Detection: A Perspective from Natural Language Processing"
      },
      {
        "id": "1755eeb45cc8532882a88c27d2811aa6f2fa3181",
        "title": "VNLP: Visible natural language processing"
      },
      {
        "id": "43fae0a7af211d91557d115d2f82e3c46d8bf022",
        "title": "Compression, Transduction, and Creation: A Unified Framework for Evaluating Natural Language Generation"
      },
      {
        "id": "89daa253cfd707958b1539ec4d8ea9664e8ceb7d",
        "title": "NL-Augmenter: A Framework for Task-Sensitive Natural Language Augmentation"
      },
      {
        "id": "364621e7e864d3399ee90a7b2a058474e698e6de",
        "title": "Task-adaptive Pre-training and Self-training are Complementary for Natural Language Understanding"
      },
      {
        "id": "21174b47cca9679d3425db4545bd3fac285e36f9",
        "title": "Event Log Construction from Customer Service Conversations Using Natural Language Inference"
      },
      {
        "id": "96ea07447d2f9adefe03852a878517a2a6d45b96",
        "title": "Learning to Prompt for Vision-Language Models"
      },
      {
        "id": "4724ebee34ca2cd0a19c3a1ddb83d6d870dd7904",
        "title": "Few-shot Learning with Multilingual Generative Language Models"
      },
      {
        "id": "d095f9ffcb5905bf0858ad1769d3d90e2e8737e2",
        "title": "Jigsaw: Large Language Models meet Program Synthesis"
      },
      {
        "id": "4a8964ea0de47010fb458021b68fa3ef5c4b77b2",
        "title": "Primer: Searching for Efficient Transformers for Language Modeling"
      },
      {
        "id": "42fc019b2668c9d9d984154d4c57f6c6d5a91619",
        "title": "Language Models are Few-shot Multilingual Learners"
      },
      {
        "id": "290867638c5ca520de5c48aa4336f196d426c226",
        "title": "Knowledge Enhanced Pretrained Language Models: A Compreshensive Survey"
      },
      {
        "id": "e8be95b0e265044c3234b0ffc849a8d807c0a51d",
        "title": "A Comparative Study of Transformer-Based Language Models on Extractive Question Answering"
      },
      {
        "id": "5075a0df5fc7ad5f1399450498044627ebe7a9f9",
        "title": "Drop Redundant, Shrink Irrelevant: Selective Knowledge Injection for Language Pretraining"
      },
      {
        "id": "b587204402ceb03dd85d00b0e8cc3286408b7cf2",
        "title": "CUGE: A Chinese Language Understanding and Generation Evaluation Benchmark"
      },
      {
        "id": "85241d5942966f6b5af19f3cf80f7156dbcddf5f",
        "title": "Aspect Sentiment Quad Prediction as Paraphrase Generation"
      },
      {
        "id": "cbf98ebe967e0f3f3236e7932f37013b98244e94",
        "title": "ExT5: Towards Extreme Multi-Task Scaling for Transfer Learning"
      },
      {
        "id": "d617f51833860dc50d202af7f80be71304b2e994",
        "title": "Between words and characters: A Brief History of Open-Vocabulary Modeling and Tokenization in NLP"
      },
      {
        "id": "8f4bc7e92526faeb65fabd60e5d8c86392fce414",
        "title": "MT3: Multi-Task Multitrack Music Transcription"
      },
      {
        "id": "4097ae9aca6444fd7536bfbed1e62560521b70d3",
        "title": "PAIR: Leveraging Passage-Centric Similarity Relation for Improving Dense Passage Retrieval"
      },
      {
        "id": "54e00dfd4821b0b21bb4e8392336a8c8ac062d43",
        "title": "Conversational Agents: Goals, Technologies, Vision and Challenges"
      },
      {
        "id": "04833b92c9002f241b8f8b956d018759eebc85b3",
        "title": "Tailor: Generating and Perturbing Text with Semantic Controls"
      },
      {
        "id": "7e0c7fdad758482375cb89a110b2f5ad4bee57dd",
        "title": "Domain Adaptation with Pre-trained Transformers for Query-Focused Abstractive Text Summarization"
      },
      {
        "id": "e853ef5d79b5584f4476e82c7a6b736c53a18bfc",
        "title": "MultiCite: Modeling realistic citations requires moving beyond the single-sentence single-label setting"
      },
      {
        "id": "99c766f0d71130e7db1290520e48f86cedcebfc4",
        "title": "SMAT: An Attention-Based Deep Learning Solution to the Automation of Schema Matching"
      },
      {
        "id": "f9f27e0f196e1b76caa44cf11aef7a40ca95b3f0",
        "title": "Why don’t people use character-level machine translation?"
      },
      {
        "id": "a41856aa69a9b06ab37f0ce5dc4cc861f7099292",
        "title": "Validation on machine reading comprehension software without annotated labels: a property-based method"
      },
      {
        "id": "94f8066cb3fe63f67c41d6f59cb3de578c99c8db",
        "title": "Ensembling Graph Predictions for AMR Parsing"
      },
      {
        "id": "d85e994a2f993a65b15865784fee9d68776343d9",
        "title": "Overview of the First Shared Task on Automatic Minuting (AutoMin) at Interspeech 2021"
      },
      {
        "id": "426474f1a807199b5a74942b100076c2bbb61455",
        "title": "Generating Senses and RoLes: An End-to-End Model for Dependency- and Span-based Semantic Role Labeling"
      },
      {
        "id": "9542a2320faba261caa4de35dae3ba66769dcc50",
        "title": "Pirá: A Bilingual Portuguese-English Dataset for Question-Answering about the Ocean"
      },
      {
        "id": "c33f649e45d5c709d9450a6dce7ba1d7112fb901",
        "title": "Monolingual vs multilingual BERTology for Vietnamese extractive multi-document summarization"
      },
      {
        "id": "d87647784c12517d31964cc508d5b8423cc24f50",
        "title": "Integrating Approaches to Word Representation"
      },
      {
        "id": "2fab75cfd8394de70bca365572bc5bb04a1b1eb5",
        "title": "DKPLM: Decomposable Knowledge-enhanced Pre-trained Language Model for Natural Language Understanding"
      },
      {
        "id": "705c8acb411ac45c52ec35e05385e0339a53741c",
        "title": "Recent Advances in Intelligent Source Code Generation: A Survey on Natural Language Based Studies"
      },
      {
        "id": "bd9de0db79272f24c57486f22812f893f9895599",
        "title": "Towards Transparent Interactive Semantic Parsing via Step-by-Step Correction"
      },
      {
        "id": "e7735be4f0fc427515fd7206ebc714356b97e71a",
        "title": "The Benchmark Lottery"
      },
      {
        "id": "c4788d6d19c9c6555264f274d01fd0c34c22c674",
        "title": "Putting Humans in the Natural Language Processing Loop: A Survey"
      },
      {
        "id": "97fcbad1088e219621b72ef928b2e3824c46bbd7",
        "title": "Local Interpretations for Explainable Natural Language Processing: A Survey"
      },
      {
        "id": "7ef33fd5b0ef0c4de42cf0afdc9f7dfb0f430b20",
        "title": "From Natural Language Processing to Neural Databases"
      },
      {
        "id": "ec155bd3dd1cea6bd6be1d4d0badad7c52f6dc30",
        "title": "Adapting natural language processing for technical text."
      },
      {
        "id": "962aa5b847f1692af058bd14fc0e8c3f0a0fee73",
        "title": "Teach Me to Explain: A Review of Datasets for Explainable Natural Language Processing"
      },
      {
        "id": "fe0b1f6194b490f6bbc41c716a58901c1049ccd8",
        "title": "IndoNLG: Benchmark and Resources for Evaluating Indonesian Natural Language Generation"
      },
      {
        "id": "911b7539e964782670e555930b291de16fa971c5",
        "title": "Flexible Generation of Natural Language Deductions"
      },
      {
        "id": "b58d8579ece27a60432e667bfbdb750590fa65d9",
        "title": "True Few-Shot Learning with Language Models"
      },
      {
        "id": "73b6de24eb0e5f6ff4f9c3bdd9257f4554faca19",
        "title": "Measuring and Improving Consistency in Pretrained Language Models"
      },
      {
        "id": "64a1dbdd7653eaca25c78e87335ee156b6f6959e",
        "title": "Constrained Language Models Yield Few-Shot Semantic Parsers"
      },
      {
        "id": "bbfdcbfee1762d48cae9db8637f21ea3c234ba30",
        "title": "GPT3Mix: Leveraging Large-scale Language Models for Text Augmentation"
      },
      {
        "id": "d7a7ebd1565c3795bc2bcdec4334d42a65ad17c5",
        "title": "Pretrained Language Models for Text Generation: A Survey"
      },
      {
        "id": "d331de3b6bebb0f9af1fddf1b730ec057a7026d4",
        "title": "Relational World Knowledge Representation in Contextual Language Models: A Review"
      },
      {
        "id": "983921bd0ccaee71df7580ce13dd0d53dba5f368",
        "title": "Empathetic BERT2BERT Conversational Model: Learning Arabic Language Generation with Little Data"
      },
      {
        "id": "4e3935ef7da6bcbb202ec7f8b285c313cadcd044",
        "title": "A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers"
      },
      {
        "id": "31852f9fc732c0868af12d631c72693702d80521",
        "title": "Text Data Augmentation for Deep Learning"
      },
      {
        "id": "db9296eaa252231e24d066e8413bf29fb058ee45",
        "title": "Retrieving and Reading: A Comprehensive Survey on Open-domain Question Answering"
      },
      {
        "id": "2b9762e91305986ac8a2d624d0a69521304405f3",
        "title": "XTREME-R: Towards More Challenging and Nuanced Multilingual Evaluation"
      },
      {
        "id": "e79d1206292bc5e67ba19737d87d4b2ea4a37105",
        "title": "Charformer: Fast Character Transformers via Gradient-based Subword Tokenization"
      },
      {
        "id": "79b4ec1aaf67a04a9afa0d8138f84b7be66c00cb",
        "title": "Do Transformer Modifications Transfer Across Implementations and Applications?"
      },
      {
        "id": "9b54941de1e21826ecc28b32730ac3f69991ede4",
        "title": "Robustness Gym: Unifying the NLP Evaluation Landscape"
      },
      {
        "id": "3df5343edf4da012e39a5ed79b6ceb723f38b2bf",
        "title": "Kleister: Key Information Extraction Datasets Involving Long Documents with Complex Layouts"
      },
      {
        "id": "e403faa971e2c750999a3d10bef8b01dd3e85f7b",
        "title": "PADA: Example-based Prompt Learning for on-the-fly Adaptation to Unseen Domains"
      },
      {
        "id": "d88c1255876b62fb5f5a8b292098ca430710a540",
        "title": "The NLP Cookbook: Modern Recipes for Transformer Based Deep Learning Architectures"
      },
      {
        "id": "cefd3993db4d065b95ab8f105452fb728c02b60e",
        "title": "Can We Automate Scientific Reviewing?"
      },
      {
        "id": "64902a5077ee68011cd467398dbb66511e8e891a",
        "title": "It’s All in the Heads: Using Attention Heads as a Baseline for Cross-Lingual Transfer in Commonsense Reasoning"
      },
      {
        "id": "245bef79e41012b6856ef0ec4749e6bcd0e906d1",
        "title": "GAIA: A Transfer Learning System of Object Detection that Fits Your Needs"
      },
      {
        "id": "c7f977f556d2060238fdc1286d057d46958afaf9",
        "title": "ESTER: A Machine Reading Comprehension Dataset for Reasoning about Event Semantic Relations"
      },
      {
        "id": "16529f7194bf7faee8a4e43fd54aefeb8730f236",
        "title": "Database reasoning over text"
      },
      {
        "id": "0f2f9cbb1b3ab8c5718d64359052d5e71f2d0dc7",
        "title": "Translation Quality Assessment: A Brief Survey on Manual and Automatic Methods"
      },
      {
        "id": "46ce523f8ace9d5cd811ef608d4f19432bdd0f37",
        "title": "Automatic Generation of Descriptive Titles for Video Clips Using Deep Learning"
      },
      {
        "id": "a2ce4d4be33379cbc3b4b295d93e098637638761",
        "title": "Decrypting Cryptic Crosswords: Semantically Complex Wordplay Puzzles as a Target for NLP"
      },
      {
        "id": "af931c9a67ddda30be86a964c0544cc1a6d54cb5",
        "title": "Text-to-Text Multi-view Learning for Passage Re-ranking"
      },
      {
        "id": "5849d6cc9180b6b22ccf5a482f6b5d8f34e065fd",
        "title": "Meta-Learning for Effective Multi-task and Multilingual Modelling"
      },
      {
        "id": "2e2ea29356e006fdbedb7592caf5090260f81f1e",
        "title": "What’s in Your Head? Emergent Behaviour in Multi-Task Transformer Models"
      },
      {
        "id": "155ba0a6a126e997661c65cef8a7d504657d28be",
        "title": "Knowledge-Grounded Self-Rationalization via Extractive and Natural Language Explanations"
      },
      {
        "id": "b9c0d572402d38976d4bf99c78f4cc65e6d8f1e4",
        "title": "MedNLI Is Not Immune: Natural Language Inference Artifacts in the Clinical Domain"
      },
      {
        "id": "4bd0e72a6e41e34ae4d8d01f72aee0a3ce2d646a",
        "title": "Going Full-TILT Boogie on Document Understanding with Text-Image-Layout Transformer"
      },
      {
        "id": "71fab1ce3c66998ba681ab378484be77690327a9",
        "title": "RiddleSense: Reasoning about Riddle Questions Featuring Linguistic Creativity and Commonsense Knowledge"
      },
      {
        "id": "8c4f89a9ac30cf94186916be1bfaa02dbfb3600d",
        "title": "CoDesc: A Large Code–Description Parallel Dataset"
      },
      {
        "id": "373bc164d7b552f8782988e7da6b0d00092a20b0",
        "title": "Continual Lifelong Learning in Natural Language Processing: A Survey"
      },
      {
        "id": "069a05c0ae7ac49ad7eb8e0a0744c212c58bd863",
        "title": "Meta-learning for Few-shot Natural Language Processing: A Survey"
      },
      {
        "id": "1c6970dc9d4da9f5e94399e344fe8ba901d8fe81",
        "title": "PyMT5: Multi-mode Translation of Natural Language and Python Code with Transformers"
      },
      {
        "id": "1841cf23c65ff2f27f21ba0d2268c3445f20332f",
        "title": "Few-Shot Text Generation with Natural Language Instructions"
      },
      {
        "id": "15f002dde348b82817fa2a59e7ed56e6e3ec6972",
        "title": "Augmented Natural Language for Generative Sequence Labeling"
      },
      {
        "id": "a381826827df23f11c0dc600e1d7445fe4fa7e7c",
        "title": "Towards Interpretable Natural Language Understanding with Explanations as Latent Variables"
      },
      {
        "id": "a113053b624b599b204fbd6599284b726c17f916",
        "title": "ConjNLI: Natural Language Inference over Conjunctive Sentences"
      },
      {
        "id": "b68b2e81ae2de647394ec05ee62ecf108bf2b50a",
        "title": "Eliciting Knowledge from Language Models Using Automatically Generated Prompts"
      },
      {
        "id": "c0c11be3de5d102b9cd6de1ff7a413a8ea007b92",
        "title": "ERICA: Improving Entity and Relation Understanding for Pre-trained Language Models via Contrastive Learning"
      },
      {
        "id": "8fd7c10e8c9115a72a2c8e6494d4693c6501fa0e",
        "title": "Chatbot Interaction with Artificial Intelligence: human data augmentation with T5 and language transformer ensemble for text classification"
      },
      {
        "id": "c845494445f3bfa01d8245a4759b144e27aa3788",
        "title": "A Survey of Knowledge-enhanced Text Generation"
      },
      {
        "id": "b1330ac569550ee40afef26d3f989e5bad24d974",
        "title": "Deep Learning for Text Style Transfer: A Survey"
      },
      {
        "id": "343e06bae852f74a98573e798b501f6003bcb1c0",
        "title": "Measuring Association Between Labels and Free-Text Rationales"
      },
      {
        "id": "734f85727161f27bc7b295f0140a905363202d3f",
        "title": "Learning from others' mistakes: Avoiding dataset biases without modeling them"
      },
      {
        "id": "55c4a747855c74210919c45f7899e1f79e4c97f5",
        "title": "Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters & Less Data"
      },
      {
        "id": "f0d6db2186d8bf2d8530f01de6c6518bb9711392",
        "title": "Interpretability and Analysis in Neural NLP"
      },
      {
        "id": "68f2d74f82ec544433f3936dbbf6b6f5255fee10",
        "title": "An Empirical Study of Tokenization Strategies for Various Korean NLP Tasks"
      },
      {
        "id": "335a05c16fcbc7a2c2bf5221299de608b08030f0",
        "title": "From Hero to Zéroe: A Benchmark of Low-Level Adversarial Attacks"
      },
      {
        "id": "d616b408df04cdcbddcf5af423b4d915bd40c750",
        "title": "Deep learning based question answering system in Bengali"
      },
      {
        "id": "c968e8dc442102b38b134b1afadc7cc78fc5b5fb",
        "title": "Interpretable Multi-dataset Evaluation for Named Entity Recognition"
      },
      {
        "id": "dff95fd900aa88861c6dae0f4ac0a543135ed4e3",
        "title": "Flight of the PEGASUS? Comparing Transformers on Few-Shot and Zero-Shot Multi-document Abstractive Summarization"
      },
      {
        "id": "c6dc2f21e943c5a1dd35fb3d6ff18525c9c86ca0",
        "title": "Infusing Finetuning with Semantic Dependencies"
      },
      {
        "id": "28709eca90cac4102518fce9d9b4982ea949d20a",
        "title": "Survey of Neural Text Representation Models"
      },
      {
        "id": "8aadeb990e9471f4bd8f63ae4b463d1a4ececf73",
        "title": "Explaining Deep Neural Networks"
      },
      {
        "id": "f7e782a76590a22c5955263399087e58cd2fcfc1",
        "title": "Argumentation Mining on Essays at Multi Scales"
      },
      {
        "id": "2f2b5a62de851b49e3c2f9ad1adcead4751bf3de",
        "title": "Global Encoding for Long Chinese Text Summarization"
      },
      {
        "id": "a20712b1b9779ee43ce143a19b3f67f0cacbbf57",
        "title": "Neural Databases"
      },
      {
        "id": "b360427d0991143013da6a208ccf28bcc8028fab",
        "title": "Large Scale Knowledge Graph Based Synthetic Corpus Generation for Knowledge-Enhanced Language Model Pre-training"
      },
      {
        "id": "2aa1d4350e80613feed88d5a6337e79693f7aa57",
        "title": "KQA Pro: A Dataset with Explicit Compositional Programs for Complex Question Answering over Knowledge Base"
      },
      {
        "id": "4f4202aac8c900efc79ec534f5f3b10b07bb45f5",
        "title": "Unnatural Language Processing: Bridging the Gap Between Synthetic and Natural Language Data"
      },
      {
        "id": "d01bf02019df255673db1c989baf031bbebecf18",
        "title": "Computer Science Meets Education: Natural Language Processing for Automatic Grading of Open-Ended Questions in eBooks"
      },
      {
        "id": "5c09b7be6a7d4b0cd34fd95c4f783dc5c266edf3",
        "title": "A Survey on Transfer Learning in Natural Language Processing"
      },
      {
        "id": "b589bce24ae76b72de831b2ce15dc8668b8d30b8",
        "title": "Convolution-deconvolution word embedding: An end-to-end multi-prototype fusion embedding method for natural language processing"
      },
      {
        "id": "aa9c6d43b36a55b34c2e9207355d355fd94691af",
        "title": "Machine Reading Comprehension: The Role of Contextualized Language Models and Beyond"
      },
      {
        "id": "d97e7561fa7710213ccd4f8128044ea6849be377",
        "title": "XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning"
      },
      {
        "id": "b2a839e3ee68e81b863b73ee08c6626c94477fef",
        "title": "WT5?! Training Text-to-Text Models to Explain their Predictions"
      },
      {
        "id": "56d1003fd02346e93354ab55cd204485c268512a",
        "title": "Compositional Explanations of Neurons"
      },
      {
        "id": "3fa8d2a9e9a9cf3ee9626424a157888580dcfaba",
        "title": "A Survey of Deep Learning Techniques for Neural Machine Translation"
      },
      {
        "id": "29121a31e4d684839cfd0bb358f33ea1266cece5",
        "title": "Learning What Makes a Difference from Counterfactual Examples and Gradient Supervision"
      },
      {
        "id": "71b429939be72c1f7560de5bca4d7b31e8405b92",
        "title": "A Survey on Machine Reading Comprehension: Tasks, Evaluation Metrics, and Benchmark Datasets"
      },
      {
        "id": "28307bc149a74cfcae657f782f1c7630b6f4acce",
        "title": "Contextualized Embeddings based Transformer Encoder for Sentence Similarity Modeling in Answer Selection Task"
      },
      {
        "id": "7fd7494a0c988c569aca7c8a156c4ae1219331c9",
        "title": "A Survey on Machine Reading Comprehension Systems"
      },
      {
        "id": "807323d435ca555e02bc66b5c5f74aee3e33217e",
        "title": "CycleGT: Unsupervised Graph-to-Text and Text-to-Graph Generation via Cycle Training"
      },
      {
        "id": "697e36c12b55dbd62743a864c4ba93109531d2b9",
        "title": "Direct Feedback Alignment Scales to Modern Deep Learning Tasks and Architectures"
      },
      {
        "id": "e2d2f64b3bb200c2c3db5ddc367b06311c369341",
        "title": "Kleister: A novel task for Information Extraction involving Long Documents with Complex Layout"
      },
      {
        "id": "97c5f41275b3dbacec17a6c7340724616713b7e2",
        "title": "Style-transfer and Paraphrase: Looking for a Sensible Semantic Similarity Metric"
      },
      {
        "id": "76a211ec3b4b96f37038c3993c81597cb1ea7a4a",
        "title": "Morphological Word Segmentation on Agglutinative Languages for Neural Machine Translation"
      },
      {
        "id": "d9ec170160c69df9863f390d06bfefc213d0836f",
        "title": "Document Summarization with VHTM: Variational Hierarchical Topic-Aware Mechanism"
      },
      {
        "id": "2e808fa44bd52e7234f04f9fb8819ff840608586",
        "title": "Morfessor EM+Prune: Improved Subword Segmentation with Expectation Maximization and Pruning"
      },
      {
        "id": "0bfb508fd350cc988e8880f37215e10f02c835cd",
        "title": "Unsupervised Dual Paraphrasing for Two-stage Semantic Parsing"
      },
      {
        "id": "5d09257af1fd231e14b3f3a2d9f209ccc0e5d768",
        "title": "New Vietnamese Corpus for Machine Reading Comprehension of Health News Articles"
      },
      {
        "id": "0abcbdf40f872e6baf1c082811d4ae93df787698",
        "title": "Are We Modeling the Task or the Annotator? An Investigation of Annotator Bias in Natural Language Understanding Datasets"
      },
      {
        "id": "4e14cf96c60e3d35b05e3a740c7c6bbe52f14677",
        "title": "Unlearn Dataset Bias in Natural Language Inference by Fitting the Residual"
      },
      {
        "id": "44834accf04f5c029f79e7a21f6715b74872ac94",
        "title": "Investigating Meta-Learning Algorithms for Low-Resource Natural Language Understanding Tasks"
      },
      {
        "id": "d4fc020db15584ea040162a1afb6abc81aa6c7e4",
        "title": "Analyzing machine-learned representations: A natural language case study"
      },
      {
        "id": "d0086b86103a620a86bc918746df0aa642e2a8a3",
        "title": "Language Models as Knowledge Bases?"
      },
      {
        "id": "63748e59f4e106cbda6b65939b77589f40e48fcb",
        "title": "Text Summarization with Pretrained Encoders"
      },
      {
        "id": "0c5598424cc96d8fb500eb553cb7969f86a0ede0",
        "title": "Evaluating the Factual Consistency of Abstractive Text Summarization"
      },
      {
        "id": "47f1eb0dc42189ba7cf21b76598c8217eb1b6e05",
        "title": "Learning the Difference that Makes a Difference with Counterfactually-Augmented Data"
      },
      {
        "id": "f67fcbb1aec92ae293998ddfd904f61a31bef334",
        "title": "Inducing Relational Knowledge from BERT"
      },
      {
        "id": "6ffb1cc32ddde6ae01e2fc0286eafa116ade0ffb",
        "title": "KorQuAD1.0: Korean QA Dataset for Machine Reading Comprehension"
      },
      {
        "id": "007bc04c97f9f8bcec0487699e197315418f22e7",
        "title": "From 'F' to 'A' on the N.Y. Regents Science Exams: An Overview of the Aristo Project"
      },
      {
        "id": "904d305e232f3590189f6108441bdce4584027de",
        "title": "On the Linguistic Representational Power of Neural Machine Translation Models"
      },
      {
        "id": "d198c9667c38db589e92e1280e08e2ac226c7063",
        "title": "Incorporating External Knowledge into Machine Reading for Generative Question Answering"
      },
      {
        "id": "b6131228b53f65e1b65c0e7450e6f9c3e4687a56",
        "title": "A Topic Augmented Text Generation Model: Joint Learning of Semantics and Structural Features"
      },
      {
        "id": "7610f16f70b4c68989c277fa16c77e6159ceb0a1",
        "title": "Winograd Schemas in Portuguese"
      },
      {
        "id": "1a88e53ab07328a497b8e153e18c78cb174e0e89",
        "title": "CFO: A Framework for Building Production NLP Systems"
      },
      {
        "id": "4338266891240f968b3968cf7727fed394bae3ce",
        "title": "Make Up Your Mind! Adversarial Generation of Inconsistent Natural Language Explanations"
      },
      {
        "id": "ad7d5e5cea44c60605f742509eebe8a22502ffa9",
        "title": "A Natural Language Corpus of Common Grounding under Continuous and Partially-Observable Context"
      },
      {
        "id": "a84dc7a639406089ebade96c2e013c272c91e8e5",
        "title": "An Annotated Corpus of Reference Resolution for Interpreting Common Grounding"
      },
      {
        "id": "d296414c6dcec961e56eabadfc6ee6cce56d4605",
        "title": "Selection Bias Explorations and Debias Methods for Natural Language Sentence Matching Datasets"
      },
      {
        "id": "124c17b7152a92ea8b15cbcb21eb8b697f7c99b2",
        "title": "Complex Program Induction for Querying Knowledge Bases in the Absence of Gold Programs"
      }
    ],
    "1": [
      {
        "id": "97f08c1ae8ca5ddf5948c66bfbbc0546ac154807",
        "title": "Pretrained Transformers Improve Out-of-Distribution Robustness"
      },
      {
        "id": "9ae293dbcb0a3d2311775a7f4d23854fe9b0ee3d",
        "title": "TTTTTackling WinoGrande Schemas"
      },
      {
        "id": "8771679aac0e90371340bd8c657317f5be113e81",
        "title": "Train Large, Then Compress: Rethinking Model Size for Efficient Training and Inference of Transformers"
      },
      {
        "id": "a54b56af24bb4873ed0163b77df63b92bd018ddc",
        "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"
      },
      {
        "id": "7a064df1aeada7e69e5173f7d4c8606f4470365b",
        "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"
      },
      {
        "id": "663f4cc30a69aee07e291299d196806ead12d520",
        "title": "Technical report on Conversational Question Answering"
      },
      {
        "id": "0cbf97173391b0430140117027edcaf1a37968c7",
        "title": "TinyBERT: Distilling BERT for Natural Language Understanding"
      },
      {
        "id": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de",
        "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"
      },
      {
        "id": "21da617a0f79aabf94272107184606cefe90ab75",
        "title": "Generating Long Sequences with Sparse Transformers"
      },
      {
        "id": "7ebed46b7f3ec913e508e6468304fcaea832eda1",
        "title": "Improving Multi-Task Deep Neural Networks via Knowledge Distillation for Natural Language Understanding"
      },
      {
        "id": "cb0de2de79533d4faada3d745f43702eb89d1a60",
        "title": "Reusable Templates and Guides For Documenting Datasets and Models for Natural Language Processing and Generation: A Case Study of the HuggingFace and GEM Data and Model Cards"
      },
      {
        "id": "a5881560968963d0c845c468a273261fde0b7248",
        "title": "Perturbing Inputs for Fragile Interpretations in Deep Natural Language Processing"
      },
      {
        "id": "49294af4478741e296815b4c49f491eaf2db9f94",
        "title": "Event-Centric Natural Language Processing"
      },
      {
        "id": "08460ecff91b8a54358b9c1709d7dc6a77417f62",
        "title": "Distiller: A Systematic Study of Model Distillation Methods in Natural Language Processing"
      },
      {
        "id": "511e2fe08d8ce170736b59d386a3301a6d6e57b0",
        "title": "NxMTransformer: Semi-Structured Sparsification for Natural Language Understanding via ADMM"
      },
      {
        "id": "9b56086e420ecb216f85d408a25264f640e46705",
        "title": "Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners"
      },
      {
        "id": "a50ee01a66aa92b664a78b2a0628ac346f53e31d",
        "title": "ClimateBert: A Pretrained Language Model for Climate-Related Text"
      },
      {
        "id": "9202a718ce05395b6e17d5301e3a2e8b1021f31b",
        "title": "Prune Once for All: Sparse Pre-Trained Language Models"
      },
      {
        "id": "ef18db2a18ac61e72783a613328842ce86ef00bf",
        "title": "AutoTinyBERT: Automatic Hyper-parameter Optimization for Efficient Pre-trained Language Models"
      },
      {
        "id": "fb1810f403288c40291fbe65fdfa4adf55c466e7",
        "title": "Your fairness may vary: Pretrained language model fairness in toxic text classification"
      },
      {
        "id": "e55391a9406245584b3e5b3225dad2e171b9a06b",
        "title": "RuleBERT: Teaching Soft Rules to Pre-Trained Language Models"
      },
      {
        "id": "acac699d02a972f58b091bfbef7518f0e61c8225",
        "title": "Frustratingly Simple Pretraining Alternatives to Masked Language Modeling"
      },
      {
        "id": "574072ae4556649de1c59d8f284955730f5a71a0",
        "title": "A Short Study on Compressing Decoder-Based Language Models"
      },
      {
        "id": "08c2e7812ff224db1c877b4d14730d6288d529aa",
        "title": "From Dense to Sparse: Contrastive Pruning for Better Pre-trained Language Model Compression"
      },
      {
        "id": "d201f6fa44e1959b389a2f48dc564576a89e521a",
        "title": "Transformers-sklearn: a toolkit for medical language understanding with transformer-based models"
      },
      {
        "id": "73d64ecbe3e846394444dab6c5e89ba33e5daa49",
        "title": "Memory transformer with hierarchical attention for long document processing"
      },
      {
        "id": "38f683ec0b9fda2069c0b2cb7ee1c71035915723",
        "title": "KroneckerBERT: Learning Kronecker Decomposition for Pre-trained Language Models via Knowledge Distillation"
      },
      {
        "id": "a0118fc91478bde959d41c4e2231f1767915d207",
        "title": "Interpreting Language Models Through Knowledge Graph Extraction"
      },
      {
        "id": "c4e98b8e4482b166750e4a211a99632f08778c34",
        "title": "Sentiment Analysis for Thai Language in Hotel Domain Using Machine Learning Algorithms"
      },
      {
        "id": "234c0e26e011c67fe4e6af2925439eb922104eff",
        "title": "JavaBERT: Training a Transformer-Based Model for the Java Programming Language"
      },
      {
        "id": "dba9d6ace6871fffaf5d7b0d437231c2fb01e54f",
        "title": "Bridging the Language Gap: Knowledge Injected Multilingual Question Answering"
      },
      {
        "id": "86a466b2c245e82c5216be072ebc28763f48c963",
        "title": "HRKD: Hierarchical Relational Knowledge Distillation for Cross-domain Language Model Compression"
      },
      {
        "id": "9dc109baa16795d0248c9401e5bd95417b8b18c0",
        "title": "Injecting Descriptive Meta-Information into Pre-Trained Language Models with Hypernetworks"
      },
      {
        "id": "9ab78eb54f26693cff1cc07335c31e698349f972",
        "title": "StoryDB: Broad Multi-language Narrative Dataset"
      },
      {
        "id": "b97c3c370401dc34d2adbeb24f34de5180a14be6",
        "title": "Sanger: A Co-Design Framework for Enabling Sparse Attention using Reconfigurable Architecture"
      },
      {
        "id": "2e644c67a697073d561da4f4dad35e5ad5316cfd",
        "title": "SOFT: Softmax-free Transformer with Linear Complexity"
      },
      {
        "id": "2743e66939b30c43affb3c9e31f20cfac2109045",
        "title": "Two Contrasting Data Annotation Paradigms for Subjective NLP Tasks"
      },
      {
        "id": "73bcf4577284fa116ee73487b7cbb85c8266eaa0",
        "title": "Understanding and Overcoming the Challenges of Efficient Transformer Quantization"
      },
      {
        "id": "4698fc4712f0212c8a3810fd67b41ee8b8896aba",
        "title": "Generate & Rank: A Multi-task Framework for Math Word Problems"
      },
      {
        "id": "37187ceb6008d49e1758bab0d4f86bf39aa175cf",
        "title": "A Survey on Green Deep Learning"
      },
      {
        "id": "2b38ddff8e24a07597c8d042ea7b8b85a678e9b2",
        "title": "FLAT: An Optimized Dataflow for Mitigating Attention Bottlenecks"
      },
      {
        "id": "8d911c2be6b68771cc1dae24fd3c5c5dc5261e81",
        "title": "Towards Efficient NLP: A Standard Evaluation and A Strong Baseline"
      },
      {
        "id": "c67b1a62b868a758791c88d5465c7b6d53510fc3",
        "title": "Energon: Toward Efficient Acceleration of Transformers Using Dynamic Sparse Attention"
      },
      {
        "id": "47354f49a4768719add414ea853977cb868faf25",
        "title": "AutoBERT-Zero: Evolving BERT Backbone from Scratch"
      },
      {
        "id": "b6f616e9305e59c9dc7ccf33c311ede47584caf6",
        "title": "Kronecker Decomposition for GPT Compression"
      },
      {
        "id": "d7a8d2d2e73f786caf03c86137428055399e5267",
        "title": "Bridge the Gap Between CV and NLP! A Gradient-based Textual Adversarial Attack Framework"
      },
      {
        "id": "51819d708e00c0fe7ca3e8befc4f8665ac12ad0e",
        "title": "Importance Estimation from Multiple Perspectives for Keyphrase Extraction"
      },
      {
        "id": "48af9b314181b04edcc0b7224ffe4689036b755f",
        "title": "Improving Transformers with Probabilistic Attention Keys"
      },
      {
        "id": "ee09751fab987e60d8d005ef20fe57c5defc408e",
        "title": "MalBERT: Malware Detection using Bidirectional Encoder Representations from Transformers*"
      },
      {
        "id": "f5a3dbc0518df5ca1b6333ae93244dde7f793736",
        "title": "Block-Skim: Efficient Question Answering for Transformer"
      },
      {
        "id": "b7b3343b45c785ccab1c94beecc28ea91e041685",
        "title": "E.T.: Re-Thinking Self-Attention for Transformer Models on GPUs"
      },
      {
        "id": "55f86dacdccd192e0c2c4def0a9662e9053f2d9c",
        "title": "Correlation-Guided Representation for Multi-Label Text Classification"
      },
      {
        "id": "a82b020fb5358a69173201a276aa4ea18c9dd0cd",
        "title": "Toward Software-Equivalent Accuracy on Transformer-Based Deep Neural Networks With Analog Memory Devices"
      },
      {
        "id": "d581587c87c6c1e9cd2c84646edd0231c13fcc63",
        "title": "Research on Multi-label Text Classification Method Based on tALBERT-CNN"
      },
      {
        "id": "9f9667c06c94cc854eb55f16cfad2b9db7da49cd",
        "title": "Salience-Aware Event Chain Modeling for Narrative Understanding"
      },
      {
        "id": "e0cbbca02b332f398c6639b3bea0613f79166220",
        "title": "ABC: Attention with Bounded-memory Control"
      },
      {
        "id": "96fd89de07a69dd2dc94d71f884e64174c5974e2",
        "title": "Interpreting the Robustness of Neural NLP Models to Textual Perturbations"
      },
      {
        "id": "54793533142d6ec5e0e03d0f5ec8fd4796311b54",
        "title": "FLiText: A Faster and Lighter Semi-Supervised Text Classification with Convolution Networks"
      },
      {
        "id": "0a56bacc4e20e024bcdc6d35e09f1b259d751ab8",
        "title": "MeLT: Message-Level Transformer with Masked Document Representations as Pre-Training for Stance Detection"
      },
      {
        "id": "346f1e8d8c1eb316d077b9444980c356bacb2634",
        "title": "Text-based automatic personality prediction: a bibliographic review"
      },
      {
        "id": "217913c84a4bdbe5cee3630d70480fda8d44bfb0",
        "title": "Magic Pyramid: Accelerating Inference with Early Exiting and Token Pruning"
      },
      {
        "id": "59e1748506640a3ef8f69c0fe2f22bbe8db8c7ca",
        "title": "A Comprehensive Guideline for Bengali Sentiment Annotation"
      },
      {
        "id": "281db7515227b36a45e41bf00b66c8f5924b1df0",
        "title": "BERT got a Date: Introducing Transformers to Temporal Tagging"
      },
      {
        "id": "1158a9a9fe1f557c19f3450097cbb76ef5fe6aee",
        "title": "“So You Think You’re Funny?”: Rating the Humour Quotient in Standup Comedy"
      },
      {
        "id": "f5d9ce3e28de74e793212947a29d6ea26b64c2ab",
        "title": "Pile-up mitigation using attention"
      },
      {
        "id": "ea007f49008faa5c547fdec30b456f8b71d3b23e",
        "title": "VivesDebate: A New Annotated Multilingual Corpus of Argumentation in a Debate Tournament"
      },
      {
        "id": "c1526ec26d67a4976eae17548e6c3296adc6f5ac",
        "title": "kFolden: k-Fold Ensemble for Out-Of-Distribution Detection"
      },
      {
        "id": "c2848530890acd7549fe7cfec7d4fc5a80c2feb7",
        "title": "Distilling the Knowledge of Romanian BERTs Using Multiple Teachers"
      },
      {
        "id": "00ac7891f1024244aa902e14f681a5a7fcd40228",
        "title": "Can Deep Neural Networks Predict Data Correlations from Column Names?"
      },
      {
        "id": "cc9d336749119a2053ac3bb2c5a9d0bdb4d1e1dc",
        "title": "Contrasting Human- and Machine-Generated Word-Level Adversarial Examples for Text Classification"
      },
      {
        "id": "ffcd58f453f207d48075627da011f62782334c8f",
        "title": "Go Wider Instead of Deeper"
      },
      {
        "id": "a55c399bbb0382650459da59fc545f2dd275012b",
        "title": "FedNLP: Benchmarking Federated Learning Methods for Natural Language Processing Tasks"
      },
      {
        "id": "9f840be023309cc957dc741dce85dfc6b1a3b486",
        "title": "NPE: An FPGA-based Overlay Processor for Natural Language Processing"
      },
      {
        "id": "00e1d284260e2f8be8cd47c0bb22a1892d91deba",
        "title": "Combat COVID-19 infodemic using explainable natural language processing models"
      },
      {
        "id": "ed57d8fea73b2c480aca5e3696316554b07a284c",
        "title": "Deep Learning-Based Natural Language Processing for Screening Psychiatric Patients"
      },
      {
        "id": "7a320541d7772bedc9b7f537f6bd459675675bb0",
        "title": "Hardware Acceleration of Fully Quantized BERT for Efficient Natural Language Processing"
      },
      {
        "id": "a7ca9df39318fb12b5fcd99664fa48538bdb0bb4",
        "title": "Greedy-layer pruning: Speeding up transformer models for natural language processing"
      },
      {
        "id": "d25a4dcb26f0c6cb3ff0a98bcceb23e04d765dc3",
        "title": "Information Extraction From FDA Drug Labeling to Enhance Product-Specific Guidance Assessment Using Natural Language Processing"
      },
      {
        "id": "fe9cd5bcca161289b0e3da0f49114dcccf62eaa1",
        "title": "Token-Aware Virtual Adversarial Training in Natural Language Understanding"
      },
      {
        "id": "df59d0098c1b2c1ee8995da802dd6b12d158c2b8",
        "title": "Large-scale chemical language representations capture molecular structure and properties"
      },
      {
        "id": "cf5e670a79847d9be0eb185fb372d99d30d4d98f",
        "title": "Adapt-and-Distill: Developing Small, Fast and Effective Pretrained Language Models for Domains"
      },
      {
        "id": "0a9b7f2ff0e25f4eecd946bae4ad2f8c2d53b562",
        "title": "Automated essay scoring using efficient transformer-based language models"
      },
      {
        "id": "54b75720b82f2af779e11910985faa9eb343a345",
        "title": "Distilling Large Language Models into Tiny and Effective Students using pQRNN"
      },
      {
        "id": "2310444978f516b2f9db56abacad9c3df27a84fb",
        "title": "Variable Name Recovery in Decompiled Binary Code using Constrained Masked Language Modeling"
      },
      {
        "id": "093253653cd0b55970c390d77b75137c4095dc29",
        "title": "A Survey of Quantization Methods for Efficient Neural Network Inference"
      },
      {
        "id": "8690d62d4bbbd0b1ed5e1f25320d10853bfbeb01",
        "title": "Scaling Vision with Sparse Mixture of Experts"
      },
      {
        "id": "6fa1cfc4f97f03a8485692418c7aa1a06c574a85",
        "title": "Nyströmformer: A Nyström-Based Algorithm for Approximating Self-Attention"
      },
      {
        "id": "7b8f3f65a98340d6e5ab94bd9a4ccb8f75704fd8",
        "title": "I-BERT: Integer-only BERT Quantization"
      },
      {
        "id": "5af69480a7ae3b571df6782a11ec4437b386a7d9",
        "title": "ELSA: Hardware-Software Co-design for Efficient, Lightweight Self-Attention Mechanism in Neural Networks"
      },
      {
        "id": "c1272cf10f827bd9b8e43cc06b0d5831c59de52e",
        "title": "Challenges of Hate Speech Detection in Social Media"
      },
      {
        "id": "b080ba53a471348e7e76234decdf14e730fea7db",
        "title": "Softermax: Hardware/Software Co-Design of an Efficient Softmax for Transformers"
      },
      {
        "id": "d6eeb0ca9e2f34f2427866aa864d364ec78e6049",
        "title": "Accelerating Transformer-based Deep Learning Models on FPGAs using Column Balanced Block Pruning"
      },
      {
        "id": "dd0a27aa2285bc64798fa76944400ab6d9ce3025",
        "title": "NAS-BERT: Task-Agnostic and Adaptive-Size BERT Compression with Neural Architecture Search"
      },
      {
        "id": "06635ebccbc4c13998aea284df9b3a08f0e14821",
        "title": "TextGNN: Improving Text Encoder via Graph Neural Network in Sponsored Search"
      },
      {
        "id": "054e307c1edf4b28137ffcbce980fe81f0647d20",
        "title": "Finetuning Pretrained Transformers into RNNs"
      },
      {
        "id": "c1d0e73ec3aaf7ffdcbe41835d649d638cbc2f2d",
        "title": "Consistent Accelerated Inference via Confident Adaptive Transformers"
      },
      {
        "id": "40235eded15f44c8c4a7f48468adcc7df4e171fb",
        "title": "Rethinking Network Pruning – under the Pre-train and Fine-tune Paradigm"
      },
      {
        "id": "36a2c27ffa72c05c2a17dc90b7c54e492b88ba01",
        "title": "Few-shot Conformal Prediction with Auxiliary Tasks"
      },
      {
        "id": "4badd753be64c5c5b57dd2bb2e515fbe0c0720d8",
        "title": "SparseBERT: Rethinking the Importance Analysis in Self-attention"
      },
      {
        "id": "d226e0b7245ed94c07d869e5daecc68c135782ef",
        "title": "Benchmarking Differential Privacy and Federated Learning for BERT Models"
      },
      {
        "id": "ce9a7d4652192a4f32cd10cff211b47b2a2d9817",
        "title": "Accommodating Transformer onto FPGA: Coupling the Balanced Model Compression and FPGA-Implementation Optimization"
      },
      {
        "id": "50de6d069125f556dedb7cdf058071e66673f992",
        "title": "Attention mechanisms and deep learning for machine vision: A survey of the state of the art"
      },
      {
        "id": "0789d0f6f3459b7689486ebc80ce39373dd8cc17",
        "title": "MATE-KD: Masked Adversarial TExt, a Companion to Knowledge Distillation"
      },
      {
        "id": "f4566761fe39c4b5273d696d9bc3f4195c9325bb",
        "title": "Long-Span Summarization via Local Attention and Content Selection"
      },
      {
        "id": "3232bdf3035473dab4d7d9fefa3699146220e7b8",
        "title": "Leveraging Multilingual Transformers for Hate Speech Detection"
      },
      {
        "id": "0fe8b49369d70a2be473435a82b01544704b3c9f",
        "title": "Evolving Attention with Residual Convolutions"
      },
      {
        "id": "c0eea2237a1bfb280c9f733b14157751c20f42d4",
        "title": "Evaluating Pretrained Transformer-based Models for COVID-19 Fake News Detection"
      },
      {
        "id": "f98f32e05fffb50437b556412127a92108d1d0b2",
        "title": "Transformers: \"The End of History\" for NLP?"
      },
      {
        "id": "a8debd8f58ee690005d996d223c37239e25273ec",
        "title": "CIDER: Commonsense Inference for Dialogue Explanation and Reasoning"
      },
      {
        "id": "f222f684560cfcaf42ed3c0fe323a9ebc4830fec",
        "title": "Using Transformers to Provide Teachers with Personalized Feedback on their Classroom Discourse: The TalkMoves Application"
      },
      {
        "id": "2a0ae7182b13789056e13dc1887904c923a92675",
        "title": "KDLSQ-BERT: A Quantized Bert Combining Knowledge Distillation with Learned Step Size Quantization"
      },
      {
        "id": "cec62e7a1ad6b6aa7dcab0e27a7d9c44ce6e486e",
        "title": "InferBERT: A Transformer-Based Causal Inference Framework for Enhancing Pharmacovigilance"
      },
      {
        "id": "2f0ff0641adc372919fb0b3f183de66f7a2dae75",
        "title": "Automatic Sexism Detection with Multilingual Transformer Models AIT FHSTP@EXIST2021"
      },
      {
        "id": "27a9bdedcc2c3c0bc9116d7cd56fb72744b6a26a",
        "title": "Clustering Word Embeddings with Self-Organizing Maps. Application on LaRoSeDa - A Large Romanian Sentiment Data Set"
      },
      {
        "id": "82ab2f4a51d37c9dca79251a684c8507a156aff7",
        "title": "Structured Sparsity Inducing Adaptive Optimizers for Deep Learning"
      },
      {
        "id": "9a0ce4d9b12337c1c4b65e56cab5b87dcc5f5aa2",
        "title": "XtremeDistilTransformers: Task Transfer for Task-agnostic Distillation"
      },
      {
        "id": "33fa38d80ca900dafe708747f062b75f6e4abd96",
        "title": "Us vs. Them: A Dataset of Populist Attitudes, News Bias and Emotions"
      },
      {
        "id": "d73d8edbc804b7848b4a5a1a11b6d33f9f42fa94",
        "title": "Elbert: Fast Albert with Confidence-Window Based Early Exit"
      },
      {
        "id": "3d0853eb0429fff9a6ff04fd46ea221e4f84fbf2",
        "title": "The Case for NLP-Enhanced Database Tuning: Towards Tuning Tools that \"Read the Manual\""
      },
      {
        "id": "13b8f918f94c1c553d68f9724b8ad300d8651035",
        "title": "Performance analysis of Word Embeddings for Cyberbullying Detection"
      },
      {
        "id": "edd3a60cb7295af7d845f0be4ea62de6ef699602",
        "title": "On Sample Based Explanation Methods for NLP: Faithfulness, Efficiency and Semantic Evaluation"
      },
      {
        "id": "964301fe5fd0d09fb261346238bd3b19c9f6ab94",
        "title": "Banking news-events representation and classification with a novel hybrid model using DistilBERT and rule-based features"
      },
      {
        "id": "fc5650e2ebc30787bc644eaa2656225ed62408a1",
        "title": "Evaluating Neural Word Embeddings for Sanskrit"
      },
      {
        "id": "dbcff24e72e8360f2026018a5cde646f369767cb",
        "title": "Not All Attention Is All You Need"
      },
      {
        "id": "1c2e60e0e31d06c909ddffbb2387987b449aceb0",
        "title": "Defending Pre-trained Language Models from Adversarial Word Substitution Without Performance Sacrifice"
      },
      {
        "id": "65cc7839ee6e595382bb45b15968c565746d1d94",
        "title": "Incremental Few-shot Text Classification with Multi-round New Classes: Formulation, Dataset and System"
      },
      {
        "id": "7d9a3b94f78827952b078c664b0da1c02e1c2ee3",
        "title": "What Ingredients Make for an Effective Crowdsourcing Protocol for Difficult NLU Data Collection Tasks?"
      },
      {
        "id": "db233bac71c35e222a78a7e730e14b336bf9915e",
        "title": "Towards Automating Code Review Activities"
      },
      {
        "id": "659c7a93a05b96dc803bb86e5522369bdeb173fa",
        "title": "Analyzing Sustainability Reports Using Natural Language Processing"
      },
      {
        "id": "e2d38543bd3cf813c63df336b21b003156ed48a8",
        "title": "Universal Natural Language Processing with Limited Annotations: Try Few-shot Textual Entailment as a Start"
      },
      {
        "id": "c5c5d1d96abd187e7b164c70d212006093258dbf",
        "title": "Natural Language Processing on Marketplace Product Review Sentiment Analysis"
      },
      {
        "id": "926329e8c699c7310a42c4090a5190870a05c8a5",
        "title": "Discriminative Nearest Neighbor Few-Shot Intent Detection by Transferring Natural Language Inference"
      },
      {
        "id": "4c3b044cc98def3defc3d562e5c0d811f7b0d200",
        "title": "LRC-BERT: Latent-representation Contrastive Knowledge Distillation for Natural Language Understanding"
      },
      {
        "id": "4e64399b54bc4de8d97328cddf38dd1038459cad",
        "title": "Ranking Clarification Questions via Natural Language Inference"
      },
      {
        "id": "6b21fd64502205bdb5134f13157283c52b701cde",
        "title": "Scene Graph Modification Based on Natural Language Commands"
      },
      {
        "id": "4bff523f34599564e2909731267c27b1ce5e4d9b",
        "title": "Comparison of Deep Learning Models and Various Text Pre-Processing Techniques for the Toxic Comments Classification"
      },
      {
        "id": "19803adec3b97fb2e3c8097f17bf33fabf311795",
        "title": "Fine-Tuning Pre-trained Language Model with Weak Supervision: A Contrastive-Regularized Self-Training Approach"
      },
      {
        "id": "48745e3485f84cc5a2dab8e1ce41de0a38afb490",
        "title": "Efficient Transformer-based Large Scale Language Representations using Hardware-friendly Block Structured Pruning"
      },
      {
        "id": "8e990e779cd70b70e316b129f334edfb8aa89af1",
        "title": "Differentially Private Language Models Benefit from Public Pre-training"
      },
      {
        "id": "8af3de56807c32172b06982cf785c9c8b14d117a",
        "title": "TweetBERT: A Pretrained Language Representation Model for Twitter Text Analysis"
      },
      {
        "id": "9db7ebe9e3a27118300a105531aa7e9309f993d9",
        "title": "Customizing Contextualized Language Models for Legal Document Reviews"
      },
      {
        "id": "7e5709d81558d3ef4265de29ea75931afeb1f2dd",
        "title": "Efficient Transformers: A Survey"
      },
      {
        "id": "2f0a7bcb51a09020656266b2c336ddf017d7d367",
        "title": "UPB at SemEval-2020 Task 12: Multilingual Offensive Language Detection on Social Media by Fine-tuning a Variety of BERT-based Models"
      },
      {
        "id": "9169f9afdd42aaa60e34f57ff89c882a50e71229",
        "title": "An Investigation on Different Underlying Quantization Schemes for Pre-trained Language Models"
      },
      {
        "id": "73e0f38ab49b19b86321016b773e15f1d02e3a72",
        "title": "SpAtten: Efficient Sparse Attention Architecture with Cascade Token and Head Pruning"
      },
      {
        "id": "e71aed7a0680c8fc09733f1dcd0cd3f6bb9cb7aa",
        "title": "The Lottery Ticket Hypothesis for Pre-trained BERT Networks"
      },
      {
        "id": "a554a0aae55be5597de8f6ece0a4dd0bd5a0e5f4",
        "title": "A Survey on Text Classification: From Traditional to Deep Learning"
      },
      {
        "id": "472cd41fa2ba2e520706f232cae12db4a7b5e60a",
        "title": "Contextualized Perturbation for Textual Adversarial Attack"
      },
      {
        "id": "097210dc65924f8ce59523faf444e635523dc714",
        "title": "TernaryBERT: Distillation-aware Ultra-low Bit BERT"
      },
      {
        "id": "f46f9683925e32177802933b494d6f93835c69cc",
        "title": "GAN-BERT: Generative Adversarial Learning for Robust Text Classification with a Bunch of Labeled Examples"
      },
      {
        "id": "7c6c31412c5dad22543bb71e31620e8868d644a3",
        "title": "FTRANS: energy-efficient acceleration of transformers using FPGA"
      },
      {
        "id": "3af8a493cf756f9fe72623204a11e378a9cd71a5",
        "title": "EdgeBERT: Sentence-Level Energy Optimizations for Latency-Aware Multi-Task NLP Inference"
      },
      {
        "id": "63c966e28b471551f2d9c7a5b4c639de6c8953b0",
        "title": "Reinforced Multi-Teacher Selection for Knowledge Distillation"
      },
      {
        "id": "518a0d1669369511c6b2f0687b68d65da3938e12",
        "title": "Joint Constrained Learning for Event-Event Relation Extraction"
      },
      {
        "id": "9baab08fbe37369856688b2abe5b3c90cce1682c",
        "title": "Compression of Deep Learning Models for Text: A Survey"
      },
      {
        "id": "b6451cfb71be72f8f9e0f5d2f529fea231adb382",
        "title": "Hardware Accelerator for Multi-Head Attention and Position-Wise Feed-Forward in the Transformer"
      },
      {
        "id": "63c2790ae3e086711e8e28c05867221f49c0401c",
        "title": "TwinBERT: Distilling Knowledge to Twin-Structured Compressed BERT Models for Large-Scale Retrieval"
      },
      {
        "id": "d99e71e1191d4814b725fa71beb0ca67f3282df6",
        "title": "100,000 Podcasts: A Spoken English Document Corpus"
      },
      {
        "id": "8b0a0f6d1cd6f3aa9b54be45d5127bb016a98171",
        "title": "The birth of Romanian BERT"
      },
      {
        "id": "52c8c417771a582c77fef22bfc38a0db835212b4",
        "title": "Two Stage Transformer Model for COVID-19 Fake News Detection and Fact Checking"
      },
      {
        "id": "b1b848860dc03366665fdcafc96a8c096d8c80ef",
        "title": "Load What You Need: Smaller Versions of Mutlilingual BERT"
      },
      {
        "id": "218ddb2d8182d197dd2cff40220179d7867c3589",
        "title": "RoBERT – A Romanian BERT Model"
      },
      {
        "id": "062c4ef3bf914186cd4b6f9c952ab28cdbe708b1",
        "title": "Large Scale Legal Text Classification Using Transformer Models"
      },
      {
        "id": "8fd0b70cfd6bbdaef9fbe1073afb3920cb61f80b",
        "title": "BERT-EMD: Many-to-Many Layer Mapping for BERT Compression with Earth Mover’s Distance"
      },
      {
        "id": "c0f709acf38eb27702b0fbce1215db0ebaa2de2b",
        "title": "SMYRF: Efficient Attention using Asymmetric Clustering"
      },
      {
        "id": "7b81b5a3bd6214ed813fa5f427e77e78142ee91b",
        "title": "The Pragmatics behind Politics: Modelling Metaphor, Framing and Emotion in Political Discourse"
      },
      {
        "id": "3938fe72ccfe4fe92387258874cb1cbe66194d4f",
        "title": "Point to the Expression: Solving Algebraic Word Problems Using the Expression-Pointer Transformer Model"
      },
      {
        "id": "e4f146f795c2bf6c5bb33b7229c1bad12370c2c4",
        "title": "Knowledge distillation for BERT unsupervised domain adaptation"
      },
      {
        "id": "1888436d50b9079803f25f8972100336595ada36",
        "title": "Transformer-Based Models for Automatic Identification of Argument Relations: A Cross-Domain Evaluation"
      },
      {
        "id": "7cd71be12746d56f161f253d110f37b16ae6c7eb",
        "title": "Improving Sentiment Analysis over non-English Tweets using Multilingual Transformers and Automatic Translation for Data-Augmentation"
      },
      {
        "id": "0b98f8ec299de3358c5dfc0d842529b5aee0e97c",
        "title": "Progressively Stacking 2.0: A Multi-stage Layerwise Training Method for BERT Training Speedup"
      },
      {
        "id": "3deb38dae20efacab76dc93767c02098741e749f",
        "title": "DeNERT-KG: Named Entity and Relation Extraction Model Using DQN, Knowledge Graph, and BERT"
      },
      {
        "id": "ffb0bbe26f1cbc0ab22ef34784248f2dcd3a5e5c",
        "title": "Finding Fast Transformers: One-Shot Neural Architecture Search by Component Composition"
      },
      {
        "id": "3f2e5102b44e4323cdc11c396b89c7491899ac14",
        "title": "Empowering Real-Time Traffic Reporting Systems With NLP-Processed Social Media Data"
      },
      {
        "id": "4ed811133638ceed1f1cd22e2725649ef24cb5fe",
        "title": "EasyTransfer: A Simple and Scalable Deep Transfer Learning Platform for NLP Applications"
      },
      {
        "id": "d9b7620f9b9653ada1a7ce36b0d6617f5979fff2",
        "title": "CAPT: Contrastive Pre-Training for Learning Denoised Sequence Representations"
      },
      {
        "id": "44992ae2c3dd74f9dfb5b4847df20b17e7e01aeb",
        "title": "Multi-label Classification of Commit Messages using Transfer Learning"
      },
      {
        "id": "0a970e6f462a5c4eb9ee4f25b5d4043fc8a077c7",
        "title": "Uncertainty-Aware Machine Support for Paper Reviewing on the Interspeech 2019 Submission Corpus"
      },
      {
        "id": "8e844acf10d6e0efd0bd4744ec77f52186873efd",
        "title": "Undivided Attention: Are Intermediate Layers Necessary for BERT?"
      },
      {
        "id": "7b404cca77f8eecd85ab2df24101023e8c40c505",
        "title": "The Thieves on Sesame Street Are Polyglots — Extracting Multilingual Models from Monolingual APIs"
      },
      {
        "id": "086e6733e5fda70bbce0c7545bd06d5634918a60",
        "title": "CLIMATE-FEVER: A Dataset for Verification of Real-World Climate Claims"
      },
      {
        "id": "ef8d788a904ed66bd8e30ffa69bc3ea1fe57dda7",
        "title": "HAT: Hardware-Aware Transformers for Efficient Natural Language Processing"
      },
      {
        "id": "501a8b86428563539667e8117cd8409674ef97c3",
        "title": "TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural Language Processing"
      },
      {
        "id": "c26f90d4cfa33ceff373cf49c2a534e2004685da",
        "title": "HULK: An Energy Efficiency Benchmark Platform for Responsible Natural Language Processing"
      },
      {
        "id": "baf60d13c98916b77b09bc525ede1cd610ed1db5",
        "title": "Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping"
      },
      {
        "id": "b0b0dddb8310e01b9407a21674c2d33a23a6e967",
        "title": "Byte Pair Encoding is Suboptimal for Language Model Pretraining"
      },
      {
        "id": "c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87",
        "title": "Linformer: Self-Attention with Linear Complexity"
      },
      {
        "id": "2573af4e13d9a5dddb257d22cd38a600528d9a8b",
        "title": "MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices"
      },
      {
        "id": "6bc3ad9b70feca27c3bf7374628d52c52a491657",
        "title": "lamBERT: Language and Action Learning Using Multimodal BERT"
      },
      {
        "id": "7ae4b59702e6f82c74299acb5a9e721b135c6bce",
        "title": "Selecting Informative Contexts Improves Language Model Fine-tuning"
      },
      {
        "id": "66f0f35fc78bdf2af9de46093d49a428970cde2e",
        "title": "Movement Pruning: Adaptive Sparsity by Fine-Tuning"
      },
      {
        "id": "4c7346ae1126dd853f4802962d26f844ceb82940",
        "title": "Compressing Language Models using Doped Kronecker Products"
      },
      {
        "id": "c94e49617f569204f989643e5462691b9b3a482b",
        "title": "Estimating Training Data Influence by Tracking Gradient Descent"
      },
      {
        "id": "1c332cfa211400fc6f56983fb01a6692046116dd",
        "title": "DynaBERT: Dynamic BERT with Adaptive Width and Depth"
      },
      {
        "id": "8af925f4edf45131b5b6fed8aa655089d58692fa",
        "title": "Lite Transformer with Long-Short Range Attention"
      },
      {
        "id": "d27669c82faf78ea08cceaa0a171b540cccc304d",
        "title": "ETC: Encoding Long and Structured Inputs in Transformers"
      },
      {
        "id": "d9b824dbecbe3a1f0b1489f9e4521a532a63818d",
        "title": "Compressing BERT: Studying the Effects of Weight Pruning on Transfer Learning"
      },
      {
        "id": "52f47e781852a77abedada48cfa971b24c919dde",
        "title": "Calibration of Pre-trained Transformers"
      },
      {
        "id": "0171ad4cc87cc7db25b4ec3169e293eed9a13b39",
        "title": "Training with Quantization Noise for Extreme Model Compression"
      },
      {
        "id": "d3c6c635b9cfd8890c7244d3db4be53d45944963",
        "title": "A^3: Accelerating Attention Mechanisms in Neural Networks with Approximation"
      },
      {
        "id": "5290d7921f0266c8b50b79fc8a0b7d22868f4f60",
        "title": "The Cost of Training NLP Models: A Concise Overview"
      },
      {
        "id": "738215a396f6eee1709c6b521a6199769f0ce674",
        "title": "Compressing Large-Scale Transformer-Based Models: A Case Study on BERT"
      },
      {
        "id": "0dee2c053f2ff17d134d5ff7795765750560311e",
        "title": "A Multilingual Evaluation for Online Hate Speech Detection"
      },
      {
        "id": "eb1602ecba96beadeb7d2f05e1b57fa6b339fc69",
        "title": "SqueezeBERT: What can computer vision teach NLP about efficient neural networks?"
      },
      {
        "id": "2b9955bc08fc5f4ddba73082ddabcfaabdbb4416",
        "title": "Poor Man's BERT: Smaller and Faster Transformer Models"
      },
      {
        "id": "3809fc1545f9876efd3cf8737662e2f88c609788",
        "title": "Neural Entity Linking: A Survey of Models based on Deep Learning"
      },
      {
        "id": "14216c91c7d02e58717204f04131107778a84e7b",
        "title": "Multi-Head Attention: Collaborate Instead of Concatenate"
      },
      {
        "id": "54d4ff8d536b292149a4fa017c22349cf4e54ce4",
        "title": "AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural Architecture Search"
      },
      {
        "id": "8f29451c1c53ac5c2c837fca0305bada56aff618",
        "title": "An Overview of Neural Network Compression"
      },
      {
        "id": "52347be1d7fc47815e624cd896b8942beb62c774",
        "title": "Evidence Inference 2.0: More Data, Better Models"
      },
      {
        "id": "7dc21b6c7c02708e4de6c6c260b4439b46fbd086",
        "title": "Improving BERT Fine-Tuning via Self-Ensemble and Self-Distillation"
      },
      {
        "id": "0f3ff6b94c6cd31b4c83ea9a3aac5362ee7b6c53",
        "title": "A Report on the 2020 Sarcasm Detection Shared Task"
      },
      {
        "id": "baed71eed57ad462f3ab138d4b1700a738cd5414",
        "title": "ETC: Encoding Long and Structured Data in Transformers"
      },
      {
        "id": "9c5a239b75bade55c830b164e2fadc424e879137",
        "title": "XtremeDistil: Multi-stage Distillation for Massive Multilingual Models"
      },
      {
        "id": "ebeed3d81649ab67e6220d6db0c2c361cbc20784",
        "title": "Privacy at Scale: Introducing the PrivaSeer Corpus of Web Privacy Policies"
      },
      {
        "id": "63857190aaf5aab1d94b54bb257b7b03b8cb5a50",
        "title": "GMAT: Global Memory Augmentation for Transformers"
      },
      {
        "id": "a81674f480dba239e12c80910528cae5d3a28e97",
        "title": "schuBERT: Optimizing Elements of BERT"
      },
      {
        "id": "0d5df0745bc961e2e76aef9a940172226ac1172b",
        "title": "Speech to Text Adaptation: Towards an Efficient Cross-Modal Distillation"
      },
      {
        "id": "782a50a48ba5d32839631254285d989bfadfd193",
        "title": "Interpretable Entity Representations through Large-Scale Typing"
      },
      {
        "id": "7718a9b2b33bc6b9c1d4c4b9a3e1d473ffe5c330",
        "title": "DuReader_robust: A Chinese Dataset Towards Evaluating Robustness and Generalization of Machine Reading Comprehension in Real-World Applications"
      },
      {
        "id": "4b3d6911700101a0f99b32749514b80f2b7c3685",
        "title": "Application of Pre-training Models in Named Entity Recognition"
      },
      {
        "id": "268b4c0cbbce656a582b6903fb85e3c517bd137c",
        "title": "Fixed-Point Optimization of Transformer Neural Network"
      },
      {
        "id": "1b0c8b26affd13e10ace5770e85478d60dcc368e",
        "title": "GOBO: Quantizing Attention-Based NLP Models for Low Latency and Energy Efficient Inference"
      },
      {
        "id": "53c8b98eb9180ed9f46820627715c7ae2803cee7",
        "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing"
      },
      {
        "id": "fb1245f80e8ca682e6ede2f1b9696fc1dbeee46e",
        "title": "Natural language processing to facilitate breast cancer research and management"
      },
      {
        "id": "83b8108014e3db4f46354a28ae68193f143c4e7e",
        "title": "Structured Pruning of Large Language Models"
      },
      {
        "id": "80cf2a6af4200ecfca1c18fc89de16148f1cd4bf",
        "title": "Patient Knowledge Distillation for BERT Model Compression"
      },
      {
        "id": "f4a8480cffa491020bdbb8c4c4e7a7e923b1c2c1",
        "title": "Reducing Transformer Depth on Demand with Structured Dropout"
      },
      {
        "id": "745e4b36a1759177871288cae51fbae0b873b5e5",
        "title": "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT"
      },
      {
        "id": "ce106590145e89ea4b621c99665862967ccf5dac",
        "title": "Q8BERT: Quantized 8Bit BERT"
      },
      {
        "id": "0e4cd6bae6ac1017e7b1b9bd644375aee65b8372",
        "title": "Show Your Work: Improved Reporting of Experimental Results"
      },
      {
        "id": "4d8a4509753cc91832f80ec35795064e79630ef3",
        "title": "Structured Pruning of a BERT-based Question Answering Model"
      },
      {
        "id": "b03cf6324ecf7a295a4aeae5970c88d1a1c3f336",
        "title": "Explicit Sparse Transformer: Concentrated Attention Through Explicit Selection"
      },
      {
        "id": "2e14e84ccec924ed770b58108ad1d9de6f0ca295",
        "title": "BP-Transformer: Modelling Long-Range Context via Binary Partitioning"
      },
      {
        "id": "48988bd2d17ff4fa00654e3e983acf390bb0f110",
        "title": "word2ket: Space-efficient Word Embeddings inspired by Quantum Entanglement"
      },
      {
        "id": "0fc85e11928eb15d3c3a2fa737490ffc7b3986e2",
        "title": "Transformer to CNN: Label-scarce distillation for efficient text classification"
      },
      {
        "id": "09c03220d8a1d5cf97b00e1a5138ae42b6805afe",
        "title": "Hate Speech Detection on Vietnamese Social Media Text using the Bi-GRU-LSTM-CNN Model"
      },
      {
        "id": "c1957e25155d713e7599b9d7e1e318c03cd2631a",
        "title": "Distilling Transformers into Simple Neural Networks with Unlabeled Transfer Data"
      },
      {
        "id": "4237bdd7df710c08b58d02bb48f8dcecd2521a80",
        "title": "Sparse Transformer: Concentrated Attention Through Explicit Selection"
      },
      {
        "id": "cb4571fa905abb70868d0bb9d4681f0a612c2d0f",
        "title": "Differentiable Reasoning on Large Knowledge Bases and Natural Language"
      },
      {
        "id": "5240bad304d5e9dd6a7ab1e089e024119ae55567",
        "title": "Lightweight and Efficient Neural Natural Language Processing with Quaternion Networks"
      },
      {
        "id": "296e8ceeba6550d7ec9b9ee727e0c17420ebb926",
        "title": "UR-FUNNY: A Multimodal Language Dataset for Understanding Humor"
      },
      {
        "id": "a08293b2c9c5bcddb023cc7eb3354d4d86bfae89",
        "title": "Distilling Task-Specific Knowledge from BERT into Simple Neural Networks"
      },
      {
        "id": "5a3749929bf5fb8b1f98a7b2a43c3b957bcf6c88",
        "title": "Efficient Training of BERT by Progressively Stacking"
      },
      {
        "id": "387e0b95d56e9ecec60a1037ddf7cc57b2851835",
        "title": "Playing the lottery with rewards and multiple languages: lottery tickets in RL and NLP"
      },
      {
        "id": "9525b632500dd201774943c55b3001ba56646b16",
        "title": "The Essential of Sentiment Analysis and Opinion Mining in Social Media : Introduction and Survey of the Recent Approaches and Techniques"
      },
      {
        "id": "cac3363ff4e0ac131bf5c3d46696db90ae81619e",
        "title": "Sentiment Analysis In Twitter Using Lexicon Based and Polarity Multiplication"
      },
      {
        "id": "742644f0c966b6177bd3287c21fdad73f5adab35",
        "title": "Measuring scheduling efficiency of RNNs for NLP applications"
      },
      {
        "id": "be95abdcbb1faf85f32577896b2e9fa78a70c307",
        "title": "Incorporating Emoji Descriptions Improves Tweet Classification"
      }
    ],
    "6": [
      {
        "id": "e6c561d02500b2596a230b341a8eb8b921ca5bf2",
        "title": "Scaling Laws for Neural Language Models"
      },
      {
        "id": "ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc",
        "title": "Cross-lingual Language Model Pretraining"
      },
      {
        "id": "6c761cfdb031701072582e434d8f64d436255da6",
        "title": "AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing"
      },
      {
        "id": "760f807406272b5ede591f19241824f2d17c319a",
        "title": "Multi-Task Learning in Natural Language Processing: An Overview"
      },
      {
        "id": "74ddc64ccd760df61031b4640c3fee45e5e1ce79",
        "title": "Applying natural language processing to automatically assess student conceptual understanding from textual responses"
      },
      {
        "id": "f47ef903bc325eef4c2d57e819dbce79308bb2ae",
        "title": "Deep Learning-Based Natural Language Processing in Radiology: The Impact of Report Complexity, Disease Prevalence, Dataset Size, and Algorithm Type on Model Performance"
      },
      {
        "id": "39afb79bc3c3eb37ff244357d29f3055e43047b6",
        "title": "LegalNLP - Natural Language Processing methods for the Brazilian Legal Language"
      },
      {
        "id": "a0b777b25cdf0fc992568ca52a5c7bebf1ee987f",
        "title": "Deep Transfer Learning & Beyond: Transformer Language Models in Information Systems Research"
      },
      {
        "id": "f619ec168bf900b11ff2a94bf526d107ab8c0394",
        "title": "Using deep learning to value free-form text data for predictive maintenance"
      },
      {
        "id": "1a8c0bc4520f9836d36e1e09fa8df6b54b4b363e",
        "title": "A Statutory Article Retrieval Dataset in French"
      },
      {
        "id": "36ecc1e815820915c52a30700e7ee5350723f971",
        "title": "On cross-lingual retrieval with multilingual text encoders"
      },
      {
        "id": "311e48e1c4a0dcd65a6699376ffc85a24a333a56",
        "title": "Enjoy the Salience: Towards Better Transformer-based Faithful Explanations with Word Salience"
      },
      {
        "id": "e3b100e5a8847c150985af5ccc838220b2d30e35",
        "title": "AdapterHub Playground: Simple and Flexible Few-Shot Learning with Adapters"
      },
      {
        "id": "b99bc890c8ccb78eee6fdf5aa0cc52cb73d4efed",
        "title": "Explaining transformer-based models for automatic short answer grading"
      },
      {
        "id": "78e8400bdffb9901826f16cd6472661064be37fd",
        "title": "A Computational Look at Oral History Archives"
      },
      {
        "id": "dbb695e1752a2b8d539e0c0f5165442ae5fc8f2a",
        "title": "UzBERT: pretraining a BERT model for Uzbek"
      },
      {
        "id": "541502d193616b7d3c5fba2fb252a8d86698b99f",
        "title": "Pre-trained Transformer-Based Approach for Arabic Question Answering : A Comparative Study"
      },
      {
        "id": "d1d3dde91e3e73ccfbeb176f3af565a4507be077",
        "title": "AI-Based Misogyny Detection from Arabic Levantine Twitter Tweets"
      },
      {
        "id": "065715bf35d1dba5bf06f59f7e1e8390b93e6adf",
        "title": "Evaluation of contextual embeddings on less-resourced languages"
      },
      {
        "id": "a2412fdebd53bd25476f834ae2b8aa8cb44cb1e1",
        "title": "The Inductive Bias of In-Context Learning: Rethinking Pretraining Example Design"
      },
      {
        "id": "9606c85e44e421f7eb822c9f7130610d6d9d8ad9",
        "title": "Deep Learning Transformer Architecture for Named-Entity Recognition on Low-Resourced Languages: State of the art results"
      },
      {
        "id": "74a7b6d3bd3b58280c7b8dbcb9598b4e4e0ad624",
        "title": "Natural language processing of radiology reports to investigate the effects of the COVID-19 pandemic on the incidence and age distribution of fractures"
      },
      {
        "id": "642e280df732665249315d6c144871f0e2ceeae6",
        "title": "NeurIPS 2020 NLC2CMD Competition: Translating Natural Language to Bash Commands"
      },
      {
        "id": "dc70b180329a6ffead5e48093fb5a551955047c4",
        "title": "HerBERT: Efficiently Pretrained Transformer-based Language Model for Polish"
      },
      {
        "id": "5310ef9f4179a6771df7be8479247953691f8600",
        "title": "A Comparison of Pre-Trained Language Models for Multi-Class Text Classification in the Financial Domain"
      },
      {
        "id": "c4a24f0a480b15254b84b1f5620a6c1fc34f4c72",
        "title": "Probing Multilingual Language Models for Discourse"
      },
      {
        "id": "138d78692f72d44fa49629ce6d2b01d83add3f89",
        "title": "Exploring the Data Efficiency of Cross-Lingual Post-Training in Pretrained Language Models"
      },
      {
        "id": "6803adc7d8b891be652d18815f830f7a42a0f5b5",
        "title": "Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets"
      },
      {
        "id": "6e2a57b46a96694e6dfd3c65796c877dd0094f3d",
        "title": "QASR: QCRI Aljazeera Speech Resource A Large Scale Annotated Arabic Speech Corpus"
      },
      {
        "id": "b17065b024705a4146e2686d12a2c5052bfb5b89",
        "title": "A BERT-based transfer learning approach to text classification on software requirements specifications"
      },
      {
        "id": "ea6beaaa274cf4e8a906690951e6867ff87ded05",
        "title": "HeBERT & HebEMO: a Hebrew BERT Model and a Tool for Polarity Analysis and Emotion Recognition"
      },
      {
        "id": "68713fdc2b2e7182548c8d7d3a247bddb79c51b4",
        "title": "Domain Adaptation for Arabic Cross-Domain and Cross-Dialect Sentiment Analysis from Contextualized Word Embedding"
      },
      {
        "id": "d13a0c8d49cb268d8d245925baee0316c1fe1875",
        "title": "Which transformer architecture fits my data? A vocabulary bottleneck in self-attention"
      },
      {
        "id": "aba19f5ae0747dd1d02137ca596a74e70514a246",
        "title": "Low-Resource Named Entity Recognition via the Pre-Training Model"
      },
      {
        "id": "0c791b2299bf910cea23fe4d13f2509532891c26",
        "title": "Automatic Part-of-Speech Tagging for Security Vulnerability Descriptions"
      },
      {
        "id": "142d60c73140c82ce382525fcac6358999d71627",
        "title": "Evaluating the Values of Sources in Transfer Learning"
      },
      {
        "id": "724cc225a0171bcde03e06e83b64bc21d9aa5460",
        "title": "Combining Context-Free and Contextualized Representations for Arabic Sarcasm Detection and Sentiment Identification"
      },
      {
        "id": "fe53ea09903af7e0a32a29c2c9578ad3350749d7",
        "title": "How Low is Too Low? A Computational Perspective on Extremely Low-Resource Languages"
      },
      {
        "id": "980fe68a95a38779e87126492a4cedf084f42f73",
        "title": "BERT Multilingual and Capsule Network for Arabic Sentiment Analysis"
      },
      {
        "id": "f69e4f2129c28b84a12b17d893160fcf02576e4e",
        "title": "SICK-NL: A Dataset for Dutch Natural Language Inference"
      },
      {
        "id": "e77c8f93bf92bc9198c3b8b981d223bf56aa707f",
        "title": "BanglaBERT: Language Model Pretraining and Benchmarks for Low-Resource Language Understanding Evaluation in Bangla"
      },
      {
        "id": "618a84ea5d9ac23c6a93961ba798154026754ddd",
        "title": "A panoramic survey of natural language processing in the Arab world"
      },
      {
        "id": "523d9b25339be038d7c58f99e5dfb713c3f36be4",
        "title": "ARBML: Democritizing Arabic Natural Language Processing Tools"
      },
      {
        "id": "26da56580fcf8fc6dd5644ede6575bdbbd7caf1a",
        "title": "IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding"
      },
      {
        "id": "a32f54895262470319c744987c62e23a0786fae1",
        "title": "Natural Language-based Integration of Online Review Datasets for Identification of Sex Trafficking Businesses"
      },
      {
        "id": "470735385073e6b378717a886dcc8f1014e69e8a",
        "title": "A Comprehensive Survey on Word Representation Models: From Classical to State-of-the-Art Word Representation Language Models"
      },
      {
        "id": "d26236ea10369adfc0ee594fd1e4536a70eb7e8f",
        "title": "Latin BERT: A Contextual Language Model for Classical Philology"
      },
      {
        "id": "09bf4d005cb334e38bc28c5ad2d4f21d3a1d13cc",
        "title": "Language ID in the Wild: Unexpected Challenges on the Path to a Thousand-Language Web Text Corpus"
      },
      {
        "id": "f0520b991c1a16449a95ff98771d3cf86ed71428",
        "title": "GottBERT: a pure German Language Model"
      },
      {
        "id": "9ef33af1b2ebda2f2edd6c1394f314d7ac2f00f2",
        "title": "TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification"
      },
      {
        "id": "1e4cda8be54999ced1324777fa462a85e2c9746c",
        "title": "ARBERT & MARBERT: Deep Bidirectional Transformers for Arabic"
      },
      {
        "id": "1d95011355628f7aef068ab1914198e43258c530",
        "title": "BERTimbau: Pretrained BERT Models for Brazilian Portuguese"
      },
      {
        "id": "0d965ed237a3b4592ecefdb618c29f63adedff76",
        "title": "Towards Debiasing Sentence Representations"
      },
      {
        "id": "0bd100685a492501d3f5f82a383edb3b5ded0f06",
        "title": "GREEK-BERT: The Greeks visiting Sesame Street"
      },
      {
        "id": "5b2ec7a534cab750c6b00fe491500681ae3b1527",
        "title": "PTT5: Pretraining and validating the T5 model on Brazilian Portuguese data"
      },
      {
        "id": "2f4898cd30ac6758cc510d3a99346e8ec78a4c52",
        "title": "Combining BERT with Static Word Embeddings for Categorizing Social Media"
      },
      {
        "id": "163c0b3516753ce9679410484c608636a4d5da15",
        "title": "Automatic Arabic Dialect Identification Systems for Written Texts: A Survey"
      },
      {
        "id": "043c2dfda82378ebfbf937b5a8bf20702d429062",
        "title": "Decoding Strategies for Improving Low-Resource Machine Translation"
      },
      {
        "id": "d38c6e29c800b11fc60c0db6776f949a8ebd4aaf",
        "title": "Towards Improved Deep Contextual Embedding for the identification of Irony and Sarcasm"
      },
      {
        "id": "db8fdf93aaf27cfd93fa0a41d78ce11b61a3a6dc",
        "title": "The Depth-to-Width Interplay in Self-Attention."
      },
      {
        "id": "10efdde1ae3a9d359ac1aae0bd5ef7bfd68810dd",
        "title": "DICT-MLM: Improved Multilingual Pre-Training using Bilingual Dictionaries"
      },
      {
        "id": "e139edac03b4ddf6e8ab26a2045b196388f16313",
        "title": "Using Argument Mining for Legal Text Summarization"
      },
      {
        "id": "d4277569f7238db3d39cc7780e755a4f77558ac1",
        "title": "Bangla Documents Classification using Transformer Based Deep Learning Models"
      },
      {
        "id": "1d0b7260eb159cb91e5d232bb656afe9f4c5a20f",
        "title": "Evaluating Bias In Dutch Word Embeddings"
      },
      {
        "id": "0f4f27bb267b238d6044375863335db7fe69d661",
        "title": "This is a BERT. Now there are several of them. Can they generalize to novel words?"
      },
      {
        "id": "b97a283f777dd0562a8714263700cc8746e4987c",
        "title": "Multilingual Contextual Affective Analysis of LGBT People Portrayals in Wikipedia"
      },
      {
        "id": "a37b7c0785693a25a2ef9351ff4c348a727843f7",
        "title": "Hybrid Emoji-Based Masked Language Models for Zero-Shot Abusive Language Detection"
      },
      {
        "id": "18f44e11e7586202c6d15775089f7b3f6cbbfd57",
        "title": "Emergent Communication Pretraining for Few-Shot Machine Translation"
      },
      {
        "id": "995ec006ac98a697ea38bd4eea8c1f3170a8adb4",
        "title": "CAMeL Tools: An Open Source Python Toolkit for Arabic Natural Language Processing"
      },
      {
        "id": "21b45128f795a2dc1b8ed683c7226760c8f2f8fe",
        "title": "Towards data-driven medical imaging using natural language processing in patients with suspected urolithiasis"
      },
      {
        "id": "1359d2ef45f1550941e22bf046026c89f6edf315",
        "title": "AraBERT: Transformer-based Model for Arabic Language Understanding"
      },
      {
        "id": "634e8ee7e86f253c4b6c722a3bb7c32b7aa3892b",
        "title": "RobBERT: a Dutch RoBERTa-based Language Model"
      },
      {
        "id": "be158d5ab493b2f2dae736a2ca92afcd66ed5be4",
        "title": "ParsBERT: Transformer-based Model for Persian Language Understanding"
      },
      {
        "id": "b3c73de96640ee858f83c3f0eda2a3d15d59b847",
        "title": "Privacy Risks of General-Purpose Language Models"
      },
      {
        "id": "6551f742b825561d26242ca8a646ba0e33fb109f",
        "title": "What the [MASK]? Making Sense of Language-Specific BERT Models"
      },
      {
        "id": "20895098dedfb656f333834319db729df7a9e0fa",
        "title": "Intra-Processing Methods for Debiasing Neural Networks"
      },
      {
        "id": "10467a1466aeec246ac0a577bfc311ec4de110de",
        "title": "Alternating Language Modeling for Cross-Lingual Pre-Training"
      },
      {
        "id": "82453548b97f78ab2cdb9a8626ff858db9ce5a82",
        "title": "Pre-training Polish Transformer-based Language Models at Scale"
      },
      {
        "id": "4a7e7b24389d190d20f214054156e43dc269e595",
        "title": "POSIT: Simultaneously Tagging Natural and Programming Languages"
      },
      {
        "id": "15315e111d7c2d49a6f40660fd6e85e96258f7d3",
        "title": "Transferring Monolingual Model to Low-Resource Language: The Case of Tigrinya"
      },
      {
        "id": "df56748cd4f52a58973b4ac52c0bf9156c5f52f0",
        "title": "Unsupervised Translation of Programming Languages"
      },
      {
        "id": "297ad41c0e7264e67ae078921e2a57436293ce72",
        "title": "XGLUE: A New Benchmark Datasetfor Cross-lingual Pre-training, Understanding and Generation"
      },
      {
        "id": "085b360d3c08aaf997f45a78e27f2629f5625205",
        "title": "Translation Artifacts in Cross-lingual Transfer Learning"
      },
      {
        "id": "7907d06a0a8cd2d25480422944c88f66db950d3d",
        "title": "FQuAD: French Question Answering Dataset"
      },
      {
        "id": "58e825d96454aeba9c780e5bfb1c1f872ad9e603",
        "title": "Exploring Cross-sentence Contexts for Named Entity Recognition with BERT"
      },
      {
        "id": "969044e66f4b4064078b2c8b787a11f79094300f",
        "title": "Investigating Transformers for Automatic Short Answer Grading"
      },
      {
        "id": "c014f8bc3b521453a93a13bb2c90700fcf462738",
        "title": "Limits to Depth Efficiencies of Self-Attention"
      },
      {
        "id": "e00631018e737355f1b0b3db779641f8f26288b1",
        "title": "WikiBERT Models: Deep Transfer Learning for Many Languages"
      },
      {
        "id": "93928395177b28ffb5ecf4030bad61136d17bb08",
        "title": "Beheshti-NER: Persian named entity recognition Using BERT"
      },
      {
        "id": "65dbb886849e44d8375ba5ee815dae581d332daf",
        "title": "Banner: A Cost-Sensitive Contextualized Model for Bangla Named Entity Recognition"
      },
      {
        "id": "05d6af4dc79ff045249e2732a17d855af66500b5",
        "title": "Establishing a New State-of-the-Art for French Named Entity Recognition"
      },
      {
        "id": "2d374cdc65c047e5e860e9e5147775a81216f23e",
        "title": "Viability of Neural Networks for Core Technologies for Resource-Scarce Languages"
      },
      {
        "id": "0dc7591b9111bfe14eb9fbdc366e15d894f5b659",
        "title": "Testing Pre-trained Transformer Models for Lithuanian News Clustering"
      },
      {
        "id": "32603503638c3a0a2ee81cf4952d7317ee611c20",
        "title": "Linguistic Fundamentals for Natural Language Processing II: 100 Essentials from Semantics and Pragmatics"
      },
      {
        "id": "b61c6405f4de381758e8b52a20313554d68a9d85",
        "title": "CamemBERT: a Tasty French Language Model"
      },
      {
        "id": "069e0d896da7c79faeee4cf057548d5da7ce885e",
        "title": "FlauBERT: Unsupervised Language Model Pre-training for French"
      },
      {
        "id": "65f788fb964901e3f1149a0a53317535ca85ed7d",
        "title": "Unicoder: A Universal Language Encoder by Pre-training with Multiple Cross-lingual Tasks"
      },
      {
        "id": "8199b4c196b09d6176816e4d7db8d6f3d65e07c1",
        "title": "From English To Foreign Languages: Transferring Pre-trained Language Models"
      },
      {
        "id": "c20c68c45127439139a08adb0b1f2b8354a94d6c",
        "title": "CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data"
      },
      {
        "id": "9ada4f98ae8d81011ed6383f7911c45959966596",
        "title": "Abusive Language Detection: A Comprehensive Review"
      },
      {
        "id": "a4d5e425cac0bf84c86c0c9f720b6339d6288ffa",
        "title": "BERTje: A Dutch BERT Model"
      },
      {
        "id": "477d66dcd2c08243dcc69822d6da7ec06393773a",
        "title": "Multilingual is not enough: BERT for Finnish"
      },
      {
        "id": "40c6fadf7b08fbcd5aedfc8bebf99ccbdb52d945",
        "title": "Portuguese Named Entity Recognition using BERT-CRF"
      },
      {
        "id": "753cc560d7735734aa7ef17a3966fd02bef68cb1",
        "title": "A transformer-based approach to irony and sarcasm detection"
      },
      {
        "id": "cf2fcb73e2effff29ceb5a5b89bbca34d2d27c1a",
        "title": "Learning to Deceive with Attention-Based Explanations"
      },
      {
        "id": "7e95535491b1b0cea66d182a9bd894a5e6be5562",
        "title": "The MADAR Shared Task on Arabic Fine-Grained Dialect Identification"
      },
      {
        "id": "be16e643ed6cead716df162c4ac0806a2cdf52b0",
        "title": "Fine-tuning BERT for Joint Entity and Relation Extraction in Chinese Medical Text"
      },
      {
        "id": "921ce943fffda93dfbea66038a8b84155d471ef7",
        "title": "Fully Unsupervised Crosslingual Semantic Textual Similarity Metric Based on BERT for Identifying Parallel Data"
      },
      {
        "id": "3b3973af3002a2eb7740a2bf3cc2085d64c9e7c6",
        "title": "Quasi Bidirectional Encoder Representations from Transformers for Word Sense Disambiguation"
      },
      {
        "id": "3b58ba9561bfe599b4022130961e51652694bc49",
        "title": "Evaluating Resource-Lean Cross-Lingual Embedding Models in Unsupervised Retrieval"
      },
      {
        "id": "5140c7db54b0f038002115edee8ce1f6081b47a4",
        "title": "Arabic Dialect Identification for Travel and Twitter Text"
      },
      {
        "id": "7f98fff4c5bf4b19321f5476fd76106ce32edcc4",
        "title": "Enhanced Bert-Based Ranking Models for Spoken Document Retrieval"
      },
      {
        "id": "157a7ae44613a1fcf34e2be8c1e19a4f6e3c50e3",
        "title": "Transfer Learning in Natural Language Processing"
      },
      {
        "id": "acd047180ea5ec148ab2ef6e7b227e501a72ab26",
        "title": "Natural Language Processing and Classification Methods for the Maintenance and Optimization of US Weapon Systems"
      },
      {
        "id": "c846cbb24866af99a8d02d4c73aa4d7dd1831538",
        "title": "XLDA: Cross-Lingual Data Augmentation for Natural Language Inference and Question Answering"
      },
      {
        "id": "ba10b8f9ee40b68053af9e6c2383aa2c6e39e9be",
        "title": "Text Classification Algorithms: A Survey"
      },
      {
        "id": "2fa3f7ce620a1c7155daef6620dd6bb0e01934f3",
        "title": "Beto, Bentz, Becas: The Surprising Cross-Lingual Effectiveness of BERT"
      },
      {
        "id": "6be22cd8badcd0b6d59d9763c63acd612a6cf245",
        "title": "A Robust Deep Ensemble Classifier for Figurative Language Detection"
      },
      {
        "id": "426dc04094d1e2cd1ab84e979a2db3af669d018f",
        "title": "Sentiment and Sarcasm Classification With Multitask Learning"
      },
      {
        "id": "c39e409d6b7744200c4fd12a6b81e51f6145cfae",
        "title": "Unsupervised Domain Adaptation of Contextualized Embeddings for Sequence Labeling"
      },
      {
        "id": "33c1296c2de0bf7a491d0ff4d75afe8b421bfc04",
        "title": "Mazajak: An Online Arabic Sentiment Analyser"
      },
      {
        "id": "2ce676acd17a5bd2ab1561f4a219406c2c8346b6",
        "title": "Text emotion detection in social networks using a novel ensemble classifier based on Parzen Tree Estimator (TPE)"
      },
      {
        "id": "5ac0784c5f9a6d54e369fb70c2f75ef17f8e9c77",
        "title": "Contextual Word Representations: A Contextual Introduction"
      },
      {
        "id": "55205176bba4ac40f6ea4733744f63f2f6158a47",
        "title": "A Generalized Framework of Sequence Generation with Application to Undirected Sequence Models"
      },
      {
        "id": "bfab4f9b5c8c700abb99d23ce1e83f6c59600641",
        "title": "ASA: A framework for Arabic sentiment analysis"
      }
    ],
    "4": [
      {
        "id": "207da6d2c07289bf72a2b5974bb3f011ebb5dd0d",
        "title": "Adversarial NLI: A New Benchmark for Natural Language Understanding"
      },
      {
        "id": "d28c18a3c2a0afdc0a8634d18345af8d36e1f948",
        "title": "A Constructive Prediction of the Generalization Error Across Scales"
      },
      {
        "id": "8323c591e119eb09b28b29fd6c7bc76bd889df7a",
        "title": "Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"
      },
      {
        "id": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
        "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"
      },
      {
        "id": "145b8b5d99a2beba6029418ca043585b90138d12",
        "title": "MASS: Masked Sequence to Sequence Pre-training for Language Generation"
      },
      {
        "id": "658721bc13b0fa97366d38c05a96bf0a9f4bb0ac",
        "title": "Multi-Task Deep Neural Networks for Natural Language Understanding"
      },
      {
        "id": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6",
        "title": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"
      },
      {
        "id": "d5784fd3ac7e06ec030abb8f7787faa9279c1a50",
        "title": "Interpreting Deep Learning Models in Natural Language Processing: A Review"
      },
      {
        "id": "e7b6ceca1fd4e81861b8432d43ed0cfc7d05fb34",
        "title": "Natural Language Processing Algorithms for Normalizing Expressions of Synonymous Symptoms in Traditional Chinese Medicine"
      },
      {
        "id": "e322030712d88accf303b1f84340e93bb98298cc",
        "title": "Explainable natural language processing with matrix product states"
      },
      {
        "id": "638e198424f81570441a91bafda16d96f53d3c72",
        "title": "SLUE: New Benchmark Tasks For Spoken Language Understanding Evaluation on Natural Speech"
      },
      {
        "id": "319b84be7a843250bc81d7086f79a4126d550277",
        "title": "ERNIE 3.0: Large-scale Knowledge Enhanced Pre-training for Language Understanding and Generation"
      },
      {
        "id": "a3184d40d390793232c99c89b57b8f65c16320b2",
        "title": "ERNIE 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training for Language Understanding and Generation"
      },
      {
        "id": "0ab41d455d676542b37ca1499bb19ea6a5d1cf79",
        "title": "Yuan 1.0: Large-Scale Pre-trained Language Model in Zero-Shot and Few-Shot Learning"
      },
      {
        "id": "17aa05693a9d3dcbb0ffc7a05be59ef621c4d0d4",
        "title": "PatentNet: multi-label classification of patent documents using deep learning based language understanding"
      },
      {
        "id": "cb416e2d8bd72203bc73c1005251dcb12b153d20",
        "title": "Language Representation Models: An Overview"
      },
      {
        "id": "48a3184b25a90d6864326aec7950af6aee60ef49",
        "title": "A Survey of Knowledge Enhanced Pre-trained Language Models"
      },
      {
        "id": "a30f912f8c5e2a2bfb06351d4578e1ba3fa37896",
        "title": "CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation"
      },
      {
        "id": "b90c090f7928a78d85d952737488be1ef8587ae5",
        "title": "A Literature Survey of Recent Advances in Chatbots"
      },
      {
        "id": "2122ed4a82bc7d8affc5f7ae5026d174ea34ea52",
        "title": "GPT-3 Models are Poor Few-Shot Learners in the Biomedical Domain"
      },
      {
        "id": "865bc9d894a55f3e77ea29f11691f8bf550571d5",
        "title": "Emerging trends: A gentle introduction to fine-tuning"
      },
      {
        "id": "ea0ea0da2e774bc0b73c4470de6cbd1fc979b265",
        "title": "So Cloze Yet So Far: N400 Amplitude Is Better Predicted by Distributional Information Than Human Predictability Judgements"
      },
      {
        "id": "f9c0f78521e5bf4a38f2fd9c417dfc9c54950af1",
        "title": "Automated Essay Scoring Using Transformer Models"
      },
      {
        "id": "160efdab15386cc890b436fb79c536bdecf228d3",
        "title": "Part-Guided Relational Transformers for Fine-Grained Visual Recognition"
      },
      {
        "id": "a1040e3d1aeb952b8a1d940e68f8632c34d58421",
        "title": "LOT: A Story-Centric Benchmark for Evaluating Chinese Long Text Understanding and Generation"
      },
      {
        "id": "5f86fc35a5e22eb82a5fe9a8fa0fbf7aa8e058f2",
        "title": "Enhancing Chinese Character Representation With Lattice-Aligned Attention"
      },
      {
        "id": "12de79e60271e2bd8aed4efc98d4a0b67fe62ade",
        "title": "An Adaptive Graph Pre-training Framework for Localized Collaborative Filtering"
      },
      {
        "id": "4690eb050572a279f94560b6bbdccaae577b45f5",
        "title": "MVP-BERT: Multi-Vocab Pre-training for Chinese BERT"
      },
      {
        "id": "79244bdbe17a1dd01e2ee2435a6b667c86539727",
        "title": "Application of Sequence Embedding in Protein Sequence-Based Predictions"
      },
      {
        "id": "b5cd0f26c629fe5a695e7d472d392a0f5268b74c",
        "title": "Adversarial Training with Contrastive Learning in NLP"
      },
      {
        "id": "adf453436f027f684147194b8fad59c2743214e6",
        "title": "IBERT: Idiom Cloze-style reading comprehension with Attention"
      },
      {
        "id": "8436897e713c2242d6291df9a6a33c1544d4dd39",
        "title": "Adversarial GLUE: A Multi-Task Benchmark for Robustness Evaluation of Language Models"
      },
      {
        "id": "8a4b9c22d45c9136e3494164b9a40a7da7a1c2cf",
        "title": "Weibo Text Sentiment Analysis Based on BERT and Deep Learning"
      },
      {
        "id": "5ef4e013ce7bf0c19873c83ffd6898ce33ffd542",
        "title": "AST-Transformer: Encoding Abstract Syntax Trees Efficiently for Code Summarization"
      },
      {
        "id": "dfb4c9396e99a4eb7abfe3798e83ec56b4ccdb9c",
        "title": "Human Evaluation of Creative NLG Systems: An Interdisciplinary Survey on Recent Papers"
      },
      {
        "id": "7f5d5e032011ec4f3f6b2a414ba5a5c0a8b696f6",
        "title": "Security Vulnerability Detection Using Deep Learning Natural Language Processing"
      },
      {
        "id": "90980746fea6a3e351d527c92606c7a3ebe1fc11",
        "title": "Multimodal Surprise Adequacy Analysis of Inputs for Natural Language Processing DNN Models"
      },
      {
        "id": "ebdb02f9d0f31d3a13070f61fa07fe2fa11cb531",
        "title": "Model Explainability in Deep Learning Based Natural Language Processing"
      },
      {
        "id": "68d0a423c33cea71eeb6a7fc7418bd7f94ec8772",
        "title": "Identifying and Responding to Health Misinformation on Reddit Dermatology Forums With Artificially Intelligent Bots Using Natural Language Processing: Design and Evaluation Study"
      },
      {
        "id": "0f71a4fa9736ae916e6aef53045f6be4c901b0ff",
        "title": "Reliability Testing for Natural Language Processing Systems"
      },
      {
        "id": "de2d64e0c66c2f1d4e68fc2528fe07eebb4ada57",
        "title": "Summary of Research Methods on Pre-Training Models of Natural Language Processing"
      },
      {
        "id": "86ff29da65c3fd7f80a49c6cfcda9818480b83dc",
        "title": "Draw Me a Flower: Processing and Grounding Abstraction in Natural Language"
      },
      {
        "id": "73f949b35d0d6a234565ba219ad0f865c2db5657",
        "title": "Evaluating Gender Bias in Natural Language Inference"
      },
      {
        "id": "49a77a36a0a60d29aa7838ac49a055a69658b195",
        "title": "K-PLUG: Knowledge-injected Pre-trained Language Model for Natural Language Understanding and Generation in E-Commerce"
      },
      {
        "id": "78bd4518950e3f0bcd6aa9f7f8e09cbbf13eb11f",
        "title": "PanGu-α: Large-scale Autoregressive Pretrained Chinese Language Models with Auto-parallel Computation"
      },
      {
        "id": "6d8052588c62e5bf2a073ae414867a78784ff663",
        "title": "Transformer-based deep neural network language models for Alzheimer’s disease risk assessment from targeted speech"
      },
      {
        "id": "5bfb0cc16b871c75e32a6a9d54dd7db225260e04",
        "title": "CodeTrans: Towards Cracking the Language of Silicone's Code Through Self-Supervised Deep Learning and High Performance Computing"
      },
      {
        "id": "89711a7e91ad81874a5a0b1c3359bb67b27c0578",
        "title": "Low-Dimensional Structure in the Space of Language Representations is Reflected in Brain Responses"
      },
      {
        "id": "857a091532c3641071cb7e411980eb6454a000ae",
        "title": "The Evolution of Language Models Applied to Emotion Analysis of Arabic Tweets"
      },
      {
        "id": "f864d4d2267abba15eb43db54f58286aef78292b",
        "title": "Offline Reinforcement Learning as One Big Sequence Modeling Problem"
      },
      {
        "id": "6799d0f9c15680c3d727dac12cd25ee5248d73f8",
        "title": "Comparative Analysis of Transformer based Language Models"
      },
      {
        "id": "7072db6eddb85ecd2c117365d91bd694760f726e",
        "title": "Position Information in Transformers: An Overview"
      },
      {
        "id": "79604e29340a8336003d1e8a348083b6249cc754",
        "title": "MusicBERT: Symbolic Music Understanding with Large-Scale Pre-Training"
      },
      {
        "id": "ee8848f3f6a08e80ff08a1093f78b3f7a3d84f37",
        "title": "A Survey on Document-level Neural Machine Translation"
      },
      {
        "id": "a8f2c28e6721beb39e3696d78dd7da93596e3778",
        "title": "A Survey of Textual Emotion Recognition and Its Challenges"
      },
      {
        "id": "5e08011d3ef194650a1471caa7996c2186788a6b",
        "title": "Learned Embeddings from Deep Learning to Visualize and Predict Protein Sets"
      },
      {
        "id": "7038a6b7070d2ffff88e8b12d43a1e185d739884",
        "title": "Representation learning applications in biological sequence analysis"
      },
      {
        "id": "d8e8e35bf4cf8821ade2d58b34d9ae23a9b08ab2",
        "title": "LET: Linguistic Knowledge Enhanced Graph Transformer for Chinese Short Text Matching"
      },
      {
        "id": "04b40daa1ca74bdbb578beb314bf662538ecd18e",
        "title": "ZEN 2.0: Continue Training and Adaption for N-gram Enhanced Text Encoders"
      },
      {
        "id": "d8df456f790381f4ddb388be24a546625bd75ee2",
        "title": "Maximizing Parallelism in Distributed Training for Huge Neural Networks"
      },
      {
        "id": "b92a27526a47af9ed9db6071d54b776da85b234b",
        "title": "Text Compression-Aided Transformer Encoding"
      },
      {
        "id": "84de025e0ead8a5bbfde6e28d43c6c1d456930f9",
        "title": "AngryBERT: Joint Learning Target and Emotion for Hate Speech Detection"
      },
      {
        "id": "8fc27b2f4c118c50e208a563835fd5e52a522980",
        "title": "Building Interpretable Interaction Trees for Deep NLP Models"
      },
      {
        "id": "f386368c0868793b90d7e03b50010af320c21722",
        "title": "deGraphCS: Embedding Variable-based Flow Graph for Neural Code Search"
      },
      {
        "id": "53a85023877c279ada7252ed3232deb1c5ba30b7",
        "title": "External features enriched model for biomedical question answering"
      },
      {
        "id": "44725678a7e2b48fdcf6ad3b86d1a96dec736a9e",
        "title": "Evaluating pre-trained models for user feedback analysis in software engineering: a study on classification of app-reviews"
      },
      {
        "id": "ff24b920d7a70e209c21f27274c22f8a0d5f6a7f",
        "title": "Pretraining model for biological sequence data"
      },
      {
        "id": "b3a81dc5cd86de75db25b565b0fd01d22f2d24f3",
        "title": "Semantic categorization of Chinese eligibility criteria in clinical trials using machine learning methods"
      },
      {
        "id": "285831411cfb23f9d3cd8956e6bba000189f85af",
        "title": "Artificial Intelligence in the fight against Covid-19"
      },
      {
        "id": "6fb369c5776cc17273ff74f46c641000e51dca2e",
        "title": "Discriminative Self-training for Punctuation Prediction"
      },
      {
        "id": "ba900412ab47fd890e69bfa7e909d34ae476b870",
        "title": "Exploring Transformers in Natural Language Generation: GPT, BERT, and XLNet"
      },
      {
        "id": "111dbe14083359ab39886790632e7f1421732a8a",
        "title": "Lattice-BERT: Leveraging Multi-Granularity Representations in Chinese Pre-trained Language Models"
      },
      {
        "id": "a07ff593c396078ee91e797d6f03a8c0517a401c",
        "title": "Generating novel protein sequences using Gibbs sampling of masked language models"
      },
      {
        "id": "71a7ba06ef16fa00d1e5638f4231957f2a90c1ef",
        "title": "Research Review for Broad Learning System: Algorithms, Theory, and Applications"
      },
      {
        "id": "065c51b1d5306788a5ecf88c949210b1ba1369d0",
        "title": "Empirical Studies of Institutional Federated Learning For Natural Language Processing"
      },
      {
        "id": "a2c44f0b729740c5e0aadff833f8031919cf75a8",
        "title": "A Study of Pre-trained Language Models in Natural Language Processing"
      },
      {
        "id": "09bfe057c9285577242636950c6835b8731a07fb",
        "title": "Multi-task learning for natural language processing in the 2020s: where are we going?"
      },
      {
        "id": "c8ca3ec06368092f972ef8bb0b0ef089d9341fab",
        "title": "Natural Language Processing of Reddit Data to Evaluate Dermatology Patient Experiences and Therapeutics."
      },
      {
        "id": "db065dfb401c6af22e59145db8414ef20ed46052",
        "title": "Towards the Natural Language Processing as Spelling Correction for Offline Handwritten Text Recognition Systems"
      },
      {
        "id": "2bc77cdfa44bdea93cee56f8a4eaae60ddc195e1",
        "title": "An Analysis of Natural Language Inference Benchmarks through the Lens of Negation"
      },
      {
        "id": "ca9b4fc03ad3ea4680ab2204ecf215f333c616a4",
        "title": "ProtTrans: Towards Cracking the Language of Life’s Code Through Self-Supervised Deep Learning and High Performance Computing"
      },
      {
        "id": "df0498605d5131098237e37914b402b67fea3936",
        "title": "FinBERT: A Pre-trained Financial Language Representation Model for Financial Text Mining"
      },
      {
        "id": "b1e6aa78db5478be5eaa47697382241c2b7aab1f",
        "title": "Multi-Task Learning for Knowledge Graph Completion with Pre-trained Language Models"
      },
      {
        "id": "5fe78eb0f142902237df11cb67c455787a759172",
        "title": "GLGE: A New General Language Generation Evaluation Benchmark"
      },
      {
        "id": "59c0076b3d814588e320820b95563965733d1875",
        "title": "AMBERT: A Pre-trained Language Model with Multi-Grained Tokenization"
      },
      {
        "id": "b0b06553abaccdbefdcfb447b3bf34308d93f04d",
        "title": "CURETO: Skin Diseases Detection Using Image Processing And CNN"
      },
      {
        "id": "4b3ee579f82457421db9d75147571ab51f95cf6c",
        "title": "Artificial Intelligence in the Battle against Coronavirus (COVID-19): A Survey and Future Research Directions"
      },
      {
        "id": "54e267587f4493a6dc600724af03a70d35d3067d",
        "title": "Should You Fine-Tune BERT for Automated Essay Scoring?"
      },
      {
        "id": "b252328704c5a7d9cebd8e29b0210f3bc2f214a2",
        "title": "Sentiment Analysis for Software Engineering: How Far Can Pre-trained Transformer Models Go?"
      },
      {
        "id": "244a0d1ab812d5a69c2a3fe26a1686f379d650aa",
        "title": "A Survey of Active Learning for Text Classification using Deep Neural Networks"
      },
      {
        "id": "9e96657d76ce74173b658cf933b4bd74c13f8b8d",
        "title": "Jointly Masked Sequence-to-Sequence Model for Non-Autoregressive Neural Machine Translation"
      },
      {
        "id": "1f1ba4520e646ab27b2978a1d76f18c5e387ba7b",
        "title": "MQTransformer: Multi-Horizon Forecasts with Context Dependent and Feedback-Aware Attention"
      },
      {
        "id": "24c5242f71af8795021270f52030534e587dfc1e",
        "title": "Tensorized Embedding Layers"
      },
      {
        "id": "fae68ee703880a95afa9c2029822b904dd55f9ba",
        "title": "SHAP values for Explaining CNN-based Text Classification Models"
      },
      {
        "id": "96ab2549f608f433849455454271c7b8b63adc6b",
        "title": "Comparative Analysis of Different Transformer Based Architectures Used in Sentiment Analysis"
      },
      {
        "id": "4efce0678152d770d21f81c4bcb5f44793a02ee1",
        "title": "CORD19STS: COVID-19 Semantic Textual Similarity Dataset"
      },
      {
        "id": "c7c201d81538bf68ff373238597fd2991a0dca44",
        "title": "Profile Prediction: An Alignment-Based Pre-Training Task for Protein Sequence Models"
      },
      {
        "id": "e25dc08340655401a034a90bf091c1a185c422b6",
        "title": "Evaluating Pretrained Transformer-based Models on the Task of Fine-Grained Named Entity Recognition"
      },
      {
        "id": "ef46b392f470bd8dca1de5a49596f5557bfc59fb",
        "title": "Injecting Entity Types into Entity-Guided Text Generation"
      },
      {
        "id": "7868efef17b3879565f959cd9b3575e0fc584d97",
        "title": "Deep Learning Methods in Communication Systems: A Review"
      },
      {
        "id": "f6588e7577f97328a37d442802fd9985bafa1a2f",
        "title": "NUIG-Shubhanker@Dravidian-CodeMix- FIRE2020: Sentiment Analysis of Code-Mixed Dravidian text using XLNet"
      },
      {
        "id": "98b87b8ce5657398e058c58c305f84ed4f687991",
        "title": "Behavioral correlates of cortical semantic representations modeled by word vectors"
      },
      {
        "id": "2eb1e3be05c3680eb392d226cd53c7e94bc8ad6d",
        "title": "Towards Grounding of Formulae"
      },
      {
        "id": "ffbfce72f12aa0be619be5e49698c2657853409f",
        "title": "Natural Language Inference in Context - Investigating Contextual Reasoning over Long Texts"
      },
      {
        "id": "3250b43f23d67fe5fd3df1245daf0343da212d82",
        "title": "Improving Constituency Parsing with Span Attention"
      },
      {
        "id": "210cf704dddaa922e4eafe634dbabf707d6683bc",
        "title": "LIMIT-BERT : Linguistics Informed Multi-Task BERT"
      },
      {
        "id": "3bcb17559ce96eb20fa79af8194f4af0380d194a",
        "title": "Pre-trained models for natural language processing: A survey"
      },
      {
        "id": "d16ab5c19ed33a263b6412ac41a4ea1f068d254a",
        "title": "Revisiting Pre-Trained Models for Chinese Natural Language Processing"
      },
      {
        "id": "18318b10e7c2dd4ad292208f4399eb1d4dca5768",
        "title": "CLUE: A Chinese Language Understanding Evaluation Benchmark"
      },
      {
        "id": "f496dca10078a5a12b71da6524014122b0039dcf",
        "title": "SIFRank: A New Baseline for Unsupervised Keyphrase Extraction Based on Pre-Trained Language Model"
      },
      {
        "id": "7cf8510d5905bd8a63f1e098e05ab591d689e0fd",
        "title": "Are Pre-trained Language Models Aware of Phrases? Simple but Strong Baselines for Grammar Induction"
      },
      {
        "id": "ad21aa6e4e0d70ac093ff9071d6fb832507c8f47",
        "title": "Joint Modelling of Emotion and Abusive Language Detection"
      },
      {
        "id": "8b4a6937bad9f6d858a389423444084e229278d4",
        "title": "How recurrent networks implement contextual processing in sentiment analysis"
      },
      {
        "id": "14b65a86c82e38fce0eb3506e0d4084ad5cdb583",
        "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention"
      },
      {
        "id": "d462340eb5245cb9b1c2b4db8a03e72eb60693b1",
        "title": "Investigating the Effectiveness of Representations Based on Pretrained Transformer-based Language Models in Active Learning for Labelling Text Datasets"
      },
      {
        "id": "e092ecf56fcca38d0cd6fe9e1e6b11c380f6c286",
        "title": "A Survey on Contextual Embeddings"
      },
      {
        "id": "1657220981714a6c312b364dbb51d604521f894e",
        "title": "Generating Hierarchical Explanations on Text Classification via Feature Interaction Detection"
      },
      {
        "id": "168fc3525f7b97695a97b04e257ee9bd1e832acb",
        "title": "Memory Transformer"
      },
      {
        "id": "9b2b96adf4ec05b086037222a893fa778f83a985",
        "title": "A Cross-Task Analysis of Text Span Representations"
      },
      {
        "id": "39283c3d6262b24bd61c88038353f3ed0145b6e4",
        "title": "Self-Attention with Cross-Lingual Position Representation"
      },
      {
        "id": "956cc65a5fa297d9e38c5d1da910fa6de02bdf0c",
        "title": "CAiRE-COVID: A Question Answering and Multi-Document Summarization System for COVID-19 Research"
      },
      {
        "id": "576bf2c6b3ec95b6a0488ee4c64d5e6e90d8cf83",
        "title": "Math-word embedding in math search and semantic extraction"
      },
      {
        "id": "a002acfb4dbb5981dd40b363e5aeb75f241d1d17",
        "title": "QURIOUS: Question Generation Pretraining for Text Generation"
      },
      {
        "id": "31c21da64f5f416d0f6e5505debd13776f81e8d6",
        "title": "Task-Optimized Word Embeddings for Text Classification Representations"
      },
      {
        "id": "5e8fb5667e712caa9098f8c28c32ccb672dcfc6d",
        "title": "Comparing BERT and XLNet from the Perspective of Computational Characteristics"
      },
      {
        "id": "2e7a2736c83955ba7bd44d4cb1034b64aa6a3902",
        "title": "Analyzing the Surprising Variability in Word Embedding Stability Across Languages"
      },
      {
        "id": "0d38ca7f3b631e731d6275497cb0230b27610508",
        "title": "SDN2GO: An Integrated Deep Learning Model for Protein Function Prediction"
      },
      {
        "id": "0a110d4b6ed2eb2567d1fdfdc74ee6ec5e570156",
        "title": "An Empirical Evaluation of Multi-task Learning in Deep Neural Networks for Natural Language Processing"
      },
      {
        "id": "4d1316798f575b564d0bd3da96a8b02be760e21c",
        "title": "An Augmented Transformer Architecture for Natural Language Generation Tasks"
      },
      {
        "id": "0cd8ab37c3f6e3ec1e570dcb2f73fc0bc3a4f541",
        "title": "Modeling aspects of the language of life through transfer-learning protein sequences"
      },
      {
        "id": "c7fc1cac162c0e2a934704184c7554fd6b6253f0",
        "title": "Pretrained Encyclopedia: Weakly Supervised Knowledge-Pretrained Language Model"
      },
      {
        "id": "b85d339e49399966d629973c889e8edfca56517c",
        "title": "A Mutual Information Maximization Perspective of Language Representation Learning"
      },
      {
        "id": "ba01747d847a70419d992c7c40932ceb953d1da9",
        "title": "Language models and Automated Essay Scoring"
      },
      {
        "id": "3aa0c9b7725b47bafbe74f220d51f9121f450825",
        "title": "Quasi-compositional mapping from form to meaning: a neural network-based approach to capturing neural responses during human language comprehension"
      },
      {
        "id": "783888854a808e76e3d769967192afe74232cd48",
        "title": "ASU at TextGraphs 2019 Shared Task: Explanation ReGeneration using Language Models and Iterative Re-Ranking"
      },
      {
        "id": "bf703a692a39687563c82bcc623eb55d3fbfccee",
        "title": "Sentiment Analysis Using Autoregressive Language Modeling and Broad Learning System"
      },
      {
        "id": "eb606d9ce65139754232cee62f6ab77f3e0c665f",
        "title": "Leveraging Pre-trained Checkpoints for Sequence Generation Tasks"
      },
      {
        "id": "59a916cdc943f0282908e6f3fa0360f4c5fb78d0",
        "title": "Stabilizing Transformers for Reinforcement Learning"
      },
      {
        "id": "d6b414487787d0b6efd735a3236a690ad13aae70",
        "title": "TENER: Adapting Transformer Encoder for Named Entity Recognition"
      },
      {
        "id": "ca57cad707e340db0ea1168d2e1e925ec8b59387",
        "title": "Ouroboros: On Accelerating Training of Transformer-Based Language Models"
      },
      {
        "id": "ff0347fc260ed8e976ae748297d4653114c13d7c",
        "title": "A survey of word embeddings based on deep learning"
      },
      {
        "id": "4a4646a5ce6b57e369403e4efea1a2e4559fe9f1",
        "title": "What Would Elsa Do? Freezing Layers During Transformer Fine-Tuning"
      },
      {
        "id": "d22b6f9b2281c15b605c39210e0ca25e41f4efac",
        "title": "PrivFT: Private and Fast Text Classification With Homomorphic Encryption"
      },
      {
        "id": "ce1287c86f71ca6fa32337dbe12cf6cfbd99334f",
        "title": "Fast and Accurate Capitalization and Punctuation for Automatic Speech Recognition Using Transformer and Chunk Merging"
      },
      {
        "id": "4f8e1a4247ce06a15760fc2692c6849601d41b6f",
        "title": "Infusing Knowledge into the Textual Entailment Task Using Graph Convolutional Networks"
      },
      {
        "id": "d2a2a587f499fa787bce632cf56e8dd9ef7049ee",
        "title": "Towards Non-Toxic Landscapes: Automatic Toxic Comment Detection Using DNN"
      },
      {
        "id": "95f0cb99549cb59fbfa14ce4eb3c5279a8c0786b",
        "title": "Not Enough Data? Deep Learning to the Rescue!"
      },
      {
        "id": "2232d067d91e97cb0fa5f79c3987849f340a13b5",
        "title": "Scalable Attentive Sentence-Pair Modeling via Distilled Sentence Embedding"
      },
      {
        "id": "f1ebf9a5a4688931b2e78bf2590bd56c47ae19b5",
        "title": "UDSMProt: universal deep sequence models for protein classification"
      },
      {
        "id": "1c71771c701aadfd72c5866170a9f5d71464bb88",
        "title": "Unified Language Model Pre-training for Natural Language Understanding and Generation"
      },
      {
        "id": "62dc8ddb4907db4b889c5e93673d9b3c189d1f25",
        "title": "A Tensorized Transformer for Language Modeling"
      },
      {
        "id": "9d6e6cd09b2f47a74c41848563608367db3df363",
        "title": "A Survey on Neural Network Language Models"
      },
      {
        "id": "031e4e43aaffd7a479738dcea69a2d5be7957aa3",
        "title": "ERNIE: Enhanced Representation through Knowledge Integration"
      },
      {
        "id": "2c211f6ca5dbdca92a2091f07889f943d634ad7a",
        "title": "DEEPred: Automated Protein Function Prediction with Multi-task Feed-forward Deep Neural Networks"
      },
      {
        "id": "ed1262a5734425f5e24113b992e5a144cf400b51",
        "title": "Towards a Deep and Unified Understanding of Deep Neural Models in NLP"
      },
      {
        "id": "e7704f7ce8060b4461be57256d99c15ce38dbf52",
        "title": "PKUSEG: A Toolkit for Multi-Domain Chinese Word Segmentation"
      },
      {
        "id": "31e34e907264e2aef7c0239d22d64db8b54bd6cb",
        "title": "Reverse engineering recurrent networks for sentiment classification reveals line attractor dynamics"
      },
      {
        "id": "b386c3788aadc868e5d98c4ab9e2b55ef3fcdf7f",
        "title": "Sentiment-Aware Word Embedding for Emotion Classification"
      },
      {
        "id": "f876efb3f336c7fa782c63d7aaffb947e826bbc0",
        "title": "Leveraging Small Software Engineering Data Sets with Pre-Trained Neural Networks"
      }
    ],
    "7": [
      {
        "id": "0feea94f89d395436bf41bd10c797447eecbc128",
        "title": "Unsupervised Data Augmentation for Consistency Training"
      },
      {
        "id": "eeec016e6cb725efce680d8172c1fcaf58727a7e",
        "title": "Data Augmentation Approaches in Natural Language Processing: A Survey"
      },
      {
        "id": "2607dce6dcb9043ca9cae67e25e6a24411f08c0b",
        "title": "BERT, mBERT, or BiBERT? A Study on Contextualized Embeddings for Neural Machine Translation"
      },
      {
        "id": "1982899ca875375227be5c131249cf3107bb9560",
        "title": "Virtual Augmentation Supported Contrastive Learning of Sentence Representations"
      },
      {
        "id": "9fc493346c6673e9b1ded18580322b3e79032274",
        "title": "OVANA: An Approach to Analyze and Improve the Information Quality of Vulnerability Databases"
      },
      {
        "id": "ba53ea9e88486b8a0eda94e1cd84f6b0c33dffe9",
        "title": "SupCL-Seq: Supervised Contrastive Learning for Downstream Optimized Sequence Representations"
      },
      {
        "id": "bf5dd0f1c58d12d3216d6e6a9e5b2e00b2648120",
        "title": "Geographic context-aware text mining: enhance social media message classification for situational awareness by integrating spatial and temporal features"
      },
      {
        "id": "3bf21376726896f73554288121b8263382d3984f",
        "title": "Bi-directional Joint Neural Networks for Intent Classification and Slot Filling"
      },
      {
        "id": "00213d44e03dae916860c0512025b5f96c3ee231",
        "title": "Data augmentation in natural language processing: a novel text generation approach for long and short text classifiers"
      },
      {
        "id": "d29036946152bddf950fec7a08c2828a8a8f902e",
        "title": "Crossing the Conversational Chasm: A Primer on Natural Language Processing for Multilingual Task-Oriented Dialogue Systems"
      },
      {
        "id": "01730636fe12bd3c15597e9439aba9b0b27ac150",
        "title": "A Primer on Contrastive Pretraining in Language Processing: Methods, Lessons Learned, and Perspectives"
      },
      {
        "id": "c26759e6c701201af2f62f7ee4eb68742b5bf085",
        "title": "SimCSE: Simple Contrastive Learning of Sentence Embeddings"
      },
      {
        "id": "077c713bccd9d2c7fde68d4cbde06ab0f07a6855",
        "title": "ConSERT: A Contrastive Framework for Self-Supervised Sentence Representation Transfer"
      },
      {
        "id": "a2fd50aa4dff5e04ed8535d84550da8bff316208",
        "title": "Whitening Sentence Representations for Better Semantics and Faster Retrieval"
      },
      {
        "id": "1ec59b4fb52f7ba4e6f37313d46fd8327c36e254",
        "title": "A guided latent Dirichlet allocation approach to investigate real-time latent topics of Twitter data during Hurricane Laura"
      },
      {
        "id": "e9c3993535fa43af54481b62c7e0aa51c57aded7",
        "title": "Deep Neural Approaches to Relation Triplets Extraction: a Comprehensive Survey"
      },
      {
        "id": "ab151c1ca0479b677003ef200018b93e983aa0ec",
        "title": "Learning to Remove: Towards Isotropic Pre-trained BERT Embedding"
      },
      {
        "id": "c8b35d9b54d517c3304b86ef78211934c8443b47",
        "title": "A Neural Few-Shot Text Classification Reality Check"
      },
      {
        "id": "0689ff6e4027b06d7350b0c674286b5d1b2b557e",
        "title": "Predicting Frequently Asked Questions (FAQs) on the COVID-19 Chatbot using the DIET Classifier"
      },
      {
        "id": "455cdafd55a5b5ddefa029bf97801327e142646d",
        "title": "A Survey on Recent Approaches for Natural Language Processing in Low-Resource Scenarios"
      },
      {
        "id": "02f3c052a9cf675a6f033eac56c9dacb0a10ea28",
        "title": "A Survey on Contrastive Self-supervised Learning"
      },
      {
        "id": "8edf070ee55db69f06b43fb46b055182837598f7",
        "title": "On the Sentence Embeddings from BERT for Semantic Textual Similarity"
      },
      {
        "id": "20033971c228a982513cd2f8fe454288de481d5f",
        "title": "Contrastive Triple Extraction with Generative Transformer"
      },
      {
        "id": "54cbabd7bbe22eb56ccb87a0d0e190eb689fc984",
        "title": "A Survey of Deep Learning Approaches for OCR and Document Understanding"
      },
      {
        "id": "7d96eaaa71a9556ab3b0c04c691af0b27b769d03",
        "title": "HateGAN: Adversarial Generative-Based Data Augmentation for Hate Speech Detection"
      },
      {
        "id": "3e8420d1bebb3f93d285da2de801d2e43b290880",
        "title": "Adaptive Self-training for Few-shot Neural Sequence Labeling"
      },
      {
        "id": "a11d58fe8436f360ef43716b05a33bdadd5c695a",
        "title": "OpenUE: An Open Toolkit of Universal Extraction from Text"
      },
      {
        "id": "eb2f1480eca6195fe8dbab5de8bbac8749e9be58",
        "title": "RODA: Reverse Operation Based Data Augmentation for Solving Math Word Problems"
      },
      {
        "id": "885275636fcde952a41f5272af72bc956b106f3d",
        "title": "Text Data Augmentation: Towards better detection of spear-phishing emails"
      },
      {
        "id": "deb5dcb8d09213837b2b87008585783e73302c42",
        "title": "Sequence Generation with Mixed Representations"
      },
      {
        "id": "61ca814207fe4cce027f9b07ac38b782dc5b29e7",
        "title": "Intent Classification and Slot Filling for Turkish Dialogue Systems"
      },
      {
        "id": "5a11bd4e678fcb05cb8f5d30c45877fb58bdd3b3",
        "title": "A Simple but Tough-to-Beat Data Augmentation Approach for Natural Language Understanding and Generation"
      },
      {
        "id": "7fed15cc79332f83b7bfe920c02a9c954322ddcc",
        "title": "Improving Neural Language Generation with Spectrum Control"
      },
      {
        "id": "32d281a1e7a0a2d4e2b3f34e0f71780c987e1374",
        "title": "DeCLUTR: Deep Contrastive Learning for Unsupervised Textual Representations"
      },
      {
        "id": "40c1847ae9a1d4305bb6dc72e51d083a9fdf3ff9",
        "title": "Multi-branch Attentive Transformer"
      },
      {
        "id": "b46194ac5696379cfa920ff08cda8d7c4cb6579c",
        "title": "Augment to Prevent: Short-Text Data Augmentation in Deep Learning for Hate-Speech Classification"
      },
      {
        "id": "2c1c847bfb4f8558f899e41e6b1c8bb521673289",
        "title": "Using error decay prediction to overcome practical issues of deep active learning for named entity recognition"
      },
      {
        "id": "533e72f1772a986901b1098e975ab23af64a17d7",
        "title": "A Conversational User Interface for Stock Analysis"
      },
      {
        "id": "96f2a288295f581b0077fa2db89c6c6c46d293c3",
        "title": "Incrementalizing RASA's Open-Source Natural Language Understanding Pipeline"
      },
      {
        "id": "7eba731a7fd8de712b7b79b5af41a6e2d4dbd191",
        "title": "Do Not Have Enough Data? Deep Learning to the Rescue!"
      },
      {
        "id": "64f94eb97891ca17273464fcb9c507c5a5c7dba7",
        "title": "Acquiring Knowledge from Pre-trained Model to Neural Machine Translation"
      },
      {
        "id": "d3952c122d4f3787718707305435b761c6c441a5",
        "title": "Identifying disaster-related tweets and their semantic, spatial and temporal context using deep learning, natural language processing and spatial analysis: a case study of Hurricane Irma"
      },
      {
        "id": "476029ac9be26bf7f121a388f5c1e45d204efe52",
        "title": "BERT for Joint Intent Classification and Slot Filling"
      },
      {
        "id": "f2944e3c0fe4908afeb421fff3bc8965c44b6aae",
        "title": "Descriptive and visual summaries of disaster events using artificial intelligence techniques: case studies of Hurricanes Harvey, Irma, and Maria"
      },
      {
        "id": "9f1e350a97a4f5f3809c350be6db3e75f0bebf43",
        "title": "Benchmarking Natural Language Understanding Services for building Conversational Agents"
      }
    ],
    "5": [
      {
        "id": "11907f691e9b7fc32a492e1de676a4b788add155",
        "title": "On the Validity of Pre-Trained Transformers for Natural Language Processing in the Software Engineering Domain"
      },
      {
        "id": "dc1402d05c6a18843d1fc6b31f1bd4fcdaa8ad30",
        "title": "Benchmarking for biomedical natural language processing tasks with a domain specific ALBERT"
      },
      {
        "id": "caf3df05598d26698c700d57fd044c0bcd34a0d6",
        "title": "Neural Natural Language Processing for Unstructured Data in Electronic Health Records: a Review"
      },
      {
        "id": "a9c5e23c5559bfc4d95dd166c1ed29fa026bbf2e",
        "title": "Fine-tuning large neural language models for biomedical natural language processing"
      },
      {
        "id": "388bdd6aa76d719a617fa32f8c733b4d73abc6d8",
        "title": "Developing a Natural Language Processing tool to identify perinatal self-harm in electronic healthcare records"
      },
      {
        "id": "ae31edefdfd8b964625568f9c56d3f9c692b4ea4",
        "title": "Developing A Deep Learning Natural Language Processing Algorithm For Automated Reporting Of Adverse Drug Reactions"
      },
      {
        "id": "c9f16be20afd5424f1e31077d130a5f8e2648e77",
        "title": "Automated Identification and Measurement Extraction of Pancreatic Cystic Lesions from Free-Text Radiology Reports Using Natural Language Processing."
      },
      {
        "id": "5572fd371a3ac287fb0d68f90f4a3f8574c9547b",
        "title": "Listening to Mental Health Crisis Needs at Scale: Using Natural Language Processing to Understand and Evaluate a Mental Health Crisis Text Messaging Service"
      },
      {
        "id": "b0c59e65ea6d4eb7a9dec5a01d4df8f4d449285f",
        "title": "Keyword Extraction Algorithm for Classifying Smoking Status from Unstructured Bilingual Electronic Health Records Based on Natural Language Processing"
      },
      {
        "id": "d639c05ac81060554b26c1ebbbff73641a077da3",
        "title": "Machine learning‐enabled multitrust audit of stroke comorbidities using natural language processing"
      },
      {
        "id": "b146be9e80c66a6e062a1525693311fac65ae19e",
        "title": "MatSciBERT: A materials domain language model for text mining and information extraction"
      },
      {
        "id": "b15469d0ab3dc3a9dec037d761817b3fe546bed6",
        "title": "Pre-trained Language Models in Biomedical Domain: A Systematic Survey"
      },
      {
        "id": "4c5f4ddc68be643fb34ea969bf2c105ff7538995",
        "title": "Can Language Models be Biomedical Knowledge Bases?"
      },
      {
        "id": "ae9e743c6ca4ac7e33c72cf140c69aa434eb3b19",
        "title": "RoBERTuito: a pre-trained language model for social media text in Spanish"
      },
      {
        "id": "cee993b4bbfe23d47be828bf7887a882975a1c98",
        "title": "Building astroBERT, a language model for Astronomy & Astrophysics"
      },
      {
        "id": "a01d7465a1361f44787c36f8f4c80ef4f1e44853",
        "title": "Deep learning with language models improves named entity recognition for PharmaCoNER"
      },
      {
        "id": "5aaeb50d8051890e9fbb9b9b8f34d9f3f2d85c1a",
        "title": "Recent advances and applications of deep learning methods in materials science"
      },
      {
        "id": "2fe1c8221dd90ad8655d4b518f9c10420cc6ed55",
        "title": "Balancing Methods for Multi-label Text Classification with Long-Tailed Class Distribution"
      },
      {
        "id": "ad17316915298103c59f2ce5bc97001dd9611409",
        "title": "Clinical Trial Information Extraction with BERT"
      },
      {
        "id": "08efb9803c035df9e60617bc6ff9e571ecc60e76",
        "title": "Deep learning-based NLP data pipeline for EHR-scanned document information extraction"
      },
      {
        "id": "25f102a11fbfa6663d56664ac87ad789ce7bd3c4",
        "title": "Comparison of Pretraining Models and Strategies for Health-Related Social Media Text Classification"
      },
      {
        "id": "e8761be78e9222495c63e54ae386b7ea023c72be",
        "title": "Supporting Complaints Investigation for Nursing and Midwifery Regulatory Agencies"
      },
      {
        "id": "0293c0ab2871f42e46a3a2e9e77196ad544326ff",
        "title": "The Unreasonable Effectiveness of the Baseline: Discussing SVMs in Legal Text Classification"
      },
      {
        "id": "6456edc602f038bc4922f1314485d4a625e5d8b3",
        "title": "CyBERT: Contextualized Embeddings for the Cybersecurity Domain"
      },
      {
        "id": "879eaab2275a364549809560b42f0fef357ebbce",
        "title": "BERT: A Review of Applications in Natural Language Processing and Understanding"
      },
      {
        "id": "059524838ac1db807ecf3ec4145e69d9b9976ee4",
        "title": "A natural language processing approach for identifying temporal disease onset information from mental healthcare text"
      },
      {
        "id": "a72ade0fd6c83a9b26b3c60bf15670bb5c9c50ed",
        "title": "Cohort Design and Natural Language Processing to Reduce Bias in Electronic Health Records Research: The Community Care Cohort Project"
      },
      {
        "id": "76f3d302537f3a46167472d9ffaaac0c7fe9fbee",
        "title": "Looking through glass: Knowledge discovery from materials science literature using natural language processing"
      },
      {
        "id": "0c23ee8a8c69ff208b9530e659dd9ad784e5fe1b",
        "title": "Automatic Classification of Thyroid Findings Using Static and Contextualized Ensemble Natural Language Processing Systems: Development Study"
      },
      {
        "id": "10175b9bea1f16dce439200da93f6ab3c76e1a86",
        "title": "A survey on extremism analysis using Natural Language Processing"
      },
      {
        "id": "e451e1717a8fd4238b7d36e06da478d2d3333f1a",
        "title": "ChEMU 2020: Natural Language Processing Methods Are Effective for Information Extraction From Chemical Patents"
      },
      {
        "id": "fae9a0d669d808f8321469aa1bdb64d96fb05145",
        "title": "Natural Language Processing-Based Quantification of the Mental State of Psychiatric Patients"
      },
      {
        "id": "58fe64beb45b18f63cbc001849a0dee3e4e60482",
        "title": "Improving Biomedical Pretrained Language Models with Knowledge"
      },
      {
        "id": "1991ea2ec85113cadf38faea840f4b5cf73ae0c7",
        "title": "ELECTRAMed: a new pre-trained language representation model for biomedical NLP"
      },
      {
        "id": "0b24f27d920bd1d23c8f6a1ab2b603c5c14f0a36",
        "title": "Deep Learning applications for COVID-19"
      },
      {
        "id": "ef03f3910685dda98279aa2bcefbeada3362a626",
        "title": "When does pretraining help?: assessing self-supervised learning for law and the CaseHOLD dataset of 53,000+ legal holdings"
      },
      {
        "id": "a0f788f6de0fb83d623c875a98120e3f347f70d1",
        "title": "Biomedical and clinical English model packages for the Stanza Python NLP library"
      },
      {
        "id": "474c63c4238e830ae395cad69bb4533e69731ff3",
        "title": "Limitations of Transformers on Clinical Text Classification"
      },
      {
        "id": "9eea59c34f139f3d2153226c8cf026e975622074",
        "title": "Memorization vs. Generalization : Quantifying Data Leakage in NLP Performance Evaluation"
      },
      {
        "id": "1dd525b5af40e613ae1665cf15a193b5ef23431b",
        "title": "Improving BERT Model Using Contrastive Learning for Biomedical Relation Extraction"
      },
      {
        "id": "e46bb3b5568c563ca19dc3ad9192850f3875a6ad",
        "title": "Text and Dynamic Network Analysis for Measuring Technological Convergence: A Case Study on Defense Patent Data"
      },
      {
        "id": "9802a49ed454751f6dc6d1097b384516443d5ee9",
        "title": "Uncovering interpretable potential confounders in electronic medical records"
      },
      {
        "id": "9d312b231b42c6fe4ff4259a86b28da3d5cb2d86",
        "title": "A method Based on an Attention Mechanism to Measure the Similarity of two Sentences"
      },
      {
        "id": "4a9a9eda87ad3bea27346ab61686daaa7cacdc4b",
        "title": "On the Use of Parsing for Named Entity Recognition"
      },
      {
        "id": "a38010318f08d86ae93f0593039c27feececb9f8",
        "title": "Benchmarking Effectiveness and Efficiency of Deep Learning Models for Semantic Textual Similarity in the Clinical Domain: Validation Study"
      },
      {
        "id": "32c47bf9a459cb7d4a45227b04c835488f143d8f",
        "title": "NaijaNER : Comprehensive Named Entity Recognition for 5 Nigerian Languages"
      },
      {
        "id": "44a422a2514c1cd6828423b5edce53d0dbdabd73",
        "title": "Structure-inducing pre-training"
      },
      {
        "id": "b668738dde6c770a19f6f7441dd1748d82032d48",
        "title": "RadGraph: Extracting Clinical Entities and Relations from Radiology Reports"
      },
      {
        "id": "a2f38d03fd363e920494ad65a5f0ad8bd18cd60b",
        "title": "Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing"
      },
      {
        "id": "f12051f407cd7da491ae5c965d6b03500450fa50",
        "title": "UMLS-based data augmentation for natural language processing of clinical research literature"
      },
      {
        "id": "e8f4b7de50f3f3ea50eb5ab362923ab2dc1d5c1e",
        "title": "Multi-domain Clinical Natural Language Processing with MedCAT: the Medical Concept Annotation Toolkit"
      },
      {
        "id": "8487a7dd9321a6cb2aae16451ace766d89a125ee",
        "title": "Advanced natural language processing technique to predict patient disposition based on emergency triage notes"
      },
      {
        "id": "3fe561abcd974917d7d22f235c59bb9dd7ea0593",
        "title": "Natural language processing to identify the creation and impact of new technologies in patent text: Code, data, and new measures"
      },
      {
        "id": "b81e0154125e5865ce026e73c59c36564ed50f5d",
        "title": "Applied natural language processing in mental health big data"
      },
      {
        "id": "2d6896c04dcdb2a862f0a5f025338e86b5a64e5a",
        "title": "Validation of deep learning natural language processing algorithm for keyword extraction from pathology reports in electronic health records"
      },
      {
        "id": "581e386b5971429cb60d3594076dc365c7a54827",
        "title": "Extracting Family History Information From Electronic Health Records: Natural Language Processing Analysis"
      },
      {
        "id": "22735a48750b1f3de43b53d44c94d8642d19d103",
        "title": "Sentence, Phrase, and Triple Annotations to Build a Knowledge Graph of Natural Language Processing Contributions—A Trial Dataset"
      },
      {
        "id": "03935e520c612ac9f137d9e9ef388e0c08568b60",
        "title": "UmlsBERT: Clinical Domain Knowledge Augmentation of Contextual Embeddings Using the Unified Medical Language System Metathesaurus"
      },
      {
        "id": "f2861a7c7155c50e2efab3bdec1a491a1b786b03",
        "title": "BioALBERT: A Simple and Effective Pre-trained Language Model for Biomedical Named Entity Recognition"
      },
      {
        "id": "54b804fd5511a431bbeb49accd21152296dcad67",
        "title": "E-BERT: A Phrase and Product Knowledge Enhanced Language Model for E-commerce"
      },
      {
        "id": "fc97c3f375c7228a1df7caa5c0ce5d2a6a171bd7",
        "title": "What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams"
      },
      {
        "id": "a2cf2dd164f0bae1f153aa0b38ba24a03fe05528",
        "title": "Exploit Multilingual Language Model at Scale for ICD-10 Clinical Text Classification"
      },
      {
        "id": "2d7425a74e82765f74d6a0cc2e40c530011e9bab",
        "title": "VNLawBERT: A Vietnamese Legal Answer Selection Approach Using BERT Language Model"
      },
      {
        "id": "23849edbce90489b29264367c855b7eb3e2275b5",
        "title": "An Empirical Investigation towards Efficient Multi-Domain Language Model Pre-training"
      },
      {
        "id": "79c27f8093679151ced8debc332473867d7d6a1e",
        "title": "Detecting ESG topics using domain-specific language models and data augmentation approaches"
      },
      {
        "id": "fc93fd5802598d8034056b94f53b6f76c32a3805",
        "title": "Named Entity Recognition and Relation Detection for Biomedical Information Extraction"
      },
      {
        "id": "b9868f59ed09866143261e43e7596d1c71326399",
        "title": "Clinical concept extraction using transformers"
      },
      {
        "id": "64bcfed67750fbf3b52c2b6b60d85f9413401561",
        "title": "A database of battery materials auto-generated using ChemDataExtractor"
      },
      {
        "id": "3186deef8c2aa3839b40c7f56b05807592cbe918",
        "title": "An Empirical Study on Large-Scale Multi-Label Text Classification Including Few and Zero-Shot Labels"
      },
      {
        "id": "06af86469540794522169e80361aff89d6d9535e",
        "title": "Summarizing Medical Conversations via Identifying Important Utterances"
      },
      {
        "id": "b2ff13555c3e9264e7d56644b659b9d201a270b0",
        "title": "Medical Information Extraction in the Age of Deep Learning"
      },
      {
        "id": "3d09912d7630b11dcb36af59eff64474ea281d80",
        "title": "The 2019 n2c2/OHNLP Track on Clinical Semantic Textual Similarity: Overview"
      },
      {
        "id": "930eaa5486f1e8a5947fa5d7ac48ecfa6f3c42ea",
        "title": "A comparative review on deep learning models for text classification"
      },
      {
        "id": "6b6e3ad8df96cd409e6798a65150cb5ba80a4c13",
        "title": "Inferring experimental procedures from text-based representations of chemical reactions"
      },
      {
        "id": "5eea6a9de39c41715e105f5943ac0fcb98fa245c",
        "title": "Enhancing Clinical BERT Embedding using a Biomedical Knowledge Base"
      },
      {
        "id": "8f786d6cdd4e65581a67ace176d0ead1658b5463",
        "title": "Multi-modal Multi-label Emotion Detection with Modality and Label Dependence"
      },
      {
        "id": "9390ff2d6d530396b318bc7aa1035d90ec79b4da",
        "title": "Automatic ICD-10 Coding and Training System: Deep Neural Network Based on Supervised Learning"
      },
      {
        "id": "16cca900a850eee1b832937281bb08c84beb86ff",
        "title": "Identification of Semantically Similar Sentences in Clinical Notes: Iterative Intermediate Training Using Multi-Task Learning"
      },
      {
        "id": "e29b1fe2f592115322365e7c6ffa5b23d0d0aecc",
        "title": "Biomedical Named-Entity Recognition by Hierarchically Fusing BioBERT Representations and Deep Contextual-Level Word-Embedding"
      },
      {
        "id": "63afca040c4cc4aecb9cac5c7c7358e1b0d599d7",
        "title": "Predicting Semantic Similarity Between Clinical Sentence Pairs Using Transformer Models: Evaluation and Representational Analysis"
      },
      {
        "id": "cb6deacd399fb335f89d4308adbec3bab11d1e30",
        "title": "Text classification based on gated recurrent unit combines with support vector machine"
      },
      {
        "id": "70b0c85638d195dbde56cbedc94ae4363b272b58",
        "title": "A Pre-Training Technique to Localize Medical BERT and to Enhance Biomedical BERT"
      },
      {
        "id": "8f2be495f8d4be177d3fa4f90ceac39772235862",
        "title": "Hierarchical Bi-Directional Self-Attention Networks for Paper Review Rating Recommendation"
      },
      {
        "id": "5fd5f0a146ca7c558dcea505e07c12a5d3dedfa0",
        "title": "COVID-SEE: Scientific Evidence Explorer for COVID-19 Related Research"
      },
      {
        "id": "3e83d34b61584df960d900290a9b5038968817c1",
        "title": "Assessment of DistilBERT performance on Named Entity Recognition task for the detection of Protected Health Information and medical concepts"
      },
      {
        "id": "a50aaa6eab310470cde1ffe10b8c27b93cc27d13",
        "title": "Topic-Centric Unsupervised Multi-Document Summarization of Scientific and News Articles"
      },
      {
        "id": "c4ce6aca9aed41d57d588674484932e0c2cd3547",
        "title": "Extracting a Knowledge Base of Mechanisms from COVID-19 Papers"
      },
      {
        "id": "126fb7df6bcab2b70000dfe5b940ada63ae1ba6a",
        "title": "COVID-Twitter-BERT: A natural language processing model to analyse COVID-19 content on Twitter"
      },
      {
        "id": "77b91d7607518994d04f75119db4138b23e2eb87",
        "title": "Natural Language Processing Advancements By Deep Learning: A Survey"
      },
      {
        "id": "f8fe7acad3d38b05b3de94421b13a83e8ac0b93a",
        "title": "Generation and evaluation of artificial mental health records for Natural Language Processing"
      },
      {
        "id": "13f7f75be4d81af3cd4d886b5beab6660eeafba5",
        "title": "Prediction of general medical admission length of stay with natural language processing and deep learning: a pilot study"
      },
      {
        "id": "37710e4b0dd851bd0d9bc4994c3b32cb10279151",
        "title": "Calibrating Structured Output Predictors for Natural Language Processing"
      },
      {
        "id": "654e2c9b5c1602e5fb0b746a25cd5b3e29063332",
        "title": "NLPContributions: An Annotation Scheme for Machine Reading of Scholarly Contributions in Natural Language Processing Literature"
      },
      {
        "id": "646b844f8e563d6813c3c4aeb8d121bb154b253f",
        "title": "Multi-label natural language processing to identify diagnosis and procedure codes from MIMIC-III inpatient notes"
      },
      {
        "id": "2080d30261ab4b13d66349fcfdf6c84d2f307c58",
        "title": "Improving Emergency Department ESI Acuity Assignment Using Machine Learning and Clinical Natural Language Processing"
      },
      {
        "id": "cecfdcb28735860b791060b865bc762849911da0",
        "title": "Risk of mortality and cardiopulmonary arrest in critical patients presenting to the emergency department using machine learning and natural language processing"
      },
      {
        "id": "a3e4ceb42cbcd2c807d53aff90a8cb1f5ee3f031",
        "title": "SPECTER: Document-level Representation Learning using Citation-informed Transformers"
      },
      {
        "id": "5d4de0fa45aeddc31142e6a24666d06ed7923f1e",
        "title": "Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction"
      },
      {
        "id": "11342d45911ee8a7c9e3a94117ce774ad7036172",
        "title": "Neural Unsupervised Domain Adaptation in NLP—A Survey"
      },
      {
        "id": "02809fc23aecf33e3ed95b83d1d03b54fb5c3d0a",
        "title": "An Empirical Study of Multi-Task Learning on BERT for Biomedical Text Mining"
      },
      {
        "id": "f4e7e312e1e2b462936534fd566fb4a16e0d29d2",
        "title": "Text classification models for the automatic detection of nonmedical prescription medication use from social media"
      },
      {
        "id": "5ec5f9629bc508f28334e13f0769c676399ac91f",
        "title": "Deidentification of free-text medical records using pre-trained bidirectional transformers"
      },
      {
        "id": "8b13e9ae5517731ad126a7b09f12d5d5a8e0d0ab",
        "title": "A multi-perspective analysis of retractions in life sciences"
      },
      {
        "id": "f005a6f34972ce4364cc1bb85a77cfce854bcda0",
        "title": "Application of Machine Learning and Word Embeddings in the Classification of Cancer Diagnosis Using Patient Anamnesis"
      },
      {
        "id": "0b09edd6be4e55167f055c00def29e6b221d8ee6",
        "title": "Federated pretraining and fine tuning of BERT using clinical notes from multiple silos"
      },
      {
        "id": "4c1111aadf4452f40268df582cfad1334c526841",
        "title": "Distributed representation and one-hot representation fusion with gated network for clinical semantic textual similarity"
      },
      {
        "id": "1296715c88e599f61d94ffdc646d552a3daddc38",
        "title": "Comparison of rule-based and neural network models for negation detection in radiology reports"
      },
      {
        "id": "6618ea725149ec5b7ee0a988f22b49caf440140e",
        "title": "Artificial-intelligence tools aim to tame the coronavirus literature"
      },
      {
        "id": "3656b82b68566d664c644bd52cbe471c5070288e",
        "title": "MedLinker: Medical Entity Linking with Neural Representations and Dictionary Matching"
      },
      {
        "id": "53f84cb7ca66073169c5e34b3732e757586a113f",
        "title": "Fully-connected LSTM–CRF on medical concept extraction"
      },
      {
        "id": "a2d2a482ccd62a705c8fafeb5f93bca33a4d796d",
        "title": "Deep learning in clinical natural language processing: a methodical review"
      },
      {
        "id": "4046c644025e10bdcc20a45b48965b91acc35390",
        "title": "Use of Natural Language Processing to Extract Clinical Cancer Phenotypes from Electronic Medical Records."
      },
      {
        "id": "3f272a4f39355933dcbc25e8cad4fdf235fc35e2",
        "title": "Natural language processing of MIMIC-III clinical notes for identifying diagnosis and procedures with neural networks"
      },
      {
        "id": "4e561318668f0ae190217ffe82bf44c9c33b9c0d",
        "title": "Transformers: State-of-the-Art Natural Language Processing"
      },
      {
        "id": "b81067d5dbea3c1343a20b407958258b60c251af",
        "title": "Women in ISIS Propaganda: A Natural Language Processing Analysis of Topics and Emotions in a Comparison with Mainstream Religious Group"
      },
      {
        "id": "222b9a7b8038120671a1610e857d3edbc7ac5550",
        "title": "Mixout: Effective Regularization to Finetune Large-scale Pretrained Language Models"
      },
      {
        "id": "3c44813030602b79a69c4a4d7c9a952f82d339b8",
        "title": "Efficient processing of GRU based on word embedding for text classification"
      },
      {
        "id": "23c26e6ed3de8ec90fbffb3f4c90f8d24432682a",
        "title": "End-to-end Named Entity Recognition and Relation Extraction using Pre-trained Language Models"
      },
      {
        "id": "45118de829e4cf8dd59937b2165c88988a86b30c",
        "title": "Healthcare NER Models Using Language Model Pretraining"
      },
      {
        "id": "ac0f9bd6d00644215515be42d203f59945a41107",
        "title": "Text-mined dataset of inorganic materials synthesis recipes"
      },
      {
        "id": "c33b69855e03958f1d9d3cff7abd2eb2184ecd52",
        "title": "Fine-Tuning Bidirectional Encoder Representations From Transformers (BERT)–Based Models on Large-Scale Electronic Health Record Notes: An Empirical Study"
      },
      {
        "id": "fd83bfb69b874509a964d9984061fdd6c1634fe6",
        "title": "Automated extraction of chemical synthesis actions from experimental procedures"
      },
      {
        "id": "105905e42812a88b5060e6f45805aa7889e6218c",
        "title": "Learning to Learn and Predict: A Meta-Learning Approach for Multi-Label Classification"
      },
      {
        "id": "9c800a101fdbc95d76494e74cfec4f533bc1adab",
        "title": "Enhancing Dialogue Symptom Diagnosis with Global Attention and Symptom Graph"
      },
      {
        "id": "53578863c843a71e6b2ca6ff4b9da02bee4b6dff",
        "title": "Identifying relations of medications with adverse drug events using recurrent convolutional neural networks and gradient boosting"
      },
      {
        "id": "0439f8c9b686bd83d1e8641025b1959ffe2e6d9f",
        "title": "Family history information extraction via deep joint learning"
      },
      {
        "id": "9d05dde42df429a6e09310bc5fe65433bff90261",
        "title": "BioRelEx 1.0: Biological Relation Extraction Benchmark"
      },
      {
        "id": "cd077f26767eba20c36c54a4dea96fb3b25dd9c7",
        "title": "Learning Conceptual-Contextual Embeddings for Medical Text"
      },
      {
        "id": "6bb20fe9099fbee39df252fbff1289d0a8ec3cf2",
        "title": "Complaint Analysis and Classification for Economic and Food Safety"
      },
      {
        "id": "c6a220226b8bdb5539f2b5496c00821d0353f9cb",
        "title": "Automatic Identification of Economic Activities in Complaints"
      },
      {
        "id": "e9ea42bdf19144c54c6531e60288df43f4866336",
        "title": "BAS: An Answer Selection Method Using BERT Language Model"
      },
      {
        "id": "de28ec1d7bd38c8fc4e8ac59b6133800818b4e29",
        "title": "ScispaCy: Fast and Robust Models for Biomedical Natural Language Processing"
      },
      {
        "id": "347bac45298f37cd83c3e79d99b826dc65a70c46",
        "title": "Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets"
      },
      {
        "id": "454f204abc72354dd3405beda8098309f5424f88",
        "title": "Overview of the First Natural Language Processing Challenge for Extracting Medication, Indication, and Adverse Drug Events from Electronic Health Record Notes (MADE 1.0)"
      },
      {
        "id": "cf5aff3412455a23abbac02bf0d02e7383a6873c",
        "title": "Using natural language processing to construct a metastatic breast cancer cohort from linked cancer registry and electronic medical records data"
      },
      {
        "id": "9fc8a8a9d54a8f598e98bbc52001af13a40007d9",
        "title": "Automated Detection of Measurements and Their Descriptors in Radiology Reports Using a Hybrid Natural Language Processing Algorithm"
      },
      {
        "id": "34899e393f491564799d9ad89fe97ecdd7e59a19",
        "title": "Natural language processing of lifestyle modification documentation"
      },
      {
        "id": "81e29a12f8e419b11624f7425dc375f7cbb6e823",
        "title": "Prediction of emergency department patient disposition based on natural language processing of triage notes"
      },
      {
        "id": "1e43c7084bdcb6b3102afaf301cce10faead2702",
        "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"
      },
      {
        "id": "156d217b0a911af97fa1b5a71dc909ccef7a8028",
        "title": "SciBERT: A Pretrained Language Model for Scientific Text"
      },
      {
        "id": "2a567ebd78939d0861d788f0fedff8d40ae62bf2",
        "title": "Publicly Available Clinical BERT Embeddings"
      },
      {
        "id": "06b36e744dca445863c9f9aefe76aea95ba95999",
        "title": "Enhancing Clinical Concept Extraction with Contextual Embedding"
      },
      {
        "id": "b81a7bee3ca63c3665a8ab55fe178ea521ba0477",
        "title": "MetaPred: Meta-Learning for Clinical Risk Prediction with Limited Patient Electronic Health Records"
      },
      {
        "id": "51112c6f69a4ad4bf67f9a44cba680e09cda65f0",
        "title": "Argument Mining for Understanding Peer Reviews"
      },
      {
        "id": "21cba8ba3d80b415cc66209077e3c6836f49eaab",
        "title": "A Compare-Aggregate Model with Latent Clustering for Answer Selection"
      },
      {
        "id": "3b681a0265a5f7fe6e009b93ac0d18425a9a4116",
        "title": "Detecting Adverse Drug Events with Rapidly Trained Classification Models"
      },
      {
        "id": "7f514191e205517cb802c61f060bc68c536d587c",
        "title": "Integrating shortest dependency path and sentence sequence into a deep learning framework for relation extraction in clinical text"
      },
      {
        "id": "7ad2a61efda2bcf81dad3e84e687669336b5868d",
        "title": "MADEx: A System for Detecting Medications, Adverse Drug Events, and Their Relations from Clinical Notes"
      },
      {
        "id": "3b1ac14467a3d0360b95e919a8b4c282423826ef",
        "title": "Import2vec: Learning Embeddings for Software Libraries"
      },
      {
        "id": "52f578ded219702d485357e75b92b2129ef341ad",
        "title": "Detection of Bleeding Events in Electronic Health Record Notes Using Convolutional Neural Network Models Enhanced With Recurrent Neural Network Autoencoders: Deep Learning Approach"
      },
      {
        "id": "33d0c192af20cf37fb0c91ea35e9e13974454c04",
        "title": "deepBioWSD: effective deep neural word sense disambiguation of biomedical text data"
      },
      {
        "id": "76fe678236f9a03cb46e9c3d35861dbf6cb46610",
        "title": "Using distant supervision to augment manually annotated data for relation extraction"
      },
      {
        "id": "52f7807fb6c987cda32cf3661e2d03f370f3097f",
        "title": "PharmacoNER Tagger: a deep learning-based tool for automatically finding chemicals and drugs in Spanish medical texts"
      },
      {
        "id": "e5fa5022e736ff3ce137f3b243ed9f8c87749a49",
        "title": "Deep Learning Approach for Receipt Recognition"
      },
      {
        "id": "86c8e5e2979377f87c7fdb2108497d074943d462",
        "title": "A question-entailment approach to question answering"
      }
    ],
    "9": [
      {
        "id": "0a1ff1d4102d94a50f8862f60bc2ac21f36ad592",
        "title": "ContractNLI: A Dataset for Document-level Natural Language Inference for Contracts"
      },
      {
        "id": "379e9d5bba8a617b3114bd5b562b14aa6abc5282",
        "title": "Natural SQL: Making SQL Easier to Infer from Natural Language Specifications"
      },
      {
        "id": "096618aba19bce1d917df488a04891ab239cffdd",
        "title": "Towards Natural Language Interfaces for Data Visualization: A Survey"
      },
      {
        "id": "98bb0a6a7944afe38dd2ac2505dd8057bb507577",
        "title": "nvBench: A Large-Scale Synthesized Dataset for Cross-Domain Natural Language to Visualization Task"
      },
      {
        "id": "294a3bbfaa5382c7b475ebd283aac7ad02e2d075",
        "title": "A Differentiable Language Model Adversarial Attack on Text Classifiers"
      },
      {
        "id": "2406b1ae0be691f235a824e5a366842c633665d1",
        "title": "Unifying Privacy Policy Detection"
      },
      {
        "id": "bdaa46edaf6596a3c67cd23d5f140d3ab0fb85e1",
        "title": "On the Difficulty of Translating Free-Order Case-Marking Languages"
      },
      {
        "id": "df2f4e150765ce15cd7956266d8d958b37676201",
        "title": "Natural Language to Visualization by Neural Machine Translation"
      },
      {
        "id": "82451ff3ac88da3c206f75abcbfe7389a4d89268",
        "title": "Talk2Data: A Natural Language Interface for Exploratory Visual Analysis via Question Decomposition"
      },
      {
        "id": "b53c386b7c65af80905dc05a9b27e98e03324739",
        "title": "Trankit: A Light-Weight Transformer-based Toolkit for Multilingual Natural Language Processing"
      },
      {
        "id": "70791eb3e2b87f361f8977eafd78f8d3e1b5affb",
        "title": "BNLP: Natural language processing toolkit for Bengali language"
      },
      {
        "id": "d64192da0b6d43c91c902105c089b18b76f9fe77",
        "title": "Dynamic Hybrid Relation Network for Cross-Domain Context-Dependent Semantic Parsing"
      },
      {
        "id": "8bf3a9ae1bda4465f66bc6bc22207737303372c9",
        "title": "D-BERT: Incorporating dependency-based attention into BERT for relation extraction"
      },
      {
        "id": "408032f4a72d58e6733140df571bafab5c1e334d",
        "title": "Cross-lingual alignments of ELMo contextual embeddings"
      },
      {
        "id": "9522f69a033fbd5ad200a775c983e05b5cab5e95",
        "title": "Gamified crowdsourcing for idiom corpora construction"
      },
      {
        "id": "8b20173b98914f36302389e4c761c334fe867dcd",
        "title": "Evaluating the Morphosyntactic Well-formedness of Generated Texts"
      },
      {
        "id": "c114db5f1c38cbe6797bc74ef98072cac71f6cc6",
        "title": "ShadowGNN: Graph Projection Neural Network for Text-to-SQL Parser"
      },
      {
        "id": "9d0130a8f9677311cdc7a1e353fe586afe2ccd58",
        "title": "Story Analysis Using Natural Language Processing and Interactive Dashboards"
      },
      {
        "id": "47a2723639bd29591472c64e3c47cbffad4eecdf",
        "title": "Extending Drag-and-Drop Actions-Based Model-to-Model Transformations with Natural Language Processing"
      },
      {
        "id": "5593676873d799a4727123a2cbffb231d3b4eb80",
        "title": "NL4DV: A Toolkit for Generating Analytic Specifications for Data Visualization from Natural Language Queries"
      },
      {
        "id": "a778f025f2bfdd628d622bff50dbccde7e3a7192",
        "title": "KLPT – Kurdish Language Processing Toolkit"
      },
      {
        "id": "40330055346d9ace82a8cdefd9d8cd757cf276d1",
        "title": "N-LTP: A Open-source Neural Chinese Language Technology Platform with Pretrained Models"
      },
      {
        "id": "4d1367141eb8210a981428f3a7fdbdbc9db3e248",
        "title": "A Tokenization System for the Kurdish Language"
      },
      {
        "id": "07eb06b8d8480f130cc28734b022cadcafe336d6",
        "title": "Privacy Policies over Time: Curation and Analysis of a Million-Document Dataset"
      },
      {
        "id": "c8752767677efc3a3514dc52a7ac1973b08fb774",
        "title": "Crosscast: Adding Visuals to Audio Travel Podcasts"
      },
      {
        "id": "d3acb7e3ed1156d9c876a5866435e3e7b0213a22",
        "title": "Leveraging Multilingual News Websites for Building a Kurdish Parallel Corpus"
      },
      {
        "id": "3888cc7d41469be1adba7f942606336539262860",
        "title": "Enhancing deep neural networks with morphological information"
      },
      {
        "id": "849a987959193eed1d0ca9303d2ee9c7359b011a",
        "title": "Tracking Interaction States for Multi-Turn Text-to-SQL Semantic Parsing"
      },
      {
        "id": "641a9749fe546a02bbab9a86bfc91492db1c3bc5",
        "title": "Stanza: A Python Natural Language Processing Toolkit for Many Human Languages"
      },
      {
        "id": "e52220473fe88febf6c2336c1cc8c1d1c05c6f13",
        "title": "Interweaving Multimodal Interaction With Flexible Unit Visualizations for Data Exploration"
      },
      {
        "id": "9d11d18c91aef64538156df205b1668af2821a2d",
        "title": "FlowSense: A Natural Language Interface for Visual Data Exploration within a Dataflow System"
      },
      {
        "id": "b43079ba3f115e6e17a77addb61ef27f9d04cba1",
        "title": "Semantic Relation Classification via Bidirectional LSTM Networks with Entity-aware Attention using Latent Entity Typing"
      },
      {
        "id": "360d05b60c0c8e86d191796e0774e7a7522294c3",
        "title": "White-to-Black: Efficient Distillation of Black-Box Adversarial Attacks"
      },
      {
        "id": "424906c3e4590f789027d1c773a7c929cef2630f",
        "title": "Cross-Lingual Word Embeddings"
      },
      {
        "id": "e24e44515b15e1326dd25ab092a152a067c63fc1",
        "title": "Word-order Biases in Deep-agent Emergent Communication"
      },
      {
        "id": "3c89068551a84430a0b1fdfeb8d963e2b2fc7ecc",
        "title": "Towards Complex Text-to-SQL in Cross-Domain Database with Intermediate Representation"
      }
    ],
    "10": [
      {
        "id": "f659031ceb7bbdcb7b0690742f35e2924fd1ed75",
        "title": "Towards Robustness Against Natural Language Word Substitutions"
      },
      {
        "id": "8b954e1654c6b759a957fd11e66c111e6105fb3f",
        "title": "CLINE: Contrastive Learning with Semantic Negative Examples for Natural Language Understanding"
      },
      {
        "id": "3b451fa663704f927e1ec602d7c0845a9826922d",
        "title": "Evaluating the Robustness of Neural Language Models to Input Perturbations"
      },
      {
        "id": "b60c7b63fdf9269734ffc8a55746c57b87c09fa6",
        "title": "Adversarial Attacks and Defenses for Social Network Text Processing Applications: Techniques, Challenges and Future Research Directions"
      },
      {
        "id": "efd9d88c9fff716340e6122d95db6d5219871331",
        "title": "Adversarial Robustness of Deep Code Comment Generation"
      },
      {
        "id": "023719b69c1722e35ad4d06e2efe130f630334f0",
        "title": "Simple Contrastive Representation Adversarial Learning for NLP Tasks"
      },
      {
        "id": "a4f533f2b7d77b667e1f05b210924ec7c90cc5d1",
        "title": "How Should Pre-Trained Language Models Be Fine-Tuned Towards Adversarial Robustness?"
      },
      {
        "id": "aa84beaf7d94f09e0fdcb899c7fbc97822050546",
        "title": "EditSum: A Retrieve-and-Edit Framework for Source Code Summarization"
      },
      {
        "id": "35bbb7e34f709384591ab822a353b4b664dd5c90",
        "title": "Token-modification adversarial attacks for natural language processing: A survey"
      },
      {
        "id": "cbc1e8bbfe98f94c0d13d111b824cf603b62712c",
        "title": "Bad Characters: Imperceptible NLP Attacks"
      },
      {
        "id": "0021b3beb2ee0906b425eef7c0f453623c1c6a03",
        "title": "Certified Robustness to Word Substitution Attack with Differential Privacy"
      },
      {
        "id": "546daf45b98dcaa1c7b438ec04b2a8b744f279d7",
        "title": "Certified Robustness to Programmable Transformations in LSTMs"
      },
      {
        "id": "2ef79342ff22661cd7bc18833049085e6b3501c4",
        "title": "Generating Natural Language Attacks in a Hard Label Black Box Setting"
      },
      {
        "id": "85b063ab7990c2a54ab2f009988cd1af4b84df6d",
        "title": "Adversarial Machine Learning in Wireless Communications Using RF Data: A Review"
      },
      {
        "id": "9b9a6d6a698cce777929ecc65c9fc5d09b2232ac",
        "title": "T3: Tree-Autoencoder Constrained Adversarial Text Generation for Targeted Attack"
      },
      {
        "id": "132b9d7908b527ef2b95670884482902163f345e",
        "title": "Enhancing scientific discoveries in molecular biology with deep generative models"
      },
      {
        "id": "adc9533f3d4c3b41b21c10a948a6118018df2a5a",
        "title": "Searching for a Search Method: Benchmarking Search Algorithms for Generating NLP Adversarial Examples"
      },
      {
        "id": "88338c58701f34503c7af77e34f19d9a5cd66313",
        "title": "Adversarial Attacks on Deep-learning Models in Natural Language Processing"
      },
      {
        "id": "bf9a8fb50aca26774ebf4815db2d8712e2c5830c",
        "title": "TextAttack: A Framework for Adversarial Attacks in Natural Language Processing"
      },
      {
        "id": "a58c97f8421ad97da4a08c8d45b8e355ab7de2ad",
        "title": "Defense against Adversarial Attacks in NLP via Dirichlet Neighborhood Ensemble"
      },
      {
        "id": "4916fce2cbfdd23ef46f962bf6fffca39379dc70",
        "title": "Defense of Word-level Adversarial Attacks via Random Substitution Encoding"
      },
      {
        "id": "07aef2a873fd79651766baddf0ccdfd5564f1b2d",
        "title": "Robustness to Programmable String Transformations via Augmented Abstract Training"
      },
      {
        "id": "b8216617cec1c7bb73e962773c4458d16cbf8700",
        "title": "Generating Adversarial Examples for Holding Robustness of Source Code Processing Models"
      },
      {
        "id": "bbcccb1dfacb6a20ae2eaf4a7778c064369d1c51",
        "title": "Natural Language Adversarial Attacks and Defenses in Word Level"
      },
      {
        "id": "7fa35ebeb6e7e4ed8706a9f41e9f53cfa4af2c77",
        "title": "Natural language adversarial defense through synonym encoding"
      },
      {
        "id": "afd975a296886e89722891ad13c8dba0d26b1ed2",
        "title": "Generating Fluent Adversarial Examples for Natural Languages"
      },
      {
        "id": "8c27a3b115609bb44e5c93a240152d748957bbc6",
        "title": "Speech-VGG: A deep feature extractor for speech processing"
      },
      {
        "id": "791ca7f9f3eb5c0914880711f109e7372fb05959",
        "title": "Deep learning: new computational modelling techniques for genomics"
      },
      {
        "id": "c0ef94be9067ec3ad492272bfe793c3d0ff484b5",
        "title": "Coverage-Guided Testing for Recurrent Neural Networks"
      },
      {
        "id": "46f2c91124681b9a2653249efc058453c476dd75",
        "title": "Robustness to Modification with Shared Words in Paraphrase Identification"
      },
      {
        "id": "e51454c75dc9224917ddea837829f6b0552cfbbb",
        "title": "DeepStellar: model-based quantitative analysis of stateful deep learning systems"
      },
      {
        "id": "652107ea8161f607e3bdabc89199e9ff2fdfd015",
        "title": "Adversarial Attacks on Deep Learning Models in Natural Language Processing: A Survey"
      },
      {
        "id": "3092325d55f6aa9ba28b0841bdcfd61991a38d48",
        "title": "A Neural Model for Generating Natural Language Summaries of Program Subroutines"
      }
    ]
  },
  "cluster_keywords": {
    "0": [
      "speech",
      "textual",
      "corpora",
      "texts",
      "assistant"
    ],
    "2": [
      "models",
      "multimodal",
      "captioning",
      "trained",
      "bias"
    ],
    "8": [
      "word",
      "fairness",
      "equalizing",
      "grammar",
      "debiasing"
    ],
    "3": [
      "reading",
      "task",
      "questions",
      "multilingual",
      "tasks"
    ],
    "1": [
      "distilling",
      "trained",
      "pretrained",
      "memory",
      "textual"
    ],
    "6": [
      "arabic",
      "french",
      "retrieval",
      "grading",
      "monolingual"
    ],
    "4": [
      "deep",
      "trained",
      "attention",
      "pretrained",
      "pretraining"
    ],
    "7": [
      "deep",
      "hurricane",
      "bert",
      "generative",
      "lessons"
    ],
    "5": [
      "clinical",
      "drug",
      "automated",
      "healthcare",
      "medication"
    ],
    "9": [
      "dataset",
      "visual",
      "exploratory",
      "nl4dv",
      "visualizations"
    ],
    "10": [
      "examples",
      "defense",
      "programmable",
      "attack",
      "extractor"
    ]
  }
}