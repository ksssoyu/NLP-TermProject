import pandas as pd
import numpy as np
import pickle
import networkx as nx
import random
import ast
from sklearn.metrics.pairwise import cosine_similarity
from tqdm import tqdm

# --------------------------
# 1. CSV ë¡œë“œ ë° ì„ë² ë”© íŒŒì‹±
# --------------------------
df = pd.read_csv("merged_nlp_papers_for_enrichment.csv")

# ì„ë² ë”© ë¬¸ìì—´ì„ ì•ˆì „í•˜ê²Œ ë¦¬ìŠ¤íŠ¸ë¡œ íŒŒì‹±
def parse_embedding(e_str):
    try:
        vec = ast.literal_eval(e_str)
        return np.array(vec) if isinstance(vec, list) else None
    except:
        return None

# ì„ë² ë”©ì´ ì¡´ì¬í•˜ëŠ” ë…¼ë¬¸ë§Œ í•„í„°ë§
df = df[df["embedding"].notna()].copy()
df["parsed_embedding"] = df["embedding"].apply(parse_embedding)
df = df[df["parsed_embedding"].notnull()]

print(f"âœ… ìœ íš¨í•œ ì„ë² ë”© ìˆ˜: {len(df)}")

# --------------------------
# 2. ê·¸ë˜í”„ ë¡œë“œ
# --------------------------
with open("nlp_similarity_graph_with_cluster.gpickle", "rb") as f:
    G = pickle.load(f)
graph_node_set = set(G.nodes())
embedding_node_set = set(df["paperId"])
print("ğŸ“Œ ìƒ˜í”Œ ê·¸ë˜í”„ ë…¸ë“œ 10ê°œ:")
print(list(graph_node_set)[:10])
print(type(next(iter(graph_node_set))))
print(type(next(iter(embedding_node_set))))
print(f"ğŸ§© ê·¸ë˜í”„ ë…¸ë“œ ìˆ˜: {len(graph_node_set)}")
print(f"ğŸ§  ì„ë² ë”© ë³´ìœ  ë…¼ë¬¸ ìˆ˜: {len(embedding_node_set)}")
print(f"ğŸ”— êµì§‘í•© ìˆ˜: {len(graph_node_set & embedding_node_set)}")
# --------------------------
# 3. ID â†’ ì„ë² ë”© ë§¤í•‘
# --------------------------
id2embedding = dict(zip(df["paperId"], df["parsed_embedding"]))

# ê·¸ë˜í”„ì— ì¡´ì¬í•˜ë©´ì„œ ì„ë² ë”©ë„ ìˆëŠ” ë…¸ë“œë§Œ ëŒ€ìƒìœ¼ë¡œ
valid_node_set = set(G.nodes()).intersection(id2embedding.keys())
valid_nodes = list(valid_node_set)

# --------------------------
# 4. ì‹¤ì œ ê·¸ë˜í”„ ì—£ì§€ ìœ ì‚¬ë„ ê³„ì‚°
# --------------------------
similarities = []

for a, b in tqdm(G.edges(), desc="ğŸ“ˆ ê·¸ë˜í”„ ìœ ì‚¬ë„ ê³„ì‚° ì¤‘"):
    if a in id2embedding and b in id2embedding:
        vec_a = id2embedding[a].reshape(1, -1)
        vec_b = id2embedding[b].reshape(1, -1)
        sim = cosine_similarity(vec_a, vec_b)[0][0]
        similarities.append(sim)

print(f"âœ… ê³„ì‚°ëœ ê·¸ë˜í”„ ì—£ì§€ ìˆ˜: {len(similarities)}")

# --------------------------
# 5. ëœë¤ ì—£ì§€ ìœ ì‚¬ë„ ê³„ì‚°
# --------------------------
random_similarities = []
sample_size = len(similarities)

random_edges = random.sample([(a, b) for a in valid_nodes for b in valid_nodes if a != b], sample_size)

for a, b in tqdm(random_edges, desc="ğŸ² ëœë¤ ìœ ì‚¬ë„ ê³„ì‚° ì¤‘"):
    vec_a = id2embedding[a].reshape(1, -1)
    vec_b = id2embedding[b].reshape(1, -1)
    sim = cosine_similarity(vec_a, vec_b)[0][0]
    random_similarities.append(sim)

# --------------------------
# 6. ê²°ê³¼ ì¶œë ¥
# --------------------------
if similarities and random_similarities:
    mean_graph = np.mean(similarities)
    mean_random = np.mean(random_similarities)
    print(f"\nğŸ“Š ê·¸ë˜í”„ ì—£ì§€ í‰ê·  ìœ ì‚¬ë„: {mean_graph:.4f}")
    print(f"ğŸ² ëœë¤ ì—£ì§€ í‰ê·  ìœ ì‚¬ë„: {mean_random:.4f}")
    print(f"ğŸ” ì°¨ì´: {mean_graph - mean_random:.4f}")
else:
    print("âš ï¸ ìœ ì‚¬ë„ ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆì–´ ê²°ê³¼ë¥¼ ì¶œë ¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
