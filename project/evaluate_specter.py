from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import networkx as nx
import pandas as pd
import pickle
import numpy as np
import random
from tqdm import tqdm

# 1. ë…¼ë¬¸ ë©”íƒ€ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv("nlp_papers.csv").fillna("")
paper_texts = {row["id"]: row["title"] for _, row in df.iterrows()}

# 2. ê·¸ë˜í”„ ë¡œë“œ
with open("nlp_similarity_graph_with_cluster.gpickle", "rb") as f:
    G = pickle.load(f)

# 3. âœ… all-mpnet-base-v2 ëª¨ë¸ ë¡œë“œ ë° ì„ë² ë”© ìƒì„±
model = SentenceTransformer("sentence-transformers/all-mpnet-base-v2")
nodes = list(G.nodes())
texts = [paper_texts[n] for n in nodes if n in paper_texts]
print(f"ğŸ”¢ ì´ ì„ë² ë”©í•  ë…¼ë¬¸ ìˆ˜: {len(texts)}")

embeddings = model.encode(texts, batch_size=16, show_progress_bar=True)

# 4. ë§¤í•‘
id2embedding = {
    n: e for n, e in zip(nodes, embeddings)
}

# 5. ì‹¤ì œ ê·¸ë˜í”„ ì—£ì§€ì˜ ìœ ì‚¬ë„ ê³„ì‚°
similarities = []
for a, b in tqdm(G.edges(), desc="ğŸ“ˆ ê·¸ë˜í”„ ìœ ì‚¬ë„ ê³„ì‚° ì¤‘"):
    if a in id2embedding and b in id2embedding:
        sim = cosine_similarity([id2embedding[a]], [id2embedding[b]])[0][0]
        similarities.append(sim)

# 6. ëœë¤ ì—£ì§€ ìœ ì‚¬ë„ (baseline ë¹„êµìš©)
random_similarities = []
random_edges = random.sample([(a, b) for a in nodes for b in nodes if a != b], len(similarities))
for a, b in tqdm(random_edges, desc="ğŸ² ëœë¤ ìœ ì‚¬ë„ ê³„ì‚° ì¤‘"):
    if a in id2embedding and b in id2embedding:
        sim = cosine_similarity([id2embedding[a]], [id2embedding[b]])[0][0]
        random_similarities.append(sim)

# 7. ê²°ê³¼ ì¶œë ¥
print(f"ğŸ“Š ê·¸ë˜í”„ ì—£ì§€ í‰ê·  ìœ ì‚¬ë„: {np.mean(similarities):.4f}")
print(f"ğŸ² ëœë¤ ì—£ì§€ í‰ê·  ìœ ì‚¬ë„: {np.mean(random_similarities):.4f}")
