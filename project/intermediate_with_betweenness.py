import networkx as nx
import pandas as pd
import pickle
from collections import defaultdict

# -------------------------------
# 1. ê·¸ë˜í”„ ë° í´ëŸ¬ìŠ¤í„° ë¡œë”©
# -------------------------------
with open("nlp_similarity_graph_with_cluster.gpickle", "rb") as f:
    G = pickle.load(f)

df_cluster = pd.read_csv("paper_clusters.csv")
cluster_map = dict(zip(df_cluster["paper_id"], df_cluster["community_id"]))

# -------------------------------
# 2. inter-cluster betweenness ê³„ì‚°
# -------------------------------
inter_cluster_betweenness = defaultdict(float)
nodes = list(G.nodes)

for i, source in enumerate(nodes):
    source_cluster = cluster_map.get(source)
    if source_cluster is None:
        continue

    # ìµœë‹¨ ê²½ë¡œ êµ¬í•˜ê¸°
    try:
        lengths, paths = nx.single_source_shortest_path_length(G, source), nx.single_source_shortest_path(G, source)
    except nx.NetworkXError:
        continue

    for target, path in paths.items():
        if source == target:
            continue
        target_cluster = cluster_map.get(target)
        if target_cluster is None or target_cluster == source_cluster:
            continue  # ë‚´ë¶€ ê²½ë¡œëŠ” ë¬´ì‹œ

        # ì¤‘ê°„ ë…¸ë“œë“¤ì— ì ìˆ˜ ë¶„ë°°
        intermediates = path[1:-1]  # sourceì™€ targetì€ ì œì™¸
        for v in intermediates:
            inter_cluster_betweenness[v] += 1

    if i % 500 == 0:
        print(f"ğŸ”„ ì§„í–‰ ì¤‘: {i}/{len(nodes)}")

# -------------------------------
# 3. ê²°ê³¼ ì •ë ¬ ë° ì €ì¥
# -------------------------------
result_df = pd.DataFrame([
    (node, inter_cluster_betweenness[node])
    for node in inter_cluster_betweenness
], columns=["node", "inter_cluster_betweenness"])

result_df = result_df.sort_values(by="inter_cluster_betweenness", ascending=False)
result_df.to_csv("inter_cluster_betweenness.csv", index=False)

print("âœ… inter_cluster_betweenness.csv ì €ì¥ ì™„ë£Œ!")
